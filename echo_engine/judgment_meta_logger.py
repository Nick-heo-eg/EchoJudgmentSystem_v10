#!/usr/bin/env python3
"""
ğŸ§  Judgment Meta Logger - EchoJudgmentSystem v10 ê³ ë„í™” ë©”íƒ€ ë¡œê¹… ì‹œìŠ¤í…œ

íŒë‹¨ ê³¼ì •ì˜ ëª¨ë“  ë©”íƒ€ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ë¶„ì„, ì €ì¥í•˜ëŠ” ê³ ë„í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
ì„±ëŠ¥, íŒ¨í„´, í•™ìŠµ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê´€ë¦¬
"""

import json
import os
import time
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import threading
from collections import defaultdict


@dataclass
class JudgmentMetaData:
    """íŒë‹¨ ë©”íƒ€ë°ì´í„° êµ¬ì¡°"""

    # ê¸°ë³¸ ì •ë³´
    judgment_id: str
    timestamp: datetime
    input_text: str
    input_hash: str
    session_id: str

    # íŒë‹¨ ê²°ê³¼
    echo_judgment: Optional[str] = None
    claude_judgment: Optional[str] = None
    final_judgment: str = ""
    confidence_score: float = 0.0

    # ê°ì • ë° ì „ëµ
    detected_emotion: Optional[str] = None
    emotion_confidence: float = 0.0
    suggested_strategy: Optional[str] = None
    strategy_confidence: float = 0.0

    # ì„±ëŠ¥ ì§€í‘œ
    processing_time: float = 0.0
    echo_response_time: float = 0.0
    claude_response_time: float = 0.0
    total_tokens_used: int = 0

    # ì»¨í…ìŠ¤íŠ¸
    user_context: Optional[str] = None
    system_context: Dict[str, Any] = None
    previous_judgments: List[str] = None

    # í’ˆì§ˆ ì§€í‘œ
    consistency_score: float = 0.0  # Echo vs Claude ì¼ì¹˜ë„
    complexity_score: float = 0.0  # ì…ë ¥ ë³µì¡ë„
    novelty_score: float = 0.0  # ìƒˆë¡œìš´ íŒ¨í„´ ì •ë„

    # í•™ìŠµ ë°ì´í„°
    feedback_received: Optional[str] = None
    user_rating: Optional[int] = None
    correction_applied: bool = False

    def __post_init__(self):
        if isinstance(self.timestamp, str):
            self.timestamp = datetime.fromisoformat(self.timestamp)
        if self.system_context is None:
            self.system_context = {}
        if self.previous_judgments is None:
            self.previous_judgments = []


class JudgmentMetaLogger:
    """íŒë‹¨ ë©”íƒ€ ë¡œê±° í´ë˜ìŠ¤"""

    def __init__(self, log_directory: str = "meta_logs"):
        self.log_directory = log_directory
        self.session_id = f"meta_session_{int(time.time())}"
        self.current_session_data = []
        self.performance_aggregates = defaultdict(list)
        self.pattern_cache = {}
        self.lock = threading.Lock()

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.log_directory, exist_ok=True)

        # ì„¸ì…˜ ì‹œì‘ ë¡œê·¸
        self._log_session_start()

    def _log_session_start(self):
        """ì„¸ì…˜ ì‹œì‘ ë¡œê·¸"""
        session_info = {
            "session_id": self.session_id,
            "start_time": datetime.now().isoformat(),
            "system_info": {
                "python_version": "3.11+",
                "echo_engine_version": "v10",
                "logging_features": [
                    "meta_logging",
                    "performance_tracking",
                    "pattern_analysis",
                    "learning_data_collection",
                ],
            },
        }

        session_file = os.path.join(
            self.log_directory, f"session_{self.session_id}.json"
        )
        with open(session_file, "w", encoding="utf-8") as f:
            json.dump(session_info, f, ensure_ascii=False, indent=2)

    def generate_judgment_id(self, input_text: str, timestamp: datetime) -> str:
        """íŒë‹¨ ID ìƒì„±"""
        combined = f"{input_text}_{timestamp.isoformat()}_{self.session_id}"
        return hashlib.md5(combined.encode()).hexdigest()[:12]

    def calculate_input_hash(self, input_text: str) -> str:
        """ì…ë ¥ í…ìŠ¤íŠ¸ í•´ì‹œ ê³„ì‚°"""
        return hashlib.sha256(input_text.encode()).hexdigest()[:16]

    def analyze_text_complexity(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ ë¶„ì„"""
        # ê°„ë‹¨í•œ ë³µì¡ë„ ì§€í‘œ
        factors = {
            "length": len(text) / 100,  # ê¸¸ì´
            "sentences": text.count(".") + text.count("!") + text.count("?"),
            "words": len(text.split()),
            "unique_words": len(set(text.lower().split())),
            "punctuation": sum(1 for c in text if c in ".,!?;:"),
        }

        # ì •ê·œí™” ë° ê°€ì¤‘ í‰ê· 
        normalized_length = min(factors["length"], 5) / 5
        sentence_complexity = min(factors["sentences"], 10) / 10
        word_diversity = factors["unique_words"] / max(factors["words"], 1)

        complexity = (
            normalized_length * 0.3 + sentence_complexity * 0.3 + word_diversity * 0.4
        )

        return min(complexity, 1.0)

    def calculate_consistency_score(
        self, echo_judgment: str, claude_judgment: str
    ) -> float:
        """Echoì™€ Claude íŒë‹¨ ì¼ì¹˜ë„ ê³„ì‚°"""
        if not echo_judgment or not claude_judgment:
            return 0.0

        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš©)
        echo_words = set(echo_judgment.lower().split())
        claude_words = set(claude_judgment.lower().split())

        if not echo_words or not claude_words:
            return 0.0

        intersection = len(echo_words & claude_words)
        union = len(echo_words | claude_words)

        return intersection / union if union > 0 else 0.0

    def calculate_novelty_score(self, input_text: str) -> float:
        """ìƒˆë¡œìš´ íŒ¨í„´ ì •ë„ ê³„ì‚°"""
        input_hash = self.calculate_input_hash(input_text)

        # ìºì‹œì—ì„œ ìœ ì‚¬í•œ íŒ¨í„´ ê²€ìƒ‰
        similar_patterns = 0
        for cached_hash, cached_data in self.pattern_cache.items():
            # í•´ì‹œì˜ ìœ ì‚¬ë„ ì²´í¬ (ê°„ë‹¨í•œ ë°©ë²•)
            if sum(a == b for a, b in zip(input_hash, cached_hash)) > 8:
                similar_patterns += 1

        # ìƒˆë¡œìš´ íŒ¨í„´ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        novelty = 1.0 - (similar_patterns / max(len(self.pattern_cache), 1))

        # íŒ¨í„´ ìºì‹œ ì—…ë°ì´íŠ¸
        self.pattern_cache[input_hash] = {
            "first_seen": datetime.now().isoformat(),
            "frequency": self.pattern_cache.get(input_hash, {}).get("frequency", 0) + 1,
        }

        return novelty

    def create_meta_data(
        self,
        input_text: str,
        echo_judgment: Optional[str] = None,
        claude_judgment: Optional[str] = None,
        final_judgment: str = "",
        confidence_score: float = 0.0,
        detected_emotion: Optional[str] = None,
        emotion_confidence: float = 0.0,
        suggested_strategy: Optional[str] = None,
        strategy_confidence: float = 0.0,
        processing_time: float = 0.0,
        echo_response_time: float = 0.0,
        claude_response_time: float = 0.0,
        user_context: Optional[str] = None,
        previous_judgments: List[str] = None,
    ) -> JudgmentMetaData:
        """ë©”íƒ€ë°ì´í„° ìƒì„±"""

        timestamp = datetime.now()
        judgment_id = self.generate_judgment_id(input_text, timestamp)
        input_hash = self.calculate_input_hash(input_text)

        # ë¶„ì„ ì§€í‘œ ê³„ì‚°
        complexity_score = self.analyze_text_complexity(input_text)
        consistency_score = self.calculate_consistency_score(
            echo_judgment or "", claude_judgment or ""
        )
        novelty_score = self.calculate_novelty_score(input_text)

        return JudgmentMetaData(
            judgment_id=judgment_id,
            timestamp=timestamp,
            input_text=input_text,
            input_hash=input_hash,
            session_id=self.session_id,
            echo_judgment=echo_judgment,
            claude_judgment=claude_judgment,
            final_judgment=final_judgment,
            confidence_score=confidence_score,
            detected_emotion=detected_emotion,
            emotion_confidence=emotion_confidence,
            suggested_strategy=suggested_strategy,
            strategy_confidence=strategy_confidence,
            processing_time=processing_time,
            echo_response_time=echo_response_time,
            claude_response_time=claude_response_time,
            user_context=user_context,
            system_context={
                "session_id": self.session_id,
                "timestamp": timestamp.isoformat(),
                "system_version": "v10",
            },
            previous_judgments=previous_judgments or [],
            consistency_score=consistency_score,
            complexity_score=complexity_score,
            novelty_score=novelty_score,
        )

    def log_judgment(self, meta_data: JudgmentMetaData):
        """íŒë‹¨ ë©”íƒ€ë°ì´í„° ë¡œê·¸"""
        with self.lock:
            try:
                # ì„¸ì…˜ ë°ì´í„°ì— ì¶”ê°€
                self.current_session_data.append(meta_data)

                # ì„±ëŠ¥ ì§‘ê³„ ì—…ë°ì´íŠ¸
                self.performance_aggregates["processing_times"].append(
                    meta_data.processing_time
                )
                self.performance_aggregates["confidence_scores"].append(
                    meta_data.confidence_score
                )
                self.performance_aggregates["consistency_scores"].append(
                    meta_data.consistency_score
                )
                self.performance_aggregates["complexity_scores"].append(
                    meta_data.complexity_score
                )
                self.performance_aggregates["novelty_scores"].append(
                    meta_data.novelty_score
                )

                # ê°œë³„ íŒë‹¨ íŒŒì¼ ì €ì¥
                judgment_file = os.path.join(
                    self.log_directory, f"judgment_{meta_data.judgment_id}.json"
                )

                with open(judgment_file, "w", encoding="utf-8") as f:
                    json.dump(
                        asdict(meta_data), f, ensure_ascii=False, indent=2, default=str
                    )

                # ì„¸ì…˜ ì§‘ê³„ ì—…ë°ì´íŠ¸
                self._update_session_aggregates()

                print(f"âœ… ë©”íƒ€ ë¡œê·¸ ì €ì¥: {meta_data.judgment_id}")

            except Exception as e:
                print(f"âŒ ë©”íƒ€ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _update_session_aggregates(self):
        """ì„¸ì…˜ ì§‘ê³„ ì—…ë°ì´íŠ¸"""
        if not self.current_session_data:
            return

        # ì§‘ê³„ ê³„ì‚°
        processing_times = [d.processing_time for d in self.current_session_data]
        confidence_scores = [d.confidence_score for d in self.current_session_data]
        consistency_scores = [d.consistency_score for d in self.current_session_data]

        aggregates = {
            "session_id": self.session_id,
            "last_updated": datetime.now().isoformat(),
            "total_judgments": len(self.current_session_data),
            "average_processing_time": sum(processing_times) / len(processing_times),
            "average_confidence": sum(confidence_scores) / len(confidence_scores),
            "average_consistency": sum(consistency_scores) / len(consistency_scores),
            "emotion_distribution": self._calculate_distribution("detected_emotion"),
            "strategy_distribution": self._calculate_distribution("suggested_strategy"),
            "complexity_stats": {
                "min": min(d.complexity_score for d in self.current_session_data),
                "max": max(d.complexity_score for d in self.current_session_data),
                "avg": sum(d.complexity_score for d in self.current_session_data)
                / len(self.current_session_data),
            },
        }

        # ì§‘ê³„ íŒŒì¼ ì €ì¥
        aggregates_file = os.path.join(
            self.log_directory, f"session_aggregates_{self.session_id}.json"
        )
        with open(aggregates_file, "w", encoding="utf-8") as f:
            json.dump(aggregates, f, ensure_ascii=False, indent=2)

    def _calculate_distribution(self, field: str) -> Dict[str, int]:
        """í•„ë“œë³„ ë¶„í¬ ê³„ì‚°"""
        distribution = defaultdict(int)
        for data in self.current_session_data:
            value = getattr(data, field, None)
            if value:
                distribution[value] += 1
        return dict(distribution)

    def get_session_summary(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        if not self.current_session_data:
            return {"message": "ì„¸ì…˜ ë°ì´í„° ì—†ìŒ"}

        latest_data = self.current_session_data[-1]

        return {
            "session_id": self.session_id,
            "total_judgments": len(self.current_session_data),
            "session_duration": str(
                datetime.now() - self.current_session_data[0].timestamp
            ),
            "latest_judgment": {
                "id": latest_data.judgment_id,
                "text": latest_data.input_text[:50] + "...",
                "judgment": latest_data.final_judgment,
                "confidence": latest_data.confidence_score,
                "emotion": latest_data.detected_emotion,
                "strategy": latest_data.suggested_strategy,
            },
            "performance_summary": {
                "avg_processing_time": sum(
                    d.processing_time for d in self.current_session_data
                )
                / len(self.current_session_data),
                "avg_confidence": sum(
                    d.confidence_score for d in self.current_session_data
                )
                / len(self.current_session_data),
                "avg_consistency": sum(
                    d.consistency_score for d in self.current_session_data
                )
                / len(self.current_session_data),
                "avg_complexity": sum(
                    d.complexity_score for d in self.current_session_data
                )
                / len(self.current_session_data),
                "avg_novelty": sum(d.novelty_score for d in self.current_session_data)
                / len(self.current_session_data),
            },
        }

    def analyze_patterns(self, lookback_days: int = 7) -> Dict[str, Any]:
        """íŒ¨í„´ ë¶„ì„"""
        # ì§€ë‚œ Nì¼ê°„ì˜ ë¡œê·¸ íŒŒì¼ ìˆ˜ì§‘
        cutoff_date = datetime.now() - timedelta(days=lookback_days)

        pattern_analysis = {
            "time_range": f"{lookback_days}ì¼",
            "emotion_patterns": {},
            "strategy_patterns": {},
            "performance_trends": {},
            "complexity_trends": {},
            "novelty_insights": {},
        }

        # íŒ¨í„´ ë¶„ì„ ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¶„ì„)
        emotion_counts = defaultdict(int)
        strategy_counts = defaultdict(int)

        for data in self.current_session_data:
            if data.timestamp >= cutoff_date:
                if data.detected_emotion:
                    emotion_counts[data.detected_emotion] += 1
                if data.suggested_strategy:
                    strategy_counts[data.suggested_strategy] += 1

        pattern_analysis["emotion_patterns"] = dict(emotion_counts)
        pattern_analysis["strategy_patterns"] = dict(strategy_counts)

        return pattern_analysis

    def export_learning_data(self, output_file: str = None) -> str:
        """í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        if output_file is None:
            output_file = f"learning_data_{self.session_id}.json"

        learning_data = {
            "export_timestamp": datetime.now().isoformat(),
            "session_id": self.session_id,
            "total_samples": len(self.current_session_data),
            "data": [asdict(data) for data in self.current_session_data],
        }

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(learning_data, f, ensure_ascii=False, indent=2, default=str)

        print(f"âœ… í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°: {output_file}")
        return output_file


# ì „ì—­ ë©”íƒ€ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
_global_meta_logger = None


def get_meta_logger() -> JudgmentMetaLogger:
    """ì „ì—­ ë©”íƒ€ ë¡œê±° ë°˜í™˜"""
    global _global_meta_logger
    if _global_meta_logger is None:
        _global_meta_logger = JudgmentMetaLogger()
    return _global_meta_logger


def log_judgment_meta(input_text: str, **kwargs):
    """í¸ì˜ í•¨ìˆ˜: íŒë‹¨ ë©”íƒ€ë°ì´í„° ë¡œê·¸"""
    logger = get_meta_logger()
    meta_data = logger.create_meta_data(input_text, **kwargs)
    logger.log_judgment(meta_data)
    return meta_data


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_meta_logger():
    """ë©”íƒ€ ë¡œê±° í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  íŒë‹¨ ë©”íƒ€ ë¡œê±° í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    logger = JudgmentMetaLogger()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_cases = [
        {
            "input_text": "ì˜¤ëŠ˜ ì •ë§ ì¢‹ì€ ë‚ ì´ì—ìš”!",
            "echo_judgment": "ê¸ì •ì ì¸ í•˜ë£¨",
            "claude_judgment": "ê¸°ìœ ê°ì • í‘œí˜„",
            "final_judgment": "positive_day",
            "confidence_score": 0.95,
            "detected_emotion": "joy",
            "emotion_confidence": 0.9,
            "suggested_strategy": "empathetic",
            "strategy_confidence": 0.85,
            "processing_time": 0.234,
        },
        {
            "input_text": "ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•´ìš”.",
            "echo_judgment": "ë¬¸ì œ í•´ê²° í•„ìš”",
            "claude_judgment": "ë…¼ë¦¬ì  ì ‘ê·¼ ê¶Œì¥",
            "final_judgment": "problem_solving",
            "confidence_score": 0.78,
            "detected_emotion": "neutral",
            "emotion_confidence": 0.7,
            "suggested_strategy": "logical",
            "strategy_confidence": 0.88,
            "processing_time": 0.456,
        },
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}: {test_case['input_text']}")

        meta_data = logger.create_meta_data(**test_case)
        logger.log_judgment(meta_data)

        print(f"  ğŸ“Š ë³µì¡ë„: {meta_data.complexity_score:.2f}")
        print(f"  ğŸ”„ ì¼ì¹˜ë„: {meta_data.consistency_score:.2f}")
        print(f"  âœ¨ ìƒˆë¡œì›€: {meta_data.novelty_score:.2f}")

    # ì„¸ì…˜ ìš”ì•½
    print("\nğŸ“‹ ì„¸ì…˜ ìš”ì•½:")
    summary = logger.get_session_summary()
    print(f"  ì´ íŒë‹¨ ìˆ˜: {summary['total_judgments']}")
    print(
        f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['performance_summary']['avg_processing_time']:.3f}ì´ˆ"
    )
    print(f"  í‰ê·  ì‹ ë¢°ë„: {summary['performance_summary']['avg_confidence']:.2f}")
    print(f"  í‰ê·  ì¼ì¹˜ë„: {summary['performance_summary']['avg_consistency']:.2f}")

    # í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
    export_file = logger.export_learning_data()
    print(f"\nğŸ’¾ í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°: {export_file}")

    print("\nğŸ‰ ë©”íƒ€ ë¡œê±° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    test_meta_logger()
