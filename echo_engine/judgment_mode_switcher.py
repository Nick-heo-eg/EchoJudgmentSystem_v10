#!/usr/bin/env python3
"""
ğŸ›ï¸ EchoJudgmentSystem v10.5 - Judgment Mode Switcher
ì§€ëŠ¥í˜• íŒë‹¨ ëª¨ë“œ ì „í™˜ ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- ë™ì  ëª¨ë“œ ì „í™˜ (llm_free/claude/hybrid)
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë“œ ì„ íƒ
- ì„±ëŠ¥ ê¸°ë°˜ ìë™ ì „í™˜
- ì‹¤ì‹œê°„ ëª¨ë“œ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
"""

import time
import json
import os
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from .shared_judgment_logic import JudgmentMode, SharedJudgmentResult
except ImportError:
    from shared_judgment_logic import JudgmentMode, SharedJudgmentResult


class SwitchingTrigger(Enum):
    """ëª¨ë“œ ì „í™˜ íŠ¸ë¦¬ê±°"""

    MANUAL = "manual"  # ìˆ˜ë™ ì „í™˜
    CONFIDENCE_BASED = "confidence"  # ì‹ ë¢°ë„ ê¸°ë°˜
    PERFORMANCE_BASED = "performance"  # ì„±ëŠ¥ ê¸°ë°˜
    CONTEXT_BASED = "context"  # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜
    ERROR_RECOVERY = "error_recovery"  # ì˜¤ë¥˜ ë³µêµ¬
    LOAD_BALANCING = "load_balancing"  # ë¶€í•˜ ë¶„ì‚°
    COST_OPTIMIZATION = "cost_optimization"  # ë¹„ìš© ìµœì í™”


class SwitchingStrategy(Enum):
    """ì „í™˜ ì „ëµ"""

    CONSERVATIVE = "conservative"  # ë³´ìˆ˜ì  (ì•ˆì •ì„± ìš°ì„ )
    AGGRESSIVE = "aggressive"  # ì ê·¹ì  (ì„±ëŠ¥ ìš°ì„ )
    BALANCED = "balanced"  # ê· í˜• (ì•ˆì •ì„± + ì„±ëŠ¥)
    ADAPTIVE = "adaptive"  # ì ì‘ì  (í•™ìŠµ ê¸°ë°˜)


@dataclass
class ModePerformanceMetrics:
    """ëª¨ë“œë³„ ì„±ëŠ¥ ì§€í‘œ"""

    mode: JudgmentMode
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    average_response_time: float = 0.0
    average_confidence: float = 0.0
    error_rate: float = 0.0
    last_success_time: Optional[datetime] = None
    last_failure_time: Optional[datetime] = None
    recent_response_times: deque = field(default_factory=lambda: deque(maxlen=10))
    recent_confidences: deque = field(default_factory=lambda: deque(maxlen=10))


@dataclass
class SwitchingRule:
    """ì „í™˜ ê·œì¹™"""

    trigger: SwitchingTrigger
    condition: Dict[str, Any]
    target_mode: JudgmentMode
    priority: int = 5  # 1=highest, 10=lowest
    enabled: bool = True
    description: str = ""


@dataclass
class SwitchingDecision:
    """ì „í™˜ ê²°ì •"""

    from_mode: JudgmentMode
    to_mode: JudgmentMode
    trigger: SwitchingTrigger
    reason: str
    confidence: float
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)


class JudgmentModeSwitcher:
    """ì§€ëŠ¥í˜• íŒë‹¨ ëª¨ë“œ ì „í™˜ê¸°"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        ëª¨ë“œ ì „í™˜ê¸° ì´ˆê¸°í™”

        Args:
            config: ì „í™˜ê¸° ì„¤ì •
        """
        self.config = config or self._load_default_config()

        # í˜„ì¬ ëª¨ë“œ
        self.current_mode = JudgmentMode(self.config.get("default_mode", "hybrid"))

        # ì„±ëŠ¥ ì§€í‘œ ì¶”ì 
        self.performance_metrics = {
            mode: ModePerformanceMetrics(mode) for mode in JudgmentMode
        }

        # ì „í™˜ ê·œì¹™
        self.switching_rules = self._initialize_switching_rules()

        # ì „í™˜ íˆìŠ¤í† ë¦¬
        self.switching_history = deque(maxlen=100)

        # ì „í™˜ ì „ëµ
        self.switching_strategy = SwitchingStrategy(
            self.config.get("switching_strategy", "balanced")
        )

        # í†µê³„
        self.stats = {
            "total_switches": 0,
            "manual_switches": 0,
            "auto_switches": 0,
            "switch_success_rate": 1.0,
            "modes_usage": defaultdict(int),
            "triggers_used": defaultdict(int),
        }

        # ëª¨ë‹ˆí„°ë§
        self.monitoring_enabled = self.config.get("enable_monitoring", True)
        self.last_optimization = datetime.now()

        print(f"ğŸ›ï¸ íŒë‹¨ ëª¨ë“œ ì „í™˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ê¸°ë³¸ ëª¨ë“œ: {self.current_mode.value})")

    def _load_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ë¡œë“œ"""
        return {
            "default_mode": "hybrid",
            "switching_strategy": "balanced",
            "enable_monitoring": True,
            "confidence_thresholds": {"low": 0.3, "medium": 0.6, "high": 0.8},
            "performance_thresholds": {
                "max_error_rate": 0.15,
                "min_success_rate": 0.8,
                "max_response_time": 5.0,
            },
            "switching_cooldown": 30,  # seconds
            "optimization_interval": 300,  # seconds
            "enable_cost_optimization": False,
            "enable_load_balancing": True,
        }

    def _initialize_switching_rules(self) -> List[SwitchingRule]:
        """ì „í™˜ ê·œì¹™ ì´ˆê¸°í™”"""
        rules = []

        # 1. ì‹ ë¢°ë„ ê¸°ë°˜ ì „í™˜ ê·œì¹™
        rules.append(
            SwitchingRule(
                trigger=SwitchingTrigger.CONFIDENCE_BASED,
                condition={"min_confidence": 0.8},
                target_mode=JudgmentMode.LLM_FREE,
                priority=1,
                description="ë†’ì€ ì‹ ë¢°ë„ ì‹œ LLM-Free ì‚¬ìš©",
            )
        )

        rules.append(
            SwitchingRule(
                trigger=SwitchingTrigger.CONFIDENCE_BASED,
                condition={"max_confidence": 0.3},
                target_mode=JudgmentMode.CLAUDE,
                priority=2,
                description="ë‚®ì€ ì‹ ë¢°ë„ ì‹œ Claude ì‚¬ìš©",
            )
        )

        # 2. ì„±ëŠ¥ ê¸°ë°˜ ì „í™˜ ê·œì¹™
        rules.append(
            SwitchingRule(
                trigger=SwitchingTrigger.PERFORMANCE_BASED,
                condition={"max_error_rate": 0.15},
                target_mode=JudgmentMode.HYBRID,
                priority=3,
                description="ì˜¤ë¥˜ìœ¨ ë†’ì„ ì‹œ í•˜ì´ë¸Œë¦¬ë“œ ì‚¬ìš©",
            )
        )

        # 3. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì „í™˜ ê·œì¹™
        rules.append(
            SwitchingRule(
                trigger=SwitchingTrigger.CONTEXT_BASED,
                condition={"context_types": ["complex", "creative"]},
                target_mode=JudgmentMode.CLAUDE,
                priority=4,
                description="ë³µì¡í•œ ì»¨í…ìŠ¤íŠ¸ ì‹œ Claude ì‚¬ìš©",
            )
        )

        rules.append(
            SwitchingRule(
                trigger=SwitchingTrigger.CONTEXT_BASED,
                condition={"context_types": ["simple", "routine"]},
                target_mode=JudgmentMode.LLM_FREE,
                priority=4,
                description="ë‹¨ìˆœí•œ ì»¨í…ìŠ¤íŠ¸ ì‹œ LLM-Free ì‚¬ìš©",
            )
        )

        # 4. ì˜¤ë¥˜ ë³µêµ¬ ê·œì¹™
        rules.append(
            SwitchingRule(
                trigger=SwitchingTrigger.ERROR_RECOVERY,
                condition={"consecutive_failures": 3},
                target_mode=JudgmentMode.HYBRID,
                priority=1,
                description="ì—°ì† ì‹¤íŒ¨ ì‹œ í•˜ì´ë¸Œë¦¬ë“œë¡œ ë³µêµ¬",
            )
        )

        return rules

    def get_current_mode(self) -> JudgmentMode:
        """í˜„ì¬ ëª¨ë“œ ë°˜í™˜"""
        return self.current_mode

    def switch_mode(
        self,
        target_mode: JudgmentMode,
        trigger: SwitchingTrigger = SwitchingTrigger.MANUAL,
        reason: str = "Manual switch",
        metadata: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        ëª¨ë“œ ì „í™˜ ì‹¤í–‰

        Args:
            target_mode: ëŒ€ìƒ ëª¨ë“œ
            trigger: ì „í™˜ íŠ¸ë¦¬ê±°
            reason: ì „í™˜ ì´ìœ 
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            ì „í™˜ ì„±ê³µ ì—¬ë¶€
        """
        if target_mode == self.current_mode:
            return True  # ì´ë¯¸ í•´ë‹¹ ëª¨ë“œ

        # ì¿¨ë‹¤ìš´ ì²´í¬
        if not self._check_switching_cooldown():
            return False

        # ì „í™˜ ì‹¤í–‰
        previous_mode = self.current_mode

        try:
            # ì „í™˜ ê²°ì • ê¸°ë¡
            decision = SwitchingDecision(
                from_mode=previous_mode,
                to_mode=target_mode,
                trigger=trigger,
                reason=reason,
                confidence=1.0,  # ìˆ˜ë™ ì „í™˜ì€ 100% ì‹ ë¢°ë„
                metadata=metadata or {},
            )

            # ëª¨ë“œ ë³€ê²½
            self.current_mode = target_mode

            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            self.switching_history.append(decision)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["total_switches"] += 1
            if trigger == SwitchingTrigger.MANUAL:
                self.stats["manual_switches"] += 1
            else:
                self.stats["auto_switches"] += 1

            self.stats["modes_usage"][target_mode.value] += 1
            self.stats["triggers_used"][trigger.value] += 1

            print(
                f"ğŸ›ï¸ ëª¨ë“œ ì „í™˜: {previous_mode.value} â†’ {target_mode.value} ({reason})"
            )

            return True

        except Exception as e:
            print(f"âŒ ëª¨ë“œ ì „í™˜ ì‹¤íŒ¨: {e}")
            return False

    def auto_switch_mode(self, context: Dict[str, Any]) -> Optional[SwitchingDecision]:
        """
        ìë™ ëª¨ë“œ ì „í™˜ í‰ê°€ ë° ì‹¤í–‰

        Args:
            context: íŒë‹¨ ì»¨í…ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸, ì‹ ë¢°ë„, ì„±ëŠ¥ ë“±)

        Returns:
            ì „í™˜ ê²°ì • (ì „í™˜ëœ ê²½ìš°) ë˜ëŠ” None
        """
        # ì „í™˜ ê·œì¹™ í‰ê°€
        best_rule = self._evaluate_switching_rules(context)

        if not best_rule:
            return None

        # ì „í™˜ ì‹¤í–‰
        success = self.switch_mode(
            target_mode=best_rule.target_mode,
            trigger=best_rule.trigger,
            reason=best_rule.description,
            metadata={"rule_priority": best_rule.priority, "context": context},
        )

        if success:
            return self.switching_history[-1]

        return None

    def _evaluate_switching_rules(
        self, context: Dict[str, Any]
    ) -> Optional[SwitchingRule]:
        """ì „í™˜ ê·œì¹™ í‰ê°€"""
        applicable_rules = []

        for rule in self.switching_rules:
            if not rule.enabled:
                continue

            if self._check_rule_condition(rule, context):
                applicable_rules.append(rule)

        if not applicable_rules:
            return None

        # ìš°ì„ ìˆœìœ„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚®ì€ ìˆ«ìê°€ ë†’ì€ ìš°ì„ ìˆœìœ„)
        applicable_rules.sort(key=lambda r: r.priority)

        return applicable_rules[0]

    def _check_rule_condition(
        self, rule: SwitchingRule, context: Dict[str, Any]
    ) -> bool:
        """ê·œì¹™ ì¡°ê±´ í™•ì¸"""
        try:
            if rule.trigger == SwitchingTrigger.CONFIDENCE_BASED:
                confidence = context.get("confidence", 0.5)
                if "min_confidence" in rule.condition:
                    return confidence >= rule.condition["min_confidence"]
                if "max_confidence" in rule.condition:
                    return confidence <= rule.condition["max_confidence"]

            elif rule.trigger == SwitchingTrigger.PERFORMANCE_BASED:
                current_metrics = self.performance_metrics[self.current_mode]
                if "max_error_rate" in rule.condition:
                    return (
                        current_metrics.error_rate >= rule.condition["max_error_rate"]
                    )
                if "min_success_rate" in rule.condition:
                    success_rate = current_metrics.successful_requests / max(
                        current_metrics.total_requests, 1
                    )
                    return success_rate <= rule.condition["min_success_rate"]
                if "max_response_time" in rule.condition:
                    return (
                        current_metrics.average_response_time
                        >= rule.condition["max_response_time"]
                    )

            elif rule.trigger == SwitchingTrigger.CONTEXT_BASED:
                context_type = context.get("context_type", "general")
                if "context_types" in rule.condition:
                    return context_type in rule.condition["context_types"]

            elif rule.trigger == SwitchingTrigger.ERROR_RECOVERY:
                if "consecutive_failures" in rule.condition:
                    recent_failures = self._count_recent_failures()
                    return recent_failures >= rule.condition["consecutive_failures"]

            return False

        except Exception as e:
            print(f"âš ï¸ ê·œì¹™ ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def record_judgment_result(self, mode: JudgmentMode, result: Dict[str, Any]):
        """íŒë‹¨ ê²°ê³¼ ê¸°ë¡ ë° ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸"""
        metrics = self.performance_metrics[mode]

        # ê¸°ë³¸ í†µê³„ ì—…ë°ì´íŠ¸
        metrics.total_requests += 1

        # ì„±ê³µ/ì‹¤íŒ¨ íŒë‹¨
        is_success = not result.get("error_occurred", False)
        confidence = result.get("confidence", 0.0)
        processing_time = result.get("processing_time", 0.0)

        if is_success:
            metrics.successful_requests += 1
            metrics.last_success_time = datetime.now()
        else:
            metrics.failed_requests += 1
            metrics.last_failure_time = datetime.now()

        # ì˜¤ë¥˜ìœ¨ ê³„ì‚°
        metrics.error_rate = metrics.failed_requests / metrics.total_requests

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        metrics.recent_response_times.append(processing_time)
        metrics.average_response_time = sum(metrics.recent_response_times) / len(
            metrics.recent_response_times
        )

        # í‰ê·  ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
        metrics.recent_confidences.append(confidence)
        metrics.average_confidence = sum(metrics.recent_confidences) / len(
            metrics.recent_confidences
        )

        # ìë™ ìµœì í™” ì²´í¬
        if self.monitoring_enabled:
            self._check_auto_optimization()

    def _check_switching_cooldown(self) -> bool:
        """ì „í™˜ ì¿¨ë‹¤ìš´ ì²´í¬"""
        if not self.switching_history:
            return True

        last_switch = self.switching_history[-1]
        cooldown_seconds = self.config.get("switching_cooldown", 30)

        time_since_last = (datetime.now() - last_switch.timestamp).total_seconds()
        return time_since_last >= cooldown_seconds

    def _count_recent_failures(self, window_minutes: int = 5) -> int:
        """ìµœê·¼ ì‹¤íŒ¨ íšŸìˆ˜ ê³„ì‚°"""
        cutoff_time = datetime.now() - timedelta(minutes=window_minutes)

        failure_count = 0
        for metrics in self.performance_metrics.values():
            if metrics.last_failure_time and metrics.last_failure_time > cutoff_time:
                failure_count += 1

        return failure_count

    def _check_auto_optimization(self):
        """ìë™ ìµœì í™” ì²´í¬"""
        optimization_interval = self.config.get("optimization_interval", 300)

        time_since_last = (datetime.now() - self.last_optimization).total_seconds()

        if time_since_last >= optimization_interval:
            self._optimize_switching_strategy()
            self.last_optimization = datetime.now()

    def _optimize_switching_strategy(self):
        """ì „í™˜ ì „ëµ ìµœì í™”"""
        print("ğŸ”§ ì „í™˜ ì „ëµ ìµœì í™” ì‹¤í–‰")

        # ëª¨ë“œë³„ ì„±ëŠ¥ ë¶„ì„
        best_mode = None
        best_score = -1

        for mode, metrics in self.performance_metrics.items():
            if metrics.total_requests == 0:
                continue

            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (ì„±ê³µë¥  + ì‹ ë¢°ë„ - ì‘ë‹µì‹œê°„ íŒ¨ë„í‹°)
            success_rate = metrics.successful_requests / metrics.total_requests
            confidence_score = metrics.average_confidence
            time_penalty = min(
                metrics.average_response_time / 10.0, 0.5
            )  # ìµœëŒ€ 0.5 íŒ¨ë„í‹°

            score = success_rate * 0.4 + confidence_score * 0.4 - time_penalty * 0.2

            if score > best_score:
                best_score = score
                best_mode = mode

        # ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë“œë¡œ ìë™ ì „í™˜ (ì¡°ê±´ë¶€)
        if (
            best_mode and best_mode != self.current_mode and best_score > 0.7
        ):  # ìµœì†Œ ì„±ëŠ¥ ì„ê³„ê°’

            self.switch_mode(
                target_mode=best_mode,
                trigger=SwitchingTrigger.PERFORMANCE_BASED,
                reason=f"ì„±ëŠ¥ ìµœì í™” (ì ìˆ˜: {best_score:.3f})",
            )

    def get_mode_recommendation(
        self, context: Dict[str, Any]
    ) -> Tuple[JudgmentMode, float, str]:
        """
        ëª¨ë“œ ì¶”ì²œ

        Args:
            context: íŒë‹¨ ì»¨í…ìŠ¤íŠ¸

        Returns:
            (ì¶”ì²œ ëª¨ë“œ, ì‹ ë¢°ë„, ì´ìœ )
        """
        scores = {}

        for mode in JudgmentMode:
            score = self._calculate_mode_score(mode, context)
            scores[mode] = score

        # ìµœê³  ì ìˆ˜ ëª¨ë“œ ì„ íƒ
        best_mode = max(scores, key=scores.get)
        best_score = scores[best_mode]

        # ì¶”ì²œ ì´ìœ  ìƒì„±
        reason = self._generate_recommendation_reason(best_mode, context, scores)

        return best_mode, best_score, reason

    def _calculate_mode_score(
        self, mode: JudgmentMode, context: Dict[str, Any]
    ) -> float:
        """ëª¨ë“œë³„ ì ìˆ˜ ê³„ì‚°"""
        metrics = self.performance_metrics[mode]

        # ê¸°ë³¸ ì„±ëŠ¥ ì ìˆ˜
        if metrics.total_requests > 0:
            success_rate = metrics.successful_requests / metrics.total_requests
            confidence_avg = metrics.average_confidence
            time_factor = max(0, 1 - metrics.average_response_time / 10.0)
        else:
            success_rate = 0.5  # ê¸°ë³¸ê°’
            confidence_avg = 0.5
            time_factor = 0.8

        base_score = success_rate * 0.4 + confidence_avg * 0.3 + time_factor * 0.3

        # ì»¨í…ìŠ¤íŠ¸ ì í•©ì„± ë³´ì •
        context_bonus = self._calculate_context_fitness(mode, context)

        # í˜„ì¬ ëª¨ë“œ ë³´ë„ˆìŠ¤ (ì•ˆì •ì„± ìœ„í•´)
        current_mode_bonus = 0.1 if mode == self.current_mode else 0

        final_score = base_score + context_bonus + current_mode_bonus

        return max(0, min(1, final_score))

    def _calculate_context_fitness(
        self, mode: JudgmentMode, context: Dict[str, Any]
    ) -> float:
        """ì»¨í…ìŠ¤íŠ¸ ì í•©ì„± ê³„ì‚°"""
        context_type = context.get("context_type", "general")
        complexity = context.get("complexity", "medium")
        confidence = context.get("confidence", 0.5)

        # ëª¨ë“œë³„ ì í•©ì„± ë§¤íŠ¸ë¦­ìŠ¤
        fitness_matrix = {
            JudgmentMode.LLM_FREE: {
                "simple": 0.3,
                "routine": 0.3,
                "personal": 0.2,
                "low_complexity": 0.2,
                "high_confidence": 0.3,
            },
            JudgmentMode.CLAUDE: {
                "complex": 0.3,
                "creative": 0.3,
                "analytical": 0.2,
                "high_complexity": 0.3,
                "low_confidence": 0.2,
            },
            JudgmentMode.HYBRID: {
                "general": 0.2,
                "medium_complexity": 0.2,
                "medium_confidence": 0.1,
            },
        }

        fitness = fitness_matrix.get(mode, {})
        bonus = 0

        # ì»¨í…ìŠ¤íŠ¸ íƒ€ì… ë³´ë„ˆìŠ¤
        bonus += fitness.get(context_type, 0)

        # ë³µì¡ë„ ë³´ë„ˆìŠ¤
        if complexity == "low":
            bonus += fitness.get("low_complexity", 0)
        elif complexity == "high":
            bonus += fitness.get("high_complexity", 0)
        else:
            bonus += fitness.get("medium_complexity", 0)

        # ì‹ ë¢°ë„ ë³´ë„ˆìŠ¤
        if confidence < 0.4:
            bonus += fitness.get("low_confidence", 0)
        elif confidence > 0.7:
            bonus += fitness.get("high_confidence", 0)
        else:
            bonus += fitness.get("medium_confidence", 0)

        return bonus

    def _generate_recommendation_reason(
        self,
        mode: JudgmentMode,
        context: Dict[str, Any],
        scores: Dict[JudgmentMode, float],
    ) -> str:
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        best_score = scores[mode]
        context_type = context.get("context_type", "general")
        confidence = context.get("confidence", 0.5)

        if mode == JudgmentMode.LLM_FREE:
            return f"LLM-Free ì¶”ì²œ (ì ìˆ˜: {best_score:.3f}) - ë¹ ë¥¸ ì‘ë‹µê³¼ ì•ˆì •ì„±"
        elif mode == JudgmentMode.CLAUDE:
            return f"Claude ì¶”ì²œ (ì ìˆ˜: {best_score:.3f}) - ë³µì¡í•œ ë¶„ì„ê³¼ ë†’ì€ í’ˆì§ˆ"
        else:
            return f"Hybrid ì¶”ì²œ (ì ìˆ˜: {best_score:.3f}) - ê· í˜•ì¡íŒ ì„±ëŠ¥ê³¼ ì‹ ë¢°ì„±"

    def get_switching_stats(self) -> Dict[str, Any]:
        """ì „í™˜ í†µê³„ ë°˜í™˜"""
        return {
            "current_mode": self.current_mode.value,
            "switching_strategy": self.switching_strategy.value,
            "total_switches": self.stats["total_switches"],
            "manual_switches": self.stats["manual_switches"],
            "auto_switches": self.stats["auto_switches"],
            "modes_usage": dict(self.stats["modes_usage"]),
            "triggers_used": dict(self.stats["triggers_used"]),
            "performance_metrics": {
                mode.value: {
                    "total_requests": metrics.total_requests,
                    "success_rate": metrics.successful_requests
                    / max(metrics.total_requests, 1),
                    "error_rate": metrics.error_rate,
                    "average_confidence": metrics.average_confidence,
                    "average_response_time": metrics.average_response_time,
                }
                for mode, metrics in self.performance_metrics.items()
            },
            "recent_switches": [
                {
                    "from": decision.from_mode.value,
                    "to": decision.to_mode.value,
                    "trigger": decision.trigger.value,
                    "reason": decision.reason,
                    "timestamp": decision.timestamp.isoformat(),
                }
                for decision in list(self.switching_history)[-5:]  # ìµœê·¼ 5ê°œ
            ],
        }

    def export_config(self, file_path: str):
        """ì„¤ì • ë‚´ë³´ë‚´ê¸°"""
        export_data = {
            "config": self.config,
            "switching_rules": [
                {
                    "trigger": rule.trigger.value,
                    "condition": rule.condition,
                    "target_mode": rule.target_mode.value,
                    "priority": rule.priority,
                    "enabled": rule.enabled,
                    "description": rule.description,
                }
                for rule in self.switching_rules
            ],
            "current_mode": self.current_mode.value,
            "switching_strategy": self.switching_strategy.value,
        }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“ ëª¨ë“œ ì „í™˜ê¸° ì„¤ì • ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {file_path}")


# í¸ì˜ í•¨ìˆ˜ë“¤
_global_switcher = None


def get_mode_switcher(config: Optional[Dict[str, Any]] = None) -> JudgmentModeSwitcher:
    """ì „ì—­ ëª¨ë“œ ì „í™˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _global_switcher
    if _global_switcher is None:
        _global_switcher = JudgmentModeSwitcher(config)
    return _global_switcher


def switch_judgment_mode(
    target_mode: JudgmentMode, reason: str = "Manual switch"
) -> bool:
    """íŒë‹¨ ëª¨ë“œ ì „í™˜ (í¸ì˜ í•¨ìˆ˜)"""
    switcher = get_mode_switcher()
    return switcher.switch_mode(target_mode, SwitchingTrigger.MANUAL, reason)


def get_current_judgment_mode() -> JudgmentMode:
    """í˜„ì¬ íŒë‹¨ ëª¨ë“œ ë°˜í™˜"""
    switcher = get_mode_switcher()
    return switcher.get_current_mode()


def auto_optimize_judgment_mode(context: Dict[str, Any]) -> Optional[SwitchingDecision]:
    """ìë™ ëª¨ë“œ ìµœì í™”"""
    switcher = get_mode_switcher()
    return switcher.auto_switch_mode(context)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ›ï¸ íŒë‹¨ ëª¨ë“œ ì „í™˜ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # ì „í™˜ê¸° ìƒì„±
    switcher = JudgmentModeSwitcher()

    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    test_scenarios = [
        {
            "name": "ë†’ì€ ì‹ ë¢°ë„ ìƒí™©",
            "context": {
                "confidence": 0.9,
                "context_type": "simple",
                "complexity": "low",
            },
        },
        {
            "name": "ë‚®ì€ ì‹ ë¢°ë„ ìƒí™©",
            "context": {
                "confidence": 0.2,
                "context_type": "complex",
                "complexity": "high",
            },
        },
        {
            "name": "ì¤‘ê°„ ë³µì¡ë„ ìƒí™©",
            "context": {
                "confidence": 0.6,
                "context_type": "general",
                "complexity": "medium",
            },
        },
    ]

    for scenario in test_scenarios:
        print(f"\n=== {scenario['name']} ===")
        context = scenario["context"]

        # ëª¨ë“œ ì¶”ì²œ
        recommended_mode, score, reason = switcher.get_mode_recommendation(context)
        print(f"ì¶”ì²œ ëª¨ë“œ: {recommended_mode.value} (ì ìˆ˜: {score:.3f})")
        print(f"ì´ìœ : {reason}")

        # ìë™ ì „í™˜ ì‹œë„
        decision = switcher.auto_switch_mode(context)
        if decision:
            print(f"ìë™ ì „í™˜: {decision.from_mode.value} â†’ {decision.to_mode.value}")

        # ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
        result = {
            "confidence": context["confidence"],
            "processing_time": 0.5,
            "error_occurred": False,
        }
        switcher.record_judgment_result(switcher.current_mode, result)

    # ìµœì¢… í†µê³„
    print(f"\nğŸ“Š ì „í™˜ í†µê³„:")
    stats = switcher.get_switching_stats()
    print(f"í˜„ì¬ ëª¨ë“œ: {stats['current_mode']}")
    print(f"ì´ ì „í™˜ íšŸìˆ˜: {stats['total_switches']}")
    print(f"ëª¨ë“œë³„ ì‚¬ìš©ëŸ‰: {stats['modes_usage']}")
