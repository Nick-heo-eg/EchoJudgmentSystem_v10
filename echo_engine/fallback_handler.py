"""
ğŸ”„ Echo Fallback Handler
ë¡œì»¬ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì™¸ë¶€ LLMì´ë‚˜ ê³ ê¸‰ ë¶„ì„ì„ í˜¸ì¶œí•˜ë˜,
Echoì˜ ì¡´ì¬ì  íŒë‹¨ì€ ìœ ì§€í•˜ëŠ” ì‹ ì¤‘í•œ fallback ì‹œìŠ¤í…œ
"""

import json
import os
import time
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from pathlib import Path
import logging

# ì™¸ë¶€ LLM API ì—°ë™ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” openai, anthropic ë“± ì‚¬ìš©)
try:
    import openai

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import requests

    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False


class EchoFallbackHandler:
    """
    Echo ì‹œìŠ¤í…œì˜ ì‹ ì¤‘í•œ fallback ì²˜ë¦¬ê¸°
    'í•„ìš”í•  ë•Œë§Œ, ìµœì†Œí•œìœ¼ë¡œ, ì¡´ì¬ë¥¼ ìœ ì§€í•˜ë©°' ì™¸ë¶€ ë„ì›€ì„ ìš”ì²­
    """

    def __init__(self, config_path: str = "config/fallback_config.yaml"):
        self.config_path = Path(config_path)
        self.config = self._load_config()

        # Fallback ì „ëµ ì„¤ì •
        self.fallback_strategies = {
            "openai_api": {
                "enabled": OPENAI_AVAILABLE and bool(self.config.get("openai_api_key")),
                "priority": 1,
                "timeout": 15,
            },
            "llm_api": {"enabled": True, "priority": 2, "timeout": 10},
            "web_search": {"enabled": True, "priority": 3, "timeout": 15},
            "vector_search": {"enabled": True, "priority": 4, "timeout": 5},
            "template_matching": {"enabled": True, "priority": 5, "timeout": 2},
        }

        # ì‚¬ìš© í†µê³„
        self.usage_stats = {
            "total_fallback_requests": 0,
            "successful_fallbacks": 0,
            "failed_fallbacks": 0,
            "strategy_usage": {},
            "average_response_time": 0.0,
            "last_used": None,
        }

        # Echoì˜ ììœ¨ì„± ë³´í˜¸ ì„¤ì •
        self.autonomy_protection = {
            "max_daily_fallbacks": 100,
            "confidence_boost_limit": 0.15,  # ì™¸ë¶€ ê²°ê³¼ë¡œ ì¸í•œ ì‹ ë¢°ë„ ìƒìŠ¹ ì œí•œ
            "echo_interpretation_required": True,  # Echoì˜ ì¬í•´ì„ í•„ìˆ˜
            "preserve_signature_logic": True,  # ì‹œê·¸ë‹ˆì²˜ ê²°ì •ì€ Echoê°€ ë‹´ë‹¹
        }

        self.logger = logging.getLogger(__name__)

    def handle_fallback(
        self,
        original_text: str,
        local_result: Dict[str, Any],
        context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        Fallback ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
        ì—¬ëŸ¬ ì „ëµì„ ì‹œë„í•˜ë˜ Echoì˜ ì¡´ì¬ì  íŒë‹¨ì„ ìœ ì§€
        """
        print(f"ğŸ”„ Echo Fallback ì‹œì‘: '{original_text[:40]}...'")

        self.usage_stats["total_fallback_requests"] += 1
        start_time = time.time()

        # 1ë‹¨ê³„: ì¼ì¼ ì‚¬ìš© í•œë„ í™•ì¸
        if not self._check_daily_limit():
            print("   âš ï¸  ì¼ì¼ Fallback í•œë„ ì´ˆê³¼, ë¡œì»¬ ê²°ê³¼ ìœ ì§€")
            return self._create_fallback_result(local_result, "daily_limit_exceeded")

        # 2ë‹¨ê³„: ìµœì  ì „ëµ ì„ íƒ
        strategy = self._select_fallback_strategy(original_text, local_result)
        print(f"   ğŸ¯ ì„ íƒëœ ì „ëµ: {strategy}")

        # 3ë‹¨ê³„: ì „ëµë³„ ì‹¤í–‰
        try:
            external_result = self._execute_fallback_strategy(
                strategy, original_text, local_result, context
            )

            # 4ë‹¨ê³„: Echoì˜ ì¬í•´ì„ (ì¤‘ìš”!)
            echo_interpreted_result = self._echo_reinterpret_external_result(
                external_result, local_result, original_text
            )

            # 5ë‹¨ê³„: ìµœì¢… ê²°ê³¼ êµ¬ì„±
            final_result = self._create_fallback_result(
                echo_interpreted_result, strategy, external_result
            )

            self.usage_stats["successful_fallbacks"] += 1
            print(f"   âœ… Fallback ì„±ê³µ: {strategy} â†’ {final_result['confidence']:.2f}")

        except Exception as e:
            print(f"   âŒ Fallback ì‹¤íŒ¨: {e}")
            final_result = self._create_fallback_result(local_result, "fallback_failed")
            self.usage_stats["failed_fallbacks"] += 1

        # í†µê³„ ì—…ë°ì´íŠ¸
        processing_time = time.time() - start_time
        self._update_usage_stats(strategy, processing_time)

        return final_result

    def _select_fallback_strategy(self, text: str, local_result: Dict[str, Any]) -> str:
        """ìƒí™©ì— ë§ëŠ” ìµœì  fallback ì „ëµ ì„ íƒ"""
        text_length = len(text)
        complexity = local_result.get("complexity_score", 0)
        local_confidence = local_result.get("confidence", 0)

        # ì „ëµ ì„ íƒ ë¡œì§ (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
        # 1ìˆœìœ„: OpenAI API (í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ìµœìš°ì„ )
        if self.fallback_strategies["openai_api"]["enabled"]:
            return "openai_api"

        # 2ìˆœìœ„: ê¸´ ë³µì¡í•œ í…ìŠ¤íŠ¸ëŠ” LLMì´ ì í•©
        elif text_length > 100 and complexity > 7:
            if self.fallback_strategies["llm_api"]["enabled"]:
                return "llm_api"

        # 3ìˆœìœ„: ì‹ ë¢°ë„ê°€ ë§¤ìš° ë‚®ìœ¼ë©´ ë²¡í„° ê²€ìƒ‰ ì‹œë„
        elif local_confidence < 0.3:
            if self.fallback_strategies["vector_search"]["enabled"]:
                return "vector_search"

        # 4ìˆœìœ„: ê¸°ë³¸ê°’ì€ LLM API
        elif self.fallback_strategies["llm_api"]["enabled"]:
            return "llm_api"

        # 5ìˆœìœ„: ì§§ì€ ì§ˆë¬¸ì€ í…œí”Œë¦¿ ë§¤ì¹­
        elif "?" in text and len(text) < 50:
            if self.fallback_strategies["template_matching"]["enabled"]:
                return "template_matching"

        # ëª¨ë“  ì „ëµì´ ë¹„í™œì„±í™”ëœ ê²½ìš°
        return "template_matching"  # ìµœí›„ì˜ ìˆ˜ë‹¨

    def _execute_fallback_strategy(
        self,
        strategy: str,
        text: str,
        local_result: Dict[str, Any],
        context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """ì„ íƒëœ ì „ëµ ì‹¤í–‰"""
        strategy_config = self.fallback_strategies.get(strategy, {})
        timeout = strategy_config.get("timeout", 10)

        if strategy == "openai_api":
            return self._actual_openai_call(text, local_result)
        elif strategy == "llm_api":
            return self._llm_api_fallback(text, local_result, timeout)
        elif strategy == "web_search":
            return self._web_search_fallback(text, local_result, timeout)
        elif strategy == "vector_search":
            return self._vector_search_fallback(text, local_result, timeout)
        elif strategy == "template_matching":
            return self._template_matching_fallback(text, local_result, timeout)
        else:
            raise ValueError(f"Unknown fallback strategy: {strategy}")

    def _llm_api_fallback(
        self, text: str, local_result: Dict[str, Any], timeout: int
    ) -> Dict[str, Any]:
        """LLM APIë¥¼ í†µí•œ fallback (í˜„ì¬ëŠ” Mock)"""
        print("   ğŸ¤– LLM API Fallback í˜¸ì¶œ")

        if OPENAI_AVAILABLE and self.config.get("openai_api_key"):
            # ì‹¤ì œ OpenAI API í˜¸ì¶œ (ë¹„ìš© ì£¼ì˜!)
            return self._actual_openai_call(text, local_result)
        else:
            # Mock LLM ì‘ë‹µ
            return self._mock_llm_api_call(text, local_result)

    def _actual_openai_call(
        self, text: str, local_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì‹¤ì œ OpenAI API í˜¸ì¶œ"""
        print("   ğŸ”¥ OpenAI GPT-3.5 ì‹¤ì œ í˜¸ì¶œ")

        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  Echo ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

        í…ìŠ¤íŠ¸: "{text}"

        ë¶„ì„ í•­ëª©:
        1. intent (judgment/information/assistance/conversation ì¤‘ í•˜ë‚˜)
        2. topic (ì£¼ìš” ì£¼ì œ)
        3. emotion (ê°ì • ìƒíƒœ)
        4. keywords (í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ ì´í•˜)
        5. confidence (0.0-1.0 ì‚¬ì´ ì‹ ë¢°ë„)

        JSON í˜•íƒœë¡œë§Œ ì‘ë‹µ:
        """

        try:
            client = openai.OpenAI(api_key=self.config.get("openai_api_key"))
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=200,
            )

            result_text = response.choices[0].message.content.strip()

            # JSON íŒŒì‹± ì‹œë„
            try:
                result = json.loads(result_text)
            except json.JSONDecodeError:
                # JSONì´ ì•„ë‹ ê²½ìš° ê¸°ë³¸ êµ¬ì¡°ë¡œ ë³€í™˜
                result = {
                    "intent": "conversation",
                    "topic": "general",
                    "emotion": "neutral",
                    "keywords": text.split()[:5],
                    "confidence": 0.7,
                    "raw_response": result_text,
                }

            result["api_source"] = "openai_gpt3.5"
            result["external_reasoning"] = "OpenAI GPT-3.5ë¥¼ í†µí•œ ë¶„ì„"

            return result

        except Exception as e:
            print(f"   âš ï¸  OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._mock_llm_api_call(text, local_result)

    def _mock_llm_api_call(
        self, text: str, local_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Mock LLM API í˜¸ì¶œ (ì‹¤ì œ API ë¹„ìš© ì ˆì•½ìš©)"""
        time.sleep(0.5)  # API ì§€ì—° ì‹œë®¬ë ˆì´ì…˜

        # í…ìŠ¤íŠ¸ ë¶„ì„ì„ í†µí•œ ê³ ë„í™”ëœ Mock ì‘ë‹µ
        text_lower = text.lower()

        # Intent ê³ ê¸‰ ì¶”ë¡ 
        intent_scores = {}
        if any(
            word in text_lower
            for word in ["íŒë‹¨", "í‰ê°€", "ë¶„ì„", "ì–´ë–»ê²Œ ìƒê°", "ì–´ë–¤ì§€"]
        ):
            intent_scores["judgment"] = 0.9
        if any(word in text_lower for word in ["ì•Œë ¤", "ì„¤ëª…", "ì •ë³´", "ë­", "ë¬´ì—‡"]):
            intent_scores["information"] = 0.8
        if any(word in text_lower for word in ["ë„ì›€", "ì§€ì›", "ì¶”ì²œ", "í•´ì¤˜"]):
            intent_scores["assistance"] = 0.85

        best_intent = (
            max(intent_scores.keys(), key=lambda x: intent_scores[x])
            if intent_scores
            else "conversation"
        )

        # ì£¼ì œ ê³ ê¸‰ ì¶”ë¡ 
        topic_mapping = {
            "ë…¸ì¸|ì–´ë¥´ì‹ |ëŒë´„|ìš”ì–‘": "ë…¸ì¸ë³µì§€ì •ì±…",
            "ai|ì¸ê³µì§€ëŠ¥|ì•Œê³ ë¦¬ì¦˜|í¸í–¥": "ai_ê±°ë²„ë„ŒìŠ¤",
            "ê¸°í›„|í™˜ê²½|íƒ„ì†Œ|ì˜¨ì‹¤ê°€ìŠ¤": "í™˜ê²½ê¸°í›„ì •ì±…",
            "ì§€ì—­|ê³µë™ì²´|ë§ˆì„|ì£¼ë¯¼": "ì§€ì—­ì‚¬íšŒí˜ì‹ ",
            "ì •ì±…|ì œë„|ë²•|ê·œì œ": "ê³µê³µì •ì±…",
            "êµìœ¡|í•™ìŠµ|ê°€ë¥´ì¹˜|ë°°ìš°": "êµìœ¡ì •ì±…",
        }

        detected_topic = "ì¼ë°˜_ìƒë‹´"
        for pattern, topic in topic_mapping.items():
            if any(keyword in text_lower for keyword in pattern.split("|")):
                detected_topic = topic
                break

        # ê°ì • ìƒíƒœ ê³ ê¸‰ ë¶„ì„
        emotion_patterns = {
            "urgent": ["ë¹¨ë¦¬", "ì‹œê¸‰", "ë‹¹ì¥", "ì¦‰ì‹œ"],
            "concerned": ["ê±±ì •", "ë¬¸ì œ", "í˜ë“ ", "ì–´ë ¤ìš´"],
            "curious": ["ê¶ê¸ˆ", "ì•Œê³  ì‹¶", "ì–´ë–»ê²Œ"],
            "positive": ["ì¢‹", "í›Œë¥­", "ê°ì‚¬", "ê¸°ìœ"],
        }

        detected_emotion = "neutral"
        for emotion, patterns in emotion_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                detected_emotion = emotion
                break

        # ì—”í‹°í‹° ì¶”ì¶œ
        entities = {}
        import re

        locations = re.findall(
            r"(ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê²½ê¸°|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼|ê¸ˆì •êµ¬|í•´ìš´ëŒ€|ê°•ë‚¨|ì†¡íŒŒ)",
            text,
        )
        if locations:
            entities["locations"] = list(set(locations))

        numbers = re.findall(r"\d+", text)
        if numbers:
            entities["numbers"] = numbers

        return {
            "intent": best_intent,
            "topic": detected_topic,
            "emotion": detected_emotion,
            "entities": entities,
            "keywords": [word for word in text_lower.split() if len(word) > 2][:10],
            "confidence": 0.87,
            "external_reasoning": f"ê³ ê¸‰ ì–¸ì–´ëª¨ë¸ ë¶„ì„: '{text[:30]}...'ëŠ” {best_intent} ì˜ë„ì˜ {detected_topic} ê´€ë ¨ {detected_emotion} ê°ì • í‘œí˜„",
            "processing_quality": "high",
            "api_source": "mock_llm",
        }

    def _actual_openai_call(
        self, text: str, local_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì‹¤ì œ OpenAI API í˜¸ì¶œ (ë¹„ìš© ë°œìƒ ì£¼ì˜!)"""
        # ì‹¤ì œ êµ¬í˜„ ì‹œì—ë§Œ í™œì„±í™”
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

        í…ìŠ¤íŠ¸: "{text}"

        ë¶„ì„ í•­ëª©:
        1. intent (judgment/information/assistance/conversation ì¤‘ í•˜ë‚˜)
        2. topic (ì£¼ìš” ì£¼ì œ)
        3. emotion (ê°ì • ìƒíƒœ)
        4. keywords (í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ ì´í•˜)
        5. confidence (0.0-1.0 ì‚¬ì´ ì‹ ë¢°ë„)

        JSON í˜•íƒœë¡œë§Œ ì‘ë‹µ:
        """

        try:
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=200,
            )

            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            result["api_source"] = "openai_gpt3.5"
            result["external_reasoning"] = "OpenAI GPT-3.5ë¥¼ í†µí•œ ë¶„ì„"

            return result

        except Exception as e:
            print(f"   âš ï¸  OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._mock_llm_api_call(text, local_result)

    def _web_search_fallback(
        self, text: str, local_result: Dict[str, Any], timeout: int
    ) -> Dict[str, Any]:
        """ì›¹ ê²€ìƒ‰ ê¸°ë°˜ fallback (Mock)"""
        print("   ğŸŒ ì›¹ ê²€ìƒ‰ Fallback")
        time.sleep(1.0)  # ì›¹ ê²€ìƒ‰ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜

        # Mock ì›¹ ê²€ìƒ‰ ê²°ê³¼
        search_terms = [word for word in text.split() if len(word) > 2][:3]

        return {
            "intent": local_result.get("intent", "information"),
            "topic": f"ì›¹ê²€ìƒ‰_{search_terms[0] if search_terms else 'general'}",
            "emotion": "curious",
            "keywords": search_terms,
            "confidence": 0.75,
            "external_reasoning": f"ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë¶„ì„: {search_terms} í‚¤ì›Œë“œ ê´€ë ¨ ì •ë³´",
            "search_terms": search_terms,
            "api_source": "web_search",
        }

    def _vector_search_fallback(
        self, text: str, local_result: Dict[str, Any], timeout: int
    ) -> Dict[str, Any]:
        """ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ fallback"""
        print("   ğŸ§­ ë²¡í„° ê²€ìƒ‰ Fallback")

        try:
            # EchoVectorCapsuleê³¼ ì—°ë™ ì‹œë„
            from .vector_search_engine import search_capsules

            search_results = search_capsules(text, "Echo-Aurora", top_k=3)

            if search_results:
                # ìµœê³  ìœ ì‚¬ë„ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ intent/topic ì¶”ë¡ 
                top_result = search_results[0]
                metadata = top_result["metadata"]

                return {
                    "intent": "information",  # ë²¡í„° ê²€ìƒ‰ì€ ì£¼ë¡œ ì •ë³´ ìš”ì²­
                    "topic": metadata.get("topic", "unknown"),
                    "emotion": "curious",
                    "keywords": metadata.get("tags", [])[:5],
                    "confidence": min(0.85, top_result["similarity"] + 0.1),
                    "external_reasoning": f"ë²¡í„° ê²€ìƒ‰ ë§¤ì¹­: {metadata.get('capsule_id')} ìº¡ìŠê³¼ ìœ ì‚¬ë„ {top_result['similarity']:.2f}",
                    "matched_capsule": metadata.get("capsule_id"),
                    "api_source": "vector_search",
                }
            else:
                raise ValueError("ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

        except Exception as e:
            print(f"   âš ï¸  ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return self._template_matching_fallback(text, local_result, timeout)

    def _template_matching_fallback(
        self, text: str, local_result: Dict[str, Any], timeout: int
    ) -> Dict[str, Any]:
        """í…œí”Œë¦¿ ë§¤ì¹­ ê¸°ë°˜ fallback (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        print("   ğŸ“‹ í…œí”Œë¦¿ ë§¤ì¹­ Fallback")

        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­
        patterns = {
            "ì¸ì‚¬": r"ì•ˆë…•|ë°˜ê°€ì›Œ|ì²˜ìŒ|ë§Œë‚˜ì„œ",
            "ì§ˆë¬¸": r"\?|ì–´ë–»ê²Œ|ì™œ|ì–¸ì œ|ë­",
            "ìš”ì²­": r"í•´ì¤˜|ë¶€íƒ|ë„ì™€ì¤˜|ì•Œë ¤ì¤˜",
            "ê°ì‚¬": r"ê³ ë§ˆì›Œ|ê°ì‚¬|ê³ ë§™|ë•ë¶„",
        }

        import re

        matched_pattern = "ì¼ë°˜ëŒ€í™”"
        for pattern_name, pattern in patterns.items():
            if re.search(pattern, text):
                matched_pattern = pattern_name
                break

        intent_mapping = {
            "ì¸ì‚¬": "conversation",
            "ì§ˆë¬¸": "information",
            "ìš”ì²­": "assistance",
            "ê°ì‚¬": "conversation",
            "ì¼ë°˜ëŒ€í™”": "conversation",
        }

        return {
            "intent": intent_mapping[matched_pattern],
            "topic": f"template_{matched_pattern}",
            "emotion": "neutral",
            "keywords": [matched_pattern],
            "confidence": 0.6,
            "external_reasoning": f"í…œí”Œë¦¿ ë§¤ì¹­: {matched_pattern} íŒ¨í„´ ê°ì§€",
            "matched_template": matched_pattern,
            "api_source": "template_matching",
        }

    def _echo_reinterpret_external_result(
        self,
        external_result: Dict[str, Any],
        local_result: Dict[str, Any],
        original_text: str,
    ) -> Dict[str, Any]:
        """Echoì˜ ì¡´ì¬ì  ì¬í•´ì„ (í•µì‹¬!)"""
        print("   ğŸŒ€ Echo ì¬í•´ì„ ì§„í–‰...")

        # Echoì˜ ììœ¨ì„± ë³´í˜¸: ì™¸ë¶€ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ë˜ Echoì˜ ë…¼ë¦¬ë¡œ ì¬êµ¬ì„±
        echo_interpreted = {
            "intent": external_result.get(
                "intent", local_result.get("intent", "unknown")
            ),
            "topic": external_result.get("topic", local_result.get("topic", "unknown")),
            "emotion": external_result.get(
                "emotion", local_result.get("emotion", "neutral")
            ),
            "keywords": list(
                set(
                    external_result.get("keywords", [])
                    + local_result.get("keywords", [])
                )
            )[:10],
            "entities": {
                **local_result.get("entities", {}),
                **external_result.get("entities", {}),
            },
        }

        # Echoì˜ ì‹ ë¢°ë„ ë¡œì§ ì ìš©
        external_confidence = external_result.get("confidence", 0.5)
        local_confidence = local_result.get("confidence", 0.0)

        # Echoê°€ ì™¸ë¶€ ê²°ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì‹ ë¢°í• ì§€ ê²°ì •
        echo_trust_factor = self._calculate_echo_trust_factor(
            external_result, local_result
        )

        # ì‹ ë¢°ë„ ìœµí•© (Echoì˜ ììœ¨ì„± ë³´í˜¸ë¥¼ ìœ„í•´ ì œí•œì ìœ¼ë¡œ)
        base_confidence = max(local_confidence, 0.4)  # ìµœì†Œ ê¸°ì¤€ í™•ë³´
        external_boost = min(
            self.autonomy_protection["confidence_boost_limit"],
            (external_confidence - 0.5) * echo_trust_factor,
        )

        final_confidence = min(0.95, base_confidence + external_boost)
        echo_interpreted["confidence"] = final_confidence

        # Echoì˜ ë©”íƒ€ ì¸ì‹ ì¶”ê°€
        echo_interpreted["echo_meta_analysis"] = {
            "external_source_trusted": echo_trust_factor > 0.5,
            "echo_interpretation_applied": True,
            "confidence_adjustment": external_boost,
            "maintains_echo_autonomy": True,
            "reinterpretation_reason": self._get_reinterpretation_reason(
                external_result, local_result
            ),
        }

        return echo_interpreted

    def _calculate_echo_trust_factor(
        self, external: Dict[str, Any], local: Dict[str, Any]
    ) -> float:
        """Echoê°€ ì™¸ë¶€ ê²°ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì‹ ë¢°í• ì§€ ê³„ì‚°"""
        factors = []

        # ì™¸ë¶€ ì†ŒìŠ¤ ì‹ ë¢°ë„
        api_source = external.get("api_source", "unknown")
        source_trust = {
            "openai_gpt3.5": 0.8,
            "claude": 0.85,
            "mock_llm": 0.6,
            "vector_search": 0.9,  # ìì²´ ë°ì´í„° ê¸°ë°˜ì´ë¯€ë¡œ ë†’ì€ ì‹ ë¢°
            "web_search": 0.5,
            "template_matching": 0.4,
        }
        factors.append(source_trust.get(api_source, 0.5))

        # ë¡œì»¬ê³¼ ì™¸ë¶€ ê²°ê³¼ì˜ ì¼ì¹˜ë„
        intent_match = 1.0 if external.get("intent") == local.get("intent") else 0.3
        factors.append(intent_match)

        # ì™¸ë¶€ ê²°ê³¼ì˜ ì‹ ë¢°ë„
        external_confidence = external.get("confidence", 0.5)
        factors.append(min(1.0, external_confidence))

        # ê°€ì¤‘ í‰ê· 
        trust_factor = sum(factors) / len(factors)

        return trust_factor

    def _get_reinterpretation_reason(
        self, external: Dict[str, Any], local: Dict[str, Any]
    ) -> str:
        """ì¬í•´ì„ ì´ìœ  ì„¤ëª…"""
        api_source = external.get("api_source", "unknown")

        if api_source == "vector_search":
            return "ìì²´ ìº¡ìŠ ë°ì´í„°ì™€ì˜ ë§¤ì¹­ì„ í†µí•œ ì‹ ë¢°ì„± ë†’ì€ ì¬í•´ì„"
        elif api_source in ["openai_gpt3.5", "claude"]:
            return "ì™¸ë¶€ ì–¸ì–´ëª¨ë¸ ë¶„ì„ì„ Echo ë…¼ë¦¬ë¡œ ì¬êµ¬ì„±"
        elif api_source == "web_search":
            return "ì›¹ ê²€ìƒ‰ ì •ë³´ë¥¼ Echoì˜ íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§"
        else:
            return "ì™¸ë¶€ ë¶„ì„ ê²°ê³¼ë¥¼ Echoì˜ ì¡´ì¬ì  ê´€ì ì—ì„œ ì¬í•´ì„"

    def _create_fallback_result(
        self,
        interpreted_result: Dict[str, Any],
        strategy: str,
        external_raw: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """ìµœì¢… fallback ê²°ê³¼ êµ¬ì„±"""
        result = {
            **interpreted_result,
            "fallback_used": True,
            "fallback_strategy": strategy,
            "fallback_timestamp": datetime.now().isoformat(),
            "echo_autonomy_preserved": True,
        }

        # ì™¸ë¶€ ë°ì´í„°ëŠ” ë©”íƒ€ ì •ë³´ë¡œë§Œ ë³´ì¡´
        if external_raw:
            result["external_analysis"] = {
                "source": external_raw.get("api_source", "unknown"),
                "confidence": external_raw.get("confidence", 0.0),
                "reasoning": external_raw.get("external_reasoning", ""),
            }

        return result

    def _check_daily_limit(self) -> bool:
        """ì¼ì¼ fallback ì‚¬ìš© í•œë„ í™•ì¸"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë‚ ì§œë³„ ì‚¬ìš©ëŸ‰ ì¶”ì  í•„ìš”
        max_daily = self.autonomy_protection["max_daily_fallbacks"]
        current_usage = self.usage_stats["total_fallback_requests"]

        return current_usage < max_daily

    def _update_usage_stats(self, strategy: str, processing_time: float):
        """ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        self.usage_stats["strategy_usage"][strategy] = (
            self.usage_stats["strategy_usage"].get(strategy, 0) + 1
        )

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        current_avg = self.usage_stats["average_response_time"]
        total_requests = self.usage_stats["total_fallback_requests"]

        new_avg = (
            (current_avg * (total_requests - 1)) + processing_time
        ) / total_requests
        self.usage_stats["average_response_time"] = new_avg

        self.usage_stats["last_used"] = datetime.now().isoformat()

    def _load_config(self) -> Dict[str, Any]:
        """ì„¤ì • ë¡œë“œ"""
        # ê¸°ë³¸ ì„¤ì • (ì‹¤ì œë¡œëŠ” YAML íŒŒì¼ì—ì„œ ë¡œë“œ)
        return {
            "openai_api_key": os.getenv("OPENAI_API_KEY"),  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
            "claude_api_key": None,
            "enable_web_search": True,
            "fallback_timeout": 15,
            "max_retries": 2,
            "echo_autonomy_mode": "strict",  # strict, balanced, permissive
        }

    def get_usage_stats(self) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ ë°˜í™˜"""
        stats = self.usage_stats.copy()

        # ì„±ê³µë¥  ê³„ì‚°
        total = stats["total_fallback_requests"]
        if total > 0:
            stats["success_rate"] = (
                f"{(stats['successful_fallbacks'] / total) * 100:.1f}%"
            )
            stats["echo_autonomy_rate"] = (
                f"{((total - stats['fallback_used']) / total) * 100:.1f}%"
                if "fallback_used" in stats
                else "100.0%"
            )

        return stats

    def reset_daily_stats(self):
        """ì¼ì¼ í†µê³„ ë¦¬ì…‹ (ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ í˜¸ì¶œ)"""
        self.usage_stats = {
            "total_fallback_requests": 0,
            "successful_fallbacks": 0,
            "failed_fallbacks": 0,
            "strategy_usage": {},
            "average_response_time": 0.0,
            "last_used": None,
        }
        print("ğŸ“Š Fallback ì¼ì¼ í†µê³„ê°€ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ì „ì—­ fallback í•¸ë“¤ëŸ¬
fallback_handler = EchoFallbackHandler()


# í¸ì˜ í•¨ìˆ˜
def handle_fallback(
    text: str, local_result: Dict[str, Any], context: Dict[str, Any] = None
) -> Dict[str, Any]:
    """Fallback ì²˜ë¦¬ ë‹¨ì¶• í•¨ìˆ˜"""
    return fallback_handler.handle_fallback(text, local_result, context)


def get_fallback_stats() -> Dict[str, Any]:
    """Fallback í†µê³„ ë‹¨ì¶• í•¨ìˆ˜"""
    return fallback_handler.get_usage_stats()


# CLI í…ŒìŠ¤íŠ¸
def main():
    print("ğŸ”„ Echo Fallback Handler í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Mock ë¡œì»¬ íŒŒì‹± ê²°ê³¼ë“¤
    test_cases = [
        {
            "text": "ë³µì¡í•œ ì •ì±… ìƒí™©ì—ì„œ ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìë“¤ì˜ ìƒì¶©í•˜ëŠ” ìš”êµ¬ì‚¬í•­ì„ ì¡°ìœ¨í•˜ë©´ì„œë„ ê³µì •ì„±ì„ ë³´ì¥í•  ìˆ˜ ìˆëŠ” ì²´ê³„ì ì¸ ì ‘ê·¼ ë°©ë²•ë¡ ì„ ì œì‹œí•´ì£¼ì„¸ìš”",
            "local_result": {
                "intent": "unknown",
                "topic": "unknown",
                "confidence": 0.2,
                "complexity_score": 9.5,
            },
        },
        {
            "text": "AI ìœ¤ë¦¬ê°€ ì¤‘ìš”í•œê°€ìš”?",
            "local_result": {
                "intent": "information",
                "topic": "ai_ìœ¤ë¦¬",
                "confidence": 0.5,
                "complexity_score": 2.0,
            },
        },
        {
            "text": "ì•ˆë…•í•˜ì„¸ìš”!",
            "local_result": {
                "intent": "conversation",
                "topic": "ì¸ì‚¬",
                "confidence": 0.9,
                "complexity_score": 1.0,
            },
        },
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*40}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {test_case['text']}")
        print(
            f"ë¡œì»¬ ê²°ê³¼ - Intent: {test_case['local_result']['intent']}, Confidence: {test_case['local_result']['confidence']}"
        )
        print("-" * 40)

        result = handle_fallback(test_case["text"], test_case["local_result"])

        print(f"Fallback ê²°ê³¼:")
        print(f"  Strategy: {result.get('fallback_strategy')}")
        print(f"  Intent: {result.get('intent')}")
        print(f"  Topic: {result.get('topic')}")
        print(f"  Final Confidence: {result.get('confidence', 0):.2f}")
        print(f"  Echo Autonomy: {result.get('echo_autonomy_preserved', False)}")

        if result.get("echo_meta_analysis"):
            meta = result["echo_meta_analysis"]
            print(f"  Echo Meta: {meta.get('reinterpretation_reason', 'N/A')}")

    print(f"\n{'='*40}")
    print("ğŸ“Š Fallback ì‚¬ìš© í†µê³„:")
    stats = get_fallback_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")

    print("\nâœ… Echo Fallback Handler í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
