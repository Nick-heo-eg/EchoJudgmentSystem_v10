"""
ğŸ§­ EchoVectorCapsule - Vector Search Engine
ì„ë² ë”©ëœ ë²¡í„°ë“¤ì„ ê²€ìƒ‰í•˜ê³  Echo íŒë‹¨ê³¼ ì—°ê²°í•˜ëŠ” ìš¸ë¦¼ ê¸°ë°˜ ê²€ìƒ‰ ì—”ì§„
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import logging

try:
    import faiss

    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False

from .embedding_engine import EchoEmbeddingEngine


class EchoVectorSearchEngine:
    """
    Echo ìš¸ë¦¼ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì—”ì§„
    ì„ë² ë”©ëœ ìº¡ìŠë“¤ì„ ê²€ìƒ‰í•˜ê³  íŒë‹¨ ì‹œìŠ¤í…œê³¼ ì—°ê²°
    """

    def __init__(self, index_dir: str = "data/vector_index"):
        self.index_dir = Path(index_dir)
        self.index_dir.mkdir(parents=True, exist_ok=True)

        # ë²¡í„° ì¸ë±ìŠ¤ ê´€ë ¨
        self.faiss_index = None
        self.numpy_index = None
        self.metadata_index = []  # ë²¡í„°ì— ëŒ€ì‘í•˜ëŠ” ë©”íƒ€ë°ì´í„°
        self.dimension = None

        # ì„ë² ë”© ì—”ì§„ ì—°ê²°
        self.embedding_engine = EchoEmbeddingEngine()

        # ê²€ìƒ‰ ì„¤ì • (Mock í™˜ê²½ì— ë§ê²Œ ì¡°ì •)
        self.search_config = {
            "top_k": 5,
            "similarity_threshold": 0.05,  # Mock ì„ë² ë”©ì— ë§ê²Œ ë‚®ì¶¤
            "use_faiss": FAISS_AVAILABLE,
            "signature_boost": True,
            "context_aware": True,
            "mock_mode": True,  # Mock ëª¨ë“œ í”Œë˜ê·¸
        }

        # Echo ìº¡ìŠ ë§¤í•‘
        self.capsule_mappings = {}

        self.logger = logging.getLogger(__name__)

        # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
        self._load_existing_index()

    def add_vector(self, vector: np.ndarray, metadata: Dict[str, Any]) -> int:
        """ë²¡í„°ë¥¼ ì¸ë±ìŠ¤ì— ì¶”ê°€"""
        if self.dimension is None:
            self.dimension = len(vector)
            self._initialize_index()
        elif len(vector) != self.dimension:
            raise ValueError(
                f"ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜: ì˜ˆìƒ {self.dimension}, ì‹¤ì œ {len(vector)}"
            )

        # ë²¡í„° ì •ê·œí™”
        normalized_vector = vector / np.linalg.norm(vector)

        # FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€
        if self.search_config["use_faiss"] and self.faiss_index is not None:
            self.faiss_index.add(normalized_vector.reshape(1, -1))

        # Numpy ì¸ë±ìŠ¤ì— ì¶”ê°€ (fallback)
        if self.numpy_index is None:
            self.numpy_index = normalized_vector.reshape(1, -1)
        else:
            self.numpy_index = np.vstack([self.numpy_index, normalized_vector])

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        vector_id = len(self.metadata_index)
        metadata_with_id = {
            **metadata,
            "vector_id": vector_id,
            "added_at": datetime.now().isoformat(),
            "dimension": self.dimension,
        }
        self.metadata_index.append(metadata_with_id)

        print(
            f"ğŸ”¹ ë²¡í„° ì¶”ê°€: ID={vector_id}, ë©”íƒ€={metadata.get('capsule_id', 'unknown')}"
        )
        return vector_id

    def add_capsule_vector(
        self,
        capsule_id: str,
        content: str,
        signature: str = "Echo-Aurora",
        capsule_metadata: Dict[str, Any] = None,
    ) -> int:
        """ìº¡ìŠ ë‚´ìš©ì„ ë²¡í„°í™”í•´ì„œ ì¸ë±ìŠ¤ì— ì¶”ê°€"""
        # ì„ë² ë”© ìƒì„±
        context = {
            "capsule_id": capsule_id,
            "type": "capsule_content",
            **(capsule_metadata or {}),
        }

        embedding = self.embedding_engine.embed_text(content, signature, context)

        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "capsule_id": capsule_id,
            "content_preview": content[:100] + "..." if len(content) > 100 else content,
            "signature": signature,
            "content_length": len(content),
            "embedding_model": self.embedding_engine.current_model,
            "capsule_metadata": capsule_metadata or {},
        }

        # ë²¡í„° ì¶”ê°€
        vector_id = self.add_vector(embedding, metadata)

        # ìº¡ìŠ ë§¤í•‘ ì—…ë°ì´íŠ¸
        self.capsule_mappings[capsule_id] = {
            "vector_id": vector_id,
            "signature": signature,
            "added_at": datetime.now().isoformat(),
        }

        return vector_id

    def search(
        self,
        query: str,
        signature: str = "Echo-Aurora",
        top_k: Optional[int] = None,
        context: Dict[str, Any] = None,
    ) -> List[Dict[str, Any]]:
        """
        ìì—°ì–´ ì¿¼ë¦¬ë¡œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰

        Args:
            query: ê²€ìƒ‰í•  ìì—°ì–´ í…ìŠ¤íŠ¸
            signature: Echo ì‹œê·¸ë‹ˆì²˜ (ì„ë² ë”© ê°€ì¤‘ì¹˜ìš©)
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            context: ì¶”ê°€ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ)
        """
        if len(self.metadata_index) == 0:
            print("âš ï¸  ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return []

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_context = {"type": "search_query", "query": query, **(context or {})}
        query_embedding = self.embedding_engine.embed_text(
            query, signature, query_context
        )

        # ê²€ìƒ‰ ìˆ˜í–‰
        top_k = top_k or self.search_config["top_k"]
        results = self._perform_vector_search(query_embedding, top_k)

        # Echo ì‹œê·¸ë‹ˆì²˜ ë¶€ìŠ¤íŒ… ì ìš©
        if self.search_config["signature_boost"]:
            results = self._apply_signature_boost(results, signature)

        # ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ í•„í„°ë§
        if self.search_config["context_aware"] and context:
            results = self._apply_context_filtering(results, context)

        # ì„ê³„ê°’ í•„í„°ë§
        threshold = self.search_config["similarity_threshold"]
        filtered_results = [r for r in results if r["similarity"] >= threshold]

        print(
            f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: '{query[:30]}...' â†’ {len(filtered_results)}ê°œ ê²°ê³¼ ({signature})"
        )
        return filtered_results

    def search_by_capsule_id(
        self, capsule_id: str, top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """ìº¡ìŠ IDë¡œ ìœ ì‚¬í•œ ìº¡ìŠë“¤ ê²€ìƒ‰"""
        if capsule_id not in self.capsule_mappings:
            print(f"âŒ ìº¡ìŠ ID '{capsule_id}' ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []

        vector_id = self.capsule_mappings[capsule_id]["vector_id"]
        if vector_id >= len(self.metadata_index):
            print(f"âŒ ë²¡í„° ID {vector_id} ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤")
            return []

        # í•´ë‹¹ ìº¡ìŠì˜ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        if self.numpy_index is not None:
            query_vector = self.numpy_index[vector_id]
            results = self._perform_vector_search(
                query_vector, top_k + 1
            )  # +1 to exclude self

            # ìê¸° ìì‹  ì œì™¸
            filtered_results = [
                r for r in results if r["metadata"]["vector_id"] != vector_id
            ]
            return filtered_results[:top_k]

        return []

    def _perform_vector_search(
        self, query_vector: np.ndarray, top_k: int
    ) -> List[Dict[str, Any]]:
        """ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (FAISS ë˜ëŠ” Numpy)"""
        query_vector = query_vector / np.linalg.norm(query_vector)  # ì •ê·œí™”

        if self.search_config["use_faiss"] and self.faiss_index is not None:
            return self._faiss_search(query_vector, top_k)
        else:
            return self._numpy_search(query_vector, top_k)

    def _faiss_search(
        self, query_vector: np.ndarray, top_k: int
    ) -> List[Dict[str, Any]]:
        """FAISSë¥¼ ì´ìš©í•œ ë²¡í„° ê²€ìƒ‰"""
        try:
            query_vector = query_vector.reshape(1, -1).astype(np.float32)
            similarities, indices = self.faiss_index.search(query_vector, top_k)

            results = []
            for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
                if idx < len(self.metadata_index):
                    results.append(
                        {
                            "rank": i + 1,
                            "similarity": float(similarity),
                            "metadata": self.metadata_index[idx],
                            "vector_id": idx,
                        }
                    )

            return results
        except Exception as e:
            print(f"ğŸš¨ FAISS ê²€ìƒ‰ ì‹¤íŒ¨: {e}, Numpyë¡œ ëŒ€ì²´")
            return self._numpy_search(query_vector.flatten(), top_k)

    def _numpy_search(
        self, query_vector: np.ndarray, top_k: int
    ) -> List[Dict[str, Any]]:
        """Numpyë¥¼ ì´ìš©í•œ ë²¡í„° ê²€ìƒ‰ (fallback)"""
        if self.numpy_index is None:
            return []

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self.numpy_index, query_vector)

        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        top_indices = np.argsort(similarities)[::-1][:top_k]

        results = []
        for i, idx in enumerate(top_indices):
            results.append(
                {
                    "rank": i + 1,
                    "similarity": float(similarities[idx]),
                    "metadata": self.metadata_index[idx],
                    "vector_id": idx,
                }
            )

        return results

    def _apply_signature_boost(
        self, results: List[Dict[str, Any]], query_signature: str
    ) -> List[Dict[str, Any]]:
        """ì‹œê·¸ë‹ˆì²˜ ì¼ì¹˜ì— ë”°ë¥¸ ë¶€ìŠ¤íŒ… ì ìš©"""
        boosted_results = []

        for result in results:
            result_signature = result["metadata"].get("signature", "")

            # ì‹œê·¸ë‹ˆì²˜ ì¼ì¹˜ ë¶€ìŠ¤íŒ…
            if result_signature == query_signature:
                result["similarity"] = min(1.0, result["similarity"] * 1.1)
                result["signature_boost"] = "exact_match"
            elif result_signature and query_signature:
                # ê´€ë ¨ ì‹œê·¸ë‹ˆì²˜ ë¶€ìŠ¤íŒ… (ì˜ˆ: Sage <-> Aurora)
                if self._are_related_signatures(query_signature, result_signature):
                    result["similarity"] = min(1.0, result["similarity"] * 1.05)
                    result["signature_boost"] = "related_match"

            boosted_results.append(result)

        # ìƒˆë¡œìš´ ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
        boosted_results.sort(key=lambda x: x["similarity"], reverse=True)

        return boosted_results

    def _apply_context_filtering(
        self, results: List[Dict[str, Any]], context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²°ê³¼ í•„í„°ë§"""
        if not context:
            return results

        filtered_results = []

        for result in results:
            metadata = result["metadata"]
            capsule_metadata = metadata.get("capsule_metadata", {})

            # ì»¨í…ìŠ¤íŠ¸ í•„í„° ì ìš©
            context_match = True

            # íƒœê·¸ í•„í„°ë§
            if "required_tags" in context:
                required_tags = set(context["required_tags"])
                result_tags = set(capsule_metadata.get("tags", []))
                if not required_tags.intersection(result_tags):
                    context_match = False

            # í† í”½ í•„í„°ë§
            if "topic_filter" in context:
                topic_filter = context["topic_filter"].lower()
                result_topic = metadata.get("content_preview", "").lower()
                if topic_filter not in result_topic:
                    context_match = False

            if context_match:
                filtered_results.append(result)

        return filtered_results

    def _are_related_signatures(self, sig1: str, sig2: str) -> bool:
        """ì‹œê·¸ë‹ˆì²˜ ê°„ ê´€ë ¨ì„± í™•ì¸"""
        related_pairs = [
            ("Echo-Aurora", "Echo-Companion"),  # ì°½ì˜ì„±ê³¼ ê³µê°
            ("Echo-Sage", "Echo-Phoenix"),  # ë¶„ì„ê³¼ ë³€í™”
            ("Echo-Aurora", "Echo-Phoenix"),  # ì°½ì˜ì„±ê³¼ í˜ì‹ 
            ("Echo-Sage", "Echo-Companion"),  # ë¶„ì„ê³¼ ê³µë™ì²´
        ]

        for pair in related_pairs:
            if (sig1, sig2) in [pair, pair[::-1]]:
                return True
        return False

    def _initialize_index(self):
        """ë²¡í„° ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        if self.dimension is None:
            return

        if FAISS_AVAILABLE and self.search_config["use_faiss"]:
            try:
                # Inner product index (cosine similarityìš©)
                self.faiss_index = faiss.IndexFlatIP(self.dimension)
                print(f"âœ… FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”: {self.dimension}ì°¨ì›")
            except Exception as e:
                print(f"âš ï¸  FAISS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}, Numpyë¡œ ëŒ€ì²´")
                self.faiss_index = None

        print(f"ğŸ“Š ë²¡í„° ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ ({self.dimension}ì°¨ì›)")

    def save_index(self, filepath: Optional[str] = None):
        """ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ì— ì €ì¥"""
        if filepath is None:
            filepath = self.index_dir / "echo_vector_index.json"

        index_data = {
            "dimension": self.dimension,
            "metadata_index": self.metadata_index,
            "capsule_mappings": self.capsule_mappings,
            "search_config": self.search_config,
            "created_at": datetime.now().isoformat(),
            "total_vectors": len(self.metadata_index),
        }

        # Numpy ì¸ë±ìŠ¤ ì €ì¥
        if self.numpy_index is not None:
            np.save(self.index_dir / "numpy_index.npy", self.numpy_index)

        # FAISS ì¸ë±ìŠ¤ ì €ì¥
        if self.faiss_index is not None:
            faiss.write_index(self.faiss_index, str(self.index_dir / "faiss_index.bin"))

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(index_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ ë²¡í„° ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {filepath}")

    def _load_existing_index(self):
        """ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ"""
        index_file = self.index_dir / "echo_vector_index.json"
        if not index_file.exists():
            return

        try:
            with open(index_file, "r", encoding="utf-8") as f:
                index_data = json.load(f)

            self.dimension = index_data["dimension"]
            self.metadata_index = index_data["metadata_index"]
            self.capsule_mappings = index_data["capsule_mappings"]
            self.search_config.update(index_data.get("search_config", {}))

            # Numpy ì¸ë±ìŠ¤ ë¡œë“œ
            numpy_file = self.index_dir / "numpy_index.npy"
            if numpy_file.exists():
                self.numpy_index = np.load(numpy_file)

            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            faiss_file = self.index_dir / "faiss_index.bin"
            if FAISS_AVAILABLE and faiss_file.exists():
                try:
                    self.faiss_index = faiss.read_index(str(faiss_file))
                except Exception as e:
                    print(f"âš ï¸  FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")

            print(f"ğŸ“– ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ: {len(self.metadata_index)}ê°œ ë²¡í„°")

        except Exception as e:
            print(f"âš ï¸  ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ í†µê³„ ë°˜í™˜"""
        stats = {
            "total_vectors": len(self.metadata_index),
            "dimension": self.dimension,
            "faiss_available": FAISS_AVAILABLE,
            "using_faiss": self.faiss_index is not None,
            "capsule_count": len(self.capsule_mappings),
            "search_config": self.search_config,
        }

        # ì‹œê·¸ë‹ˆì²˜ë³„ ë¶„í¬
        signature_counts = {}
        for metadata in self.metadata_index:
            sig = metadata.get("signature", "unknown")
            signature_counts[sig] = signature_counts.get(sig, 0) + 1
        stats["signature_distribution"] = signature_counts

        return stats


# ì „ì—­ ê²€ìƒ‰ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
vector_search_engine = EchoVectorSearchEngine()


# í¸ì˜ í•¨ìˆ˜ë“¤
def search_capsules(
    query: str,
    signature: str = "Echo-Aurora",
    top_k: int = 5,
    context: Dict[str, Any] = None,
) -> List[Dict[str, Any]]:
    """ìº¡ìŠ ê²€ìƒ‰ ë‹¨ì¶• í•¨ìˆ˜"""
    return vector_search_engine.search(query, signature, top_k, context)


def add_capsule(
    capsule_id: str,
    content: str,
    signature: str = "Echo-Aurora",
    metadata: Dict[str, Any] = None,
) -> int:
    """ìº¡ìŠ ì¶”ê°€ ë‹¨ì¶• í•¨ìˆ˜"""
    return vector_search_engine.add_capsule_vector(
        capsule_id, content, signature, metadata
    )


# CLI í…ŒìŠ¤íŠ¸
def main():
    print("ğŸ§­ EchoVectorSearch Engine CLI í…ŒìŠ¤íŠ¸")

    # í…ŒìŠ¤íŠ¸ ìº¡ìŠë“¤ ì¶”ê°€
    test_capsules = [
        {
            "id": "capsule_busan_senior",
            "content": "ë¶€ì‚° ê¸ˆì •êµ¬ì˜ ë…¸ì¸ ëŒë´„ ì¢…í•© ì„œë¹„ìŠ¤ëŠ” 1ì¼ 2ì‹œê°„ ì´ìƒ ì œê³µë˜ë©°, ë§Œ 65ì„¸ ì´ìƒ ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.",
            "signature": "Echo-Companion",
            "metadata": {
                "tags": ["ë…¸ì¸ë³µì§€", "ë¶€ì‚°", "ëŒë´„"],
                "topic": "social_policy",
            },
        },
        {
            "id": "capsule_ai_ethics",
            "content": "AI ì‹œìŠ¤í…œì˜ íˆ¬ëª…ì„±ê³¼ ê³µì •ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            "signature": "Echo-Sage",
            "metadata": {"tags": ["AI", "ìœ¤ë¦¬", "ê°€ì´ë“œë¼ì¸"], "topic": "ai_policy"},
        },
        {
            "id": "capsule_climate_action",
            "content": "ê¸°í›„ ë³€í™”ì— ëŒ€ì‘í•˜ê¸° ìœ„í•œ íƒ„ì†Œ ì¤‘ë¦½ ì •ì±…ê³¼ ì¬ìƒì—ë„ˆì§€ ì „í™˜ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.",
            "signature": "Echo-Phoenix",
            "metadata": {"tags": ["ê¸°í›„", "íƒ„ì†Œì¤‘ë¦½", "ì •ì±…"], "topic": "environment"},
        },
        {
            "id": "capsule_community_care",
            "content": "ì§€ì—­ì‚¬íšŒ ê¸°ë°˜ì˜ ëŒë´„ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì¶•í•˜ì—¬ ì·¨ì•½ê³„ì¸µì„ ì§€ì›í•´ì•¼ í•©ë‹ˆë‹¤.",
            "signature": "Echo-Aurora",
            "metadata": {"tags": ["ì§€ì—­ì‚¬íšŒ", "ëŒë´„", "ì§€ì›"], "topic": "community"},
        },
    ]

    print("\nğŸ“¦ í…ŒìŠ¤íŠ¸ ìº¡ìŠë“¤ ì¶”ê°€:")
    for capsule in test_capsules:
        vector_id = add_capsule(
            capsule["id"], capsule["content"], capsule["signature"], capsule["metadata"]
        )
        print(f"  âœ… {capsule['id']} â†’ ë²¡í„° ID: {vector_id}")

    # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ë“¤
    test_queries = [
        ("ì–´ë¥´ì‹  ë³µì§€ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", "Echo-Companion"),
        ("AI ê´€ë ¨ ì •ì±…ì´ í•„ìš”í•´ìš”", "Echo-Sage"),
        ("í™˜ê²½ ë³´í˜¸ ë°©ì•ˆì„ ì°¾ê³  ìˆì–´ìš”", "Echo-Phoenix"),
        ("ì§€ì—­ ê³µë™ì²´ ì§€ì›ì±…ì€?", "Echo-Aurora"),
    ]

    print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰:")
    for query, signature in test_queries:
        results = search_capsules(query, signature, top_k=3)
        print(f"\n  Q: '{query}' ({signature})")

        if results:
            for result in results:
                capsule_id = result["metadata"]["capsule_id"]
                similarity = result["similarity"]
                preview = result["metadata"]["content_preview"]
                print(f"    ğŸ¯ {capsule_id}: {similarity:.3f} - {preview[:50]}...")
        else:
            print("    âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

    # ì¸ë±ìŠ¤ í†µê³„
    print("\nğŸ“Š ì¸ë±ìŠ¤ í†µê³„:")
    stats = vector_search_engine.get_stats()
    print(f"  ì´ ë²¡í„°: {stats['total_vectors']}")
    print(f"  ì°¨ì›: {stats['dimension']}")
    print(f"  FAISS ì‚¬ìš©: {stats['using_faiss']}")
    print(f"  ì‹œê·¸ë‹ˆì²˜ ë¶„í¬: {stats['signature_distribution']}")

    # ì¸ë±ìŠ¤ ì €ì¥
    vector_search_engine.save_index()
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
