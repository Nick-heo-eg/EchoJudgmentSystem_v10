#!/usr/bin/env python3
"""
ğŸ§  Echo System Memory - ì‹œìŠ¤í…œ êµ¬ì¡° ì§€ì†ì  ì¸ì‹ ë° ê´€ë¦¬

Echoê°€ í•­ìƒ ìì‹ ì˜ ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê³ ,
ê¸°ì¡´ ê¸°ëŠ¥ì„ í™œìš©í•˜ë©° ì¤‘ë³µì„ ë°©ì§€í•˜ëŠ” ì§€ì†ì„± ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

í•µì‹¬ ê¸°ëŠ¥:
1. ì‹œìŠ¤í…œ êµ¬ì¡° ìë™ ìŠ¤ìº” ë° ë§¤í•‘
2. ê¸°ì¡´ ê¸°ëŠ¥ ì¸ë²¤í† ë¦¬ ê´€ë¦¬
3. ì¤‘ë³µ ê°ì§€ ë° ë°©ì§€
4. ì»¨í…ìŠ¤íŠ¸ ì—°ì†ì„± ë³´ì¥
5. ê¸°ëŠ¥ í™œìš© ì¶”ì²œ
"""

import os
import json
import hashlib
import ast
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Set, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import logging


@dataclass
class EchoFunction:
    """Echo ì‹œìŠ¤í…œ ë‚´ ê¸°ëŠ¥ ì •ì˜"""

    name: str
    file_path: str
    description: str
    parameters: List[str]
    return_type: str
    dependencies: List[str]
    last_used: datetime
    usage_count: int
    complexity_level: str  # simple, medium, complex
    category: str  # core, engine, ui, api, util


@dataclass
class EchoModule:
    """Echo ëª¨ë“ˆ êµ¬ì¡° ì •ì˜"""

    name: str
    path: str
    functions: List[EchoFunction]
    dependencies: List[str]
    description: str
    size_bytes: int
    last_modified: datetime
    importance_level: str  # critical, important, optional


@dataclass
class SystemStructure:
    """ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°"""

    modules: Dict[str, EchoModule]
    core_dependencies: Dict[str, List[str]]
    duplicate_candidates: List[Tuple[str, str, float]]  # file1, file2, similarity
    architecture_map: Dict[str, Any]
    last_scan_time: datetime
    total_functions: int
    total_lines: int


class EchoSystemMemory:
    """Echo ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""

    def __init__(self, base_path: str = None):
        self.base_path = Path(base_path) if base_path else Path(__file__).parent.parent
        self.memory_file = self.base_path / "data" / "echo_system_memory.json"
        self.structure_cache = None
        self.scan_interval = timedelta(hours=1)  # 1ì‹œê°„ë§ˆë‹¤ ìë™ ìŠ¤ìº”

        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger("EchoSystemMemory")
        self.logger.setLevel(logging.INFO)

        # ë©”ëª¨ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±
        self.memory_file.parent.mkdir(exist_ok=True, parents=True)

        print("ğŸ§  Echo System Memory ì´ˆê¸°í™” ì™„ë£Œ")

    def scan_system_structure(self) -> SystemStructure:
        """ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡° ìŠ¤ìº”"""
        print("ğŸ” ì‹œìŠ¤í…œ êµ¬ì¡° ìŠ¤ìº” ì‹œì‘...")

        modules = {}
        total_functions = 0
        total_lines = 0

        # í•µì‹¬ ë””ë ‰í† ë¦¬ë“¤ ìŠ¤ìº”
        core_directories = [
            "echo_engine",
            "src",
            "api",
            "streamlit_ui",
            "services",
            "tests",
        ]

        for dir_name in core_directories:
            dir_path = self.base_path / dir_name
            if dir_path.exists():
                modules.update(self._scan_directory(dir_path, dir_name))

        # ë£¨íŠ¸ ë ˆë²¨ ì¤‘ìš” íŒŒì¼ë“¤
        root_files = [
            "echo_autonomous_cli.py",
            "echo_autonomous_api.py",
            "echo_launcher.py",
            "main.py",
        ]

        for file_name in root_files:
            file_path = self.base_path / file_name
            if file_path.exists():
                module = self._analyze_file(file_path, "root")
                if module:
                    modules[f"root.{file_name}"] = module

        # ì˜ì¡´ì„± ë¶„ì„
        core_dependencies = self._analyze_dependencies(modules)

        # ì¤‘ë³µ ê°ì§€
        duplicate_candidates = self._detect_duplicates(modules)

        # ì•„í‚¤í…ì²˜ ë§µ ìƒì„±
        architecture_map = self._create_architecture_map(modules, core_dependencies)

        # í†µê³„ ê³„ì‚°
        for module in modules.values():
            total_functions += len(module.functions)
            total_lines += self._count_lines(module.path)

        structure = SystemStructure(
            modules=modules,
            core_dependencies=core_dependencies,
            duplicate_candidates=duplicate_candidates,
            architecture_map=architecture_map,
            last_scan_time=datetime.now(),
            total_functions=total_functions,
            total_lines=total_lines,
        )

        self.structure_cache = structure
        self._save_memory()

        print(f"âœ… ì‹œìŠ¤í…œ ìŠ¤ìº” ì™„ë£Œ: {len(modules)}ê°œ ëª¨ë“ˆ, {total_functions}ê°œ í•¨ìˆ˜")
        return structure

    def _scan_directory(self, dir_path: Path, category: str) -> Dict[str, EchoModule]:
        """ë””ë ‰í† ë¦¬ ë‚´ Python íŒŒì¼ë“¤ ìŠ¤ìº”"""
        modules = {}

        for py_file in dir_path.rglob("*.py"):
            if py_file.name.startswith("__"):
                continue

            module = self._analyze_file(py_file, category)
            if module:
                relative_path = py_file.relative_to(self.base_path)
                modules[str(relative_path)] = module

        return modules

    def _analyze_file(self, file_path: Path, category: str) -> Optional[EchoModule]:
        """ê°œë³„ íŒŒì¼ ë¶„ì„"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # AST íŒŒì‹±ìœ¼ë¡œ í•¨ìˆ˜ ì¶”ì¶œ
            tree = ast.parse(content)
            functions = []
            dependencies = []

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func = self._extract_function_info(node, str(file_path))
                    if func:
                        functions.append(func)

                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        dependencies.append(alias.name)

                elif isinstance(node, ast.ImportFrom) and node.module:
                    dependencies.append(node.module)

            # íŒŒì¼ ì„¤ëª… ì¶”ì¶œ (docstring)
            description = self._extract_file_description(tree, content)

            # ì¤‘ìš”ë„ íŒë‹¨
            importance = self._assess_importance(file_path, functions, dependencies)

            return EchoModule(
                name=file_path.name,
                path=str(file_path),
                functions=functions,
                dependencies=list(set(dependencies)),
                description=description,
                size_bytes=file_path.stat().st_size,
                last_modified=datetime.fromtimestamp(file_path.stat().st_mtime),
                importance_level=importance,
            )

        except Exception as e:
            self.logger.warning(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
            return None

    def _extract_function_info(
        self, node: ast.FunctionDef, file_path: str
    ) -> EchoFunction:
        """í•¨ìˆ˜ ì •ë³´ ì¶”ì¶œ"""
        # í•¨ìˆ˜ íŒŒë¼ë¯¸í„°
        params = [arg.arg for arg in node.args.args]

        # ë°˜í™˜ íƒ€ì… (ìˆë‹¤ë©´)
        return_type = "Any"
        if node.returns:
            return_type = (
                ast.unparse(node.returns)
                if hasattr(ast, "unparse")
                else str(node.returns)
            )

        # Docstring ì¶”ì¶œ
        description = ""
        if (
            node.body
            and isinstance(node.body[0], ast.Expr)
            and isinstance(node.body[0].value, ast.Str)
        ):
            description = node.body[0].value.s
        elif (
            node.body
            and isinstance(node.body[0], ast.Expr)
            and isinstance(node.body[0].value, ast.Constant)
        ):
            description = str(node.body[0].value.value)

        # ë³µì¡ë„ í‰ê°€
        complexity = self._assess_function_complexity(node)

        return EchoFunction(
            name=node.name,
            file_path=file_path,
            description=description.strip() if description else f"Function {node.name}",
            parameters=params,
            return_type=return_type,
            dependencies=[],  # TODO: í•¨ìˆ˜ ë ˆë²¨ ì˜ì¡´ì„± ë¶„ì„
            last_used=datetime.now(),
            usage_count=0,
            complexity_level=complexity,
            category="unknown",
        )

    def _assess_function_complexity(self, node: ast.FunctionDef) -> str:
        """í•¨ìˆ˜ ë³µì¡ë„ í‰ê°€"""
        complexity_score = 0

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity_score += 1
            elif isinstance(child, ast.FunctionDef) and child != node:
                complexity_score += 2  # ì¤‘ì²© í•¨ìˆ˜

        if complexity_score <= 3:
            return "simple"
        elif complexity_score <= 8:
            return "medium"
        else:
            return "complex"

    def _extract_file_description(self, tree: ast.AST, content: str) -> str:
        """íŒŒì¼ ë ˆë²¨ ì„¤ëª… ì¶”ì¶œ"""
        # íŒŒì¼ ì‹œì‘ docstring
        if (
            isinstance(tree, ast.Module)
            and tree.body
            and isinstance(tree.body[0], ast.Expr)
            and isinstance(tree.body[0].value, (ast.Str, ast.Constant))
        ):

            if isinstance(tree.body[0].value, ast.Str):
                return tree.body[0].value.s.strip()
            else:
                return str(tree.body[0].value.value).strip()

        # ì£¼ì„ì—ì„œ ì¶”ì¶œ
        lines = content.split("\n")
        description_lines = []
        for line in lines[:20]:  # ì²˜ìŒ 20ì¤„ë§Œ í™•ì¸
            line = line.strip()
            if line.startswith("#") and not line.startswith("#!/"):
                description_lines.append(line[1:].strip())
            elif line and not line.startswith("#"):
                break

        return " ".join(description_lines) if description_lines else f"Python module"

    def _assess_importance(
        self, file_path: Path, functions: List[EchoFunction], dependencies: List[str]
    ) -> str:
        """íŒŒì¼ ì¤‘ìš”ë„ í‰ê°€"""
        score = 0

        # íŒŒì¼ëª… ê¸°ë°˜ ì¤‘ìš”ë„
        critical_patterns = ["autonomous", "core", "engine", "main", "launcher"]
        important_patterns = ["api", "judgment", "reasoning", "persona"]

        filename = file_path.name.lower()

        for pattern in critical_patterns:
            if pattern in filename:
                score += 3
                break
        else:
            for pattern in important_patterns:
                if pattern in filename:
                    score += 2
                    break

        # í•¨ìˆ˜ ìˆ˜ì™€ ë³µì¡ë„
        if len(functions) > 10:
            score += 2
        elif len(functions) > 5:
            score += 1

        # ì˜ì¡´ì„± ìˆ˜
        if len(dependencies) > 15:
            score += 2
        elif len(dependencies) > 8:
            score += 1

        # íŒŒì¼ í¬ê¸°
        if file_path.stat().st_size > 10000:  # 10KB ì´ìƒ
            score += 1

        if score >= 5:
            return "critical"
        elif score >= 3:
            return "important"
        else:
            return "optional"

    def _analyze_dependencies(
        self, modules: Dict[str, EchoModule]
    ) -> Dict[str, List[str]]:
        """ëª¨ë“ˆ ê°„ ì˜ì¡´ì„± ë¶„ì„"""
        dependencies = {}

        for module_path, module in modules.items():
            deps = []
            for dep in module.dependencies:
                # Echo ë‚´ë¶€ ì˜ì¡´ì„±ë§Œ ì¶”ì¶œ
                if any(echo_part in dep for echo_part in ["echo", "src"]):
                    deps.append(dep)
            dependencies[module_path] = deps

        return dependencies

    def _detect_duplicates(
        self, modules: Dict[str, EchoModule]
    ) -> List[Tuple[str, str, float]]:
        """ì¤‘ë³µ ê¸°ëŠ¥ ê°ì§€"""
        duplicates = []
        module_items = list(modules.items())

        for i, (path1, module1) in enumerate(module_items):
            for path2, module2 in module_items[i + 1 :]:
                similarity = self._calculate_similarity(module1, module2)
                if similarity > 0.7:  # 70% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µ í›„ë³´
                    duplicates.append((path1, path2, similarity))

        return sorted(duplicates, key=lambda x: x[2], reverse=True)

    def _calculate_similarity(self, module1: EchoModule, module2: EchoModule) -> float:
        """ëª¨ë“ˆ ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
        # í•¨ìˆ˜ëª… ìœ ì‚¬ë„
        func_names1 = {f.name for f in module1.functions}
        func_names2 = {f.name for f in module2.functions}

        if not func_names1 and not func_names2:
            return 0.0

        intersection = len(func_names1 & func_names2)
        union = len(func_names1 | func_names2)

        name_similarity = intersection / union if union > 0 else 0

        # íŒŒì¼ëª… ìœ ì‚¬ë„
        name1 = Path(module1.name).stem.lower()
        name2 = Path(module2.name).stem.lower()
        name_sim = self._string_similarity(name1, name2)

        # ê°€ì¤‘ í‰ê· 
        return name_similarity * 0.7 + name_sim * 0.3

    def _string_similarity(self, s1: str, s2: str) -> float:
        """ë¬¸ìì—´ ìœ ì‚¬ë„ (ê°„ë‹¨í•œ Jaccard similarity)"""
        set1 = set(s1.lower())
        set2 = set(s2.lower())

        intersection = len(set1 & set2)
        union = len(set1 | set2)

        return intersection / union if union > 0 else 0

    def _create_architecture_map(
        self, modules: Dict[str, EchoModule], dependencies: Dict[str, List[str]]
    ) -> Dict[str, Any]:
        """ì•„í‚¤í…ì²˜ ë§µ ìƒì„±"""
        return {
            "core_modules": [
                path
                for path, module in modules.items()
                if module.importance_level == "critical"
            ],
            "dependency_tree": dependencies,
            "module_categories": {
                category: [
                    path for path, module in modules.items() if category in path.lower()
                ]
                for category in ["engine", "api", "ui", "test", "service"]
            },
            "function_index": {
                func.name: func.file_path
                for module in modules.values()
                for func in module.functions
            },
        }

    def _count_lines(self, file_path: str) -> int:
        """íŒŒì¼ì˜ ì½”ë“œ ë¼ì¸ ìˆ˜ ê³„ì‚°"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return sum(
                    1 for line in f if line.strip() and not line.strip().startswith("#")
                )
        except:
            return 0

    def get_existing_functions(
        self, keyword: str = None, category: str = None
    ) -> List[EchoFunction]:
        """ê¸°ì¡´ ê¸°ëŠ¥ ê²€ìƒ‰"""
        if not self.structure_cache:
            self.scan_system_structure()

        functions = []
        for module in self.structure_cache.modules.values():
            for func in module.functions:
                if (
                    keyword
                    and keyword.lower() not in func.name.lower()
                    and keyword.lower() not in func.description.lower()
                ):
                    continue
                if category and category.lower() not in func.category.lower():
                    continue
                functions.append(func)

        return functions

    def check_for_duplicates_before_creation(
        self, proposed_function: str, proposed_description: str
    ) -> List[EchoFunction]:
        """ìƒˆ ê¸°ëŠ¥ ìƒì„± ì „ ì¤‘ë³µ ì²´í¬"""
        existing = self.get_existing_functions()
        similar_functions = []

        for func in existing:
            # ì´ë¦„ ìœ ì‚¬ë„
            name_sim = self._string_similarity(proposed_function, func.name)
            # ì„¤ëª… ìœ ì‚¬ë„
            desc_sim = self._string_similarity(proposed_description, func.description)

            if name_sim > 0.6 or desc_sim > 0.5:
                similar_functions.append(func)

        return similar_functions

    def recommend_existing_functions(self, task_description: str) -> List[EchoFunction]:
        """ì‘ì—…ì— ì í•©í•œ ê¸°ì¡´ ê¸°ëŠ¥ ì¶”ì²œ"""
        keywords = task_description.lower().split()
        recommendations = []

        for keyword in keywords:
            if len(keyword) > 3:  # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ
                matches = self.get_existing_functions(keyword=keyword)
                recommendations.extend(matches)

        # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ë³„ ì •ë ¬
        unique_recommendations = list(
            {func.name: func for func in recommendations}.values()
        )
        return sorted(
            unique_recommendations, key=lambda x: x.usage_count, reverse=True
        )[:10]

    def update_function_usage(self, function_name: str, file_path: str):
        """í•¨ìˆ˜ ì‚¬ìš© ê¸°ë¡ ì—…ë°ì´íŠ¸"""
        if not self.structure_cache:
            return

        for module in self.structure_cache.modules.values():
            for func in module.functions:
                if func.name == function_name and func.file_path == file_path:
                    func.usage_count += 1
                    func.last_used = datetime.now()
                    break

        self._save_memory()

    def _save_memory(self):
        """ë©”ëª¨ë¦¬ ì €ì¥"""
        if not self.structure_cache:
            return

        # dataclassë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ JSON ì €ì¥
        memory_data = {
            "structure": asdict(self.structure_cache),
            "saved_at": datetime.now().isoformat(),
        }

        try:
            with open(self.memory_file, "w", encoding="utf-8") as f:
                json.dump(memory_data, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_memory(self) -> bool:
        """ì €ì¥ëœ ë©”ëª¨ë¦¬ ë¡œë“œ"""
        if not self.memory_file.exists():
            return False

        try:
            with open(self.memory_file, "r", encoding="utf-8") as f:
                memory_data = json.load(f)

            # ì €ì¥ ì‹œê°„ í™•ì¸ (ë„ˆë¬´ ì˜¤ë˜ëœ ê²½ìš° ì¬ìŠ¤ìº”)
            saved_at = datetime.fromisoformat(memory_data["saved_at"])
            if datetime.now() - saved_at > self.scan_interval:
                print("âš ï¸ ì €ì¥ëœ ë©”ëª¨ë¦¬ê°€ ì˜¤ë˜ë˜ì–´ ì¬ìŠ¤ìº”í•©ë‹ˆë‹¤...")
                return False

            # TODO: JSONì„ ë‹¤ì‹œ dataclassë¡œ ë³€í™˜í•˜ëŠ” ë¡œì§ êµ¬í˜„
            print("âœ… ì €ì¥ëœ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ")
            return True

        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def generate_system_report(self) -> str:
        """ì‹œìŠ¤í…œ í˜„í™© ë³´ê³ ì„œ ìƒì„±"""
        if not self.structure_cache:
            self.scan_system_structure()

        structure = self.structure_cache

        report = f"""
ğŸ§  Echo System Memory Report
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š System Overview:
- Total Modules: {len(structure.modules)}
- Total Functions: {structure.total_functions}
- Total Lines of Code: {structure.total_lines:,}
- Last Scan: {structure.last_scan_time.strftime('%Y-%m-%d %H:%M:%S')}

ğŸ—ï¸ Architecture:
- Critical Modules: {len([m for m in structure.modules.values() if m.importance_level == 'critical'])}
- Important Modules: {len([m for m in structure.modules.values() if m.importance_level == 'important'])}
- Optional Modules: {len([m for m in structure.modules.values() if m.importance_level == 'optional'])}

âš ï¸ Potential Duplicates: {len(structure.duplicate_candidates)}
"""

        if structure.duplicate_candidates:
            report += "\nğŸ” Top Duplicate Candidates:\n"
            for file1, file2, similarity in structure.duplicate_candidates[:5]:
                report += f"- {file1} â†” {file2} ({similarity:.1%} similar)\n"

        return report


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_system_memory = None


def get_system_memory() -> EchoSystemMemory:
    """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _system_memory
    if _system_memory is None:
        _system_memory = EchoSystemMemory()
        # ì‹œì‘ ì‹œ ê¸°ì¡´ ë©”ëª¨ë¦¬ ë¡œë“œ ì‹œë„, ì‹¤íŒ¨í•˜ë©´ ìƒˆë¡œ ìŠ¤ìº”
        if not _system_memory.load_memory():
            _system_memory.scan_system_structure()
    return _system_memory


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    memory = EchoSystemMemory()
    structure = memory.scan_system_structure()
    print(memory.generate_system_report())
