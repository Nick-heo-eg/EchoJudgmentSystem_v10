#!/usr/bin/env python3
"""
ğŸ”€ EchoJudgmentSystem v10 - Fusion Judgment Loop
ë‹¤ì¤‘ LLM ì œê³µì í†µí•© íŒë‹¨ ì‹œìŠ¤í…œ

ì§€ì› LLM:
- Claude (Anthropic)
- GPT (OpenAI)
- Perplexity
- Mistral (ë¡œì»¬/API)

í•µì‹¬ ê¸°ëŠ¥:
- EchoSignature ê¸°ë°˜ ë‹¤ì¤‘ íŒë‹¨ ìˆ˜ì§‘
- íŒë‹¨ ê²°ê³¼ ë³‘í•© ë° ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
- Config ê¸°ë°˜ LLM ì„ íƒ ë° í™œì„±í™”
- ì‹¤íŒ¨ ì‹œ í´ë°± ì²´ì¸ ì²˜ë¦¬
"""

import json
import time
import asyncio
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path

# Echo ì‹œìŠ¤í…œ í†µí•©
try:
    from .models.judgement import InputContext, JudgmentResult
    from .shared_judgment_logic import SharedJudgmentEngine, JudgmentMode

    ECHO_INTEGRATION_AVAILABLE = True
except ImportError as e:
    ECHO_INTEGRATION_AVAILABLE = False
    print(f"âš ï¸ Echo í†µí•© ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

# Mistral Wrapper í†µí•© (ë³„ë„ ì²˜ë¦¬)
try:
    from .mistral_wrapper import (
        OllamaMistralWrapper as MistralWrapper,
        MistralJudgmentRequest,
        get_mistral_wrapper,
    )

    MISTRAL_WRAPPER_AVAILABLE = True
except ImportError as e:
    MISTRAL_WRAPPER_AVAILABLE = False
    print(f"âš ï¸ Mistral Wrapper ë¡œë“œ ì‹¤íŒ¨: {e}")

    # Mock í´ë˜ìŠ¤ë“¤
    class EchoSignature:
        AURORA = "Echo-Aurora"
        PHOENIX = "Echo-Phoenix"
        SAGE = "Echo-Sage"
        COMPANION = "Echo-Companion"


# LLM ì œê³µìë³„ í†µí•© (ì„ íƒì )
try:
    from .claude_bridge import ClaudeBridge

    CLAUDE_AVAILABLE = True
except ImportError:
    CLAUDE_AVAILABLE = False

try:
    from .llm_bridge import LLMBridge  # GPT, Perplexity ë“±

    LLM_BRIDGE_AVAILABLE = True
except ImportError:
    LLM_BRIDGE_AVAILABLE = False


class LLMProvider(Enum):
    """LLM ì œê³µì"""

    CLAUDE = "claude"
    GPT = "gpt"
    PERPLEXITY = "perplexity"
    MISTRAL = "mistral"
    ECHO_INTERNAL = "echo_internal"  # Echo ë‚´ì¥ ì‹œìŠ¤í…œ


class FusionStrategy(Enum):
    """íŒë‹¨ ìœµí•© ì „ëµ"""

    MAJORITY_VOTE = "majority_vote"  # ë‹¤ìˆ˜ê²°
    WEIGHTED_AVERAGE = "weighted_average"  # ê°€ì¤‘ í‰ê· 
    CONFIDENCE_BASED = "confidence_based"  # ì‹ ë¢°ë„ ìš°ì„ 
    SIGNATURE_OPTIMIZED = "signature_optimized"  # ì‹œê·¸ë‹ˆì²˜ë³„ ìµœì í™”


@dataclass
class LLMJudgmentRequest:
    """LLM íŒë‹¨ ìš”ì²­"""

    input_text: str
    signature: EchoSignature
    context: Dict[str, Any] = field(default_factory=dict)
    providers: List[LLMProvider] = field(default_factory=list)
    fusion_strategy: FusionStrategy = FusionStrategy.WEIGHTED_AVERAGE
    require_reasoning: bool = True
    timeout: float = 30.0
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class LLMJudgmentResponse:
    """ê°œë³„ LLM íŒë‹¨ ì‘ë‹µ"""

    provider: LLMProvider
    judgment_text: str
    confidence: float
    processing_time: float
    reasoning_steps: List[str]
    emotion_detected: str
    strategy_suggested: str
    metadata: Dict[str, Any]
    error: Optional[str] = None


@dataclass
class FusedJudgmentResult:
    """ìœµí•©ëœ ìµœì¢… íŒë‹¨ ê²°ê³¼"""

    final_judgment: str
    overall_confidence: float
    signature_used: EchoSignature
    fusion_strategy: FusionStrategy
    individual_responses: List[LLMJudgmentResponse]
    processing_summary: Dict[str, Any]
    reasoning_synthesis: str
    metadata: Dict[str, Any]


class FusionJudgmentLoop:
    """ğŸ”€ ë‹¤ì¤‘ LLM ìœµí•© íŒë‹¨ ë£¨í”„"""

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}

        # LLM ì œê³µìë³„ ì´ˆê¸°í™”
        self.providers = {}
        self._initialize_providers()

        # ìœµí•© ì„¤ì •
        self.default_providers = self.config.get(
            "default_providers", [LLMProvider.MISTRAL, LLMProvider.ECHO_INTERNAL]
        )
        self.default_fusion_strategy = FusionStrategy(
            self.config.get("fusion_strategy", "weighted_average")
        )

        # í†µê³„
        self.stats = {
            "total_requests": 0,
            "successful_fusions": 0,
            "failed_fusions": 0,
            "provider_success_rates": {},
            "fusion_strategy_usage": {},
            "average_processing_time": 0.0,
        }

        print(f"ğŸ”€ Fusion Judgment Loop ì´ˆê¸°í™”")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì: {list(self.providers.keys())}")
        print(f"   ê¸°ë³¸ ìœµí•© ì „ëµ: {self.default_fusion_strategy.value}")

    def _initialize_providers(self):
        """LLM ì œê³µì ì´ˆê¸°í™”"""

        # Mistral ì´ˆê¸°í™”
        mistral_config = self.config.get("mistral", {})
        if mistral_config.get("enabled", True):
            try:
                mistral_mode = MistralMode(mistral_config.get("mode", "local"))
                self.providers[LLMProvider.MISTRAL] = get_mistral_wrapper(
                    mode=mistral_mode, config=mistral_config
                )
                print("âœ… Mistral ì œê³µì ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Mistral ì œê³µì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # Claude ì´ˆê¸°í™”
        claude_config = self.config.get("claude", {})
        if claude_config.get("enabled", False) and CLAUDE_AVAILABLE:
            try:
                self.providers[LLMProvider.CLAUDE] = ClaudeBridge(claude_config)
                print("âœ… Claude ì œê³µì ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Claude ì œê³µì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # GPT/Perplexity ì´ˆê¸°í™”
        if LLM_BRIDGE_AVAILABLE:
            gpt_config = self.config.get("gpt", {})
            if gpt_config.get("enabled", False):
                try:
                    self.providers[LLMProvider.GPT] = LLMBridge("gpt", gpt_config)
                    print("âœ… GPT ì œê³µì ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    print(f"âš ï¸ GPT ì œê³µì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

            perplexity_config = self.config.get("perplexity", {})
            if perplexity_config.get("enabled", False):
                try:
                    self.providers[LLMProvider.PERPLEXITY] = LLMBridge(
                        "perplexity", perplexity_config
                    )
                    print("âœ… Perplexity ì œê³µì ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    print(f"âš ï¸ Perplexity ì œê³µì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # Echo ë‚´ì¥ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if ECHO_INTEGRATION_AVAILABLE:
            try:
                self.providers[LLMProvider.ECHO_INTERNAL] = SharedJudgmentEngine()
                print("âœ… Echo ë‚´ì¥ ì œê³µì ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Echo ë‚´ì¥ ì œê³µì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def process_fusion_request(
        self, request: LLMJudgmentRequest
    ) -> FusedJudgmentResult:
        """ğŸ¯ ìœµí•© íŒë‹¨ ìš”ì²­ ì²˜ë¦¬"""

        start_time = time.time()
        self.stats["total_requests"] += 1

        try:
            # ì‚¬ìš©í•  ì œê³µì ê²°ì •
            active_providers = request.providers or self.default_providers
            available_providers = [p for p in active_providers if p in self.providers]

            if not available_providers:
                raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µìê°€ ì—†ìŠµë‹ˆë‹¤")

            print(f"ğŸ”€ ìœµí•© íŒë‹¨ ì‹œì‘: {len(available_providers)}ê°œ ì œê³µì")
            print(f"   ì‹œê·¸ë‹ˆì²˜: {request.signature.value}")
            print(f"   ì œê³µì: {[p.value for p in available_providers]}")

            # ë³‘ë ¬ íŒë‹¨ ì‹¤í–‰
            judgment_tasks = []
            for provider in available_providers:
                task = self._execute_provider_judgment(provider, request)
                judgment_tasks.append(task)

            # ëª¨ë“  íŒë‹¨ ì™„ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì ìš©)
            try:
                individual_responses = await asyncio.wait_for(
                    asyncio.gather(*judgment_tasks, return_exceptions=True),
                    timeout=request.timeout,
                )
            except asyncio.TimeoutError:
                print(f"âš ï¸ íŒë‹¨ íƒ€ì„ì•„ì›ƒ ({request.timeout}ì´ˆ)")
                individual_responses = [
                    self._create_timeout_response(p) for p in available_providers
                ]

            # ì„±ê³µí•œ ì‘ë‹µë§Œ í•„í„°ë§
            valid_responses = [
                resp
                for resp in individual_responses
                if isinstance(resp, LLMJudgmentResponse) and resp.error is None
            ]

            if not valid_responses:
                raise RuntimeError("ëª¨ë“  LLM ì œê³µìì—ì„œ íŒë‹¨ ì‹¤íŒ¨")

            # ìœµí•© ì „ëµ ì ìš©
            fusion_strategy = request.fusion_strategy or self.default_fusion_strategy
            fused_result = self._apply_fusion_strategy(
                valid_responses, fusion_strategy, request
            )

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["successful_fusions"] += 1
            self._update_provider_stats(individual_responses)
            self._update_stats(time.time() - start_time)

            print(f"âœ… ìœµí•© íŒë‹¨ ì™„ë£Œ (ì‹ ë¢°ë„: {fused_result.overall_confidence:.2f})")
            return fused_result

        except Exception as e:
            self.stats["failed_fusions"] += 1
            self._update_stats(time.time() - start_time)

            # ì—ëŸ¬ ì‹œ í´ë°± ì‘ë‹µ
            return self._create_fallback_fusion_result(
                request, str(e), time.time() - start_time
            )

    async def _execute_provider_judgment(
        self, provider: LLMProvider, request: LLMJudgmentRequest
    ) -> LLMJudgmentResponse:
        """ê°œë³„ ì œê³µì íŒë‹¨ ì‹¤í–‰"""

        start_time = time.time()

        try:
            provider_instance = self.providers[provider]

            if provider == LLMProvider.MISTRAL:
                # Mistral ì œê³µì ì²˜ë¦¬
                mistral_request = MistralJudgmentRequest(
                    input_text=request.input_text,
                    signature=request.signature,
                    context=request.context,
                    require_reasoning=request.require_reasoning,
                )

                mistral_response = await provider_instance.process_judgment_request(
                    mistral_request
                )

                return LLMJudgmentResponse(
                    provider=provider,
                    judgment_text=mistral_response.judgment_text,
                    confidence=mistral_response.confidence,
                    processing_time=mistral_response.processing_time,
                    reasoning_steps=mistral_response.reasoning_steps,
                    emotion_detected=mistral_response.emotion_detected,
                    strategy_suggested=mistral_response.strategy_suggested,
                    metadata=mistral_response.metadata,
                )

            elif provider == LLMProvider.CLAUDE:
                # Claude ì œê³µì ì²˜ë¦¬ (í–¥í›„ êµ¬í˜„)
                response_text = await provider_instance.process_judgment(
                    request.input_text, request.signature.value, request.context
                )

                return LLMJudgmentResponse(
                    provider=provider,
                    judgment_text=response_text,
                    confidence=0.8,  # Claude ê¸°ë³¸ ì‹ ë¢°ë„
                    processing_time=time.time() - start_time,
                    reasoning_steps=["Claude ê¸°ë°˜ ì¶”ë¡ "],
                    emotion_detected="balanced",
                    strategy_suggested="analytical",
                    metadata={"source": "claude_bridge"},
                )

            elif provider == LLMProvider.ECHO_INTERNAL:
                # Echo ë‚´ì¥ ì‹œìŠ¤í…œ ì²˜ë¦¬
                context = InputContext(text=request.input_text, source="fusion_loop")
                echo_result = provider_instance.evaluate_input(context)

                return LLMJudgmentResponse(
                    provider=provider,
                    judgment_text=getattr(echo_result, "reasoning", "Echo ë‚´ì¥ íŒë‹¨"),
                    confidence=getattr(echo_result, "confidence", 0.7),
                    processing_time=time.time() - start_time,
                    reasoning_steps=["Echo ë‚´ì¥ ì¶”ë¡ "],
                    emotion_detected=getattr(echo_result, "emotion", "neutral"),
                    strategy_suggested=getattr(echo_result, "strategy", "balanced"),
                    metadata=(
                        echo_result.metadata if hasattr(echo_result, "metadata") else {}
                    ),
                )

            else:
                # ê¸°íƒ€ ì œê³µì (GPT, Perplexity ë“±)
                response_text = await provider_instance.process_request(
                    request.input_text, request.signature.value
                )

                return LLMJudgmentResponse(
                    provider=provider,
                    judgment_text=response_text,
                    confidence=0.75,  # ê¸°ë³¸ ì‹ ë¢°ë„
                    processing_time=time.time() - start_time,
                    reasoning_steps=[f"{provider.value} ê¸°ë°˜ ì¶”ë¡ "],
                    emotion_detected="neutral",
                    strategy_suggested="balanced",
                    metadata={"source": provider.value},
                )

        except Exception as e:
            return LLMJudgmentResponse(
                provider=provider,
                judgment_text="",
                confidence=0.0,
                processing_time=time.time() - start_time,
                reasoning_steps=[],
                emotion_detected="error",
                strategy_suggested="fallback",
                metadata={},
                error=str(e),
            )

    def _apply_fusion_strategy(
        self,
        responses: List[LLMJudgmentResponse],
        strategy: FusionStrategy,
        request: LLMJudgmentRequest,
    ) -> FusedJudgmentResult:
        """ìœµí•© ì „ëµ ì ìš©"""

        if strategy == FusionStrategy.WEIGHTED_AVERAGE:
            return self._weighted_average_fusion(responses, request)
        elif strategy == FusionStrategy.CONFIDENCE_BASED:
            return self._confidence_based_fusion(responses, request)
        elif strategy == FusionStrategy.MAJORITY_VOTE:
            return self._majority_vote_fusion(responses, request)
        elif strategy == FusionStrategy.SIGNATURE_OPTIMIZED:
            return self._signature_optimized_fusion(responses, request)
        else:
            return self._weighted_average_fusion(responses, request)  # ê¸°ë³¸ê°’

    def _weighted_average_fusion(
        self, responses: List[LLMJudgmentResponse], request: LLMJudgmentRequest
    ) -> FusedJudgmentResult:
        """ê°€ì¤‘ í‰ê·  ìœµí•©"""

        # ì œê³µìë³„ ê°€ì¤‘ì¹˜
        provider_weights = {
            LLMProvider.MISTRAL: 0.4,
            LLMProvider.CLAUDE: 0.3,
            LLMProvider.ECHO_INTERNAL: 0.2,
            LLMProvider.GPT: 0.25,
            LLMProvider.PERPLEXITY: 0.2,
        }

        total_weight = 0
        weighted_confidence = 0
        judgment_parts = []
        reasoning_parts = []

        for response in responses:
            weight = provider_weights.get(response.provider, 0.2)
            confidence_weight = weight * response.confidence

            total_weight += weight
            weighted_confidence += confidence_weight

            judgment_parts.append(
                f"**{response.provider.value}**: {response.judgment_text}"
            )
            reasoning_parts.extend(response.reasoning_steps)

        # ìµœì¢… íŒë‹¨ í…ìŠ¤íŠ¸ êµ¬ì„±
        final_judgment = f"""ğŸ”€ ë‹¤ì¤‘ LLM ìœµí•© íŒë‹¨ ({request.signature.value}):

{chr(10).join(judgment_parts)}

ğŸ¯ ìœµí•© ê²°ë¡ :
{request.signature.value}ì˜ ê´€ì ì—ì„œ ìœ„ íŒë‹¨ë“¤ì„ ì¢…í•©í•˜ë©´, ê° LLMì˜ ê³ ìœ í•œ ê´€ì ì´ ì„œë¡œ ë³´ì™„ë˜ì–´ ë” ê· í˜•ì¡íŒ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤."""

        overall_confidence = (
            weighted_confidence / total_weight if total_weight > 0 else 0.5
        )

        reasoning_synthesis = (
            f"ê°€ì¤‘ í‰ê·  ìœµí•©: {len(responses)}ê°œ LLM ì œê³µìì˜ íŒë‹¨ì„ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ í†µí•©"
        )

        return FusedJudgmentResult(
            final_judgment=final_judgment,
            overall_confidence=overall_confidence,
            signature_used=request.signature,
            fusion_strategy=FusionStrategy.WEIGHTED_AVERAGE,
            individual_responses=responses,
            processing_summary={
                "total_providers": len(responses),
                "fusion_method": "weighted_average",
                "total_weight": total_weight,
            },
            reasoning_synthesis=reasoning_synthesis,
            metadata={
                "fusion_timestamp": datetime.now().isoformat(),
                "provider_weights": {
                    r.provider.value: provider_weights.get(r.provider, 0.2)
                    for r in responses
                },
            },
        )

    def _confidence_based_fusion(
        self, responses: List[LLMJudgmentResponse], request: LLMJudgmentRequest
    ) -> FusedJudgmentResult:
        """ì‹ ë¢°ë„ ê¸°ë°˜ ìœµí•© (ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ìš°ì„ )"""

        best_response = max(responses, key=lambda r: r.confidence)

        final_judgment = f"""ğŸ¯ ìµœê³  ì‹ ë¢°ë„ íŒë‹¨ ({request.signature.value}):

**ì£¼ íŒë‹¨ ({best_response.provider.value}, ì‹ ë¢°ë„: {best_response.confidence:.2f})**:
{best_response.judgment_text}

ğŸ“Š ê¸°íƒ€ íŒë‹¨ë“¤:
"""

        for response in responses:
            if response != best_response:
                final_judgment += f"- {response.provider.value} (ì‹ ë¢°ë„: {response.confidence:.2f}): {response.judgment_text[:100]}...\n"

        reasoning_synthesis = f"ì‹ ë¢°ë„ ê¸°ë°˜ ìœµí•©: {best_response.provider.value}ì˜ íŒë‹¨ì„ ì£¼ë¡œ ì±„íƒ (ì‹ ë¢°ë„: {best_response.confidence:.2f})"

        return FusedJudgmentResult(
            final_judgment=final_judgment,
            overall_confidence=best_response.confidence,
            signature_used=request.signature,
            fusion_strategy=FusionStrategy.CONFIDENCE_BASED,
            individual_responses=responses,
            processing_summary={
                "total_providers": len(responses),
                "fusion_method": "confidence_based",
                "selected_provider": best_response.provider.value,
            },
            reasoning_synthesis=reasoning_synthesis,
            metadata={
                "fusion_timestamp": datetime.now().isoformat(),
                "confidence_ranking": sorted(
                    [(r.provider.value, r.confidence) for r in responses],
                    key=lambda x: x[1],
                    reverse=True,
                ),
            },
        )

    def _majority_vote_fusion(
        self, responses: List[LLMJudgmentResponse], request: LLMJudgmentRequest
    ) -> FusedJudgmentResult:
        """ë‹¤ìˆ˜ê²° ìœµí•© (ê°ì •/ì „ëµ ê¸°ì¤€)"""

        # ê°ì • ë‹¤ìˆ˜ê²°
        emotions = [r.emotion_detected for r in responses]
        emotion_counts = {}
        for emotion in emotions:
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        majority_emotion = max(emotion_counts, key=emotion_counts.get)

        # ì „ëµ ë‹¤ìˆ˜ê²°
        strategies = [r.strategy_suggested for r in responses]
        strategy_counts = {}
        for strategy in strategies:
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
        majority_strategy = max(strategy_counts, key=strategy_counts.get)

        # ë‹¤ìˆ˜ê²° íŒë‹¨ êµ¬ì„±
        final_judgment = f"""ğŸ—³ï¸ ë‹¤ìˆ˜ê²° ìœµí•© íŒë‹¨ ({request.signature.value}):

**ë‹¤ìˆ˜ ì˜ê²¬**:
- ê°ì •: {majority_emotion} ({emotion_counts[majority_emotion]}/{len(responses)} ì œê³µì)
- ì „ëµ: {majority_strategy} ({strategy_counts[majority_strategy]}/{len(responses)} ì œê³µì)

**ì¢…í•© íŒë‹¨**:
"""

        # ë‹¤ìˆ˜ ì˜ê²¬ì— í•´ë‹¹í•˜ëŠ” íŒë‹¨ë“¤ ìš°ì„  í‘œì‹œ
        majority_judgments = [
            r
            for r in responses
            if r.emotion_detected == majority_emotion
            or r.strategy_suggested == majority_strategy
        ]

        for response in majority_judgments:
            final_judgment += f"- {response.provider.value}: {response.judgment_text}\n"

        average_confidence = sum(r.confidence for r in responses) / len(responses)
        reasoning_synthesis = (
            f"ë‹¤ìˆ˜ê²° ìœµí•©: ê°ì •({majority_emotion}), ì „ëµ({majority_strategy}) ê¸°ì¤€"
        )

        return FusedJudgmentResult(
            final_judgment=final_judgment,
            overall_confidence=average_confidence,
            signature_used=request.signature,
            fusion_strategy=FusionStrategy.MAJORITY_VOTE,
            individual_responses=responses,
            processing_summary={
                "total_providers": len(responses),
                "fusion_method": "majority_vote",
                "majority_emotion": majority_emotion,
                "majority_strategy": majority_strategy,
            },
            reasoning_synthesis=reasoning_synthesis,
            metadata={
                "fusion_timestamp": datetime.now().isoformat(),
                "emotion_votes": emotion_counts,
                "strategy_votes": strategy_counts,
            },
        )

    def _signature_optimized_fusion(
        self, responses: List[LLMJudgmentResponse], request: LLMJudgmentRequest
    ) -> FusedJudgmentResult:
        """ì‹œê·¸ë‹ˆì²˜ ìµœì í™” ìœµí•©"""

        # ì‹œê·¸ë‹ˆì²˜ë³„ ìµœì  ì œê³µì ë§¤í•‘
        signature_preferences = {
            EchoSignature.AURORA: [LLMProvider.MISTRAL, LLMProvider.CLAUDE],
            EchoSignature.PHOENIX: [LLMProvider.GPT, LLMProvider.MISTRAL],
            EchoSignature.SAGE: [LLMProvider.CLAUDE, LLMProvider.ECHO_INTERNAL],
            EchoSignature.COMPANION: [LLMProvider.MISTRAL, LLMProvider.ECHO_INTERNAL],
        }

        preferred_providers = signature_preferences.get(request.signature, [])

        # ì„ í˜¸ ì œê³µì ìš°ì„  ì„ íƒ
        preferred_responses = [
            r for r in responses if r.provider in preferred_providers
        ]
        if not preferred_responses:
            preferred_responses = responses  # í´ë°±

        # ì„ í˜¸ ì œê³µìë“¤ì˜ ê°€ì¤‘ í‰ê· 
        total_weight = 0
        weighted_confidence = 0
        judgment_parts = []

        for response in preferred_responses:
            weight = 1.0 if response.provider in preferred_providers[:2] else 0.7
            total_weight += weight
            weighted_confidence += weight * response.confidence
            judgment_parts.append(
                f"**{response.provider.value}**: {response.judgment_text}"
            )

        final_judgment = f"""â­ {request.signature.value} ìµœì í™” ìœµí•©:

{chr(10).join(judgment_parts)}

ğŸ¯ ì‹œê·¸ë‹ˆì²˜ íŠ¹í™” ê²°ë¡ :
{request.signature.value}ì— ìµœì í™”ëœ ì œê³µìë“¤ì˜ íŒë‹¨ì„ ìš°ì„  ë°˜ì˜í•˜ì—¬ ì‹œê·¸ë‹ˆì²˜ íŠ¹ì„±ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤."""

        overall_confidence = (
            weighted_confidence / total_weight if total_weight > 0 else 0.5
        )
        reasoning_synthesis = (
            f"ì‹œê·¸ë‹ˆì²˜ ìµœì í™”: {request.signature.value}ì— ìµœì ì¸ ì œê³µì ìš°ì„  ë°˜ì˜"
        )

        return FusedJudgmentResult(
            final_judgment=final_judgment,
            overall_confidence=overall_confidence,
            signature_used=request.signature,
            fusion_strategy=FusionStrategy.SIGNATURE_OPTIMIZED,
            individual_responses=responses,
            processing_summary={
                "total_providers": len(responses),
                "fusion_method": "signature_optimized",
                "preferred_providers": [p.value for p in preferred_providers],
            },
            reasoning_synthesis=reasoning_synthesis,
            metadata={
                "fusion_timestamp": datetime.now().isoformat(),
                "signature_preferences": [p.value for p in preferred_providers],
            },
        )

    def _create_timeout_response(self, provider: LLMProvider) -> LLMJudgmentResponse:
        """íƒ€ì„ì•„ì›ƒ ì‘ë‹µ ìƒì„±"""
        return LLMJudgmentResponse(
            provider=provider,
            judgment_text="",
            confidence=0.0,
            processing_time=0.0,
            reasoning_steps=[],
            emotion_detected="timeout",
            strategy_suggested="retry",
            metadata={},
            error="íŒë‹¨ íƒ€ì„ì•„ì›ƒ",
        )

    def _create_fallback_fusion_result(
        self, request: LLMJudgmentRequest, error_msg: str, processing_time: float
    ) -> FusedJudgmentResult:
        """í´ë°± ìœµí•© ê²°ê³¼ ìƒì„±"""

        fallback_judgment = f"""âš ï¸ {request.signature.value} ì•ˆì „ ëª¨ë“œ ìœµí•© íŒë‹¨:

ì‹œìŠ¤í…œ ì œì•½ìœ¼ë¡œ ì¸í•´ ì™„ì „í•œ ë‹¤ì¤‘ LLM ìœµí•©ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ì ì¸ ê´€ì ì—ì„œ "{request.input_text}"ì— ëŒ€í•´ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.

âš ï¸ ì˜¤ë¥˜: {error_msg}"""

        return FusedJudgmentResult(
            final_judgment=fallback_judgment,
            overall_confidence=0.3,
            signature_used=request.signature,
            fusion_strategy=request.fusion_strategy or self.default_fusion_strategy,
            individual_responses=[],
            processing_summary={
                "total_providers": 0,
                "fusion_method": "fallback",
                "error": error_msg,
            },
            reasoning_synthesis="ì•ˆì „ ëª¨ë“œ í´ë°±",
            metadata={
                "fallback_mode": True,
                "processing_time": processing_time,
                "error": error_msg,
            },
        )

    def _update_provider_stats(
        self, responses: List[Union[LLMJudgmentResponse, Exception]]
    ):
        """ì œê³µìë³„ í†µê³„ ì—…ë°ì´íŠ¸"""
        for response in responses:
            if isinstance(response, LLMJudgmentResponse):
                provider = response.provider.value
                if provider not in self.stats["provider_success_rates"]:
                    self.stats["provider_success_rates"][provider] = {
                        "success": 0,
                        "total": 0,
                    }

                self.stats["provider_success_rates"][provider]["total"] += 1
                if response.error is None:
                    self.stats["provider_success_rates"][provider]["success"] += 1

    def _update_stats(self, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        total_time = self.stats.get("total_processing_time", 0) + processing_time
        total_requests = self.stats["total_requests"]
        self.stats["average_processing_time"] = (
            total_time / total_requests if total_requests > 0 else 0
        )
        self.stats["total_processing_time"] = total_time

    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        return {
            **self.stats,
            "success_rate": (
                self.stats["successful_fusions"]
                / max(self.stats["total_requests"], 1)
                * 100
            ),
            "available_providers": list(self.providers.keys()),
            "default_providers": [p.value for p in self.default_providers],
            "default_fusion_strategy": self.default_fusion_strategy.value,
        }

    def to_judgment_result(
        self, fused_result: FusedJudgmentResult, original_context: InputContext = None
    ) -> JudgmentResult:
        """Echo JudgmentResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

        if not ECHO_INTEGRATION_AVAILABLE:
            raise RuntimeError("Echo í†µí•©ì´ í•„ìš”í•˜ì§€ë§Œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return JudgmentResult(
            input_text=original_context.text if original_context else "",
            judgment=fused_result.final_judgment,
            confidence=fused_result.overall_confidence,
            reasoning=fused_result.reasoning_synthesis,
            strategy="fusion_integrated",
            emotion="multi_dimensional",
            metadata={
                "source": "fusion_judgment_loop",
                "signature": fused_result.signature_used.value,
                "fusion_strategy": fused_result.fusion_strategy.value,
                "providers_used": [
                    r.provider.value for r in fused_result.individual_responses
                ],
                "processing_summary": fused_result.processing_summary,
                "fusion_metadata": fused_result.metadata,
            },
        )


# í¸ì˜ í•¨ìˆ˜ë“¤
async def create_fusion_judgment(
    input_text: str,
    signature: EchoSignature = EchoSignature.AURORA,
    providers: List[LLMProvider] = None,
    strategy: FusionStrategy = FusionStrategy.WEIGHTED_AVERAGE,
) -> FusedJudgmentResult:
    """ë¹ ë¥¸ ìœµí•© íŒë‹¨ ìƒì„±"""

    loop = FusionJudgmentLoop()
    request = LLMJudgmentRequest(
        input_text=input_text,
        signature=signature,
        providers=providers,
        fusion_strategy=strategy,
    )

    return await loop.process_fusion_request(request)


# ì „ì—­ ìœµí•© ë£¨í”„ ì¸ìŠ¤í„´ìŠ¤
_fusion_loop = None


def get_fusion_judgment_loop(config: Dict[str, Any] = None) -> FusionJudgmentLoop:
    """ìœµí•© íŒë‹¨ ë£¨í”„ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _fusion_loop
    if _fusion_loop is None:
        _fusion_loop = FusionJudgmentLoop(config)
    return _fusion_loop
