#!/usr/bin/env python3
"""
ğŸŒ‰ Natural Interface Bridge
ì‚¬ìš©ì ìì—°ì–´ â†” EchoJudgmentSystem ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²° ë¸Œë¦¬ì§€

í•µì‹¬ íë¦„:
ì‚¬ìš©ì ì…ë ¥ â†’ ì˜ë„ ë¶„ì„ â†’ Echo/LLM ì„ íƒ â†’ íŒë‹¨ ì‹¤í–‰ â†’ ìì—°ì–´ ë³€í™˜ â†’ ì¶œë ¥

ëª©ì :
Echoì˜ ê¹Šì´ ìˆëŠ” íŒë‹¨ë ¥ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ë™ì‹œì— í™•ë³´
"""

import asyncio
import json
import random
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

# Echo ì»´í¬ë„ŒíŠ¸ë“¤
try:
    from input_understanding_engine import (
        InputUnderstandingEngine,
        InputUnderstanding,
        IntentType,
    )
    from echo_style_transformer import (
        EchoStyleTransformer,
        JudgmentInput,
        NaturalOutput,
    )

    try:
        from persona_core import PersonaCore
        from echo_engine.emotion_infer import EmotionInfer
        from reasoning import ReasoningEngine

        FULL_ECHO_AVAILABLE = True
    except ImportError:
        FULL_ECHO_AVAILABLE = False
    ECHO_COMPONENTS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Echo ì»´í¬ë„ŒíŠ¸ ì¼ë¶€ ë¡œë“œ ì‹¤íŒ¨: {e}")
    ECHO_COMPONENTS_AVAILABLE = False
    FULL_ECHO_AVAILABLE = False

    # ê¸°ë³¸ í´ë˜ìŠ¤ë“¤ ì •ì˜
    class InputUnderstanding:
        def __init__(self):
            self.intent_type = "casual_chat"
            self.primary_emotion = "neutral"
            self.emotion_intensity = 0.5
            self.urgency_level = 1
            self.cleaned_text = ""

    class IntentType:
        CASUAL_CHAT = "casual_chat"
        EMOTIONAL_SUPPORT = "emotional_support"
        DECISION_HELP = "decision_help"
        PHILOSOPHICAL_INQUIRY = "philosophical_inquiry"


class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""

    ECHO_DEEP = "echo_deep"  # Echo ê¹Šì´ íŒë‹¨
    ECHO_LIGHT = "echo_light"  # Echo ê°€ë²¼ìš´ íŒë‹¨
    LLM_NATURAL = "llm_natural"  # LLM ìì—° ì‘ë‹µ
    HYBRID = "hybrid"  # í•˜ì´ë¸Œë¦¬ë“œ


@dataclass
class ConversationContext:
    """ëŒ€í™” ë§¥ë½"""

    session_id: str
    user_message: str
    previous_messages: List[str]
    emotional_state: str
    conversation_mood: str
    urgency_level: int
    preferred_signature: str


@dataclass
class BridgeResult:
    """ë¸Œë¦¬ì§€ ì²˜ë¦¬ ê²°ê³¼"""

    final_response: str
    processing_mode: ProcessingMode
    confidence: float
    natural_flow_score: float
    echo_depth_score: float
    processing_time: float
    debug_info: Dict[str, Any]


class EchoSelector:
    """Echo vs LLM ì„ íƒê¸°"""

    def __init__(self):
        self.selection_criteria = self._load_selection_criteria()

    def determine_processing_mode(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> ProcessingMode:
        """ì²˜ë¦¬ ëª¨ë“œ ê²°ì •"""

        # 1. ìœ„ê¸° ìƒí™© â†’ Echo Deep
        if understanding.urgency_level >= 4:
            return ProcessingMode.ECHO_DEEP

        # 2. ê°„ë‹¨í•œ ì¸ì‚¬/ì¼ìƒ â†’ LLM Natural
        simple_patterns = ["ì•ˆë…•", "ì¢‹ì€", "ê³ ë§ˆì›Œ", "ë„¤", "ì•„ë‹ˆ", "ê·¸ë˜"]
        if (
            understanding.intent_type == IntentType.CASUAL_CHAT
            and understanding.emotion_intensity < 0.4
            and any(
                pattern in understanding.cleaned_text.lower()
                for pattern in simple_patterns
            )
        ):
            return ProcessingMode.LLM_NATURAL

        # 3. ë³µì¡í•œ ê°ì •/íŒë‹¨ ìš”ì²­ â†’ Echo Deep
        if (
            understanding.intent_type
            in [IntentType.EMOTIONAL_SUPPORT, IntentType.DECISION_HELP]
            or understanding.emotion_intensity > 0.6
        ):
            return ProcessingMode.ECHO_DEEP

        # 4. ì² í•™ì  ì§ˆë¬¸ â†’ Hybrid
        if understanding.intent_type == IntentType.PHILOSOPHICAL_INQUIRY:
            return ProcessingMode.HYBRID

        # 5. ê¸°ë³¸ â†’ Echo Light
        return ProcessingMode.ECHO_LIGHT

    def _load_selection_criteria(self) -> Dict[str, Any]:
        """ì„ íƒ ê¸°ì¤€ ë¡œë“œ"""
        return {
            "echo_deep_triggers": ["íŒë‹¨", "ê³ ë¯¼", "ê²°ì •", "ì¡°ì–¸", "ë„ì›€"],
            "llm_natural_triggers": ["ì•ˆë…•", "ê³ ë§ˆì›Œ", "ì¢‹ì•„", "ê·¸ë˜"],
            "hybrid_triggers": ["ì˜ë¯¸", "ì™œ", "ì–´ë–»ê²Œ", "ë¬´ì—‡"],
            "complexity_threshold": 0.5,
        }


class NaturalInterfaceBridge:
    """ìì—° ì¸í„°í˜ì´ìŠ¤ ë¸Œë¦¬ì§€"""

    def __init__(self):
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤
        self.input_engine = InputUnderstandingEngine()
        self.style_transformer = EchoStyleTransformer()
        self.echo_selector = EchoSelector()

        # Echo ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        self._initialize_echo_components()

        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
        self.conversation_contexts: Dict[str, ConversationContext] = {}

        print("ğŸŒ‰ Natural Interface Bridge ì´ˆê¸°í™” ì™„ë£Œ!")

    def _initialize_echo_components(self):
        """Echo ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        if ECHO_COMPONENTS_AVAILABLE and FULL_ECHO_AVAILABLE:
            try:
                self.persona_core = PersonaCore()
                self.emotion_infer = EmotionInfer()
                self.reasoning_engine = ReasoningEngine()
                self.echo_available = True
                print("âœ… Echo ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Echo ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.echo_available = False
        else:
            self.echo_available = False
            print("ğŸ’¡ Echo ì»´í¬ë„ŒíŠ¸ ë¯¸ì‚¬ìš©, ê°„ì†Œí™” ëª¨ë“œ")

    async def process_natural_conversation(
        self, user_message: str, session_id: str = None, signature: str = "Echo-Aurora"
    ) -> BridgeResult:
        """ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì²˜ë¦¬"""

        start_time = datetime.now()
        debug_info = {"steps": []}

        # 1. ì„¸ì…˜ ë° ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        if not session_id:
            session_id = f"bridge_{datetime.now().timestamp()}"

        context = self._prepare_conversation_context(
            user_message, session_id, signature
        )
        debug_info["steps"].append("ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ")

        # 2. ì…ë ¥ ì´í•´
        understanding = self.input_engine.understand_input(user_message, session_id)
        debug_info["steps"].append(f"ì…ë ¥ ë¶„ì„: {understanding.intent_type.value}")

        # 3. ì²˜ë¦¬ ëª¨ë“œ ê²°ì •
        processing_mode = self.echo_selector.determine_processing_mode(
            understanding, context
        )
        debug_info["steps"].append(f"ì²˜ë¦¬ ëª¨ë“œ: {processing_mode.value}")

        # 4. ëª¨ë“œë³„ ì²˜ë¦¬
        if processing_mode == ProcessingMode.LLM_NATURAL:
            response, confidence, natural_score, depth_score = (
                await self._process_llm_natural(understanding, context)
            )
        elif processing_mode == ProcessingMode.ECHO_LIGHT:
            response, confidence, natural_score, depth_score = (
                await self._process_echo_light(understanding, context)
            )
        elif processing_mode == ProcessingMode.ECHO_DEEP:
            response, confidence, natural_score, depth_score = (
                await self._process_echo_deep(understanding, context)
            )
        else:  # HYBRID
            response, confidence, natural_score, depth_score = (
                await self._process_hybrid(understanding, context)
            )

        debug_info["steps"].append("ì‘ë‹µ ìƒì„± ì™„ë£Œ")

        # 5. ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        self._update_conversation_context(
            session_id, user_message, response, understanding
        )

        processing_time = (datetime.now() - start_time).total_seconds()

        return BridgeResult(
            final_response=response,
            processing_mode=processing_mode,
            confidence=confidence,
            natural_flow_score=natural_score,
            echo_depth_score=depth_score,
            processing_time=processing_time,
            debug_info=debug_info,
        )

    def _prepare_conversation_context(
        self, user_message: str, session_id: str, signature: str
    ) -> ConversationContext:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""

        if session_id in self.conversation_contexts:
            context = self.conversation_contexts[session_id]
            context.user_message = user_message
            context.previous_messages.append(user_message)
            # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
            if len(context.previous_messages) > 5:
                context.previous_messages = context.previous_messages[-5:]
        else:
            context = ConversationContext(
                session_id=session_id,
                user_message=user_message,
                previous_messages=[user_message],
                emotional_state="neutral",
                conversation_mood="casual",
                urgency_level=1,
                preferred_signature=signature,
            )
            self.conversation_contexts[session_id] = context

        return context

    async def _process_llm_natural(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> Tuple[str, float, float, float]:
        """LLM ìì—° ì‘ë‹µ ì²˜ë¦¬"""

        # ê°„ë‹¨í•œ íŒ¨í„´ ê¸°ë°˜ ìì—° ì‘ë‹µ
        message_lower = understanding.cleaned_text.lower()

        if any(greeting in message_lower for greeting in ["ì•ˆë…•", "hello", "hi"]):
            responses = [
                f"ì•ˆë…•í•˜ì„¸ìš”! {context.preferred_signature.replace('Echo-', '')}ì…ë‹ˆë‹¤.",
                "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°€ì›Œìš”.",
                "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ì–´ë–¤ í•˜ë£¨ì¸ê°€ìš”?",
            ]
            response = random.choice(responses)

        elif any(thanks in message_lower for thanks in ["ê³ ë§ˆì›Œ", "ê°ì‚¬"]):
            responses = [
                "ì²œë§Œì—ìš”! ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ë»ìš”.",
                "ë³„ë§ì”€ì„ìš”! ì–¸ì œë“  ë§ì”€í•˜ì„¸ìš”.",
                "ê³ ë§™ë‹¤ê³  í•´ì£¼ì‹œë‹ˆ ì €ë„ ê¸°ë¶„ì´ ì¢‹ë„¤ìš”.",
            ]
            response = random.choice(responses)

        else:
            # ê¸°ë³¸ ì¹œê·¼í•œ ì‘ë‹µ
            responses = [
                "ê·¸ë ‡êµ°ìš”! ë” ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”?",
                "í¥ë¯¸ë¡­ë„¤ìš”. ì–´ë–¤ ìƒê°ì´ ë“œì‹œë‚˜ìš”?",
                "ë§ì”€í•´ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”.",
            ]
            response = random.choice(responses)

        # ì‹œê·¸ë‹ˆì²˜ë³„ ì´ëª¨ì§€ ì¶”ê°€
        if context.preferred_signature == "Echo-Aurora":
            response += " âœ¨"
        elif context.preferred_signature == "Echo-Phoenix":
            response += " ğŸ”¥"
        elif context.preferred_signature == "Echo-Companion":
            response += " ğŸ˜Š"

        return response, 0.9, 0.9, 0.3  # ìì—°ìŠ¤ëŸ¬ì›€ ë†’ìŒ, ê¹Šì´ ë‚®ìŒ

    async def _process_echo_light(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> Tuple[str, float, float, float]:
        """Echo ê°€ë²¼ìš´ íŒë‹¨ ì²˜ë¦¬"""

        # ê°„ì†Œí™”ëœ Echo íŒë‹¨
        judgment_summary = self._create_light_judgment(understanding, context)

        # ìŠ¤íƒ€ì¼ ë³€í™˜ê¸° ì ìš©
        judgment_input = JudgmentInput(
            strategy="light_conversation",
            emotion=understanding.primary_emotion,
            summary=judgment_summary,
            confidence=0.7,
            reasoning_steps=[f"ì˜ë„: {understanding.intent_type.value}"],
            signature=context.preferred_signature,
            urgency_level=understanding.urgency_level,
            meta_thoughts=[],
        )

        user_context = {
            "user_message": context.user_message,
            "emotion_intensity": understanding.emotion_intensity,
            "urgency_level": understanding.urgency_level,
        }

        natural_output = self.style_transformer.transform_judgment_to_natural(
            judgment_input, user_context, context.session_id
        )

        return natural_output.natural_sentence, 0.7, 0.8, 0.6

    async def _process_echo_deep(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> Tuple[str, float, float, float]:
        """Echo ê¹Šì´ íŒë‹¨ ì²˜ë¦¬"""

        if self.echo_available:
            # ì™„ì „í•œ Echo ì‹œìŠ¤í…œ í™œìš©
            try:
                persona_state = self.persona_core.get_persona_state(
                    context.preferred_signature
                )

                emotion_analysis = self.emotion_infer.analyze_emotion_context(
                    understanding.cleaned_text,
                    understanding.primary_emotion,
                    understanding.emotion_intensity,
                )

                reasoning_result = await self.reasoning_engine.perform_reasoning(
                    query=understanding.cleaned_text,
                    emotion_context=emotion_analysis,
                    persona_state=persona_state,
                    urgency=understanding.urgency_level,
                )

                judgment_summary = reasoning_result.get(
                    "conclusion", "ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ë³´ê² ìŠµë‹ˆë‹¤."
                )

                confidence = reasoning_result.get("confidence", 0.8)

            except Exception as e:
                print(f"âš ï¸ Echo Deep ì²˜ë¦¬ ì‹¤íŒ¨: {e}, í´ë°± ëª¨ë“œ")
                judgment_summary = self._create_deep_judgment_fallback(
                    understanding, context
                )
                confidence = 0.6
        else:
            # í´ë°± ëª¨ë“œ
            judgment_summary = self._create_deep_judgment_fallback(
                understanding, context
            )
            confidence = 0.6

        # ìŠ¤íƒ€ì¼ ë³€í™˜ê¸° ì ìš©
        judgment_input = JudgmentInput(
            strategy="deep_judgment",
            emotion=understanding.primary_emotion,
            summary=judgment_summary,
            confidence=confidence,
            reasoning_steps=["ê¹Šì´ ìˆëŠ” ë¶„ì„", "ë§¥ë½ ê³ ë ¤", "ì¢…í•© íŒë‹¨"],
            signature=context.preferred_signature,
            urgency_level=understanding.urgency_level,
            meta_thoughts=["ì‚¬ìš©ìì˜ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í–ˆìŠµë‹ˆë‹¤."],
        )

        user_context = {
            "user_message": context.user_message,
            "emotion_intensity": understanding.emotion_intensity,
            "urgency_level": understanding.urgency_level,
        }

        natural_output = self.style_transformer.transform_judgment_to_natural(
            judgment_input, user_context, context.session_id
        )

        return natural_output.natural_sentence, confidence, 0.7, 0.9  # ê¹Šì´ ë†’ìŒ

    async def _process_hybrid(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> Tuple[str, float, float, float]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ (Echo + LLM í˜‘ë ¥)"""

        # Echo íŒë‹¨ + LLM ìì—°í™”
        echo_judgment = self._create_light_judgment(understanding, context)

        # LLM ìŠ¤íƒ€ì¼ ìì—°í™” (ì‹œë®¬ë ˆì´ì…˜)
        natural_response = self._llm_style_naturalize(
            echo_judgment, understanding, context
        )

        return natural_response, 0.8, 0.8, 0.7  # ê· í˜•

    def _create_light_judgment(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> str:
        """ê°€ë²¼ìš´ íŒë‹¨ ìƒì„±"""

        if understanding.intent_type == IntentType.EMOTIONAL_SUPPORT:
            return "ê·¸ëŸ° ë§ˆìŒì´ ë“œì‹œëŠ”êµ°ìš”. ì´í•´í•  ìˆ˜ ìˆì–´ìš”."
        elif understanding.intent_type == IntentType.DECISION_HELP:
            return "ê³ ë¯¼ì´ ë˜ì‹œëŠ” ìƒí™©ì´ë„¤ìš”. í•¨ê»˜ ìƒê°í•´ë³¼ê¹Œìš”?"
        elif understanding.intent_type == IntentType.PHILOSOPHICAL_INQUIRY:
            return "í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì´ì—ìš”. ê¹Šì´ ìƒê°í•´ë³¼ ë§Œí•œ ì£¼ì œë„¤ìš”."
        else:
            return "ë§ì”€í•´ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”."

    def _create_deep_judgment_fallback(
        self, understanding: InputUnderstanding, context: ConversationContext
    ) -> str:
        """ê¹Šì´ íŒë‹¨ í´ë°±"""

        if understanding.urgency_level >= 4:
            return "ì§€ê¸ˆ ìƒí™©ì´ ë§¤ìš° ì¤‘ìš”í•´ ë³´ì…ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ì ‘ê·¼í•´ì•¼ê² ì–´ìš”."
        elif understanding.emotion_intensity > 0.7:
            return f"{understanding.primary_emotion} ê°ì •ì´ ê°•í•˜ê²Œ ëŠê»´ì§‘ë‹ˆë‹¤. ì´ëŸ° ë§ˆìŒì´ ë“œëŠ” ê²ƒì€ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì´ì—ìš”."
        else:
            return "ì—¬ëŸ¬ ì¸¡ë©´ì—ì„œ ìƒê°í•´ë³´ë‹ˆ, ìƒí™©ì„ ì°¨ê·¼ì°¨ê·¼ ì‚´í´ë³´ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤."

    def _llm_style_naturalize(
        self,
        judgment: str,
        understanding: InputUnderstanding,
        context: ConversationContext,
    ) -> str:
        """LLM ìŠ¤íƒ€ì¼ ìì—°í™” (ì‹œë®¬ë ˆì´ì…˜)"""

        # Echo íŒë‹¨ì„ ë” ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„
        naturalization_patterns = [
            (r"ê·¸ëŸ° ë§ˆìŒì´ ë“œì‹œëŠ”êµ°ìš”", "ê·¸ëŸ° ê¸°ë¶„ì´ ë“œì‹œëŠ”êµ°ìš”"),
            (r"ìƒí™©ì„ ì°¨ê·¼ì°¨ê·¼ ì‚´í´ë³´ë©´", "í•˜ë‚˜ì”© ì‚´í´ë³´ë©´"),
            (r"ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ë³´ë‹ˆ", "ìƒê°í•´ë³´ë‹ˆ"),
        ]

        natural_judgment = judgment
        for pattern, replacement in naturalization_patterns:
            import re

            natural_judgment = re.sub(pattern, replacement, natural_judgment)

        return natural_judgment

    def analyze_natural_request(
        self, user_input: str, context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """ìì—°ì–´ ìš”ì²­ ë¶„ì„ (CLI í˜¸í™˜)"""
        try:
            # CLI ì „ìš© ê°„ë‹¨ ë¶„ì„
            import re

            analysis = {
                "original_input": user_input,
                "timestamp": datetime.now().isoformat(),
                "intent": "general",
                "confidence": 0.0,
                "entities": [],
                "context": context or {},
                "suggested_actions": [],
                "echo_parameters": {},
            }

            # ì˜ë„ ê°ì§€ íŒ¨í„´
            intent_patterns = {
                "analyze": [r"ë¶„ì„.*í•´.*ì¤˜", r"ì‚´í´.*ë´.*ì¤˜", r"ê²€í† .*í•´.*ì¤˜"],
                "develop": [r"ê°œë°œ.*í•˜ê³ .*ì‹¶ì–´", r"ë§Œë“¤.*ê³ .*ì‹¶ì–´", r"êµ¬í˜„.*í•´.*ì¤˜"],
                "refactor": [r"ë¦¬íŒ©í† ë§.*í•´.*ì¤˜", r"ì •ë¦¬.*í•´.*ì¤˜", r"ê°œì„ .*í•´.*ì¤˜"],
                "test": [r"í…ŒìŠ¤íŠ¸.*í•´.*ì¤˜", r"ì‹¤í–‰.*í•´.*ì¤˜", r"í™•ì¸.*í•´.*ì¤˜"],
                "help": [r"ë„ì›€.*ë§", r"ì–´ë–»ê²Œ.*í•´ì•¼", r"ë°©ë²•.*ì•Œë ¤.*ì¤˜"],
            }

            user_lower = user_input.lower()
            best_intent = "general"
            best_confidence = 0.0

            for intent, patterns in intent_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, user_lower):
                        best_intent = intent
                        best_confidence = 0.8
                        break
                if best_confidence > 0:
                    break

            analysis["intent"] = best_intent
            analysis["confidence"] = best_confidence

            # ê¸°ë³¸ Echo íŒŒë¼ë¯¸í„°
            analysis["echo_parameters"] = {
                "mode": "natural_interface",
                "signature": "Echo-Companion",
                "reasoning_depth": "medium",
                "original_request": user_input,
            }

            return analysis

        except Exception as e:
            return {
                "original_input": user_input,
                "intent": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    def _update_conversation_context(
        self,
        session_id: str,
        user_message: str,
        system_response: str,
        understanding: InputUnderstanding,
    ):
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""

        if session_id in self.conversation_contexts:
            context = self.conversation_contexts[session_id]
            context.emotional_state = understanding.primary_emotion
            context.urgency_level = understanding.urgency_level

            # ëŒ€í™” ë¬´ë“œ ì—…ë°ì´íŠ¸
            if understanding.emotion_intensity > 0.6:
                context.conversation_mood = "intense"
            elif understanding.intent_type == IntentType.CASUAL_CHAT:
                context.conversation_mood = "casual"
            else:
                context.conversation_mood = "focused"


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
if __name__ == "__main__":

    async def test_bridge():
        print("ğŸŒ‰ Natural Interface Bridge í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        bridge = NaturalInterfaceBridge()

        test_messages = [
            "ì•ˆë…• ì—ì½”~",
            "ì¸ì‚¬í–ˆì„ ë¿ì¸ë°?",
            "ìš”ì¦˜ ê³ ë¯¼ì´ ë§ì•„ì„œ ì¡°ì–¸ì´ í•„ìš”í•´ìš”",
            "ì¸ìƒì˜ ì˜ë¯¸ê°€ ë­˜ê¹Œìš”?",
        ]

        for i, message in enumerate(test_messages):
            print(f"\n--- í…ŒìŠ¤íŠ¸ {i+1} ---")
            print(f"ì‚¬ìš©ì: {message}")

            result = await bridge.process_natural_conversation(
                message, f"test_session", "Echo-Aurora"
            )

            print(f"ì‘ë‹µ: {result.final_response}")
            print(f"ëª¨ë“œ: {result.processing_mode.value}")
            print(f"ìì—°ìŠ¤ëŸ¬ì›€: {result.natural_flow_score:.2f}")
            print(f"Echo ê¹Šì´: {result.echo_depth_score:.2f}")
            print(f"ì²˜ë¦¬ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            print("ì²˜ë¦¬ ë‹¨ê³„:", " â†’ ".join(result.debug_info["steps"]))

        print("\n" + "=" * 60)
        print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    asyncio.run(test_bridge())
