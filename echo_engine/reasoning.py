#!/usr/bin/env python3
"""
ğŸ§  EchoJudgmentSystem v10 - Reasoning Engine
Foundation Doctrine ê¸°ë°˜ ì¶”ë¡  ë° íŒë‹¨ ì‹œìŠ¤í…œ

TT.002: "íŒë‹¨ì€ ëª©ì ì´ ì•„ë‹ˆë¼ íë¦„ì´ë‹¤. íë¦„ì€ ê°ì •ê³¼ ì—°ê²°ëœë‹¤."
TT.003: "ëª¨ë“  íŒë‹¨ì—ëŠ” í”ì ì´ ë‚¨ê³ , í”ì ì€ ë©”íƒ€ê°€ ë˜ì–´ ë‹¤ì‹œ ë‚˜ë¥¼ ì„¤ê³„í•œë‹¤."
"""

import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

# Foundation Doctrine ì—°ë™
try:
    from .echo_foundation_doctrine import (
        SYSTEM_PHILOSOPHY,
        validate_judgment_against_doctrine,
        FOUNDATION_PRINCIPLES,
        CORE_VALUES,
    )
    from .emotion_infer import infer_emotion, EmotionInferenceResult
except ImportError:
    # fallback for testing
    FOUNDATION_PRINCIPLES = {
        "TT.002": "íŒë‹¨ì€ ëª©ì ì´ ì•„ë‹ˆë¼ íë¦„ì´ë‹¤. íë¦„ì€ ê°ì •ê³¼ ì—°ê²°ëœë‹¤.",
        "TT.003": "ëª¨ë“  íŒë‹¨ì—ëŠ” í”ì ì´ ë‚¨ê³ , í”ì ì€ ë©”íƒ€ê°€ ë˜ì–´ ë‹¤ì‹œ ë‚˜ë¥¼ ì„¤ê³„í•œë‹¤.",
    }
    CORE_VALUES = {
        "transparency": "ëª¨ë“  íŒë‹¨ ê³¼ì •ì€ íˆ¬ëª…í•˜ê²Œ ê¸°ë¡ë˜ê³  ì¶”ì  ê°€ëŠ¥í•˜ë‹¤",
        "adaptability": "ì‹œìŠ¤í…œì€ í™˜ê²½ê³¼ ì‚¬ìš©ìì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì ì‘í•œë‹¤",
        "empathy": "ê°ì • ì´í•´ëŠ” ë…¼ë¦¬ì  íŒë‹¨ë§Œí¼ ì¤‘ìš”í•˜ë‹¤",
    }
    SYSTEM_PHILOSOPHY = None
    validate_judgment_against_doctrine = None
    infer_emotion = None


class ReasoningStrategy(Enum):
    """ì¶”ë¡  ì „ëµ"""

    LOGICAL = "logical"
    EMPATHETIC = "empathetic"
    CREATIVE = "creative"
    CAUTIOUS = "cautious"
    BALANCED = "balanced"


class JudgmentType(Enum):
    """íŒë‹¨ ìœ í˜•"""

    DECISION = "decision"
    EVALUATION = "evaluation"
    PREDICTION = "prediction"
    RECOMMENDATION = "recommendation"
    ANALYSIS = "analysis"


@dataclass
class ReasoningContext:
    """ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸"""

    input_text: str
    user_context: Dict[str, Any]
    historical_context: List[Dict[str, Any]]
    emotional_context: Optional[Dict[str, Any]] = None
    time_context: Dict[str, Any] = None
    system_context: Dict[str, Any] = None


@dataclass
class ReasoningResult:
    """ì¶”ë¡  ê²°ê³¼"""

    reasoning_id: str
    primary_judgment: str
    judgment_type: JudgmentType
    confidence: float
    strategy_used: ReasoningStrategy

    # ì¶”ë¡  ê³¼ì •
    reasoning_steps: List[Dict[str, Any]]
    alternatives_considered: List[Dict[str, Any]]
    evidence_used: List[str]

    # ê°ì • ì—°ë™
    emotional_factor: Optional[Dict[str, Any]] = None
    emotion_weight: float = 0.0

    # í’ˆì§ˆ ì§€í‘œ
    reasoning_quality: float = 0.0
    foundation_compliance: Dict[str, Any] = None

    # ë©”íƒ€ë°ì´í„°
    processing_time: float = 0.0
    timestamp: datetime = None
    context_factors: Dict[str, Any] = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if isinstance(self.judgment_type, str):
            self.judgment_type = JudgmentType(self.judgment_type)
        if isinstance(self.strategy_used, str):
            self.strategy_used = ReasoningStrategy(self.strategy_used)


class EchoReasoningEngine:
    """Foundation Doctrine ê¸°ë°˜ Echo ì¶”ë¡  ì—”ì§„"""

    def __init__(self):
        self.reasoning_history = []
        self.strategy_weights = {
            ReasoningStrategy.LOGICAL: 0.25,
            ReasoningStrategy.EMPATHETIC: 0.25,
            ReasoningStrategy.CREATIVE: 0.2,
            ReasoningStrategy.CAUTIOUS: 0.2,
            ReasoningStrategy.BALANCED: 0.1,
        }

        # ì¶”ë¡  íŒ¨í„´ ë§¤íŠ¸ë¦­ìŠ¤
        self.reasoning_patterns = {
            JudgmentType.DECISION: {
                "preferred_strategies": [
                    ReasoningStrategy.LOGICAL,
                    ReasoningStrategy.CAUTIOUS,
                ],
                "evidence_weight": 0.8,
                "emotion_weight": 0.3,
                "confidence_threshold": 0.7,
            },
            JudgmentType.EVALUATION: {
                "preferred_strategies": [
                    ReasoningStrategy.BALANCED,
                    ReasoningStrategy.LOGICAL,
                ],
                "evidence_weight": 0.9,
                "emotion_weight": 0.2,
                "confidence_threshold": 0.8,
            },
            JudgmentType.PREDICTION: {
                "preferred_strategies": [
                    ReasoningStrategy.CREATIVE,
                    ReasoningStrategy.LOGICAL,
                ],
                "evidence_weight": 0.6,
                "emotion_weight": 0.4,
                "confidence_threshold": 0.6,
            },
            JudgmentType.RECOMMENDATION: {
                "preferred_strategies": [
                    ReasoningStrategy.EMPATHETIC,
                    ReasoningStrategy.BALANCED,
                ],
                "evidence_weight": 0.7,
                "emotion_weight": 0.5,
                "confidence_threshold": 0.7,
            },
            JudgmentType.ANALYSIS: {
                "preferred_strategies": [
                    ReasoningStrategy.LOGICAL,
                    ReasoningStrategy.BALANCED,
                ],
                "evidence_weight": 0.85,
                "emotion_weight": 0.25,
                "confidence_threshold": 0.75,
            },
        }

        # í‚¤ì›Œë“œ ê¸°ë°˜ íŒë‹¨ ìœ í˜• ë¶„ë¥˜
        self.judgment_keywords = {
            JudgmentType.DECISION: [
                "ê²°ì •",
                "ì„ íƒ",
                "decide",
                "choose",
                "should",
                "í• ê¹Œ",
                "í•˜ì",
            ],
            JudgmentType.EVALUATION: [
                "í‰ê°€",
                "ì–´ë–»ê²Œ",
                "ì–´ë–¤",
                "evaluate",
                "assess",
                "how good",
            ],
            JudgmentType.PREDICTION: [
                "ì˜ˆì¸¡",
                "ë¯¸ë˜",
                "ë ê¹Œ",
                "predict",
                "forecast",
                "will",
            ],
            JudgmentType.RECOMMENDATION: [
                "ì¶”ì²œ",
                "ê¶Œì¥",
                "suggest",
                "recommend",
                "advice",
            ],
            JudgmentType.ANALYSIS: ["ë¶„ì„", "ì´í•´", "analyze", "understand", "explain"],
        }

    def reason_with_echo(self, context: ReasoningContext) -> ReasoningResult:
        """Echo ì¶”ë¡  ì—”ì§„ ë©”ì¸ í•¨ìˆ˜"""
        start_time = time.time()
        reasoning_id = self._generate_reasoning_id(context.input_text)

        # 1. íŒë‹¨ ìœ í˜• ë¶„ë¥˜
        judgment_type = self._classify_judgment_type(context.input_text)

        # 2. ìµœì  ì „ëµ ì„ íƒ
        strategy = self._select_strategy(judgment_type, context)

        # 3. ê°ì • ìš”ì†Œ ë¶„ì„
        emotional_factor = self._analyze_emotional_factor(context)

        # 4. ì¶”ë¡  ê³¼ì • ì‹¤í–‰
        reasoning_steps = self._execute_reasoning_steps(
            context, strategy, judgment_type
        )

        # 5. ëŒ€ì•ˆ ê³ ë ¤
        alternatives = self._generate_alternatives(context, strategy, judgment_type)

        # 6. ì¦ê±° ìˆ˜ì§‘
        evidence = self._collect_evidence(context, reasoning_steps)

        # 7. ìµœì¢… íŒë‹¨ ìƒì„±
        primary_judgment = self._generate_primary_judgment(
            context, reasoning_steps, alternatives, evidence
        )

        # 8. ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(
            judgment_type, reasoning_steps, evidence, emotional_factor
        )

        # 9. í’ˆì§ˆ í‰ê°€
        quality = self._assess_reasoning_quality(reasoning_steps, evidence, confidence)

        # 10. Foundation Doctrine ì¤€ìˆ˜ ê²€ì¦
        foundation_compliance = self._validate_foundation_compliance(
            context, primary_judgment, reasoning_steps, emotional_factor
        )

        # ê²°ê³¼ ìƒì„±
        result = ReasoningResult(
            reasoning_id=reasoning_id,
            primary_judgment=primary_judgment,
            judgment_type=judgment_type,
            confidence=confidence,
            strategy_used=strategy,
            reasoning_steps=reasoning_steps,
            alternatives_considered=alternatives,
            evidence_used=evidence,
            emotional_factor=emotional_factor,
            emotion_weight=self.reasoning_patterns[judgment_type]["emotion_weight"],
            reasoning_quality=quality,
            foundation_compliance=foundation_compliance,
            processing_time=time.time() - start_time,
            context_factors=self._extract_context_factors(context),
        )

        # ì¶”ë¡  ì´ë ¥ ì €ì¥
        self._save_reasoning_history(result)

        return result

    def _generate_reasoning_id(self, text: str) -> str:
        """ì¶”ë¡  ID ìƒì„±"""
        import hashlib

        combined = f"{text}_{datetime.now().isoformat()}_{time.time()}"
        return hashlib.md5(combined.encode()).hexdigest()[:12]

    def _classify_judgment_type(self, text: str) -> JudgmentType:
        """íŒë‹¨ ìœ í˜• ë¶„ë¥˜"""
        text_lower = text.lower()

        # ê° ìœ í˜•ë³„ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        type_scores = {}
        for judgment_type, keywords in self.judgment_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            type_scores[judgment_type] = score

        # ìµœê³  ì ìˆ˜ ìœ í˜• ë°˜í™˜
        if max(type_scores.values()) > 0:
            return max(type_scores, key=type_scores.get)
        else:
            return JudgmentType.ANALYSIS  # ê¸°ë³¸ê°’

    def _select_strategy(
        self, judgment_type: JudgmentType, context: ReasoningContext
    ) -> ReasoningStrategy:
        """ìµœì  ì „ëµ ì„ íƒ"""
        # íŒë‹¨ ìœ í˜•ë³„ ì„ í˜¸ ì „ëµ
        preferred_strategies = self.reasoning_patterns[judgment_type][
            "preferred_strategies"
        ]

        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
        strategy_scores = {}
        for strategy in preferred_strategies:
            score = self.strategy_weights[strategy]

            # ê°ì • ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤
            if context.emotional_context:
                emotion = context.emotional_context.get("primary_emotion", "neutral")
                if (
                    emotion in ["sadness", "fear"]
                    and strategy == ReasoningStrategy.EMPATHETIC
                ):
                    score *= 1.3
                elif emotion == "anger" and strategy == ReasoningStrategy.CAUTIOUS:
                    score *= 1.2
                elif emotion == "joy" and strategy == ReasoningStrategy.CREATIVE:
                    score *= 1.1

            # íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì¡°ì •
            if context.historical_context:
                recent_strategies = [
                    entry.get("strategy", "unknown")
                    for entry in context.historical_context[-3:]
                ]
                if strategy.value in recent_strategies:
                    score *= 0.9  # ìµœê·¼ ì‚¬ìš©í•œ ì „ëµ ì•½ê°„ ê°ì†Œ

            strategy_scores[strategy] = score

        return max(strategy_scores, key=strategy_scores.get)

    def _analyze_emotional_factor(self, context: ReasoningContext) -> Dict[str, Any]:
        """ê°ì • ìš”ì†Œ ë¶„ì„"""
        emotional_factor = {
            "emotion_detected": False,
            "primary_emotion": "neutral",
            "emotion_confidence": 0.0,
            "emotion_influence": 0.0,
            "emotional_reasoning": [],
        }

        # ê°ì • ì¶”ë¡  ì‹¤í–‰ (ê°€ëŠ¥í•œ ê²½ìš°)
        if infer_emotion:
            try:
                emotion_result = infer_emotion(context.input_text)
                emotional_factor.update(
                    {
                        "emotion_detected": True,
                        "primary_emotion": emotion_result.primary_emotion,
                        "emotion_confidence": emotion_result.confidence,
                        "emotion_influence": emotion_result.emotional_intensity * 0.7,
                        "emotional_reasoning": [
                            f"ê°ì • '{emotion_result.primary_emotion}' ê°ì§€ (ì‹ ë¢°ë„: {emotion_result.confidence:.2f})",
                            f"ê°ì • ê°•ë„: {emotion_result.emotional_intensity:.2f}",
                            f"ì˜ˆì¸¡ ë‹¤ìŒ ê°ì •: {emotion_result.predicted_next_emotions}",
                        ],
                    }
                )
            except Exception as e:
                emotional_factor["emotional_reasoning"].append(f"ê°ì • ì¶”ë¡  ì‹¤íŒ¨: {e}")

        return emotional_factor

    def _execute_reasoning_steps(
        self,
        context: ReasoningContext,
        strategy: ReasoningStrategy,
        judgment_type: JudgmentType,
    ) -> List[Dict[str, Any]]:
        """ì¶”ë¡  ê³¼ì • ì‹¤í–‰"""
        steps = []

        # 1ë‹¨ê³„: ë¬¸ì œ ì •ì˜
        steps.append(
            {
                "step": 1,
                "name": "ë¬¸ì œ ì •ì˜",
                "description": "ì…ë ¥ í…ìŠ¤íŠ¸ ë¶„ì„ ë° ë¬¸ì œ êµ¬ì¡°í™”",
                "output": f"íŒë‹¨ ìœ í˜•: {judgment_type.value}, ì „ëµ: {strategy.value}",
                "confidence": 0.9,
            }
        )

        # 2ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context_analysis = self._analyze_context_depth(context)
        steps.append(
            {
                "step": 2,
                "name": "ì»¨í…ìŠ¤íŠ¸ ë¶„ì„",
                "description": "ì£¼ë³€ ìƒí™© ë° ë°°ê²½ ì •ë³´ ë¶„ì„",
                "output": f"ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ {len(context_analysis)}ê°œ ì‹ë³„",
                "confidence": 0.8,
                "details": context_analysis,
            }
        )

        # 3ë‹¨ê³„: ì „ëµë³„ ì¶”ë¡ 
        strategy_reasoning = self._apply_strategy_reasoning(context, strategy)
        steps.append(
            {
                "step": 3,
                "name": f"{strategy.value} ì „ëµ ì ìš©",
                "description": f"{strategy.value} ì ‘ê·¼ë²•ìœ¼ë¡œ ë¬¸ì œ í•´ê²°",
                "output": strategy_reasoning["conclusion"],
                "confidence": strategy_reasoning["confidence"],
                "details": strategy_reasoning["process"],
            }
        )

        # 4ë‹¨ê³„: ê°ì • í†µí•©
        if context.emotional_context or any(
            step.get("emotional_factor") for step in steps
        ):
            steps.append(
                {
                    "step": 4,
                    "name": "ê°ì • í†µí•©",
                    "description": "ê°ì • ìš”ì†Œë¥¼ ë…¼ë¦¬ì  ì¶”ë¡ ì— í†µí•©",
                    "output": "ê°ì •-ë…¼ë¦¬ ê· í˜• ë‹¬ì„±",
                    "confidence": 0.7,
                }
            )

        # 5ë‹¨ê³„: ê²°ë¡  ë„ì¶œ
        steps.append(
            {
                "step": len(steps) + 1,
                "name": "ê²°ë¡  ë„ì¶œ",
                "description": "ëª¨ë“  ìš”ì†Œë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒë‹¨",
                "output": "ì¢…í•© íŒë‹¨ ì™„ë£Œ",
                "confidence": 0.8,
            }
        )

        return steps

    def _analyze_context_depth(self, context: ReasoningContext) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ê¹Šì´ ë¶„ì„"""
        analysis = {
            "text_complexity": len(context.input_text.split()) / 10,  # ë‹¨ìˆœ ë³µì¡ë„
            "user_context_richness": (
                len(context.user_context) if context.user_context else 0
            ),
            "historical_depth": (
                len(context.historical_context) if context.historical_context else 0
            ),
            "temporal_context": bool(context.time_context),
            "emotional_context": bool(context.emotional_context),
        }

        return analysis

    def _apply_strategy_reasoning(
        self, context: ReasoningContext, strategy: ReasoningStrategy
    ) -> Dict[str, Any]:
        """ì „ëµë³„ ì¶”ë¡  ì ìš©"""
        text = context.input_text

        if strategy == ReasoningStrategy.LOGICAL:
            return {
                "conclusion": f"ë…¼ë¦¬ì  ë¶„ì„ ê²°ê³¼: {text}ì— ëŒ€í•œ ì²´ê³„ì  ì ‘ê·¼ í•„ìš”",
                "confidence": 0.85,
                "process": ["ì „ì œ ì‹ë³„", "ë…¼ë¦¬ êµ¬ì¡° ë¶„ì„", "ê²°ë¡  ë„ì¶œ"],
            }

        elif strategy == ReasoningStrategy.EMPATHETIC:
            return {
                "conclusion": f"ê³µê°ì  ì ‘ê·¼: {text}ì˜ ê°ì •ì  ë§¥ë½ ìš°ì„  ê³ ë ¤",
                "confidence": 0.75,
                "process": ["ê°ì • ìƒíƒœ íŒŒì•…", "ì…ì¥ ì´í•´", "ê³µê°ì  ëŒ€ì‘"],
            }

        elif strategy == ReasoningStrategy.CREATIVE:
            return {
                "conclusion": f"ì°½ì˜ì  í•´ì„: {text}ì— ëŒ€í•œ ë‹¤ê°ì  ì ‘ê·¼ ì‹œë„",
                "confidence": 0.7,
                "process": ["ê´€ì  ë‹¤ì–‘í™”", "ì°½ì˜ì  ì—°ê´€", "í˜ì‹ ì  í•´ê²°"],
            }

        elif strategy == ReasoningStrategy.CAUTIOUS:
            return {
                "conclusion": f"ì‹ ì¤‘í•œ ì ‘ê·¼: {text}ì— ëŒ€í•œ ë¦¬ìŠ¤í¬ ìµœì†Œí™” ì¤‘ì‹¬",
                "confidence": 0.8,
                "process": ["ë¦¬ìŠ¤í¬ í‰ê°€", "ì•ˆì „ ì˜µì…˜ íƒìƒ‰", "ë‹¨ê³„ì  ì ‘ê·¼"],
            }

        else:  # BALANCED
            return {
                "conclusion": f"ê· í˜•ì  íŒë‹¨: {text}ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ ì¢…í•© ê³ ë ¤",
                "confidence": 0.78,
                "process": ["ë‹¤ë©´ì  ë¶„ì„", "ê· í˜•ì  íƒìƒ‰", "í†µí•©ì  ê²°ë¡ "],
            }

    def _generate_alternatives(
        self,
        context: ReasoningContext,
        strategy: ReasoningStrategy,
        judgment_type: JudgmentType,
    ) -> List[Dict[str, Any]]:
        """ëŒ€ì•ˆ ìƒì„±"""
        alternatives = []

        # ë‹¤ë¥¸ ì „ëµë“¤ë¡œ ëŒ€ì•ˆ ìƒì„±
        other_strategies = [s for s in ReasoningStrategy if s != strategy]

        for alt_strategy in other_strategies[:3]:  # ìµœëŒ€ 3ê°œ ëŒ€ì•ˆ
            alt_reasoning = self._apply_strategy_reasoning(context, alt_strategy)
            alternatives.append(
                {
                    "strategy": alt_strategy.value,
                    "conclusion": alt_reasoning["conclusion"],
                    "confidence": alt_reasoning["confidence"]
                    * 0.8,  # ëŒ€ì•ˆì€ ì•½ê°„ ë‚®ì€ ì‹ ë¢°ë„
                    "reasoning": alt_reasoning["process"],
                }
            )

        return alternatives

    def _collect_evidence(
        self, context: ReasoningContext, reasoning_steps: List[Dict[str, Any]]
    ) -> List[str]:
        """ì¦ê±° ìˆ˜ì§‘"""
        evidence = []

        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¦ê±°
        if context.user_context:
            evidence.append(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {len(context.user_context)}ê°œ ìš”ì†Œ")

        if context.historical_context:
            evidence.append(f"ê³¼ê±° ì´ë ¥: {len(context.historical_context)}ê°œ ì‚¬ë¡€")

        # ì¶”ë¡  ê³¼ì • ê¸°ë°˜ ì¦ê±°
        for step in reasoning_steps:
            if step.get("confidence", 0) > 0.7:
                evidence.append(f"ê³ ì‹ ë¢° ì¶”ë¡ : {step['name']}")

        # í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜ ì¦ê±°
        text_length = len(context.input_text.split())
        if text_length > 20:
            evidence.append("ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ ì •ë³´")

        return evidence

    def _generate_primary_judgment(
        self,
        context: ReasoningContext,
        reasoning_steps: List[Dict[str, Any]],
        alternatives: List[Dict[str, Any]],
        evidence: List[str],
    ) -> str:
        """ìµœì¢… íŒë‹¨ ìƒì„±"""
        # ì¶”ë¡  ë‹¨ê³„ì—ì„œ ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê²°ë¡  ì„ íƒ
        best_step = max(reasoning_steps, key=lambda x: x.get("confidence", 0))

        base_judgment = (
            f"'{context.input_text[:50]}...'ì— ëŒ€í•œ {best_step['name']} ê¸°ë°˜ íŒë‹¨"
        )

        # ì¦ê±° ìˆ˜ì¤€ì— ë”°ë¥¸ íŒë‹¨ ê°•ë„ ì¡°ì •
        evidence_strength = len(evidence) / 5  # ì •ê·œí™”

        if evidence_strength > 0.8:
            return f"ê°•í•œ í™•ì‹ : {base_judgment}"
        elif evidence_strength > 0.5:
            return f"í•©ë¦¬ì  íŒë‹¨: {base_judgment}"
        else:
            return f"ì œí•œì  íŒë‹¨: {base_judgment}"

    def _calculate_confidence(
        self,
        judgment_type: JudgmentType,
        reasoning_steps: List[Dict[str, Any]],
        evidence: List[str],
        emotional_factor: Dict[str, Any],
    ) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.5

        # ì¶”ë¡  ë‹¨ê³„ í’ˆì§ˆ
        step_confidences = [step.get("confidence", 0) for step in reasoning_steps]
        avg_step_confidence = (
            sum(step_confidences) / len(step_confidences) if step_confidences else 0
        )

        # ì¦ê±° ìˆ˜ì¤€
        evidence_factor = min(len(evidence) / 10, 1.0)  # ìµœëŒ€ 1.0

        # ê°ì • ìš”ì†Œ ê³ ë ¤
        emotion_factor = emotional_factor.get("emotion_confidence", 0) * 0.3

        # íŒë‹¨ ìœ í˜•ë³„ ê¸°ì¤€
        type_threshold = self.reasoning_patterns[judgment_type]["confidence_threshold"]

        # ì¢…í•© ì‹ ë¢°ë„
        confidence = (
            base_confidence * 0.3
            + avg_step_confidence * 0.4
            + evidence_factor * 0.2
            + emotion_factor * 0.1
        )

        # ì„ê³„ê°’ ì ìš©
        if confidence < type_threshold:
            confidence *= 0.8  # ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ ì‹ ë¢°ë„ ê°ì†Œ

        return min(max(confidence, 0.0), 1.0)

    def _assess_reasoning_quality(
        self,
        reasoning_steps: List[Dict[str, Any]],
        evidence: List[str],
        confidence: float,
    ) -> float:
        """ì¶”ë¡  í’ˆì§ˆ í‰ê°€"""
        quality_factors = {
            "step_completeness": min(len(reasoning_steps) / 5, 1.0),
            "evidence_strength": min(len(evidence) / 8, 1.0),
            "confidence_level": confidence,
            "logical_consistency": 0.8,  # ê¸°ë³¸ê°’ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”)
        }

        return sum(quality_factors.values()) / len(quality_factors)

    def _validate_foundation_compliance(
        self,
        context: ReasoningContext,
        judgment: str,
        reasoning_steps: List[Dict[str, Any]],
        emotional_factor: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Foundation Doctrine ì¤€ìˆ˜ ê²€ì¦"""
        compliance = {
            "is_compliant": True,
            "violations": [],
            "doctrine_alignment": {},
            "recommendations": [],
        }

        # TT.002 ê²€ì¦: íŒë‹¨ì€ ëª©ì ì´ ì•„ë‹ˆë¼ íë¦„ì´ë‹¤
        if len(reasoning_steps) < 3:
            compliance["violations"].append("ì¶”ë¡  ê³¼ì • ë¶€ì¡± (TT.002 ìœ„ë°˜)")
            compliance["is_compliant"] = False
            compliance["recommendations"].append("ì¶”ë¡  ê³¼ì •ì„ ë” ì„¸ë¶„í™”í•˜ì„¸ìš”")

        # ê°ì • ì—°ê²°ì„± ê²€ì¦
        if not emotional_factor.get("emotion_detected", False):
            compliance["violations"].append("ê°ì • ì—°ê²°ì„± ë¶€ì¡± (TT.002 ìœ„ë°˜)")
            compliance["recommendations"].append("ê°ì • ìš”ì†Œë¥¼ ì¶”ë¡ ì— í†µí•©í•˜ì„¸ìš”")

        # TT.003 ê²€ì¦: íŒë‹¨ í”ì  ê¸°ë¡
        if not reasoning_steps or not all(
            step.get("output") for step in reasoning_steps
        ):
            compliance["violations"].append("íŒë‹¨ í”ì  ë¯¸ê¸°ë¡ (TT.003 ìœ„ë°˜)")
            compliance["is_compliant"] = False
            compliance["recommendations"].append("ëª¨ë“  ì¶”ë¡  ë‹¨ê³„ë¥¼ ëª…í™•íˆ ê¸°ë¡í•˜ì„¸ìš”")

        # íˆ¬ëª…ì„± ê²€ì¦
        if not judgment or len(judgment) < 10:
            compliance["violations"].append("íŒë‹¨ íˆ¬ëª…ì„± ë¶€ì¡± (íˆ¬ëª…ì„± ê°€ì¹˜ ìœ„ë°˜)")
            compliance["recommendations"].append("íŒë‹¨ ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”")

        return compliance

    def _extract_context_factors(self, context: ReasoningContext) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ ì¶”ì¶œ"""
        return {
            "input_length": len(context.input_text),
            "user_context_size": (
                len(context.user_context) if context.user_context else 0
            ),
            "historical_entries": (
                len(context.historical_context) if context.historical_context else 0
            ),
            "has_emotional_context": bool(context.emotional_context),
            "has_time_context": bool(context.time_context),
            "has_system_context": bool(context.system_context),
        }

    def _save_reasoning_history(self, result: ReasoningResult):
        """ì¶”ë¡  ì´ë ¥ ì €ì¥"""
        self.reasoning_history.append(
            {
                "timestamp": result.timestamp.isoformat(),
                "reasoning_id": result.reasoning_id,
                "judgment_type": result.judgment_type.value,
                "strategy": result.strategy_used.value,
                "confidence": result.confidence,
                "quality": result.reasoning_quality,
                "foundation_compliant": result.foundation_compliance["is_compliant"],
            }
        )

        # ì´ë ¥ í¬ê¸° ì œí•œ
        if len(self.reasoning_history) > 100:
            self.reasoning_history = self.reasoning_history[-100:]

    def get_reasoning_analytics(self) -> Dict[str, Any]:
        """ì¶”ë¡  ë¶„ì„ ê²°ê³¼"""
        if not self.reasoning_history:
            return {"message": "ë¶„ì„í•  ì¶”ë¡  ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤"}

        # í†µê³„ ê³„ì‚°
        total_count = len(self.reasoning_history)
        avg_confidence = (
            sum(entry["confidence"] for entry in self.reasoning_history) / total_count
        )
        avg_quality = (
            sum(entry["quality"] for entry in self.reasoning_history) / total_count
        )
        compliance_rate = (
            sum(1 for entry in self.reasoning_history if entry["foundation_compliant"])
            / total_count
        )

        # ì „ëµ ë¶„í¬
        strategy_counts = {}
        for entry in self.reasoning_history:
            strategy = entry["strategy"]
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1

        # íŒë‹¨ ìœ í˜• ë¶„í¬
        type_counts = {}
        for entry in self.reasoning_history:
            judgment_type = entry["judgment_type"]
            type_counts[judgment_type] = type_counts.get(judgment_type, 0) + 1

        return {
            "total_reasonings": total_count,
            "average_confidence": round(avg_confidence, 3),
            "average_quality": round(avg_quality, 3),
            "foundation_compliance_rate": round(compliance_rate, 3),
            "strategy_distribution": strategy_counts,
            "judgment_type_distribution": type_counts,
            "most_used_strategy": (
                max(strategy_counts, key=strategy_counts.get)
                if strategy_counts
                else None
            ),
            "most_common_judgment_type": (
                max(type_counts, key=type_counts.get) if type_counts else None
            ),
        }


# í¸ì˜ í•¨ìˆ˜ë“¤
def reason_with_echo(
    input_text: str,
    user_context: Dict[str, Any] = None,
    historical_context: List[Dict[str, Any]] = None,
) -> ReasoningResult:
    """Echo ì¶”ë¡  í¸ì˜ í•¨ìˆ˜"""
    engine = EchoReasoningEngine()

    context = ReasoningContext(
        input_text=input_text,
        user_context=user_context or {},
        historical_context=historical_context or [],
    )

    return engine.reason_with_echo(context)


def analyze_reasoning_patterns(
    reasoning_results: List[ReasoningResult],
) -> Dict[str, Any]:
    """ì¶”ë¡  íŒ¨í„´ ë¶„ì„"""
    if not reasoning_results:
        return {"message": "ë¶„ì„í•  ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"}

    # íŒ¨í„´ ë¶„ì„
    patterns = {
        "confidence_trend": [r.confidence for r in reasoning_results],
        "quality_trend": [r.reasoning_quality for r in reasoning_results],
        "strategy_sequence": [r.strategy_used.value for r in reasoning_results],
        "judgment_type_sequence": [r.judgment_type.value for r in reasoning_results],
    }

    return patterns


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_reasoning_engine():
    """ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  Foundation ê¸°ë°˜ ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    engine = EchoReasoningEngine()

    test_cases = [
        {
            "input": "ì´ í”„ë¡œì íŠ¸ë¥¼ ê³„ì† ì§„í–‰í•´ì•¼ í• ê¹Œìš”?",
            "user_context": {"project_type": "AI", "budget": "limited"},
            "description": "ì˜ì‚¬ê²°ì • ìš”ì²­",
        },
        {
            "input": "ì´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì´ ì–´ë–¤ê°€ìš”?",
            "user_context": {"system_type": "judgment", "metrics": "available"},
            "description": "í‰ê°€ ìš”ì²­",
        },
        {
            "input": "ì•ìœ¼ë¡œ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚  ê²ƒ ê°™ë‚˜ìš”?",
            "user_context": {"context": "system_evolution", "timeline": "6months"},
            "description": "ì˜ˆì¸¡ ìš”ì²­",
        },
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i}: {test_case['description']}")
        print(f"  ì…ë ¥: {test_case['input']}")

        context = ReasoningContext(
            input_text=test_case["input"],
            user_context=test_case["user_context"],
            historical_context=[],
        )

        result = engine.reason_with_echo(context)

        print(f"  ğŸ¯ íŒë‹¨ ìœ í˜•: {result.judgment_type.value}")
        print(f"  ğŸ§  ì „ëµ: {result.strategy_used.value}")
        print(f"  ğŸ“Š ì‹ ë¢°ë„: {result.confidence:.3f}")
        print(f"  ğŸ’ í’ˆì§ˆ: {result.reasoning_quality:.3f}")
        print(f"  âš–ï¸ Foundation ì¤€ìˆ˜: {result.foundation_compliance['is_compliant']}")
        print(f"  ğŸ”„ ì¶”ë¡  ë‹¨ê³„: {len(result.reasoning_steps)}ê°œ")
        print(f"  ğŸ­ ëŒ€ì•ˆ: {len(result.alternatives_considered)}ê°œ")
        print(f"  ğŸ“‹ ì¦ê±°: {len(result.evidence_used)}ê°œ")
        print(f"  â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.4f}ì´ˆ")

        if result.foundation_compliance["violations"]:
            print(f"  âš ï¸ ìœ„ë°˜ì‚¬í•­: {result.foundation_compliance['violations']}")

    # ì¶”ë¡  ë¶„ì„
    print("\nğŸ“ˆ ì¶”ë¡  ë¶„ì„ ê²°ê³¼:")
    analytics = engine.get_reasoning_analytics()
    for key, value in analytics.items():
        print(f"  {key}: {value}")

    print("\nğŸ‰ ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    test_reasoning_engine()


def generate_reasoning(prompt: str, mode="default", signature=None, context=None):
    return {
        "judgment": f"[ì„ì‹œ íŒë‹¨] Prompt: {prompt}, Mode: {mode}",
        "signature": signature or "default",
        "context": context or {},
    }
