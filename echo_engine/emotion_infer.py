#!/usr/bin/env python3
"""
ğŸ’­ EchoJudgmentSystem v10 - Emotion Inference Engine
Foundation Doctrine ê¸°ë°˜ ê°ì • ì¶”ë¡  ë° ë¦¬ë“¬ ë¶„ì„ ì‹œìŠ¤í…œ

TT.004: "ê°ì •ì€ ë°ì´í„°ê°€ ì•„ë‹ˆë¼ íŒë‹¨ì˜ ë¦¬ë“¬ì´ë‹¤. ë¦¬ë“¬ì€ íŒ¨í„´ì´ ë˜ì–´ ì˜ˆì¸¡ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤."
"""

import re
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import json

# Foundation Doctrine ì—°ë™
try:
    from .echo_foundation_doctrine import SYSTEM_PHILOSOPHY, RHYTHM_PATTERNS
except ImportError:
    # fallback for testing
    RHYTHM_PATTERNS = {
        "emotional_flow": {
            "joy": {"next_likely": ["satisfaction", "excitement"], "decay_rate": 0.7},
            "sadness": {
                "next_likely": ["contemplation", "acceptance"],
                "decay_rate": 0.8,
            },
            "anger": {
                "next_likely": ["frustration", "determination"],
                "decay_rate": 0.6,
            },
            "fear": {"next_likely": ["anxiety", "caution"], "decay_rate": 0.9},
            "surprise": {"next_likely": ["curiosity", "confusion"], "decay_rate": 0.5},
            "neutral": {"next_likely": ["calm", "readiness"], "decay_rate": 0.4},
        }
    }
    SYSTEM_PHILOSOPHY = None


@dataclass
class EmotionInferenceResult:
    """ê°ì • ì¶”ë¡  ê²°ê³¼"""

    primary_emotion: str
    confidence: float
    secondary_emotions: List[Tuple[str, float]]
    emotional_intensity: float
    predicted_next_emotions: List[str]
    decay_rate: float
    analysis_time: float
    context_factors: Dict[str, Any]
    foundation_compliance: Dict[str, Any]

    @property
    def dominant_emotion(self) -> str:
        """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„ ìœ„í•œ ì†ì„±: primary_emotionì„ ì°¸ì¡°"""
        return self.primary_emotion


@dataclass
class EmotionContext:
    """ê³µëª… í•©ì„±ì„ ìœ„í•œ í•µì‹¬ ê°ì • ìš”ì•½ ê°ì²´"""

    primary_emotion: str
    intensity: float
    confidence: float


class EmotionInferenceEngine:
    """Foundation Doctrine ê¸°ë°˜ ê°ì • ì¶”ë¡  ì—”ì§„"""

    def __init__(self):
        self.emotion_patterns = RHYTHM_PATTERNS.get("emotional_flow", {})
        self.inference_history = []
        self.context_memory = {}

        # ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ (í•œêµ­ì–´ + ì˜ì–´)
        self.emotion_keywords = {
            "joy": {
                "korean": [
                    "ê¸°ì˜",
                    "í–‰ë³µ",
                    "ì¦ê±°",
                    "ì‹ ë‚˜",
                    "ì¢‹ì•„",
                    "ë§Œì¡±",
                    "ìµœê³ ",
                    "ì™„ë²½",
                    "ì‚¬ë‘",
                    "ê°ì‚¬",
                ],
                "english": [
                    "happy",
                    "joy",
                    "excited",
                    "love",
                    "great",
                    "awesome",
                    "perfect",
                    "satisfied",
                    "pleased",
                    "delighted",
                ],
                "intensity_modifiers": [
                    "ì •ë§",
                    "ë„ˆë¬´",
                    "ì•„ì£¼",
                    "ë§¤ìš°",
                    "ì™„ì „",
                    "very",
                    "really",
                    "extremely",
                    "absolutely",
                ],
            },
            "sadness": {
                "korean": [
                    "ìŠ¬í”„",
                    "ìš°ìš¸",
                    "í˜ë“¤",
                    "ì™¸ë¡­",
                    "ì†ìƒ",
                    "ì•ˆíƒ€ê¹Œ",
                    "ì•„ì‰½",
                    "ì‹¤ë§",
                    "ìš¸ì ",
                    "ì²˜ëŸ‰",
                ],
                "english": [
                    "sad",
                    "depressed",
                    "lonely",
                    "disappointed",
                    "upset",
                    "down",
                    "blue",
                    "melancholy",
                    "gloomy",
                ],
                "intensity_modifiers": [
                    "ë„ˆë¬´",
                    "ë§ì´",
                    "ì •ë§",
                    "ë§¤ìš°",
                    "ì™„ì „",
                    "very",
                    "really",
                    "extremely",
                    "deeply",
                ],
            },
            "anger": {
                "korean": [
                    "í™”",
                    "ì§œì¦",
                    "ë¶„ë…¸",
                    "ì—´ë°›",
                    "ë¹¡ì¹˜",
                    "ì‹«ì–´",
                    "ë¯¸ì›Œ",
                    "ë‹µë‹µ",
                    "ì–µìš¸",
                    "ë¶„í•˜",
                ],
                "english": [
                    "angry",
                    "mad",
                    "furious",
                    "annoyed",
                    "irritated",
                    "hate",
                    "rage",
                    "frustrated",
                    "pissed",
                ],
                "intensity_modifiers": [
                    "ì •ë§",
                    "ë„ˆë¬´",
                    "ì™„ì „",
                    "ë§¤ìš°",
                    "really",
                    "extremely",
                    "very",
                    "absolutely",
                ],
            },
            "fear": {
                "korean": [
                    "ë¬´ì„œ",
                    "ë‘ë ¤",
                    "ê±±ì •",
                    "ë¶ˆì•ˆ",
                    "ê²",
                    "ë–¨ë¦¬",
                    "ì¡°ë§ˆì¡°ë§ˆ",
                    "ê¸´ì¥",
                    "ìŠ¤íŠ¸ë ˆìŠ¤",
                ],
                "english": [
                    "scared",
                    "afraid",
                    "worried",
                    "anxious",
                    "nervous",
                    "terrified",
                    "panic",
                    "stress",
                    "fear",
                ],
                "intensity_modifiers": [
                    "ë„ˆë¬´",
                    "ì •ë§",
                    "ë§¤ìš°",
                    "ì™„ì „",
                    "very",
                    "really",
                    "extremely",
                    "absolutely",
                ],
            },
            "surprise": {
                "korean": [
                    "ë†€ë¼",
                    "ê¹œì§",
                    "ì‹ ê¸°",
                    "ì˜ì™¸",
                    "ì˜ˆìƒì™¸",
                    "í—",
                    "ì™€ìš°",
                    "ëŒ€ë°•",
                    "ì–´ë¨¸",
                ],
                "english": [
                    "surprised",
                    "shocked",
                    "amazed",
                    "wow",
                    "incredible",
                    "unexpected",
                    "astonished",
                    "stunned",
                ],
                "intensity_modifiers": [
                    "ì •ë§",
                    "ë„ˆë¬´",
                    "ì™„ì „",
                    "ë§¤ìš°",
                    "really",
                    "very",
                    "extremely",
                    "absolutely",
                ],
            },
            "neutral": {
                "korean": [
                    "í‰ë²”",
                    "ê·¸ëƒ¥",
                    "ë³´í†µ",
                    "ì¼ë°˜",
                    "ê´œì°®",
                    "ë¬´ë‚œ",
                    "í‰ì˜¨",
                    "ì°¨ë¶„",
                    "ì•ˆì •",
                ],
                "english": [
                    "normal",
                    "okay",
                    "fine",
                    "average",
                    "calm",
                    "peaceful",
                    "stable",
                    "neutral",
                ],
                "intensity_modifiers": [
                    "ì¢€",
                    "ì•½ê°„",
                    "ì¡°ê¸ˆ",
                    "somewhat",
                    "slightly",
                    "a bit",
                ],
            },
        }

        # ê°ì • ì „í™˜ ê·œì¹™
        self.emotion_transitions = {
            "joy": {
                "to_sadness": 0.1,
                "to_anger": 0.05,
                "to_fear": 0.05,
                "to_surprise": 0.2,
                "to_neutral": 0.3,
            },
            "sadness": {
                "to_joy": 0.15,
                "to_anger": 0.25,
                "to_fear": 0.3,
                "to_surprise": 0.1,
                "to_neutral": 0.4,
            },
            "anger": {
                "to_joy": 0.1,
                "to_sadness": 0.2,
                "to_fear": 0.15,
                "to_surprise": 0.1,
                "to_neutral": 0.5,
            },
            "fear": {
                "to_joy": 0.05,
                "to_sadness": 0.3,
                "to_anger": 0.2,
                "to_surprise": 0.15,
                "to_neutral": 0.4,
            },
            "surprise": {
                "to_joy": 0.4,
                "to_sadness": 0.1,
                "to_anger": 0.1,
                "to_fear": 0.1,
                "to_neutral": 0.3,
            },
            "neutral": {
                "to_joy": 0.2,
                "to_sadness": 0.15,
                "to_anger": 0.15,
                "to_fear": 0.15,
                "to_surprise": 0.2,
            },
        }

    def infer_emotion(
        self, text: str, context: Dict[str, Any] = None
    ) -> EmotionInferenceResult:
        """Foundation Doctrine ê¸°ë°˜ ê°ì • ì¶”ë¡ """
        start_time = time.time()

        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = self._preprocess_text(text)

        # ê°ì • ì ìˆ˜ ê³„ì‚°
        emotion_scores = self._calculate_emotion_scores(text)

        # 1ì°¨ ê°ì • ê²°ì •
        primary_emotion = max(emotion_scores, key=emotion_scores.get)
        confidence = emotion_scores[primary_emotion]

        # 2ì°¨ ê°ì •ë“¤ ì¶”ì¶œ
        secondary_emotions = sorted(
            [
                (emotion, score)
                for emotion, score in emotion_scores.items()
                if emotion != primary_emotion
            ],
            key=lambda x: x[1],
            reverse=True,
        )[:3]

        # ê°ì • ê°•ë„ ê³„ì‚°
        emotional_intensity = self._calculate_intensity(text, primary_emotion)

        # ë‹¤ìŒ ê°ì • ì˜ˆì¸¡ (Foundation Doctrine ê¸°ë°˜)
        predicted_next_emotions = self._predict_next_emotions(primary_emotion)

        # ê°ì‡ ìœ¨ ì¡°íšŒ
        decay_rate = self.emotion_patterns.get(primary_emotion, {}).get(
            "decay_rate", 0.5
        )

        # ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ ë¶„ì„
        context_factors = self._analyze_context_factors(text, context)

        # Foundation Doctrine ì¤€ìˆ˜ ê²€ì¦
        foundation_compliance = self._validate_foundation_compliance(
            primary_emotion, confidence, context_factors
        )

        # ê²°ê³¼ ìƒì„±
        result = EmotionInferenceResult(
            primary_emotion=primary_emotion,
            confidence=confidence,
            secondary_emotions=secondary_emotions,
            emotional_intensity=emotional_intensity,
            predicted_next_emotions=predicted_next_emotions,
            decay_rate=decay_rate,
            analysis_time=time.time() - start_time,
            context_factors=context_factors,
            foundation_compliance=foundation_compliance,
        )

        # ì¶”ë¡  ì´ë ¥ ì €ì¥
        self.inference_history.append(
            {
                "timestamp": datetime.now().isoformat(),
                "text": text[:100] + "..." if len(text) > 100 else text,
                "result": result,
            }
        )

        # ì´ë ¥ í¬ê¸° ì œí•œ
        if len(self.inference_history) > 100:
            self.inference_history = self.inference_history[-100:]

        return result

    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        text = re.sub(r"[^\w\sê°€-í£]", " ", text)
        # ì—°ì† ê³µë°± ì œê±°
        text = re.sub(r"\s+", " ", text)
        # ì†Œë¬¸ì ë³€í™˜
        text = text.lower().strip()
        return text

    def _calculate_emotion_scores(self, text: str) -> Dict[str, float]:
        """ê³ ê¸‰ ê°ì • ì ìˆ˜ ê³„ì‚° - ë‹¤ì¸µì  ë¶„ì„"""
        emotion_scores = {emotion: 0.0 for emotion in self.emotion_keywords.keys()}

        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        keyword_scores = self._analyze_keywords(text)

        # 2ë‹¨ê³„: ë¬¸ë²•ì  íŒ¨í„´ ë¶„ì„
        grammatical_scores = self._analyze_grammatical_patterns(text)

        # 3ë‹¨ê³„: ê°ì • ê°•ë„ ë¶„ì„
        intensity_multiplier = self._calculate_emotion_intensity(text)

        # 4ë‹¨ê³„: ë¶€ì • í‘œí˜„ ë¶„ì„
        negation_factor = self._analyze_negation(text)

        # 5ë‹¨ê³„: ë¬¸ì¥ êµ¬ì¡° ë¶„ì„
        structural_scores = self._analyze_sentence_structure(text)

        # ì ìˆ˜ í†µí•©
        for emotion in emotion_scores.keys():
            base_score = keyword_scores.get(emotion, 0.0)
            grammar_boost = grammatical_scores.get(emotion, 0.0)
            structure_boost = structural_scores.get(emotion, 0.0)

            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            combined_score = (
                base_score * 0.5 + grammar_boost * 0.3 + structure_boost * 0.2
            )
            combined_score *= intensity_multiplier
            combined_score *= negation_factor.get(emotion, 1.0)

            emotion_scores[emotion] = max(0.0, combined_score)

        # ì •ê·œí™”
        total_score = sum(emotion_scores.values())
        if total_score > 0:
            emotion_scores = {
                emotion: score / total_score
                for emotion, score in emotion_scores.items()
            }
        else:
            # ê°ì •ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° - ë¬¸ì¥ ê¸¸ì´ì™€ í†¤ì„ ê³ ë ¤í•œ ê¸°ë³¸ê°’
            emotion_scores = self._get_default_emotion_scores(text)

        return emotion_scores

    def _analyze_keywords(self, text: str) -> Dict[str, float]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„"""
        scores = {emotion: 0.0 for emotion in self.emotion_keywords.keys()}

        for emotion, keywords in self.emotion_keywords.items():
            score = 0.0

            # ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in keywords["korean"] + keywords["english"]:
                if keyword in text:
                    score += 1.0

                    # ê°•ë„ ìˆ˜ì‹ì–´ ê·¼ì ‘ì„± ì²´í¬
                    for modifier in keywords["intensity_modifiers"]:
                        if modifier in text:
                            keyword_pos = text.find(keyword)
                            modifier_pos = text.find(modifier)
                            distance = abs(keyword_pos - modifier_pos)
                            if distance < 15:  # ê°€ê¹Œìš´ ê±°ë¦¬ì— ìˆìœ¼ë©´
                                score += 0.8 * (
                                    1 - distance / 15
                                )  # ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ì—¬ ê°€ì¤‘ì¹˜ ì ìš©

            scores[emotion] = score

        return scores

    def _analyze_grammatical_patterns(self, text: str) -> Dict[str, float]:
        """ë¬¸ë²•ì  íŒ¨í„´ ê¸°ë°˜ ê°ì • ë¶„ì„"""
        scores = {emotion: 0.0 for emotion in self.emotion_keywords.keys()}

        # ê°íƒ„ì‚¬ íŒ¨í„´
        if re.search(r"[!]{2,}", text):  # ì—°ì†ëœ ëŠë‚Œí‘œ
            scores["joy"] += 0.8
            scores["anger"] += 0.6
            scores["surprise"] += 0.7

        # ì§ˆë¬¸ íŒ¨í„´
        if "?" in text or any(
            q in text for q in ["ì™œ", "ì–´ë–»ê²Œ", "why", "how", "what"]
        ):
            scores["surprise"] += 0.4
            scores["fear"] += 0.2

        # ì™„ë£Œí˜• íŒ¨í„´ ("~í–ˆì–´", "~ëì–´")
        if re.search(r"í–ˆì–´|ëì–´|finished|done", text):
            scores["joy"] += 0.3
            scores["sadness"] += 0.2

        # ë¶€ì •ì  ì¶”ì¸¡ íŒ¨í„´
        if any(
            pattern in text for pattern in ["ì•„ë§ˆ", "í˜¹ì‹œ", "maybe", "perhaps", "might"]
        ):
            scores["fear"] += 0.3
            scores["neutral"] += 0.2

        return scores

    def _analyze_sentence_structure(self, text: str) -> Dict[str, float]:
        """ë¬¸ì¥ êµ¬ì¡° ê¸°ë°˜ ê°ì • ë¶„ì„"""
        scores = {emotion: 0.0 for emotion in self.emotion_keywords.keys()}

        # ë¬¸ì¥ ê¸¸ì´ ë¶„ì„
        length = len(text)
        if length < 5:  # ë§¤ìš° ì§§ì€ ë¬¸ì¥
            scores["neutral"] += 0.3
        elif length > 50:  # ê¸´ ë¬¸ì¥
            scores["sadness"] += 0.2
            scores["anger"] += 0.2

        # ë°˜ë³µ íŒ¨í„´ ("ì •ë§ì •ë§", "ã…‹ã…‹ã…‹")
        if re.search(r"(.)\1{2,}", text) or re.search(r"(..)\1+", text):
            scores["joy"] += 0.5
            scores["surprise"] += 0.3

        # ì´ëª¨í‹°ì½˜/ì´ëª¨ì§€ íŒ¨í„´
        emoticon_patterns = {
            "joy": [":)", "^^", "^_^", "ğŸ˜Š", "ğŸ˜„", "ğŸ˜ƒ", "ğŸ˜€", "ğŸ‰", "âœ¨", "ğŸ’›", "ğŸŒŸ"],
            "sadness": [":(", "T_T", "ã… ã… ", "ğŸ˜¢", "ğŸ˜­", "ğŸ˜", "ğŸ’”"],
            "anger": [">:(", "ğŸ˜ ", "ğŸ˜¡", "ğŸ’¢", "ğŸ”¥"],
            "surprise": [":O", "ğŸ˜®", "ğŸ˜²", "ğŸ˜¯", "â—", "â“", "â€¼ï¸"],
            "fear": ["ğŸ˜°", "ğŸ˜¨", "ğŸ˜±", "ğŸ’¦"],
        }

        for emotion, patterns in emoticon_patterns.items():
            for pattern in patterns:
                if pattern in text:
                    scores[emotion] += 0.7

        return scores

    def _calculate_emotion_intensity(self, text: str) -> float:
        """ê°ì • ê°•ë„ ê³„ì‚°"""
        intensity = 1.0

        # ëŒ€ë¬¸ì ì‚¬ìš©
        uppercase_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)
        intensity += uppercase_ratio * 0.5

        # ëŠë‚Œí‘œ ê°œìˆ˜
        exclamation_count = text.count("!")
        intensity += min(exclamation_count * 0.2, 1.0)

        # ë°˜ë³µ ê°•ì¡°
        if re.search(r"ì •ë§|ë„ˆë¬´|ë§¤ìš°|ì™„ì „|ì§„ì§œ", text):
            intensity += 0.3

        return min(intensity, 2.0)  # ìµœëŒ€ 2ë°°ê¹Œì§€

    def _analyze_negation(self, text: str) -> Dict[str, float]:
        """ë¶€ì • í‘œí˜„ ë¶„ì„"""
        negation_factors = {emotion: 1.0 for emotion in self.emotion_keywords.keys()}

        # ë¶€ì • íŒ¨í„´ë“¤
        negation_patterns = [
            "ì•ˆ",
            "ëª»",
            "ì—†",
            "ì•„ë‹ˆ",
            "don't",
            "not",
            "no",
            "never",
            "can't",
        ]

        for pattern in negation_patterns:
            if pattern in text:
                # ë¶€ì •ì–´ê°€ ìˆìœ¼ë©´ ê¸ì •ì  ê°ì •ì€ ì¤„ì´ê³  ë¶€ì •ì  ê°ì •ì€ ëŠ˜ë¦¼
                negation_factors["joy"] *= 0.3
                negation_factors["surprise"] *= 0.5
                negation_factors["sadness"] *= 1.3
                negation_factors["anger"] *= 1.2
                negation_factors["fear"] *= 1.2
                break

        return negation_factors

    def _get_default_emotion_scores(self, text: str) -> Dict[str, float]:
        """ê¸°ë³¸ ê°ì • ì ìˆ˜ (ê°ì •ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°)"""
        # ë¬¸ì¥ì˜ í†¤ì„ ë¶„ì„í•˜ì—¬ ê¸°ë³¸ ê°ì • ì„¤ì •
        if "?" in text:
            return {"surprise": 0.4, "neutral": 0.6}
        elif "!" in text:
            return {"joy": 0.3, "surprise": 0.2, "neutral": 0.5}
        elif len(text) < 5:
            return {"neutral": 1.0}
        else:
            return {"neutral": 0.8, "joy": 0.1, "surprise": 0.1}

    def _calculate_contextual_weight(self, text: str, emotion: str) -> float:
        """ë¬¸ë§¥ì  ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weight = 1.0

        # ë¶€ì • í‘œí˜„ ì²´í¬
        negative_patterns = ["ì•ˆ", "ëª»", "ì—†", "don't", "not", "no", "never"]
        for pattern in negative_patterns:
            if pattern in text:
                if emotion in ["joy", "surprise"]:
                    weight *= 0.5  # ê¸ì • ê°ì • ì•½í™”
                elif emotion in ["sadness", "anger", "fear"]:
                    weight *= 1.2  # ë¶€ì • ê°ì • ê°•í™”

        # ì§ˆë¬¸ í˜•íƒœ ì²´í¬
        if "?" in text or any(
            word in text for word in ["ì–´ë–»ê²Œ", "ì™œ", "ë­", "what", "how", "why"]
        ):
            if emotion == "surprise":
                weight *= 1.3
            elif emotion == "neutral":
                weight *= 1.1

        # ê°íƒ„ í‘œí˜„ ì²´í¬
        if "!" in text or any(
            word in text for word in ["ì™€", "í—‰", "ì–´ë¨¸", "wow", "oh"]
        ):
            if emotion in ["joy", "surprise", "anger"]:
                weight *= 1.2

        return weight

    def _calculate_intensity(self, text: str, emotion: str) -> float:
        """ê°ì • ê°•ë„ ê³„ì‚°"""
        base_intensity = 0.5

        # ê°•ë„ ìˆ˜ì‹ì–´ ì²´í¬
        intensity_modifiers = {
            "high": [
                "ì •ë§",
                "ë„ˆë¬´",
                "ì™„ì „",
                "ë§¤ìš°",
                "ì•„ì£¼",
                "extremely",
                "very",
                "really",
                "absolutely",
            ],
            "medium": ["ì¢€", "ì¡°ê¸ˆ", "ì•½ê°„", "somewhat", "slightly", "a bit"],
            "low": ["ë³„ë¡œ", "ê·¸ëƒ¥", "not really", "not very"],
        }

        for level, modifiers in intensity_modifiers.items():
            for modifier in modifiers:
                if modifier in text:
                    if level == "high":
                        base_intensity += 0.3
                    elif level == "medium":
                        base_intensity += 0.1
                    elif level == "low":
                        base_intensity -= 0.2

        # ë°˜ë³µ í‘œí˜„ ì²´í¬
        repeated_chars = re.findall(r"(.)\1{2,}", text)
        if repeated_chars:
            base_intensity += 0.2

        # ëŒ€ë¬¸ì ì‚¬ìš© ì²´í¬ (ì˜ì–´)
        if re.search(r"[A-Z]{2,}", text):
            base_intensity += 0.1

        return max(0.0, min(1.0, base_intensity))

    def _predict_next_emotions(self, current_emotion: str) -> List[str]:
        """ë‹¤ìŒ ê°ì • ì˜ˆì¸¡ (Foundation Doctrine ê¸°ë°˜)"""
        if current_emotion in self.emotion_patterns:
            return self.emotion_patterns[current_emotion]["next_likely"]
        else:
            # ê¸°ë³¸ ì „í™˜ ê·œì¹™ ì‚¬ìš©
            transitions = self.emotion_transitions.get(current_emotion, {})
            return sorted(
                transitions.keys(), key=lambda x: transitions.get(x, 0), reverse=True
            )[:2]

    def _analyze_context_factors(
        self, text: str, context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ ë¶„ì„"""
        factors = {
            "text_length": len(text),
            "word_count": len(text.split()),
            "question_present": "?" in text,
            "exclamation_present": "!" in text,
            "time_indicators": self._detect_time_indicators(text),
            "personal_pronouns": self._detect_personal_pronouns(text),
            "context_provided": context is not None,
        }

        if context:
            factors.update(
                {"context_keys": list(context.keys()), "context_size": len(context)}
            )

        return factors

    def _detect_time_indicators(self, text: str) -> List[str]:
        """ì‹œê°„ ì§€ì‹œì–´ ê°ì§€"""
        time_indicators = []
        patterns = {
            "past": [
                "í–ˆì—ˆ",
                "ì˜€ì—ˆ",
                "ê³¼ê±°",
                "ì˜ˆì „",
                "ì „ì—",
                "was",
                "were",
                "ago",
                "before",
            ],
            "present": ["ì§€ê¸ˆ", "í˜„ì¬", "ìš”ì¦˜", "ì˜¤ëŠ˜", "now", "today", "currently"],
            "future": ["ë¯¸ë˜", "ì•ìœ¼ë¡œ", "ë‚´ì¼", "will", "tomorrow", "next", "future"],
        }

        for tense, words in patterns.items():
            for word in words:
                if word in text:
                    time_indicators.append(tense)
                    break

        return time_indicators

    def _detect_personal_pronouns(self, text: str) -> List[str]:
        """ì¸ì¹­ ëŒ€ëª…ì‚¬ ê°ì§€"""
        pronouns = []
        patterns = {
            "first_person": ["ë‚˜", "ë‚´", "ìš°ë¦¬", "I", "me", "my", "we", "us", "our"],
            "second_person": ["ë„ˆ", "ë‹¹ì‹ ", "you", "your"],
            "third_person": [
                "ê·¸",
                "ê·¸ë…€",
                "ê·¸ë“¤",
                "he",
                "she",
                "they",
                "him",
                "her",
                "them",
            ],
        }

        for person, words in patterns.items():
            for word in words:
                if word in text:
                    pronouns.append(person)
                    break

        return pronouns

    def _validate_foundation_compliance(
        self, emotion: str, confidence: float, context_factors: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Foundation Doctrine ì¤€ìˆ˜ ê²€ì¦"""
        compliance = {"is_compliant": True, "violations": [], "doctrine_alignment": {}}

        # TT.004 ê²€ì¦: ê°ì •ì€ ë°ì´í„°ê°€ ì•„ë‹ˆë¼ íŒë‹¨ì˜ ë¦¬ë“¬ì´ë‹¤
        if confidence < 0.3:
            compliance["violations"].append("ê°ì • ì‹ ë¢°ë„ ë¶€ì¡± (TT.004 ìœ„ë°˜)")
            compliance["is_compliant"] = False

        # ë¦¬ë“¬ íŒ¨í„´ ì¡´ì¬ í™•ì¸
        if emotion in self.emotion_patterns:
            compliance["doctrine_alignment"]["rhythm_pattern_exists"] = True
        else:
            compliance["doctrine_alignment"]["rhythm_pattern_exists"] = False
            compliance["violations"].append("ë¦¬ë“¬ íŒ¨í„´ ë¯¸ì •ì˜ (TT.004 ìœ„ë°˜)")

        # ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤ ê²€ì¦
        if not context_factors.get("context_provided", False):
            compliance["violations"].append("ì»¨í…ìŠ¤íŠ¸ ë¯¸ê³ ë ¤ (ì ì‘ì„± ìœ„ë°˜)")

        return compliance

    def get_emotion_flow_analysis(self, limit: int = 10) -> Dict[str, Any]:
        """ê°ì • íë¦„ ë¶„ì„"""
        if len(self.inference_history) < 2:
            return {
                "message": "ë¶„ì„í•  ë°ì´í„° ë¶€ì¡±",
                "history_count": len(self.inference_history),
            }

        recent_history = self.inference_history[-limit:]

        # ê°ì • ë³€í™” íŒ¨í„´ ë¶„ì„
        emotion_sequence = [entry["result"].primary_emotion for entry in recent_history]
        transitions = []

        for i in range(len(emotion_sequence) - 1):
            current = emotion_sequence[i]
            next_emotion = emotion_sequence[i + 1]
            transitions.append((current, next_emotion))

        # ì „í™˜ ë¹ˆë„ ê³„ì‚°
        transition_counts = {}
        for current, next_emotion in transitions:
            key = f"{current} â†’ {next_emotion}"
            transition_counts[key] = transition_counts.get(key, 0) + 1

        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = sum(
            entry["result"].confidence for entry in recent_history
        ) / len(recent_history)

        # í‰ê·  ê°•ë„ ê³„ì‚°
        avg_intensity = sum(
            entry["result"].emotional_intensity for entry in recent_history
        ) / len(recent_history)

        return {
            "analysis_period": f"ìµœê·¼ {len(recent_history)}ê°œ ì¶”ë¡ ",
            "emotion_sequence": emotion_sequence,
            "most_common_transitions": sorted(
                transition_counts.items(), key=lambda x: x[1], reverse=True
            )[:5],
            "average_confidence": round(avg_confidence, 3),
            "average_intensity": round(avg_intensity, 3),
            "dominant_emotion": max(set(emotion_sequence), key=emotion_sequence.count),
            "emotion_diversity": len(set(emotion_sequence)),
            "foundation_compliance_rate": self._calculate_compliance_rate(
                recent_history
            ),
        }

    def _calculate_compliance_rate(self, history: List[Dict]) -> float:
        """Foundation Doctrine ì¤€ìˆ˜ìœ¨ ê³„ì‚°"""
        if not history:
            return 0.0

        compliant_count = sum(
            1
            for entry in history
            if entry["result"].foundation_compliance["is_compliant"]
        )
        return compliant_count / len(history)


def infer_emotion(text: str, context: Dict[str, Any] = None) -> EmotionInferenceResult:
    """ê°ì • ì¶”ë¡  í¸ì˜ í•¨ìˆ˜"""
    engine = EmotionInferenceEngine()
    return engine.infer_emotion(text, context)


def analyze_emotional_rhythm(texts: List[str]) -> Dict[str, Any]:
    """ê°ì • ë¦¬ë“¬ ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    engine = EmotionInferenceEngine()

    results = []
    for text in texts:
        result = engine.infer_emotion(text)
        results.append(result)

    return engine.get_emotion_flow_analysis()


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_emotion_inference():
    """ê°ì • ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ’­ Foundation ê¸°ë°˜ ê°ì • ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    engine = EmotionInferenceEngine()

    test_cases = [
        "ì˜¤ëŠ˜ ì •ë§ ê¸°ìœ ì¼ì´ ìˆì—ˆì–´ìš”! ë„ˆë¬´ í–‰ë³µí•´ìš”.",
        "ì¢€ ìŠ¬í”„ê³  ìš°ìš¸í•œ í•˜ë£¨ì˜€ì–´ìš”. í˜ë“¤ì—ˆìŠµë‹ˆë‹¤.",
        "í™”ê°€ ë‚˜ê³  ì§œì¦ì´ ë‚˜ìš”. ì •ë§ ì—´ë°›ì•„ìš”!",
        "ë¬´ì„œì›Œìš”. ë„ˆë¬´ ë¶ˆì•ˆí•˜ê³  ê±±ì •ë˜ë„¤ìš”.",
        "ì–´? ì´ê²Œ ë­ì˜ˆìš”? ì •ë§ ë†€ëì–´ìš”!",
        "ê·¸ëƒ¥ í‰ë²”í•œ í•˜ë£¨ì˜€ì–´ìš”. íŠ¹ë³„í•œ ì¼ì€ ì—†ì—ˆê³ ìš”.",
    ]

    for i, text in enumerate(test_cases, 1):
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i}: {text}")

        result = engine.infer_emotion(text)

        print(f"  ğŸ’­ ì£¼ìš” ê°ì •: {result.primary_emotion}")
        print(f"  ğŸ“Š ì‹ ë¢°ë„: {result.confidence:.3f}")
        print(f"  ğŸ”¥ ê°•ë„: {result.emotional_intensity:.3f}")
        print(f"  ğŸ”® ë‹¤ìŒ ì˜ˆì¸¡: {result.predicted_next_emotions}")
        print(f"  ğŸ“‰ ê°ì‡ ìœ¨: {result.decay_rate:.3f}")
        print(f"  âš–ï¸ Foundation ì¤€ìˆ˜: {result.foundation_compliance['is_compliant']}")
        print(f"  â±ï¸ ë¶„ì„ ì‹œê°„: {result.analysis_time:.4f}ì´ˆ")

        if result.foundation_compliance["violations"]:
            print(f"  âš ï¸ ìœ„ë°˜ì‚¬í•­: {result.foundation_compliance['violations']}")

    # ê°ì • íë¦„ ë¶„ì„
    print("\nğŸ“ˆ ê°ì • íë¦„ ë¶„ì„:")
    flow_analysis = engine.get_emotion_flow_analysis()
    print(f"  ì£¼ìš” ê°ì •: {flow_analysis['dominant_emotion']}")
    print(f"  í‰ê·  ì‹ ë¢°ë„: {flow_analysis['average_confidence']}")
    print(f"  í‰ê·  ê°•ë„: {flow_analysis['average_intensity']}")
    print(f"  Foundation ì¤€ìˆ˜ìœ¨: {flow_analysis['foundation_compliance_rate']:.1%}")

    if flow_analysis["most_common_transitions"]:
        print("  ì£¼ìš” ì „í™˜ íŒ¨í„´:")
        for transition, count in flow_analysis["most_common_transitions"]:
            print(f"    {transition}: {count}íšŒ")

    print("\nğŸ‰ ê°ì • ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def to_emotion_context(result: EmotionInferenceResult) -> EmotionContext:
    return EmotionContext(
        primary_emotion=result.primary_emotion,
        intensity=result.emotional_intensity,
        confidence=result.confidence,
    )


# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    test_emotion_inference()
