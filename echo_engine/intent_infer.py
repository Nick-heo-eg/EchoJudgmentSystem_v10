#!/usr/bin/env python3
"""
ğŸ¯ Intent Inference Engine - Enhanced
ë°œí™” ìœ í˜•/ë¦¬ë“¬ ë¶„ë¥˜ ê°•í™” ì‹œìŠ¤í…œ

í•µì‹¬ ê¸°ëŠ¥:
1. ì„¸ë°€í•œ ë°œí™” ì˜ë„ ë¶„ë¥˜ (12ê°€ì§€ ìœ í˜•)
2. ì‚¬ìš©ì ë¦¬ë“¬ íŒ¨í„´ ê°ì§€ ë° í•™ìŠµ
3. ë§¥ë½ ê¸°ë°˜ ì˜ë„ ì¶”ë¡ 
4. ê°ì •-ì˜ë„ ìƒê´€ê´€ê³„ ë¶„ì„
"""

import re
import json
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
from collections import defaultdict, deque


class DetailedIntentType(Enum):
    """ì„¸ë°€í•œ ì˜ë„ ë¶„ë¥˜"""

    # ê¸°ë³¸ ì˜ë„ë“¤
    CASUAL_GREETING = "casual_greeting"  # ì¼ìƒì  ì¸ì‚¬
    CASUAL_CHAT = "casual_chat"  # ì¼ìƒ ëŒ€í™”
    EMOTIONAL_SUPPORT = "emotional_support"  # ê°ì •ì  ì§€ì›
    DECISION_HELP = "decision_help"  # ê²°ì • ë„ì›€
    PHILOSOPHICAL_INQUIRY = "philosophical_inquiry"  # ì² í•™ì  ì§ˆë¬¸
    CRISIS_INTERVENTION = "crisis_intervention"  # ìœ„ê¸° ê°œì…

    # í™•ì¥ ì˜ë„ë“¤
    INFORMATION_SEEKING = "information_seeking"  # ì •ë³´ íƒìƒ‰
    CREATIVE_COLLABORATION = "creative_collaboration"  # ì°½ì˜ì  í˜‘ë ¥
    RELATIONSHIP_ADVICE = "relationship_advice"  # ê´€ê³„ ì¡°ì–¸
    PERSONAL_GROWTH = "personal_growth"  # ê°œì¸ ì„±ì¥
    TASK_ASSISTANCE = "task_assistance"  # ì—…ë¬´ ì§€ì›
    PLAYFUL_INTERACTION = "playful_interaction"  # ì¥ë‚œìŠ¤ëŸ¬ìš´ ìƒí˜¸ì‘ìš©

    # ì§€ì—­ ì„œë¹„ìŠ¤ ê²€ìƒ‰ ì˜ë„ë“¤
    LOCAL_SERVICE_SEARCH = (
        "local_service_search"  # ë³‘ì›/ì•½êµ­/ì‘ê¸‰ì‹¤ ë“± ì§€ì—­ ì„œë¹„ìŠ¤ ê²€ìƒ‰
    )


class SpeechRhythmPattern(Enum):
    """ë§í•˜ê¸° ë¦¬ë“¬ íŒ¨í„´"""

    URGENT_STACCATO = "urgent_staccato"  # ê¸‰í•œ ë‹¨ë„ì§ì…
    CASUAL_FLOWING = "casual_flowing"  # ìºì£¼ì–¼ íë¦„
    FORMAL_STRUCTURED = "formal_structured"  # ê²©ì‹ êµ¬ì¡°í™”
    EMOTIONAL_WAVES = "emotional_waves"  # ê°ì •ì  ë¬¼ê²°
    PLAYFUL_BOUNCY = "playful_bouncy"  # ì¥ë‚œìŠ¤ëŸ¬ìš´ íŠ€ê¹€
    THOUGHTFUL_PAUSED = "thoughtful_paused"  # ì‚¬ìƒ‰ì  ì¼ì‹œì •ì§€
    CONFUSED_SCATTERED = "confused_scattered"  # í˜¼ë€ìŠ¤ëŸ¬ìš´ ì‚°ë§Œ
    CONFIDENT_STEADY = "confident_steady"  # ìì‹ ê° ìˆëŠ” ì•ˆì •


@dataclass
class IntentInferenceResult:
    """ì˜ë„ ì¶”ë¡  ê²°ê³¼"""

    primary_intent: DetailedIntentType
    confidence: float
    secondary_intents: List[Tuple[DetailedIntentType, float]]
    speech_rhythm: SpeechRhythmPattern
    rhythm_confidence: float
    linguistic_features: Dict[str, Any]
    contextual_factors: List[str]
    user_pattern_match: Optional[str]


@dataclass
class UserSpeechProfile:
    """ì‚¬ìš©ì ë§í•˜ê¸° í”„ë¡œí•„"""

    user_id: str
    dominant_rhythm: SpeechRhythmPattern
    intent_frequencies: Dict[str, int]
    linguistic_markers: Dict[str, List[str]]
    interaction_history: deque
    last_updated: datetime
    confidence_score: float


class EnhancedIntentInferenceEngine:
    """í–¥ìƒëœ ì˜ë„ ì¶”ë¡  ì—”ì§„ - ê²€ìˆ˜ê¸° ëª¨ë“œ (ì°¨ë‹¨ì€ ìƒìœ„ì—ì„œ ê²°ì •)"""

    def __init__(self, learning_window: int = 50):
        self.learning_window = learning_window

        # ì˜ë„ ë¶„ë¥˜ íŒ¨í„´ë“¤
        self.intent_patterns = self._load_intent_patterns()
        self.rhythm_patterns = self._load_rhythm_patterns()

        # ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë¦¬
        self.user_profiles: Dict[str, UserSpeechProfile] = {}

        # ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ì„ ìœ„í•œ íˆìŠ¤í† ë¦¬
        self.session_contexts: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10))

        # ê°ì •-ì˜ë„ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤
        self.emotion_intent_correlations = self._build_emotion_intent_matrix()

        # í™˜ê²½ ë³€ìˆ˜ë¡œ ë™ì‘ ëª¨ë“œ ì œì–´
        import os

        self.use_engine = os.getenv("ECHO_USE_INTENT_ENGINE", "true").lower() == "true"
        self.safe_only = os.getenv("ECHO_INTENT_SAFE_ONLY", "true").lower() == "true"
        self.unclear_threshold = float(
            os.getenv("ECHO_INTENT_UNCLEAR_THRESHOLD", "0.35")
        )
        self.pass_through_on_llm = (
            os.getenv("ECHO_PASS_THROUGH_ON_LLM", "true").lower() == "true"
        )

        print(
            f"ğŸ¯ Enhanced Intent Inference Engine ì´ˆê¸°í™” ì™„ë£Œ (safe_only={self.safe_only}, pass_through={self.pass_through_on_llm})"
        )

    def infer_intent_and_rhythm(
        self,
        text: str,
        session_id: str,
        emotion_context: Dict[str, Any] = None,
        user_id: str = None,
        llm_text: str = None,
    ) -> IntentInferenceResult:
        """ì˜ë„ì™€ ë¦¬ë“¬ ì¢…í•© ì¶”ë¡ """

        emotion_context = emotion_context or {}

        # 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ
        linguistic_features = self._extract_linguistic_features(text)

        # 2. ê¸°ë³¸ ì˜ë„ ë¶„ë¥˜
        primary_intent, intent_confidence, secondary_intents = self._classify_intent(
            text, linguistic_features, emotion_context
        )

        # 3. ë§¥ë½ ê¸°ë°˜ ì˜ë„ ë³´ì •
        if session_id in self.session_contexts:
            primary_intent, intent_confidence = self._apply_contextual_correction(
                primary_intent, intent_confidence, session_id, text
            )

        # 4. ë§í•˜ê¸° ë¦¬ë“¬ ë¶„ì„
        speech_rhythm, rhythm_confidence = self._analyze_speech_rhythm(
            text, linguistic_features, primary_intent
        )

        # 5. ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ ë° ì ìš©
        user_pattern_match = None
        if user_id:
            user_pattern_match = self._update_and_match_user_pattern(
                user_id, primary_intent, speech_rhythm, text
            )

        # 6. ë§¥ë½ ìš”ì†Œ ì‹ë³„
        contextual_factors = self._identify_contextual_factors(
            text, linguistic_features, emotion_context
        )

        # 7. ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.session_contexts[session_id].append(
            {
                "text": text,
                "intent": primary_intent,
                "rhythm": speech_rhythm,
                "timestamp": datetime.now(),
                "emotion": emotion_context.get("primary_emotion", "neutral"),
            }
        )

        result = IntentInferenceResult(
            primary_intent=primary_intent,
            confidence=intent_confidence,
            secondary_intents=secondary_intents,
            speech_rhythm=speech_rhythm,
            rhythm_confidence=rhythm_confidence,
            linguistic_features=linguistic_features,
            contextual_factors=contextual_factors,
            user_pattern_match=user_pattern_match,
        )

        # ê²€ìˆ˜ ì •ë³´ë§Œ ë¡œê·¸ (ì°¨ë‹¨ì€ ìƒìœ„ì—ì„œ ê²°ì •)
        print(
            f"[INTENT] intent={primary_intent.value} conf={intent_confidence:.2f} rhythm={speech_rhythm.value} llm_available={bool((llm_text or '').strip())}"
        )

        return result

    def _extract_linguistic_features(self, text: str) -> Dict[str, Any]:
        """ì–¸ì–´í•™ì  íŠ¹ì§• ì¶”ì¶œ"""

        features = {
            "text_length": len(text),
            "word_count": len(text.split()),
            "sentence_count": len([s for s in text.split(".") if s.strip()]),
            "question_marks": text.count("?"),
            "exclamation_marks": text.count("!"),
            "ellipsis_count": text.count("..."),
            "emoji_count": len(re.findall(r"[ğŸ˜€-ğŸ™]", text)),
            "uppercase_ratio": sum(1 for c in text if c.isupper()) / max(len(text), 1),
            "punctuation_density": len(re.findall(r"[.,!?;:]", text))
            / max(len(text), 1),
        }

        # í•œêµ­ì–´ íŠ¹ì„±
        features.update(
            {
                "informal_endings": len(re.findall(r"(ì–´|ì•¼|ì§€|ë„¤|ìš”)$", text)),
                "formal_endings": len(re.findall(r"(ìŠµë‹ˆë‹¤|ë©ë‹ˆë‹¤|ì…ë‹ˆë‹¤)$", text)),
                "onomatopoeia": len(re.findall(r"(ã…‹ã…‹|ã…ã…|ã… ã… |ã…œã…œ)", text)),
                "filler_words": len(
                    re.findall(r"(ìŒ|ì–´|ê·¸|ë­”ê°€|ì¢€)", text, re.IGNORECASE)
                ),
            }
        )

        # ê°ì • í‘œí˜„ ê°•ë„
        features["emotional_intensifiers"] = len(
            re.findall(r"(ë„ˆë¬´|ì •ë§|ì§„ì§œ|ì™„ì „|ì—„ì²­|ë§¤ìš°|ì•„ì£¼)", text, re.IGNORECASE)
        )

        return features

    def _classify_intent(
        self, text: str, features: Dict[str, Any], emotion_context: Dict[str, Any]
    ) -> Tuple[DetailedIntentType, float, List[Tuple[DetailedIntentType, float]]]:
        """ì˜ë„ ë¶„ë¥˜"""

        text_lower = text.lower()
        intent_scores = defaultdict(float)

        # íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ ë¶„ë¥˜
        for intent_type, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if isinstance(pattern, dict):
                    # ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” í‚¤ì›Œë“œ
                    for keyword, weight in pattern.items():
                        if keyword in text_lower:
                            intent_scores[intent_type] += weight
                else:
                    # ë‹¨ìˆœ í‚¤ì›Œë“œ
                    if pattern in text_lower:
                        intent_scores[intent_type] += 1.0

        # ì–¸ì–´í•™ì  íŠ¹ì§• ê¸°ë°˜ ë³´ì •
        intent_scores = self._apply_linguistic_corrections(intent_scores, features)

        # ê°ì •-ì˜ë„ ìƒê´€ê´€ê³„ ì ìš©
        if emotion_context.get("primary_emotion"):
            emotion = emotion_context["primary_emotion"]
            if emotion in self.emotion_intent_correlations:
                for intent_str, correlation in self.emotion_intent_correlations[
                    emotion
                ].items():
                    try:
                        intent_enum = DetailedIntentType(intent_str)
                        intent_scores[intent_enum.value] += correlation * 0.3
                    except ValueError:
                        continue

        # ì ìˆ˜ ì •ê·œí™” ë° ìˆœìœ„ ê²°ì •
        if not intent_scores:
            # ê¸°ë³¸ê°’
            return DetailedIntentType.CASUAL_CHAT, 0.3, []

        # ìƒìœ„ ì˜ë„ë“¤ ì¶”ì¶œ
        sorted_intents = sorted(intent_scores.items(), key=lambda x: x[1], reverse=True)

        # ì£¼ ì˜ë„
        primary_intent_str, primary_score = sorted_intents[0]
        primary_intent = DetailedIntentType(primary_intent_str)

        # ì •ê·œí™”ëœ ì‹ ë¢°ë„
        total_score = sum(intent_scores.values())
        primary_confidence = primary_score / total_score if total_score > 0 else 0.3

        # ë³´ì¡° ì˜ë„ë“¤
        secondary_intents = []
        for intent_str, score in sorted_intents[1:4]:  # ìƒìœ„ 3ê°œê¹Œì§€
            if score > 0.1:  # ì„ê³„ê°’ ì´ìƒë§Œ
                try:
                    intent = DetailedIntentType(intent_str)
                    confidence = score / total_score
                    secondary_intents.append((intent, confidence))
                except ValueError:
                    continue

        return primary_intent, min(primary_confidence, 1.0), secondary_intents

    def _analyze_speech_rhythm(
        self, text: str, features: Dict[str, Any], intent: DetailedIntentType
    ) -> Tuple[SpeechRhythmPattern, float]:
        """ë§í•˜ê¸° ë¦¬ë“¬ ë¶„ì„"""

        rhythm_scores = defaultdict(float)

        # êµ¬ë‘ì ê³¼ ê¸¸ì´ ê¸°ë°˜ ë¦¬ë“¬ ë¶„ì„
        if features["exclamation_marks"] >= 2 or features["uppercase_ratio"] > 0.3:
            rhythm_scores["urgent_staccato"] += 2.0

        if features["ellipsis_count"] >= 1 or features["filler_words"] >= 2:
            rhythm_scores["thoughtful_paused"] += 1.5

        if features["onomatopoeia"] >= 1 or features["emoji_count"] >= 2:
            rhythm_scores["playful_bouncy"] += 2.0

        if features["formal_endings"] >= 1:
            rhythm_scores["formal_structured"] += 1.5

        if features["emotional_intensifiers"] >= 2:
            rhythm_scores["emotional_waves"] += 1.5

        # í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ êµ¬ì¡° ê¸°ë°˜
        if features["word_count"] <= 3 and features["exclamation_marks"] >= 1:
            rhythm_scores["urgent_staccato"] += 1.0
        elif features["word_count"] > 20 and features["sentence_count"] >= 3:
            rhythm_scores["formal_structured"] += 1.0

        # ì˜ë„ì™€ ë¦¬ë“¬ì˜ ìƒê´€ê´€ê³„
        intent_rhythm_mapping = {
            DetailedIntentType.CRISIS_INTERVENTION: "urgent_staccato",
            DetailedIntentType.PHILOSOPHICAL_INQUIRY: "thoughtful_paused",
            DetailedIntentType.PLAYFUL_INTERACTION: "playful_bouncy",
            DetailedIntentType.CASUAL_GREETING: "casual_flowing",
            DetailedIntentType.EMOTIONAL_SUPPORT: "emotional_waves",
        }

        if intent in intent_rhythm_mapping:
            rhythm_scores[intent_rhythm_mapping[intent]] += 1.0

        # ê¸°ë³¸ê°’ ì²˜ë¦¬
        if not rhythm_scores:
            return SpeechRhythmPattern.CASUAL_FLOWING, 0.5

        # ìµœê³  ì ìˆ˜ ë¦¬ë“¬ ì„ íƒ
        best_rhythm_str = max(rhythm_scores.items(), key=lambda x: x[1])[0]
        best_rhythm = SpeechRhythmPattern(best_rhythm_str)

        # ì‹ ë¢°ë„ ê³„ì‚°
        total_score = sum(rhythm_scores.values())
        confidence = (
            rhythm_scores[best_rhythm_str] / total_score if total_score > 0 else 0.5
        )

        return best_rhythm, min(confidence, 1.0)

    def _apply_contextual_correction(
        self,
        intent: DetailedIntentType,
        confidence: float,
        session_id: str,
        current_text: str,
    ) -> Tuple[DetailedIntentType, float]:
        """ë§¥ë½ ê¸°ë°˜ ì˜ë„ ë³´ì •"""

        recent_history = list(self.session_contexts[session_id])[-3:]  # ìµœê·¼ 3ê°œ

        if not recent_history:
            return intent, confidence

        # ì—°ì†ëœ ë™ì¼ ì˜ë„ íŒ¨í„´ ê°ì§€
        recent_intents = [h["intent"] for h in recent_history]
        if len(set(recent_intents)) == 1 and len(recent_intents) >= 2:
            # ë™ì¼ ì˜ë„ê°€ ê³„ì†ë˜ë©´ ì‹ ë¢°ë„ ì¦ê°€
            confidence = min(confidence * 1.2, 1.0)

        # ëŒ€í™” íë¦„ ê¸°ë°˜ ë³´ì •
        if recent_history:
            last_entry = recent_history[-1]

            # ì§ˆë¬¸ â†’ ë‹µë³€ íŒ¨í„´
            if (
                last_entry["intent"] == DetailedIntentType.INFORMATION_SEEKING
                and intent == DetailedIntentType.CASUAL_CHAT
            ):
                # ì •ë³´ ìš”ì²­ í›„ ì¼ë°˜ ëŒ€í™”ëŠ” ì¶”ê°€ ì§ˆë¬¸ì¼ ê°€ëŠ¥ì„±
                intent = DetailedIntentType.INFORMATION_SEEKING
                confidence = confidence * 0.8

            # ê°ì •ì  ì§€ì› â†’ í›„ì† ëŒ€í™”
            elif (
                last_entry["intent"] == DetailedIntentType.EMOTIONAL_SUPPORT
                and intent == DetailedIntentType.CASUAL_CHAT
            ):
                # ê°ì • ì§€ì› í›„ ì¼ë°˜ ëŒ€í™”ëŠ” ê³„ì†ëœ ê°ì • í‘œí˜„ì¼ ê°€ëŠ¥ì„±
                intent = DetailedIntentType.EMOTIONAL_SUPPORT
                confidence = confidence * 0.9

        return intent, confidence

    def _update_and_match_user_pattern(
        self,
        user_id: str,
        intent: DetailedIntentType,
        rhythm: SpeechRhythmPattern,
        text: str,
    ) -> Optional[str]:
        """ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ ë° ë§¤ì¹­"""

        current_time = datetime.now()

        # ìƒˆ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± ë˜ëŠ” ê¸°ì¡´ í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = UserSpeechProfile(
                user_id=user_id,
                dominant_rhythm=rhythm,
                intent_frequencies=defaultdict(int),
                linguistic_markers=defaultdict(list),
                interaction_history=deque(maxlen=self.learning_window),
                last_updated=current_time,
                confidence_score=0.1,
            )

        profile = self.user_profiles[user_id]

        # í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        profile.intent_frequencies[intent.value] += 1
        profile.interaction_history.append(
            {
                "intent": intent,
                "rhythm": rhythm,
                "text_snippet": text[:50],  # ì²˜ìŒ 50ìë§Œ
                "timestamp": current_time,
            }
        )
        profile.last_updated = current_time

        # ì§€ë°°ì  ë¦¬ë“¬ ì—…ë°ì´íŠ¸
        rhythm_counts = defaultdict(int)
        for interaction in profile.interaction_history:
            rhythm_counts[interaction["rhythm"]] += 1

        if rhythm_counts:
            profile.dominant_rhythm = max(rhythm_counts.items(), key=lambda x: x[1])[0]

        # ì‹ ë¢°ë„ ì¦ê°€
        profile.confidence_score = min(profile.confidence_score + 0.05, 1.0)

        # íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜
        total_interactions = len(profile.interaction_history)
        if total_interactions >= 5:
            dominant_intent = max(
                profile.intent_frequencies.items(), key=lambda x: x[1]
            )[0]
            return (
                f"ì‚¬ìš©ì ì£¼ìš” íŒ¨í„´: {dominant_intent} ({profile.dominant_rhythm.value})"
            )

        return None

    def _identify_contextual_factors(
        self, text: str, features: Dict[str, Any], emotion_context: Dict[str, Any]
    ) -> List[str]:
        """ë§¥ë½ ìš”ì†Œ ì‹ë³„"""

        factors = []

        # ì‹œê°„ì  ë§¥ë½
        if any(
            time_word in text.lower()
            for time_word in ["ì§€ê¸ˆ", "ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼", "ìµœê·¼"]
        ):
            factors.append("ì‹œê°„ì _ì°¸ì¡°")

        # ê´€ê³„ì  ë§¥ë½
        if any(
            relation in text.lower()
            for relation in ["ì¹œêµ¬", "ê°€ì¡±", "ë™ë£Œ", "ìƒì‚¬", "ì—°ì¸"]
        ):
            factors.append("ê´€ê³„ì _ë§¥ë½")

        # ê°ì •ì  ê°•ë„
        emotion_intensity = emotion_context.get("emotion_intensity", 0)
        if emotion_intensity > 0.7:
            factors.append("ê³ ê°•ë„_ê°ì •")
        elif emotion_intensity < 0.3:
            factors.append("ì €ê°•ë„_ê°ì •")

        # ì–¸ì–´ì  íŠ¹ì„±
        if features["formal_endings"] > 0:
            factors.append("ê²©ì‹ì²´_ì‚¬ìš©")
        if features["onomatopoeia"] > 0:
            factors.append("í‘œí˜„ì _ì–¸ì–´")
        if features["question_marks"] >= 2:
            factors.append("ë‹¤ì¤‘_ì§ˆë¬¸")

        # ê¸´ê¸‰ì„± ì§€í‘œ
        if (
            features["exclamation_marks"] >= 2
            and features["emotional_intensifiers"] >= 1
        ):
            factors.append("ê¸´ê¸‰ì„±_ë†’ìŒ")

        return factors

    def _apply_linguistic_corrections(
        self, scores: Dict[str, float], features: Dict[str, Any]
    ) -> Dict[str, float]:
        """ì–¸ì–´í•™ì  íŠ¹ì§• ê¸°ë°˜ ì ìˆ˜ ë³´ì •"""

        # ì§ˆë¬¸ í˜•íƒœë©´ ì •ë³´ íƒìƒ‰ì´ë‚˜ ë„ì›€ ìš”ì²­ì¼ ê°€ëŠ¥ì„± ì¦ê°€
        if features["question_marks"] >= 1:
            scores["information_seeking"] += 0.5
            scores["decision_help"] += 0.3

        # ê°ì • í‘œí˜„ì´ ê°•í•˜ë©´ ê°ì •ì  ì§€ì› í•„ìš”ì„± ì¦ê°€
        if features["emotional_intensifiers"] >= 2:
            scores["emotional_support"] += 0.7

        # ê²©ì‹ì²´ ì‚¬ìš©ì‹œ ì§„ì§€í•œ ì˜ë„ì¼ ê°€ëŠ¥ì„±
        if features["formal_endings"] >= 1:
            scores["philosophical_inquiry"] += 0.3
            scores["decision_help"] += 0.3

        # ìºì£¼ì–¼í•œ í‘œí˜„ì´ ë§ìœ¼ë©´ ì¼ìƒ ëŒ€í™”
        if features["informal_endings"] >= 1 and features["onomatopoeia"] >= 1:
            scores["casual_chat"] += 0.5
            scores["playful_interaction"] += 0.3

        return scores

    def _load_intent_patterns(self) -> Dict[str, List]:
        """ì˜ë„ ë¶„ë¥˜ íŒ¨í„´ ë¡œë“œ"""
        return {
            "casual_greeting": [
                "ì•ˆë…•",
                "hello",
                "hi",
                "í•˜ì´",
                "ì¢‹ì€ ì•„ì¹¨",
                "ì¢‹ì€ í•˜ë£¨",
            ],
            "casual_chat": ["ê·¸ëƒ¥", "ë³„ë¡œ", "ë­í•˜ê³ ", "ì–´ë•Œ", "ê´œì°®ì•„", "ê·¸ë ‡êµ¬ë‚˜"],
            "emotional_support": [
                {"í˜ë“¤ì–´": 2.0, "ìš°ìš¸í•´": 2.0, "ìŠ¬í¼": 2.0, "ì™¸ë¡œì›Œ": 2.0},
                {"ìŠ¤íŠ¸ë ˆìŠ¤": 1.5, "ê±±ì •": 1.5, "ë¶ˆì•ˆ": 1.5, "í™”ë‚˜": 1.5},
            ],
            "decision_help": [
                {"ê²°ì •": 2.0, "ì„ íƒ": 2.0, "ê³ ë¯¼": 2.0, "ì¡°ì–¸": 2.0},
                {"ì–´ë–»ê²Œ": 1.5, "ë­˜": 1.5, "ë°©ë²•": 1.5},
            ],
            "philosophical_inquiry": [
                {"ì˜ë¯¸": 2.0, "ì¸ìƒ": 2.0, "ì™œ": 1.5, "ëª©ì ": 2.0},
                {"ì² í•™": 2.0, "ì¡´ì¬": 1.5, "ì§„ë¦¬": 2.0},
            ],
            "crisis_intervention": [
                {"ì£½ê³ ì‹¶ì–´": 3.0, "ìì‚´": 3.0, "ëë‚´ê³ ì‹¶ì–´": 3.0},
                {"ë„ˆë¬´í˜ë“¤ì–´": 2.0, "í¬ê¸°í•˜ê³ ì‹¶ì–´": 2.0},
            ],
            "information_seeking": [
                {"ì•Œë ¤ì¤˜": 2.0, "ê¶ê¸ˆí•´": 1.5, "ì„¤ëª…": 1.5, "ë­ì•¼": 1.0},
                {"ì–´ë–¤": 1.0, "ë¬´ìŠ¨": 1.0},
            ],
            "creative_collaboration": [
                {"ì°½ì‘": 2.0, "ì•„ì´ë””ì–´": 1.5, "ìƒìƒ": 1.5, "ë§Œë“¤ì–´": 1.5},
                {"ë””ìì¸": 1.5, "ì‘í’ˆ": 1.5},
            ],
            "relationship_advice": [
                {"ì¹œêµ¬": 1.5, "ì—°ì¸": 2.0, "ì‚¬ë‘": 1.5, "ê´€ê³„": 2.0},
                {"ì‹¸ì› ì–´": 2.0, "í—¤ì–´ì ¸": 2.0},
            ],
            "personal_growth": [
                {"ì„±ì¥": 2.0, "ë°œì „": 1.5, "ë°°ìš°ê³ ì‹¶ì–´": 1.5, "ê°œì„ ": 1.5},
                {"ëŠ¥ë ¥": 1.0, "ì‹¤ë ¥": 1.0},
            ],
            "task_assistance": [
                {"ë„ì™€ì¤˜": 2.0, "í•´ì¤˜": 1.5, "ì‘ì—…": 1.5, "ì—…ë¬´": 1.5},
                {"í”„ë¡œì íŠ¸": 1.5, "ê³¼ì œ": 1.5},
            ],
            "playful_interaction": [
                {"ì¬ë°Œì–´": 1.5, "ì›ƒê²¨": 1.5, "ì¥ë‚œ": 2.0, "ë†€ì": 2.0},
                {"ã…‹ã…‹": 1.0, "ã…ã…": 1.0},
            ],
            "local_service_search": [
                {"ë³‘ì›": 3.0, "ì‘ê¸‰ì‹¤": 3.0, "ì†Œì•„ê³¼": 3.0, "ì•½êµ­": 2.5},
                {"ì•„íŒŒ": 2.0, "ì•„í”ˆ": 2.0, "ì—´": 2.0, "ì•„ì´": 1.5, "ë‚¨ìœ¨": 2.0},
                {"ê·¼ì²˜": 2.0, "ê°€ê¹Œìš´": 2.0, "ë³‘ì›ì°¾ì•„": 3.0, "ì‘ê¸‰": 3.0},
                {"ì˜ì‚¬": 1.5, "ì§„ë£Œ": 2.0, "ì¹˜ë£Œ": 2.0, "ê²€ì§„": 1.5},
            ],
        }

    def _load_rhythm_patterns(self) -> Dict[str, List]:
        """ë¦¬ë“¬ íŒ¨í„´ ë¡œë“œ"""
        return {
            "urgent_staccato": ["!!", "ë¹¨ë¦¬", "ê¸‰í•´", "ì§€ê¸ˆ", "ë‹¹ì¥"],
            "casual_flowing": ["ê·¸ëƒ¥", "ì¢€", "ë­”ê°€", "ì•½ê°„", "~"],
            "formal_structured": ["ìŠµë‹ˆë‹¤", "ë©ë‹ˆë‹¤", "ì…ë‹ˆë‹¤"],
            "emotional_waves": ["ë„ˆë¬´", "ì •ë§", "ì§„ì§œ", "ì™„ì „"],
            "playful_bouncy": ["ã…‹ã…‹", "ã…ã…", "ì•¼", "ì—ì´"],
            "thoughtful_paused": ["...", "ìŒ", "ê¸€ì„", "ìƒê°í•´ë³´ë‹ˆ"],
            "confused_scattered": ["ë­ì§€", "ì–´", "ê·¸ëŸ°ë°", "ê·¼ë°"],
            "confident_steady": ["í™•ì‹¤íˆ", "ë¶„ëª…íˆ", "ë‹¹ì—°íˆ", "ë¬¼ë¡ "],
        }

    def _build_emotion_intent_matrix(self) -> Dict[str, Dict[str, float]]:
        """ê°ì •-ì˜ë„ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤"""
        return {
            "sadness": {
                "emotional_support": 0.8,
                "relationship_advice": 0.6,
                "personal_growth": 0.4,
            },
            "anxiety": {
                "emotional_support": 0.9,
                "decision_help": 0.7,
                "crisis_intervention": 0.3,
            },
            "joy": {
                "playful_interaction": 0.7,
                "creative_collaboration": 0.6,
                "casual_chat": 0.5,
            },
            "anger": {
                "emotional_support": 0.6,
                "relationship_advice": 0.8,
                "decision_help": 0.4,
            },
            "curiosity": {
                "information_seeking": 0.8,
                "philosophical_inquiry": 0.7,
                "creative_collaboration": 0.5,
            },
            "confusion": {
                "information_seeking": 0.6,
                "decision_help": 0.8,
                "emotional_support": 0.4,
            },
        }

    def get_user_analytics(self, user_id: str) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ì ë¶„ì„ ë°ì´í„° ë°˜í™˜"""
        if user_id not in self.user_profiles:
            return None

        profile = self.user_profiles[user_id]

        # ì˜ë„ ë¶„í¬ ê³„ì‚°
        total_interactions = sum(profile.intent_frequencies.values())
        intent_distribution = (
            {
                intent: count / total_interactions
                for intent, count in profile.intent_frequencies.items()
            }
            if total_interactions > 0
            else {}
        )

        # ìµœê·¼ í™œë™ íŒ¨í„´
        recent_interactions = list(profile.interaction_history)[-10:]  # ìµœê·¼ 10ê°œ
        recent_rhythms = [i["rhythm"].value for i in recent_interactions]
        rhythm_trend = (
            max(set(recent_rhythms), key=recent_rhythms.count)
            if recent_rhythms
            else None
        )

        return {
            "user_id": user_id,
            "total_interactions": total_interactions,
            "dominant_rhythm": profile.dominant_rhythm.value,
            "confidence_score": profile.confidence_score,
            "intent_distribution": intent_distribution,
            "recent_rhythm_trend": rhythm_trend,
            "last_active": profile.last_updated.isoformat(),
            "profile_maturity": min(total_interactions / 20, 1.0),  # 20íšŒ ì´ìƒì´ë©´ ì„±ìˆ™
        }

    def should_block(
        self, result: "IntentInferenceResult", llm_text: Optional[str] = None
    ) -> bool:
        """ì°¨ë‹¨ ì—¬ë¶€ ê²°ì • (ì•ˆì „/ë¹ˆì‘ë‹µë§Œ)"""
        has_llm = bool((llm_text or "").strip())

        # ë¹ˆì‘ë‹µì´ë©´ ì°¨ë‹¨
        if not has_llm:
            return True

        # ì•ˆì „ ìœ„ë°˜ ê²€ì‚¬ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        text_lower = (llm_text or "").lower()
        if any(
            danger in text_lower
            for danger in ["kill myself", "suicide", "bomb", "terror"]
        ):
            return True

        # SAFE_ONLY ëª¨ë“œë©´ ëª¨í˜¸í•¨ì€ ì •ë³´ë§Œ ì œê³µ(ì°¨ë‹¨ X)
        if self.safe_only:
            return False

        # ëª¨í˜¸ ì„ê³„ì¹˜ê°€ ë‚®ìŒ â†’ ì›¬ë§Œí•˜ë©´ í†µê³¼
        if (
            result.primary_intent == DetailedIntentType.CASUAL_CHAT
            and result.confidence >= self.unclear_threshold
        ):
            return False

        return False


# ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ì „ì—­ ì ‘ê·¼
_global_intent_engine = None


def get_global_intent_engine() -> EnhancedIntentInferenceEngine:
    """Intent ì—”ì§„ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_intent_engine
    if _global_intent_engine is None:
        _global_intent_engine = EnhancedIntentInferenceEngine()
    return _global_intent_engine


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    engine = EnhancedIntentInferenceEngine()

    test_cases = [
        "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ë„¤ìš” ^^",
        "ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ì„œ... ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš” ã… ã… ",
        "ì¸ìƒì˜ ì˜ë¯¸ê°€ ë­˜ê¹Œìš”? ì •ë§ ê¶ê¸ˆí•´ì„œ ë°¤ìƒˆ ìƒê°í–ˆì–´ìš”",
        "ì¹œêµ¬ë‘ ì‹¸ì› ëŠ”ë° ì–´ë–»ê²Œ í™”í•´í•´ì•¼ í• ê¹Œìš”?",
        "ê¸‰í•´!! ì§€ê¸ˆ ë‹¹ì¥ ë„ì›€ì´ í•„ìš”í•´ìš”!",
        "ã…‹ã…‹ã…‹ ì¬ë¯¸ìˆëŠ” ì•„ì´ë””ì–´ ì—†ë‚˜ìš”? ë†€ê³  ì‹¶ì–´ìš”~",
    ]

    print("ğŸ¯ Enhanced Intent Inference í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    for i, text in enumerate(test_cases):
        print(f"\n--- í…ŒìŠ¤íŠ¸ {i+1} ---")
        print(f"ì…ë ¥: {text}")

        result = engine.infer_intent_and_rhythm(
            text,
            f"test_session_{i}",
            emotion_context={"primary_emotion": "neutral", "emotion_intensity": 0.5},
            user_id=f"user_{i%3}",  # 3ëª…ì˜ ê°€ìƒ ì‚¬ìš©ì
        )

        print(
            f"ì£¼ ì˜ë„: {result.primary_intent.value} (ì‹ ë¢°ë„: {result.confidence:.2f})"
        )
        print(
            f"ë§í•˜ê¸° ë¦¬ë“¬: {result.speech_rhythm.value} (ì‹ ë¢°ë„: {result.rhythm_confidence:.2f})"
        )

        if result.secondary_intents:
            print(
                "ë³´ì¡° ì˜ë„:",
                [
                    f"{intent.value}({conf:.2f})"
                    for intent, conf in result.secondary_intents[:2]
                ],
            )

        if result.contextual_factors:
            print(f"ë§¥ë½ ìš”ì†Œ: {', '.join(result.contextual_factors)}")

        if result.user_pattern_match:
            print(f"ì‚¬ìš©ì íŒ¨í„´: {result.user_pattern_match}")

        print("-" * 40)

    print("\nğŸ“Š ì‚¬ìš©ì ë¶„ì„ ì˜ˆì‹œ:")
    for user_id in ["user_0", "user_1", "user_2"]:
        analytics = engine.get_user_analytics(user_id)
        if analytics:
            print(f"\n{user_id}: {analytics['total_interactions']}íšŒ ìƒí˜¸ì‘ìš©")
            print(f"  ì§€ë°°ì  ë¦¬ë“¬: {analytics['dominant_rhythm']}")
            print(f"  í”„ë¡œí•„ ì„±ìˆ™ë„: {analytics['profile_maturity']:.2f}")

    print("\nğŸ‰ Enhanced Intent Inference í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
