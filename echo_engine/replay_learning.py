#!/usr/bin/env python3
"""
ğŸ” EchoJudgmentSystem v10.6 - Replay Learning Engine
ê³¼ê±° íŒë‹¨â¨¯ê²°ì •â¨¯í”¼ë“œë°± ë¡œê·¸ë¥¼ í™œìš©í•œ ì‹œë®¬ë ˆì´ì…˜ í•™ìŠµ ëª¨ë“ˆ

TT.006: "ê³¼ê±°ëŠ” ë¯¸ë˜ì˜ êµì‚¬ì´ë‹¤. ëª¨ë“  ì‹¤ìˆ˜ì™€ ì„±ê³µì€ ë‹¤ìŒ ì§€í˜œì˜ ì”¨ì•—ì´ ëœë‹¤."

ì£¼ìš” ê¸°ëŠ¥:
- ê³¼ê±° ì„¸ì…˜ ë°ì´í„° ë¡œë“œ ë° ë¶„ì„
- ê²°ì • ì‹œí€€ìŠ¤ ì¬êµ¬ì„± ë° ì‹œë®¬ë ˆì´ì…˜
- ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ í•™ìŠµ
- íŒ¨í„´ ë°œê²¬ ë° ì „ëµ ìµœì í™”
- ë©”íƒ€ì¸ì§€ ë£¨í”„ì™€ í†µí•©ëœ í•™ìŠµ
"""

import json
import os
import time
import random
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Iterator
from dataclasses import dataclass, asdict
from pathlib import Path
import re

# EchoJudgmentSystem ëª¨ë“ˆ
try:
    from echo_engine.meta_logger import log_evolution_event, get_meta_log_writer
except ImportError:
    log_evolution_event = None
    get_meta_log_writer = None

try:
    from echo_engine.persona_meta_logger import get_persona_meta_logger
except ImportError:
    get_persona_meta_logger = None

try:
    from feedback_system import FeedbackSystem
except ImportError:
    FeedbackSystem = None

try:
    from echo_engine.reinforcement_engine import get_reinforcement_engine
except ImportError:
    get_reinforcement_engine = None


@dataclass
class DecisionStep:
    """ê°œë³„ ê²°ì • ë‹¨ê³„ ì •ì˜"""

    timestamp: str
    step_id: str
    input_text: str
    context: Dict[str, Any]
    emotion_detected: str
    strategy_selected: str
    confidence: float
    reasoning: str
    response_generated: str
    user_feedback: Optional[Dict[str, Any]] = None
    success: bool = False

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class ReplaySession:
    """ë¦¬í”Œë ˆì´ ì„¸ì…˜ ì •ì˜"""

    session_id: str
    start_time: str
    end_time: str
    total_steps: int
    success_rate: float
    average_confidence: float
    dominant_emotions: List[str]
    strategies_used: List[str]
    decision_sequence: List[DecisionStep]
    meta_insights: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
        return {
            **asdict(self),
            "decision_sequence": [step.to_dict() for step in self.decision_sequence],
        }


class ReplayLearner:
    """
    EchoJudgmentSystem ë¦¬í”Œë ˆì´ í•™ìŠµê¸°

    ê³¼ê±°ì˜ íŒë‹¨ ì„¸ì…˜ë“¤ì„ ì¬í˜„í•˜ê³  ë¶„ì„í•˜ì—¬
    ì‹œìŠ¤í…œì˜ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    """

    def __init__(self, log_directory: str = "meta_logs"):
        """
        ë¦¬í”Œë ˆì´ í•™ìŠµê¸° ì´ˆê¸°í™”

        Args:
            log_directory: ë¡œê·¸ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        """
        self.log_directory = Path(log_directory)
        self.history: List[ReplaySession] = []
        self.learned_patterns: Dict[str, Any] = {}
        self.simulation_results: List[Dict[str, Any]] = []

        # í•™ìŠµ ì„¤ì •
        self.replay_batch_size = 5
        self.pattern_threshold = 0.7
        self.max_simulations = 100

        # í†µê³„
        self.total_replays = 0
        self.successful_replays = 0
        self.patterns_discovered = 0

        # ì´ˆê¸°í™”
        self.load_learned_patterns()

        print("ğŸ” ReplayLearner ì´ˆê¸°í™” ì™„ë£Œ")

    def load_session(self, session_id: str) -> Optional[ReplaySession]:
        """
        íŠ¹ì • ì„¸ì…˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  íŒŒì‹±

        Args:
            session_id: ë¡œë“œí•  ì„¸ì…˜ ID

        Returns:
            íŒŒì‹±ëœ ReplaySession ê°ì²´ ë˜ëŠ” None
        """
        try:
            # ì„¸ì…˜ ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
            session_files = list(self.log_directory.glob(f"*{session_id}*"))

            if not session_files:
                print(f"âš ï¸ ì„¸ì…˜ {session_id} ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None

            session_file = session_files[0]

            # JSONL íŒŒì¼ ì½ê¸°
            decision_steps = []
            session_meta = {}

            with open(session_file, "r", encoding="utf-8") as f:
                for line_num, line in enumerate(f):
                    try:
                        data = json.loads(line.strip())

                        if data.get("event_type") == "session_start":
                            session_meta["start_time"] = data.get("timestamp")
                        elif data.get("event_type") == "session_end":
                            session_meta["end_time"] = data.get("timestamp")
                        elif data.get("event_type") == "persona_interaction":
                            # ê°œë³„ ê²°ì • ë‹¨ê³„ë¡œ ë³€í™˜
                            step = self._convert_to_decision_step(data, line_num)
                            if step:
                                decision_steps.append(step)

                    except json.JSONDecodeError:
                        continue

            if not decision_steps:
                print(f"âš ï¸ ì„¸ì…˜ {session_id}ì—ì„œ ìœ íš¨í•œ ê²°ì • ë‹¨ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None

            # ReplaySession ìƒì„±
            replay_session = self._create_replay_session(
                session_id, session_meta, decision_steps
            )

            print(f"ğŸ“ ì„¸ì…˜ ë¡œë“œ ì™„ë£Œ: {session_id} ({len(decision_steps)}ê°œ ë‹¨ê³„)")
            return replay_session

        except Exception as e:
            print(f"âŒ ì„¸ì…˜ ë¡œë“œ ì‹¤íŒ¨ {session_id}: {e}")
            return None

    def reconstruct_decision_sequence(
        self, session_data: ReplaySession
    ) -> List[Dict[str, Any]]:
        """
        ê²°ì • ì‹œí€€ìŠ¤ë¥¼ ì¬êµ¬ì„±í•˜ê³  ì‹œë®¬ë ˆì´ì…˜

        Args:
            session_data: ì¬êµ¬ì„±í•  ì„¸ì…˜ ë°ì´í„°

        Returns:
            ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            simulation_results = []

            print(f"ğŸ­ ê²°ì • ì‹œí€€ìŠ¤ ì¬êµ¬ì„± ì‹œì‘: {session_data.session_id}")

            # ê° ê²°ì • ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
            for i, step in enumerate(session_data.decision_sequence):
                print(
                    f"   ë‹¨ê³„ {i+1}/{len(session_data.decision_sequence)}: {step.strategy_selected}"
                )

                # í˜„ì¬ ë‹¨ê³„ ì‹œë®¬ë ˆì´ì…˜
                sim_result = self._simulate_decision_step(step, i, session_data)
                simulation_results.append(sim_result)

                # íŒ¨í„´ í•™ìŠµ
                self._learn_from_step(step, sim_result)

                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if (i + 1) % 5 == 0:
                    success_rate = sum(
                        1 for r in simulation_results if r["simulation_success"]
                    ) / len(simulation_results)
                    print(
                        f"   ì§„í–‰ë¥ : {i+1}/{len(session_data.decision_sequence)} (ì„±ê³µë¥ : {success_rate:.2f})"
                    )

            # ì „ì²´ ì‹œí€€ìŠ¤ ë¶„ì„
            sequence_analysis = self._analyze_decision_sequence(
                simulation_results, session_data
            )

            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            self.simulation_results.extend(simulation_results)
            self.total_replays += 1

            overall_success = sequence_analysis["overall_success_rate"] > 0.6
            if overall_success:
                self.successful_replays += 1

            # ë©”íƒ€ ë¡œê¹…
            self._log_replay_event(session_data, sequence_analysis)

            print(f"âœ… ì‹œí€€ìŠ¤ ì¬êµ¬ì„± ì™„ë£Œ: {len(simulation_results)}ê°œ ë‹¨ê³„ ì‹œë®¬ë ˆì´ì…˜")
            return simulation_results

        except Exception as e:
            print(f"âŒ ê²°ì • ì‹œí€€ìŠ¤ ì¬êµ¬ì„± ì‹¤íŒ¨: {e}")
            return []

    def replay_multiple_sessions(
        self, session_ids: List[str] = None, limit: int = 10
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ì„¸ì…˜ì„ ì¼ê´„ ë¦¬í”Œë ˆì´í•˜ì—¬ íŒ¨í„´ í•™ìŠµ

        Args:
            session_ids: íŠ¹ì • ì„¸ì…˜ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë™ ë°œê²¬)
            limit: ìµœëŒ€ ë¦¬í”Œë ˆì´í•  ì„¸ì…˜ ìˆ˜

        Returns:
            ì¢…í•© í•™ìŠµ ê²°ê³¼
        """
        try:
            if session_ids is None:
                session_ids = self._discover_session_ids(limit)

            print(f"ğŸ”„ ë‹¤ì¤‘ ì„¸ì…˜ ë¦¬í”Œë ˆì´ ì‹œì‘: {len(session_ids)}ê°œ ì„¸ì…˜")

            all_results = []
            successful_sessions = 0

            for i, session_id in enumerate(session_ids[:limit]):
                print(f"\nğŸ“‚ ì„¸ì…˜ {i+1}/{len(session_ids[:limit])}: {session_id}")

                # ì„¸ì…˜ ë¡œë“œ
                session = self.load_session(session_id)
                if not session:
                    continue

                # ê²°ì • ì‹œí€€ìŠ¤ ì¬êµ¬ì„±
                results = self.reconstruct_decision_sequence(session)

                if results:
                    all_results.extend(results)
                    successful_sessions += 1

                    # ì¤‘ê°„ íŒ¨í„´ ë¶„ì„
                    if (i + 1) % 3 == 0:
                        self._update_learned_patterns()

            # ìµœì¢… íŒ¨í„´ ì—…ë°ì´íŠ¸
            self._update_learned_patterns()

            # ì¢…í•© ë¶„ì„
            comprehensive_analysis = self._perform_comprehensive_analysis(all_results)

            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            self.save_learned_patterns()

            print(f"\nâœ… ë‹¤ì¤‘ ì„¸ì…˜ ë¦¬í”Œë ˆì´ ì™„ë£Œ:")
            print(f"   ì²˜ë¦¬ëœ ì„¸ì…˜: {successful_sessions}/{len(session_ids[:limit])}")
            print(f"   ì´ ê²°ì • ë‹¨ê³„: {len(all_results)}")
            print(f"   ë°œê²¬ëœ íŒ¨í„´: {self.patterns_discovered}")

            return comprehensive_analysis

        except Exception as e:
            print(f"âŒ ë‹¤ì¤‘ ì„¸ì…˜ ë¦¬í”Œë ˆì´ ì‹¤íŒ¨: {e}")
            return {}

    def generate_synthetic_scenarios(self, count: int = 5) -> List[Dict[str, Any]]:
        """
        í•™ìŠµëœ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±

        Args:
            count: ìƒì„±í•  ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜

        Returns:
            ìƒì„±ëœ ì‹œë‚˜ë¦¬ì˜¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            scenarios = []

            print(f"ğŸ² ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±: {count}ê°œ")

            for i in range(count):
                scenario = self._create_synthetic_scenario(i)

                if scenario:
                    scenarios.append(scenario)
                    print(
                        f"   ì‹œë‚˜ë¦¬ì˜¤ {i+1}: {scenario['context_type']} / {scenario['emotion_pattern']}"
                    )

            print(f"âœ… ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ: {len(scenarios)}ê°œ")
            return scenarios

        except Exception as e:
            print(f"âŒ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def _convert_to_decision_step(
        self, log_data: Dict[str, Any], step_id: int
    ) -> Optional[DecisionStep]:
        """ë¡œê·¸ ë°ì´í„°ë¥¼ DecisionStepìœ¼ë¡œ ë³€í™˜"""
        try:
            return DecisionStep(
                timestamp=log_data.get("timestamp", datetime.now().isoformat()),
                step_id=f"step_{step_id}",
                input_text=log_data.get("input_text", ""),
                context=log_data.get("context", {}),
                emotion_detected=log_data.get("emotion_detected", "neutral"),
                strategy_selected=log_data.get("strategy_selected", "balanced"),
                confidence=log_data.get("strategy_confidence", 0.5),
                reasoning=log_data.get("reasoning", ""),
                response_generated=log_data.get("response_generated", ""),
                user_feedback=log_data.get("user_feedback"),
                success=log_data.get("strategy_effectiveness", 0.5) > 0.6,
            )
        except Exception:
            return None

    def _create_replay_session(
        self, session_id: str, meta: Dict[str, Any], steps: List[DecisionStep]
    ) -> ReplaySession:
        """DecisionStep ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ReplaySession ìƒì„±"""
        successful_steps = sum(1 for step in steps if step.success)
        success_rate = successful_steps / len(steps) if steps else 0.0

        confidences = [step.confidence for step in steps if step.confidence > 0]
        average_confidence = sum(confidences) / len(confidences) if confidences else 0.5

        emotions = [step.emotion_detected for step in steps]
        emotion_counts = {}
        for emotion in emotions:
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        dominant_emotions = sorted(
            emotion_counts.items(), key=lambda x: x[1], reverse=True
        )[:3]
        dominant_emotions = [emotion for emotion, count in dominant_emotions]

        strategies = list(set(step.strategy_selected for step in steps))

        return ReplaySession(
            session_id=session_id,
            start_time=meta.get("start_time", ""),
            end_time=meta.get("end_time", ""),
            total_steps=len(steps),
            success_rate=success_rate,
            average_confidence=average_confidence,
            dominant_emotions=dominant_emotions,
            strategies_used=strategies,
            decision_sequence=steps,
            meta_insights={},
        )

    def _simulate_decision_step(
        self, step: DecisionStep, step_index: int, session: ReplaySession
    ) -> Dict[str, Any]:
        """ê°œë³„ ê²°ì • ë‹¨ê³„ ì‹œë®¬ë ˆì´ì…˜"""
        simulation_start = time.time()

        # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ìµœì  ì „ëµ ì˜ˆì¸¡
        predicted_strategy = self._predict_optimal_strategy(step, session)

        # ì‹¤ì œ ì„ íƒê³¼ ì˜ˆì¸¡ ë¹„êµ
        strategy_match = predicted_strategy == step.strategy_selected

        # ê²°ê³¼ íš¨ê³¼ì„± ì˜ˆì¸¡
        predicted_success = self._predict_step_success(step, predicted_strategy)

        # ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ ì—¬ë¶€ (ì˜ˆì¸¡ ì •í™•ë„ ê¸°ë°˜)
        simulation_success = strategy_match and (predicted_success == step.success)

        simulation_time = time.time() - simulation_start

        return {
            "step_index": step_index,
            "original_strategy": step.strategy_selected,
            "predicted_strategy": predicted_strategy,
            "strategy_match": strategy_match,
            "original_success": step.success,
            "predicted_success": predicted_success,
            "simulation_success": simulation_success,
            "confidence_delta": abs(
                step.confidence - self._calculate_predicted_confidence(step)
            ),
            "simulation_time": simulation_time,
            "learning_insights": self._extract_step_insights(step, predicted_strategy),
        }

    def _predict_optimal_strategy(
        self, step: DecisionStep, session: ReplaySession
    ) -> str:
        """í˜„ì¬ ìƒí™©ì—ì„œ ìµœì  ì „ëµ ì˜ˆì¸¡"""
        # í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡
        context_key = (
            f"{step.context.get('context_type', 'general')}:{step.emotion_detected}"
        )

        if context_key in self.learned_patterns:
            pattern = self.learned_patterns[context_key]
            best_strategies = pattern.get("best_strategies", [])
            if best_strategies:
                return best_strategies[0]

        # ì„¸ì…˜ ë‚´ ì„±ê³µ íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡
        successful_strategies = [
            s.strategy_selected
            for s in session.decision_sequence
            if s.success and s.emotion_detected == step.emotion_detected
        ]

        if successful_strategies:
            strategy_counts = {}
            for strategy in successful_strategies:
                strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
            return max(strategy_counts.items(), key=lambda x: x[1])[0]

        # ê¸°ë³¸ê°’
        return "balanced"

    def _predict_step_success(self, step: DecisionStep, strategy: str) -> bool:
        """ë‹¨ê³„ ì„±ê³µ ì—¬ë¶€ ì˜ˆì¸¡"""
        # ì „ëµë³„ ì„±ê³µë¥  ê¸°ë°˜ ì˜ˆì¸¡
        context_key = f"{step.context.get('context_type', 'general')}:{step.emotion_detected}:{strategy}"

        if context_key in self.learned_patterns:
            success_rate = self.learned_patterns[context_key].get("success_rate", 0.5)
            return success_rate > 0.6

        # ì‹ ë¢°ë„ ê¸°ë°˜ ì˜ˆì¸¡
        return step.confidence > 0.7

    def _calculate_predicted_confidence(self, step: DecisionStep) -> float:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.5

        # ê°ì • ì•ˆì •ì„± ê°€ì¤‘ì¹˜
        emotion_weights = {
            "joy": 0.8,
            "neutral": 0.7,
            "curiosity": 0.75,
            "sadness": 0.4,
            "anger": 0.3,
            "fear": 0.2,
        }
        emotion_weight = emotion_weights.get(step.emotion_detected, 0.5)

        # ì»¨í…ìŠ¤íŠ¸ ë³µì¡ë„ ê°€ì¤‘ì¹˜
        context_complexity = len(step.context)
        complexity_weight = max(0.3, 1.0 - context_complexity * 0.1)

        return min(1.0, base_confidence * emotion_weight * complexity_weight)

    def _extract_step_insights(
        self, step: DecisionStep, predicted_strategy: str
    ) -> List[str]:
        """ë‹¨ê³„ë³„ í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []

        if step.success:
            insights.append(
                f"Successful pattern: {step.emotion_detected} + {step.strategy_selected}"
            )

        if predicted_strategy != step.strategy_selected:
            insights.append(
                f"Strategy mismatch: predicted {predicted_strategy}, used {step.strategy_selected}"
            )

        if step.confidence < 0.5:
            insights.append("Low confidence decision - needs pattern reinforcement")

        return insights

    def _learn_from_step(self, step: DecisionStep, sim_result: Dict[str, Any]):
        """ê°œë³„ ë‹¨ê³„ì—ì„œ íŒ¨í„´ í•™ìŠµ"""
        context_key = (
            f"{step.context.get('context_type', 'general')}:{step.emotion_detected}"
        )
        strategy_key = f"{context_key}:{step.strategy_selected}"

        # ì»¨í…ìŠ¤íŠ¸-ê°ì • íŒ¨í„´ í•™ìŠµ
        if context_key not in self.learned_patterns:
            self.learned_patterns[context_key] = {
                "occurrences": 0,
                "successful_strategies": [],
                "best_strategies": [],
                "average_confidence": 0.0,
                "confidence_variance": 0.0,
            }

        pattern = self.learned_patterns[context_key]
        pattern["occurrences"] += 1

        if step.success:
            pattern["successful_strategies"].append(step.strategy_selected)

        # ì „ëµë³„ ì„¸ë¶€ íŒ¨í„´ í•™ìŠµ
        if strategy_key not in self.learned_patterns:
            self.learned_patterns[strategy_key] = {
                "uses": 0,
                "successes": 0,
                "success_rate": 0.0,
                "average_confidence": 0.0,
                "contexts": [],
            }

        strategy_pattern = self.learned_patterns[strategy_key]
        strategy_pattern["uses"] += 1
        if step.success:
            strategy_pattern["successes"] += 1
        strategy_pattern["success_rate"] = (
            strategy_pattern["successes"] / strategy_pattern["uses"]
        )
        strategy_pattern["contexts"].append(step.context)

    def _analyze_decision_sequence(
        self, sim_results: List[Dict[str, Any]], session: ReplaySession
    ) -> Dict[str, Any]:
        """ì „ì²´ ê²°ì • ì‹œí€€ìŠ¤ ë¶„ì„"""
        total_steps = len(sim_results)
        successful_sims = sum(1 for r in sim_results if r["simulation_success"])
        strategy_matches = sum(1 for r in sim_results if r["strategy_match"])

        return {
            "session_id": session.session_id,
            "total_simulation_steps": total_steps,
            "successful_simulations": successful_sims,
            "overall_success_rate": (
                successful_sims / total_steps if total_steps > 0 else 0
            ),
            "strategy_prediction_accuracy": (
                strategy_matches / total_steps if total_steps > 0 else 0
            ),
            "average_confidence_delta": (
                sum(r["confidence_delta"] for r in sim_results) / total_steps
                if total_steps > 0
                else 0
            ),
            "total_simulation_time": sum(r["simulation_time"] for r in sim_results),
            "learning_insights_count": sum(
                len(r["learning_insights"]) for r in sim_results
            ),
            "pattern_quality_score": self._calculate_pattern_quality_score(sim_results),
        }

    def _calculate_pattern_quality_score(
        self, sim_results: List[Dict[str, Any]]
    ) -> float:
        """íŒ¨í„´ í•™ìŠµ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not sim_results:
            return 0.0

        accuracy = sum(1 for r in sim_results if r["simulation_success"]) / len(
            sim_results
        )
        consistency = 1.0 - (
            sum(r["confidence_delta"] for r in sim_results) / len(sim_results)
        )

        return accuracy * 0.7 + consistency * 0.3

    def _update_learned_patterns(self):
        """í•™ìŠµëœ íŒ¨í„´ ì—…ë°ì´íŠ¸ ë° ì •ì œ"""
        updated_patterns = 0

        for key, pattern in self.learned_patterns.items():
            if (
                "successful_strategies" in pattern
                and len(pattern["successful_strategies"]) > 2
            ):
                # ìµœê³  ì„±ê³¼ ì „ëµë“¤ ì—…ë°ì´íŠ¸
                strategy_counts = {}
                for strategy in pattern["successful_strategies"]:
                    strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1

                sorted_strategies = sorted(
                    strategy_counts.items(), key=lambda x: x[1], reverse=True
                )
                pattern["best_strategies"] = [
                    strategy for strategy, count in sorted_strategies[:3]
                ]
                updated_patterns += 1

        self.patterns_discovered = updated_patterns
        print(f"ğŸ§  íŒ¨í„´ ì—…ë°ì´íŠ¸: {updated_patterns}ê°œ ì»¨í…ìŠ¤íŠ¸")

    def _perform_comprehensive_analysis(
        self, all_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ìˆ˜í–‰"""
        if not all_results:
            return {}

        total_steps = len(all_results)
        successful_sims = sum(1 for r in all_results if r["simulation_success"])

        # ì „ëµë³„ ì„±ê³¼ ë¶„ì„
        strategy_performance = {}
        for result in all_results:
            strategy = result["predicted_strategy"]
            if strategy not in strategy_performance:
                strategy_performance[strategy] = {"uses": 0, "successes": 0}

            strategy_performance[strategy]["uses"] += 1
            if result["simulation_success"]:
                strategy_performance[strategy]["successes"] += 1

        # ì„±ê³¼ ê³„ì‚°
        for strategy in strategy_performance:
            perf = strategy_performance[strategy]
            perf["success_rate"] = (
                perf["successes"] / perf["uses"] if perf["uses"] > 0 else 0
            )

        return {
            "total_replayed_steps": total_steps,
            "overall_simulation_success_rate": successful_sims / total_steps,
            "strategy_performance": strategy_performance,
            "patterns_learned": len(self.learned_patterns),
            "replay_sessions": self.total_replays,
            "successful_replays": self.successful_replays,
            "replay_success_rate": self.successful_replays / max(1, self.total_replays),
            "learning_quality_score": self._calculate_overall_quality_score(
                all_results
            ),
        }

    def _calculate_overall_quality_score(self, results: List[Dict[str, Any]]) -> float:
        """ì „ì²´ í•™ìŠµ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not results:
            return 0.0

        simulation_accuracy = sum(1 for r in results if r["simulation_success"]) / len(
            results
        )
        pattern_coverage = min(
            1.0, len(self.learned_patterns) / 20
        )  # 20ê°œ íŒ¨í„´ì„ ê¸°ì¤€ìœ¼ë¡œ
        learning_depth = min(1.0, self.total_replays / 10)  # 10ê°œ ì„¸ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ

        return simulation_accuracy * 0.5 + pattern_coverage * 0.3 + learning_depth * 0.2

    def _discover_session_ids(self, limit: int) -> List[str]:
        """ë¡œê·¸ ë””ë ‰í† ë¦¬ì—ì„œ ì„¸ì…˜ IDë“¤ ìë™ ë°œê²¬"""
        session_ids = []

        try:
            for log_file in self.log_directory.glob("*.jsonl"):
                # íŒŒì¼ëª…ì—ì„œ ì„¸ì…˜ ID ì¶”ì¶œ ì‹œë„
                filename = log_file.name

                # persona_session_YYYYMMDD_HHMMSS_UUID.jsonl íŒ¨í„´
                session_match = re.search(r"session_(\d{8}_\d{6}_[a-f0-9]+)", filename)
                if session_match:
                    session_ids.append(session_match.group(1))
                    continue

                # ê¸°íƒ€ íŒ¨í„´ë“¤
                meta_match = re.search(r"meta_session_(\d+)", filename)
                if meta_match:
                    session_ids.append(meta_match.group(1))

            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            session_ids = sorted(list(set(session_ids)))[:limit]

        except Exception as e:
            print(f"âš ï¸ ì„¸ì…˜ ID ìë™ ë°œê²¬ ì‹¤íŒ¨: {e}")

        return session_ids

    def _create_synthetic_scenario(self, scenario_id: int) -> Optional[Dict[str, Any]]:
        """ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
        try:
            # í•™ìŠµëœ íŒ¨í„´ì—ì„œ ëœë¤ ì„ íƒ
            if not self.learned_patterns:
                return None

            context_patterns = [
                k
                for k in self.learned_patterns.keys()
                if ":" in k and len(k.split(":")) == 2
            ]
            if not context_patterns:
                return None

            pattern_key = random.choice(context_patterns)
            context_type, emotion = pattern_key.split(":")

            pattern = self.learned_patterns[pattern_key]
            best_strategies = pattern.get("best_strategies", ["balanced"])

            return {
                "scenario_id": f"synthetic_{scenario_id}",
                "context_type": context_type,
                "emotion_pattern": emotion,
                "recommended_strategies": best_strategies,
                "expected_success_rate": pattern.get("success_rate", 0.5),
                "confidence_baseline": pattern.get("average_confidence", 0.5),
                "learning_source": "replay_learning",
                "created_at": datetime.now().isoformat(),
            }

        except Exception:
            return None

    def _log_replay_event(self, session: ReplaySession, analysis: Dict[str, Any]):
        """ë¦¬í”Œë ˆì´ í•™ìŠµ ì´ë²¤íŠ¸ ë¡œê¹…"""
        try:
            if log_evolution_event:
                event_data = {
                    "event": "Replay Learning Session",
                    "tag": ["replay_learning", "pattern_discovery", "simulation"],
                    "cause": [
                        f"session_{session.session_id}",
                        f"steps_{session.total_steps}",
                    ],
                    "effect": [
                        f"patterns_learned",
                        f"simulation_accuracy_{analysis.get('overall_success_rate', 0):.2f}",
                    ],
                    "resolution": "learning_patterns_updated",
                    "insight": f"Replay learning from {session.total_steps} decision steps",
                    "adaptation_strength": analysis.get("pattern_quality_score", 0.5),
                    "coherence_improvement": analysis.get("overall_success_rate", 0.5),
                    "reflection_depth": 2,
                }
                log_evolution_event(event_data, f"replay_{session.session_id}")

        except Exception as e:
            print(f"âš ï¸ ë¦¬í”Œë ˆì´ ì´ë²¤íŠ¸ ë¡œê¹… ì‹¤íŒ¨: {e}")

    def get_replay_statistics(self) -> Dict[str, Any]:
        """ë¦¬í”Œë ˆì´ í•™ìŠµ í†µê³„ ë°˜í™˜"""
        return {
            "total_replays": self.total_replays,
            "successful_replays": self.successful_replays,
            "replay_success_rate": self.successful_replays / max(1, self.total_replays),
            "patterns_discovered": self.patterns_discovered,
            "learned_patterns_count": len(self.learned_patterns),
            "simulation_results_count": len(self.simulation_results),
            "avg_pattern_quality": self._calculate_average_pattern_quality(),
        }

    def _calculate_average_pattern_quality(self) -> float:
        """í‰ê·  íŒ¨í„´ í’ˆì§ˆ ê³„ì‚°"""
        if not self.learned_patterns:
            return 0.0

        quality_scores = []
        for pattern in self.learned_patterns.values():
            if "success_rate" in pattern:
                quality_scores.append(pattern["success_rate"])

        return sum(quality_scores) / len(quality_scores) if quality_scores else 0.0

    def save_learned_patterns(
        self, filepath: str = "data/replay_learned_patterns.json"
    ):
        """í•™ìŠµëœ íŒ¨í„´ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)

            save_data = {
                "learned_patterns": self.learned_patterns,
                "statistics": self.get_replay_statistics(),
                "last_updated": datetime.now().isoformat(),
            }

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ í•™ìŠµ íŒ¨í„´ ì €ì¥ ì™„ë£Œ: {filepath}")

        except Exception as e:
            print(f"âŒ í•™ìŠµ íŒ¨í„´ ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_learned_patterns(
        self, filepath: str = "data/replay_learned_patterns.json"
    ):
        """í•™ìŠµëœ íŒ¨í„´ ë¡œë“œ"""
        try:
            if not os.path.exists(filepath):
                print(f"ğŸ“ í•™ìŠµ íŒ¨í„´ íŒŒì¼ ì—†ìŒ, ìƒˆë¡œ ì‹œì‘: {filepath}")
                return

            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)

            self.learned_patterns = data.get("learned_patterns", {})

            stats = data.get("statistics", {})
            self.total_replays = stats.get("total_replays", 0)
            self.successful_replays = stats.get("successful_replays", 0)
            self.patterns_discovered = stats.get("patterns_discovered", 0)

            print(f"ğŸ“‚ í•™ìŠµ íŒ¨í„´ ë¡œë“œ ì™„ë£Œ: {len(self.learned_patterns)}ê°œ íŒ¨í„´")

        except Exception as e:
            print(f"âŒ í•™ìŠµ íŒ¨í„´ ë¡œë“œ ì‹¤íŒ¨: {e}")


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
_replay_learner = None


def get_replay_learner() -> ReplayLearner:
    """ê¸€ë¡œë²Œ ë¦¬í”Œë ˆì´ í•™ìŠµê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _replay_learner
    if _replay_learner is None:
        _replay_learner = ReplayLearner()
    return _replay_learner


def replay_session(session_id: str) -> Dict[str, Any]:
    """í¸ì˜ í•¨ìˆ˜: ì„¸ì…˜ ë¦¬í”Œë ˆì´"""
    learner = get_replay_learner()
    session = learner.load_session(session_id)
    if session:
        return learner.reconstruct_decision_sequence(session)
    return {}


def batch_replay_learning(session_limit: int = 5) -> Dict[str, Any]:
    """í¸ì˜ í•¨ìˆ˜: ì¼ê´„ ë¦¬í”Œë ˆì´ í•™ìŠµ"""
    learner = get_replay_learner()
    return learner.replay_multiple_sessions(limit=session_limit)
