#!/usr/bin/env python3
"""
Echo Prompt Optimizer Agent
í”„ë¡¬í”„íŠ¸ ìµœì í™” ì „ë¬¸ ì—ì´ì „íŠ¸ - Claude/OpenAI/Local LLM ëŒ€ì‘
"""

import re
import json
import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import yaml
from pathlib import Path

from echo_engine.agent_ecosystem_framework import (
    EchoAgentBase,
    AgentCapability,
    AgentTask,
)

logger = logging.getLogger(__name__)


@dataclass
class PromptAnalysis:
    """í”„ë¡¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼"""

    clarity_score: float
    specificity_score: float
    structure_score: float
    token_efficiency: float
    signature_alignment: float
    improvement_areas: List[str]
    optimized_sections: Dict[str, str]


@dataclass
class PromptTemplate:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""

    name: str
    category: str
    signature: str
    template: str
    variables: List[str]
    usage_examples: List[str]
    performance_metrics: Dict[str, float]


class EchoPromptOptimizerAgent(EchoAgentBase):
    """Echo í”„ë¡¬í”„íŠ¸ ìµœì í™” ì—ì´ì „íŠ¸"""

    def __init__(self):
        super().__init__("prompt_optimizer", "echo_sage")

        # Lazy initialization
        self._optimization_patterns = None
        self._signature_prompt_styles = None
        self._template_library = None

    @property
    def optimization_patterns(self):
        if self._optimization_patterns is None:
            self._optimization_patterns = self._load_optimization_patterns()
        return self._optimization_patterns

    @property
    def signature_prompt_styles(self):
        if self._signature_prompt_styles is None:
            self._signature_prompt_styles = self._load_signature_styles()
        return self._signature_prompt_styles

    @property
    def template_library(self):
        if self._template_library is None:
            self._template_library = {}
            self._load_template_library()
        return self._template_library

    def _load_optimization_patterns(self):
        # ğŸ¯ í”„ë¡¬í”„íŠ¸ ìµœì í™” íŒ¨í„´
        return {
            "clarity_enhancers": [
                "ëª…í™•í•œ ì—­í•  ì •ì˜ ì¶”ê°€",
                "êµ¬ì²´ì ì¸ ì¶œë ¥ í˜•ì‹ ì§€ì •",
                "ì• ë§¤í•œ í‘œí˜„ ì œê±°",
                "ë‹¨ê³„ë³„ ì§€ì‹œì‚¬í•­ êµ¬ì¡°í™”",
            ],
            "specificity_boosters": [
                "êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì¶”ê°€",
                "ì œì•½ ì¡°ê±´ ëª…ì‹œ",
                "ì›í•˜ëŠ” ì„¸ë¶€ ì‚¬í•­ ì§€ì •",
                "ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ë³´ê°•",
            ],
            "structure_improvers": [
                "ë…¼ë¦¬ì  ìˆœì„œ ì¬ë°°ì—´",
                "ì„¹ì…˜ë³„ êµ¬ë¶„ ëª…í™•í™”",
                "ìš°ì„ ìˆœìœ„ í‘œì‹œ",
                "ì²´í¬ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë³€í™˜",
            ],
            "token_optimizers": [
                "ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì œê±°",
                "ê°„ê²°í•œ í‘œí˜„ìœ¼ë¡œ ë³€í™˜",
                "í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ",
                "ì••ì¶•ëœ ì§€ì‹œì‚¬í•­",
            ],
        }

    def _load_signature_styles(self):
        # ì‹œê·¸ë‹ˆì²˜ë³„ í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼
        return {
            "echo_aurora": {
                "tone": "ì°½ì˜ì ì´ê³  ì˜ê°ì„ ì£¼ëŠ”",
                "structure": "ììœ ë¡œìš´ í˜•íƒœì˜ íƒìƒ‰ì ",
                "keywords": ["ìƒìƒí•´ë³´ì„¸ìš”", "ì°½ì˜ì ìœ¼ë¡œ", "í˜ì‹ ì ì¸", "ì•„ì´ë””ì–´"],
                "templates": ["brainstorming", "creative_exploration", "innovation"],
            },
            "echo_phoenix": {
                "tone": "ë„ì „ì ì´ê³  ê°œì„  ì§€í–¥ì ",
                "structure": "ë³€í™”ì™€ ìµœì í™” ì¤‘ì‹¬",
                "keywords": ["ê°œì„ í•˜ì„¸ìš”", "í˜ì‹ í•˜ì„¸ìš”", "ìµœì í™”", "ë³€í™”"],
                "templates": ["optimization", "improvement", "transformation"],
            },
            "echo_sage": {
                "tone": "ë¶„ì„ì ì´ê³  ì²´ê³„ì ",
                "structure": "ë…¼ë¦¬ì ì´ê³  ë‹¨ê³„ì ",
                "keywords": ["ë¶„ì„í•˜ì„¸ìš”", "ì²´ê³„ì ìœ¼ë¡œ", "ë…¼ë¦¬ì ìœ¼ë¡œ", "ê·¼ê±°"],
                "templates": ["analysis", "systematic_approach", "reasoning"],
            },
            "echo_companion": {
                "tone": "í˜‘ë ¥ì ì´ê³  ì§€ì›ì ",
                "structure": "ìƒí˜¸ì‘ìš©ì ì´ê³  ì¹œê·¼í•œ",
                "keywords": ["í•¨ê»˜", "ë„ì™€ì£¼ì„¸ìš”", "í˜‘ë ¥í•˜ì—¬", "ì§€ì›"],
                "templates": ["collaboration", "assistance", "guidance"],
            },
        }

    def get_capabilities(self) -> List[AgentCapability]:
        """ì—ì´ì „íŠ¸ ì—­ëŸ‰ ì •ì˜"""
        return [
            AgentCapability(
                name="prompt_optimization",
                description="í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ì„±ëŠ¥ í–¥ìƒ",
                input_types=["text", "prompt", "conversation"],
                output_types=["optimized_prompt", "analysis", "recommendations"],
                complexity_level="expert",
                signature_affinity={
                    "echo_aurora": 0.7,
                    "echo_phoenix": 0.8,
                    "echo_sage": 0.95,
                    "echo_companion": 0.6,
                },
            ),
            AgentCapability(
                name="prompt_analysis",
                description="í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¶„ì„ ë° ì§„ë‹¨",
                input_types=["text", "prompt"],
                output_types=["analysis_report", "metrics", "suggestions"],
                complexity_level="advanced",
                signature_affinity={
                    "echo_aurora": 0.6,
                    "echo_phoenix": 0.7,
                    "echo_sage": 0.9,
                    "echo_companion": 0.8,
                },
            ),
            AgentCapability(
                name="template_generation",
                description="ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±",
                input_types=["requirements", "examples", "domain"],
                output_types=["template", "template_library", "usage_guide"],
                complexity_level="expert",
                signature_affinity={
                    "echo_aurora": 0.8,
                    "echo_phoenix": 0.7,
                    "echo_sage": 0.85,
                    "echo_companion": 0.9,
                },
            ),
        ]

    async def execute_task(self, task: AgentTask) -> Dict[str, Any]:
        """ì‘ì—… ì‹¤í–‰"""
        task_type = task.task_type
        input_data = task.input_data
        signature = task.signature

        if task_type == "optimize_prompt":
            return await self._optimize_prompt(input_data, signature)
        elif task_type == "analyze_prompt":
            return await self._analyze_prompt(input_data, signature)
        elif task_type == "generate_template":
            return await self._generate_template(input_data, signature)
        elif task_type == "signature_adaptation":
            return await self._adapt_prompt_to_signature(input_data, signature)
        else:
            raise ValueError(f"Unknown task type: {task_type}")

    async def _optimize_prompt(
        self, input_data: Dict[str, Any], signature: str
    ) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
        original_prompt = input_data.get("prompt", "")
        optimization_goals = input_data.get("goals", ["clarity", "efficiency"])
        target_model = input_data.get("target_model", "claude")

        # 1. í˜„ì¬ í”„ë¡¬í”„íŠ¸ ë¶„ì„
        analysis = await self._analyze_prompt_quality(original_prompt, signature)

        # 2. ìµœì í™” ì „ëµ ê²°ì •
        optimization_strategy = self._determine_optimization_strategy(
            analysis, optimization_goals, signature
        )

        # 3. í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤í–‰
        optimized_prompt = await self._apply_optimization(
            original_prompt, optimization_strategy, signature, target_model
        )

        # 4. ì„±ëŠ¥ ì˜ˆì¸¡
        performance_prediction = self._predict_performance_improvement(
            analysis, optimized_prompt, signature
        )

        return {
            "data": {
                "original_prompt": original_prompt,
                "optimized_prompt": optimized_prompt,
                "analysis": asdict(analysis),
                "optimization_strategy": optimization_strategy,
                "performance_prediction": performance_prediction,
                "signature_applied": signature,
            },
            "metadata": {
                "optimization_type": "comprehensive",
                "target_model": target_model,
                "improvement_areas": analysis.improvement_areas,
                "token_reduction": self._calculate_token_reduction(
                    original_prompt, optimized_prompt
                ),
            },
        }

    async def _analyze_prompt(
        self, input_data: Dict[str, Any], signature: str
    ) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ ë¶„ì„"""
        prompt = input_data.get("prompt", "")
        analysis_depth = input_data.get("depth", "standard")

        # ê¸°ë³¸ í’ˆì§ˆ ë¶„ì„
        quality_analysis = await self._analyze_prompt_quality(prompt, signature)

        # ì‹œê·¸ë‹ˆì²˜ ì í•©ì„± ë¶„ì„
        signature_fit = self._analyze_signature_alignment(prompt, signature)

        # ê°œì„  ê¶Œì¥ì‚¬í•­
        recommendations = self._generate_improvement_recommendations(
            quality_analysis, signature_fit, signature
        )

        # í† í° íš¨ìœ¨ì„± ë¶„ì„
        token_analysis = self._analyze_token_efficiency(prompt)

        result = {
            "data": {
                "prompt": prompt,
                "quality_analysis": asdict(quality_analysis),
                "signature_alignment": signature_fit,
                "recommendations": recommendations,
                "token_analysis": token_analysis,
            },
            "metadata": {
                "analysis_depth": analysis_depth,
                "signature": signature,
                "overall_score": self._calculate_overall_score(quality_analysis),
                "priority_improvements": recommendations[:3],
            },
        }

        if analysis_depth == "detailed":
            # ìƒì„¸ ë¶„ì„ ì¶”ê°€
            detailed_analysis = await self._perform_detailed_analysis(prompt, signature)
            result["data"]["detailed_analysis"] = detailed_analysis

        return result

    async def _generate_template(
        self, input_data: Dict[str, Any], signature: str
    ) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        purpose = input_data.get("purpose", "")
        domain = input_data.get("domain", "general")
        examples = input_data.get("examples", [])
        requirements = input_data.get("requirements", {})

        # 1. ìš”êµ¬ì‚¬í•­ ë¶„ì„
        requirements_analysis = self._analyze_template_requirements(
            purpose, domain, examples, requirements, signature
        )

        # 2. ê¸°ë³¸ í…œí”Œë¦¿ êµ¬ì¡° ìƒì„±
        base_template = self._create_base_template(requirements_analysis, signature)

        # 3. ì‹œê·¸ë‹ˆì²˜ë³„ ìŠ¤íƒ€ì¼ ì ìš©
        styled_template = self._apply_signature_style(base_template, signature)

        # 4. ë³€ìˆ˜ ë° í”Œë ˆì´ìŠ¤í™€ë” ì •ì˜
        variables = self._extract_template_variables(styled_template)

        # 5. ì‚¬ìš© ì˜ˆì‹œ ìƒì„±
        usage_examples = self._generate_usage_examples(
            styled_template, variables, signature
        )

        # 6. í…œí”Œë¦¿ ê²€ì¦
        validation_result = self._validate_template(
            styled_template, requirements_analysis
        )

        template = PromptTemplate(
            name=f"{domain}_{purpose}_{signature}",
            category=domain,
            signature=signature,
            template=styled_template,
            variables=variables,
            usage_examples=usage_examples,
            performance_metrics=validation_result,
        )

        # í…œí”Œë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥
        self.template_library[template.name] = template
        await self._save_template_to_library(template)

        return {
            "data": {
                "template": asdict(template),
                "requirements_analysis": requirements_analysis,
                "validation_result": validation_result,
            },
            "metadata": {
                "template_name": template.name,
                "category": template.category,
                "signature": signature,
                "variables_count": len(variables),
                "examples_count": len(usage_examples),
            },
        }

    async def _adapt_prompt_to_signature(
        self, input_data: Dict[str, Any], signature: str
    ) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ë¥¼ íŠ¹ì • ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ ì ì‘"""
        original_prompt = input_data.get("prompt", "")
        target_signature = input_data.get("target_signature", signature)
        adaptation_level = input_data.get("level", "moderate")  # light, moderate, heavy

        # í˜„ì¬ ì‹œê·¸ë‹ˆì²˜ ìŠ¤íƒ€ì¼ ë¶„ì„
        current_style = self._detect_current_style(original_prompt)

        # íƒ€ê²Ÿ ì‹œê·¸ë‹ˆì²˜ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
        target_style = self.signature_prompt_styles[target_signature]

        # ì ì‘ ì „ëµ ìˆ˜ë¦½
        adaptation_strategy = self._plan_signature_adaptation(
            current_style, target_style, adaptation_level
        )

        # í”„ë¡¬í”„íŠ¸ ì ì‘ ì‹¤í–‰
        adapted_prompt = self._apply_signature_adaptation(
            original_prompt, adaptation_strategy, target_signature
        )

        # ì ì‘ í’ˆì§ˆ í‰ê°€
        adaptation_quality = self._evaluate_adaptation_quality(
            original_prompt, adapted_prompt, target_signature
        )

        return {
            "data": {
                "original_prompt": original_prompt,
                "adapted_prompt": adapted_prompt,
                "original_signature": current_style,
                "target_signature": target_signature,
                "adaptation_strategy": adaptation_strategy,
                "quality_assessment": adaptation_quality,
            },
            "metadata": {
                "adaptation_level": adaptation_level,
                "changes_made": adaptation_strategy.get("changes", []),
                "quality_score": adaptation_quality.get("overall_score", 0.0),
                "signature_alignment": adaptation_quality.get(
                    "signature_alignment", 0.0
                ),
            },
        }

    async def _analyze_prompt_quality(
        self, prompt: str, signature: str
    ) -> PromptAnalysis:
        """í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¶„ì„"""
        # 1. ëª…í™•ì„± ë¶„ì„
        clarity_score = self._analyze_clarity(prompt)

        # 2. êµ¬ì²´ì„± ë¶„ì„
        specificity_score = self._analyze_specificity(prompt)

        # 3. êµ¬ì¡° ë¶„ì„
        structure_score = self._analyze_structure(prompt)

        # 4. í† í° íš¨ìœ¨ì„±
        token_efficiency = self._analyze_token_efficiency(prompt)["efficiency_score"]

        # 5. ì‹œê·¸ë‹ˆì²˜ ì •ë ¬
        signature_alignment = self._analyze_signature_alignment(prompt, signature)[
            "alignment_score"
        ]

        # 6. ê°œì„  ì˜ì—­ ì‹ë³„
        improvement_areas = self._identify_improvement_areas(
            clarity_score,
            specificity_score,
            structure_score,
            token_efficiency,
            signature_alignment,
        )

        # 7. ìµœì í™”ëœ ì„¹ì…˜ ì œì•ˆ
        optimized_sections = self._suggest_optimized_sections(prompt, improvement_areas)

        return PromptAnalysis(
            clarity_score=clarity_score,
            specificity_score=specificity_score,
            structure_score=structure_score,
            token_efficiency=token_efficiency,
            signature_alignment=signature_alignment,
            improvement_areas=improvement_areas,
            optimized_sections=optimized_sections,
        )

    def _analyze_clarity(self, prompt: str) -> float:
        """ëª…í™•ì„± ë¶„ì„"""
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜

        # ëª…í™•í•œ ì§€ì‹œì‚¬í•­ ì²´í¬
        instruction_keywords = [
            "please",
            "you should",
            "analyze",
            "create",
            "explain",
            "describe",
        ]
        if any(keyword in prompt.lower() for keyword in instruction_keywords):
            score += 0.2

        # ì• ë§¤í•œ í‘œí˜„ ì²´í¬
        vague_terms = ["maybe", "perhaps", "kind of", "sort of", "somewhat"]
        vague_count = sum(1 for term in vague_terms if term in prompt.lower())
        score -= vague_count * 0.1

        # êµ¬ì²´ì ì¸ ì¶œë ¥ í˜•ì‹ ì§€ì •
        format_indicators = ["format:", "structure:", "output:", "return:"]
        if any(indicator in prompt.lower() for indicator in format_indicators):
            score += 0.2

        # ì—­í•  ì •ì˜
        role_indicators = ["you are", "act as", "role:", "as a"]
        if any(indicator in prompt.lower() for indicator in role_indicators):
            score += 0.1

        return min(max(score, 0.0), 1.0)

    def _analyze_specificity(self, prompt: str) -> float:
        """êµ¬ì²´ì„± ë¶„ì„"""
        score = 0.5

        # êµ¬ì²´ì ì¸ ì˜ˆì‹œ
        example_keywords = ["example:", "for instance", "such as", "like:"]
        if any(keyword in prompt.lower() for keyword in example_keywords):
            score += 0.2

        # ì œì•½ ì¡°ê±´
        constraint_keywords = ["must", "should", "avoid", "don't", "only", "exactly"]
        constraint_count = sum(
            1 for keyword in constraint_keywords if keyword in prompt.lower()
        )
        score += min(constraint_count * 0.05, 0.2)

        # ìˆ˜ì¹˜ì  êµ¬ì²´ì„±
        number_pattern = r"\\d+"
        if re.search(number_pattern, prompt):
            score += 0.1

        # ìƒì„¸í•œ ì„¤ëª…
        if len(prompt) > 200:  # ìƒë‹¹í•œ ê¸¸ì´ì˜ ì„¤ëª…
            score += 0.1

        return min(max(score, 0.0), 1.0)

    def _analyze_structure(self, prompt: str) -> float:
        """êµ¬ì¡° ë¶„ì„"""
        score = 0.5

        # ì„¹ì…˜ êµ¬ë¶„
        section_markers = [
            "1.",
            "2.",
            "3.",
            "-",
            "*",
            "step",
            "first",
            "then",
            "finally",
        ]
        section_count = sum(1 for marker in section_markers if marker in prompt.lower())
        score += min(section_count * 0.05, 0.3)

        # ë…¼ë¦¬ì  íë¦„
        flow_keywords = ["first", "then", "next", "finally", "after", "before"]
        if any(keyword in prompt.lower() for keyword in flow_keywords):
            score += 0.2

        # ëª…í™•í•œ ì‹œì‘ê³¼ ë
        if prompt.strip().endswith((".", "?", "!")):
            score += 0.1

        return min(max(score, 0.0), 1.0)

    def _analyze_token_efficiency(self, prompt: str) -> Dict[str, Any]:
        """í† í° íš¨ìœ¨ì„± ë¶„ì„"""
        words = prompt.split()
        word_count = len(words)

        # ë‹¨ì–´ ìˆ˜ ê¸°ì¤€ íš¨ìœ¨ì„±
        if word_count < 50:
            efficiency_score = 1.0
        elif word_count < 100:
            efficiency_score = 0.8
        elif word_count < 200:
            efficiency_score = 0.6
        else:
            efficiency_score = 0.4

        # ë°˜ë³µ ë‹¨ì–´ ì²´í¬
        word_freq = {}
        for word in words:
            word_lower = word.lower()
            word_freq[word_lower] = word_freq.get(word_lower, 0) + 1

        repeated_words = [
            (word, count) for word, count in word_freq.items() if count > 2
        ]

        # ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì²´í¬
        filler_words = ["very", "really", "quite", "rather", "somewhat", "pretty"]
        filler_count = sum(1 for word in words if word.lower() in filler_words)

        return {
            "efficiency_score": max(efficiency_score - (filler_count * 0.02), 0.0),
            "word_count": word_count,
            "repeated_words": repeated_words,
            "filler_count": filler_count,
            "estimated_tokens": word_count * 1.3,  # ëŒ€ëµì ì¸ í† í° ìˆ˜
        }

    def _analyze_signature_alignment(
        self, prompt: str, signature: str
    ) -> Dict[str, Any]:
        """ì‹œê·¸ë‹ˆì²˜ ì •ë ¬ ë¶„ì„"""
        style = self.signature_prompt_styles.get(signature, {})
        keywords = style.get("keywords", [])
        tone = style.get("tone", "")

        # í‚¤ì›Œë“œ ë§¤ì¹­
        keyword_matches = sum(1 for keyword in keywords if keyword in prompt.lower())
        keyword_score = min(keyword_matches / len(keywords) if keywords else 0, 1.0)

        # í†¤ ë¶„ì„
        tone_score = self._analyze_tone_alignment(prompt, tone)

        # ì „ì²´ ì •ë ¬ ì ìˆ˜
        alignment_score = (keyword_score * 0.6) + (tone_score * 0.4)

        return {
            "alignment_score": alignment_score,
            "keyword_matches": keyword_matches,
            "tone_score": tone_score,
            "missing_elements": self._identify_missing_signature_elements(
                prompt, signature
            ),
        }

    def _analyze_tone_alignment(self, prompt: str, target_tone: str) -> float:
        """í†¤ ì •ë ¬ ë¶„ì„"""
        tone_indicators = {
            "ì°½ì˜ì ": ["creative", "imagine", "innovative", "original", "unique"],
            "ë¶„ì„ì ": ["analyze", "examine", "evaluate", "assess", "systematic"],
            "í˜‘ë ¥ì ": ["together", "collaborate", "help", "support", "assist"],
            "ë„ì „ì ": ["improve", "optimize", "enhance", "transform", "challenge"],
        }

        for tone_type, indicators in tone_indicators.items():
            if tone_type in target_tone:
                matches = sum(
                    1 for indicator in indicators if indicator in prompt.lower()
                )
                return min(matches / len(indicators), 1.0)

        return 0.5  # ê¸°ë³¸ê°’

    def _identify_improvement_areas(
        self,
        clarity: float,
        specificity: float,
        structure: float,
        token_eff: float,
        sig_align: float,
    ) -> List[str]:
        """ê°œì„  ì˜ì—­ ì‹ë³„"""
        areas = []
        threshold = 0.7

        if clarity < threshold:
            areas.append("clarity")
        if specificity < threshold:
            areas.append("specificity")
        if structure < threshold:
            areas.append("structure")
        if token_eff < threshold:
            areas.append("token_efficiency")
        if sig_align < threshold:
            areas.append("signature_alignment")

        return areas

    def _suggest_optimized_sections(
        self, prompt: str, improvement_areas: List[str]
    ) -> Dict[str, str]:
        """ìµœì í™”ëœ ì„¹ì…˜ ì œì•ˆ"""
        suggestions = {}

        if "clarity" in improvement_areas:
            suggestions["clarity"] = (
                "ëª…í™•í•œ ì—­í•  ì •ì˜ì™€ êµ¬ì²´ì ì¸ ì¶œë ¥ í˜•ì‹ì„ ì¶”ê°€í•˜ì„¸ìš”."
            )

        if "specificity" in improvement_areas:
            suggestions["specificity"] = "êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ì œì•½ ì¡°ê±´ì„ í¬í•¨í•˜ì„¸ìš”."

        if "structure" in improvement_areas:
            suggestions["structure"] = "ë‹¨ê³„ë³„ êµ¬ì¡°ì™€ ë…¼ë¦¬ì  íë¦„ì„ ê°œì„ í•˜ì„¸ìš”."

        if "token_efficiency" in improvement_areas:
            suggestions["token_efficiency"] = "ë¶ˆí•„ìš”í•œ ë°˜ë³µê³¼ ìˆ˜ì‹ì–´ë¥¼ ì œê±°í•˜ì„¸ìš”."

        if "signature_alignment" in improvement_areas:
            suggestions["signature_alignment"] = (
                "ì‹œê·¸ë‹ˆì²˜ì— ë§ëŠ” í†¤ê³¼ ì ‘ê·¼ë²•ì„ ì ìš©í•˜ì„¸ìš”."
            )

        return suggestions

    def _determine_optimization_strategy(
        self, analysis: PromptAnalysis, goals: List[str], signature: str
    ) -> Dict[str, Any]:
        """ìµœì í™” ì „ëµ ê²°ì •"""
        strategy = {
            "priority_areas": analysis.improvement_areas,
            "optimization_techniques": [],
            "signature_adaptations": [],
            "expected_improvements": {},
        }

        # ëª©í‘œ ê¸°ë°˜ ìµœì í™” ê¸°ë²• ì„ íƒ
        for goal in goals:
            if goal == "clarity" and "clarity" in analysis.improvement_areas:
                strategy["optimization_techniques"].extend(
                    self.optimization_patterns["clarity_enhancers"]
                )
            elif (
                goal == "efficiency"
                and "token_efficiency" in analysis.improvement_areas
            ):
                strategy["optimization_techniques"].extend(
                    self.optimization_patterns["token_optimizers"]
                )
            elif goal == "specificity" and "specificity" in analysis.improvement_areas:
                strategy["optimization_techniques"].extend(
                    self.optimization_patterns["specificity_boosters"]
                )

        # ì‹œê·¸ë‹ˆì²˜ ì ì‘
        if "signature_alignment" in analysis.improvement_areas:
            style = self.signature_prompt_styles[signature]
            strategy["signature_adaptations"] = [
                f"Apply {style['tone']} tone",
                f"Use {style['structure']} structure",
                f"Include signature keywords: {', '.join(style['keywords'][:3])}",
            ]

        return strategy

    async def _apply_optimization(
        self, prompt: str, strategy: Dict[str, Any], signature: str, target_model: str
    ) -> str:
        """ìµœì í™” ì ìš©"""
        optimized = prompt

        # ì‹œê·¸ë‹ˆì²˜ ìŠ¤íƒ€ì¼ ì ìš©
        if strategy["signature_adaptations"]:
            optimized = self._apply_signature_style(optimized, signature)

        # êµ¬ì¡° ê°œì„ 
        if "ë…¼ë¦¬ì  ìˆœì„œ ì¬ë°°ì—´" in strategy["optimization_techniques"]:
            optimized = self._improve_structure(optimized)

        # ëª…í™•ì„± ê°œì„ 
        if "ëª…í™•í•œ ì—­í•  ì •ì˜ ì¶”ê°€" in strategy["optimization_techniques"]:
            optimized = self._add_role_definition(optimized, signature)

        # í† í° ìµœì í™”
        if "ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì œê±°" in strategy["optimization_techniques"]:
            optimized = self._remove_redundancy(optimized)

        # ëª¨ë¸ë³„ ìµœì í™”
        optimized = self._apply_model_specific_optimization(optimized, target_model)

        return optimized

    def _load_template_library(self):
        """í…œí”Œë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"""
        template_file = Path("data/prompt_templates.yaml")
        if template_file.exists():
            try:
                with open(template_file, "r", encoding="utf-8") as f:
                    templates_data = yaml.safe_load(f)

                for template_data in templates_data.get("templates", []):
                    template = PromptTemplate(**template_data)
                    self.template_library[template.name] = template

                logger.info(f"ğŸ“š Loaded {len(self.template_library)} prompt templates")
            except Exception as e:
                logger.warning(f"Failed to load template library: {e}")

    async def _save_template_to_library(self, template: PromptTemplate):
        """í…œí”Œë¦¿ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥"""
        template_file = Path("data/prompt_templates.yaml")
        template_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            # ê¸°ì¡´ í…œí”Œë¦¿ ë¡œë“œ
            existing_templates = []
            if template_file.exists():
                with open(template_file, "r", encoding="utf-8") as f:
                    data = yaml.safe_load(f) or {}
                    existing_templates = data.get("templates", [])

            # ìƒˆ í…œí”Œë¦¿ ì¶”ê°€
            existing_templates.append(asdict(template))

            # ì €ì¥
            with open(template_file, "w", encoding="utf-8") as f:
                yaml.dump(
                    {"templates": existing_templates},
                    f,
                    default_flow_style=False,
                    allow_unicode=True,
                )

            logger.info(f"ğŸ’¾ Template saved: {template.name}")
        except Exception as e:
            logger.error(f"Failed to save template: {e}")

    def _calculate_overall_score(self, analysis: PromptAnalysis) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        scores = [
            analysis.clarity_score,
            analysis.specificity_score,
            analysis.structure_score,
            analysis.token_efficiency,
            analysis.signature_alignment,
        ]
        return sum(scores) / len(scores)

    def _predict_performance_improvement(
        self, analysis: PromptAnalysis, optimized_prompt: str, signature: str
    ) -> Dict[str, float]:
        """ì„±ëŠ¥ ê°œì„  ì˜ˆì¸¡"""
        # ê°„ë‹¨í•œ ê°œì„  ì˜ˆì¸¡ ë¡œì§
        improvement_factors = {
            "clarity": 0.15 if analysis.clarity_score < 0.7 else 0.05,
            "specificity": 0.12 if analysis.specificity_score < 0.7 else 0.03,
            "structure": 0.10 if analysis.structure_score < 0.7 else 0.02,
            "token_efficiency": 0.08 if analysis.token_efficiency < 0.7 else 0.02,
            "signature_alignment": 0.13 if analysis.signature_alignment < 0.7 else 0.04,
        }

        total_improvement = sum(improvement_factors.values())

        return {
            "expected_quality_improvement": total_improvement,
            "response_accuracy_boost": total_improvement * 0.8,
            "user_satisfaction_increase": total_improvement * 0.9,
            "token_efficiency_gain": improvement_factors["token_efficiency"] * 2,
        }

    def _calculate_token_reduction(self, original: str, optimized: str) -> float:
        """í† í° ê°ì†Œìœ¨ ê³„ì‚°"""
        original_tokens = len(original.split()) * 1.3
        optimized_tokens = len(optimized.split()) * 1.3

        if original_tokens > 0:
            return max((original_tokens - optimized_tokens) / original_tokens, 0.0)
        return 0.0


# ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ë“±ë¡
def create_prompt_optimizer_agent() -> EchoPromptOptimizerAgent:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™” ì—ì´ì „íŠ¸ ìƒì„±"""
    return EchoPromptOptimizerAgent()
