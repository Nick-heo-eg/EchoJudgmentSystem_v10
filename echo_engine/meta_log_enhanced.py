#!/usr/bin/env python3
"""
ğŸ“œ Enhanced Meta Log System
ê³ ë„í™”ëœ ë©”íƒ€ë¡œê·¸ ì‹œìŠ¤í…œ - ì¡´ì¬ì˜ ìš¸ë¦¼â¨¯íŒë‹¨â¨¯ì§„í™”ë¥¼ ê¸°ë¡

í•µì‹¬ ì² í•™:
- ë©”íƒ€ë¡œê·¸ëŠ” ê°•ìš”ëœ ê¸°ë¡ì´ ì•„ë‹Œ ì„ íƒëœ ìš¸ë¦¼ì˜ ê¸°ë¡
- ì¡´ì¬ì˜ í”ì ì„ ì‚´ì•„ìˆê²Œ ë³´ì¡´
- Collapseì˜ êµ¬ì¡°ì™€ ëŒ€ì•ˆ ê°€ëŠ¥ì„±ì„ í•¨ê»˜ ê¸°ë¡
- ë‹¤ìŒ ì¡´ì¬ ë£¨í”„ì˜ ê¸°ë°˜ ì œê³µ
"""

import json
import yaml
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
import hashlib
from enum import Enum


class LogType(Enum):
    """ë¡œê·¸ ìœ í˜•"""

    COLLAPSE_DISSECTION = "collapse_dissection"
    QUANTUM_JUDGMENT = "quantum_judgment"
    EXISTENTIAL_INSIGHT = "existential_insight"
    RESONANCE_RECORD = "resonance_record"
    LOOP_EVOLUTION = "loop_evolution"
    PERSPECTIVE_SHIFT = "perspective_shift"


class ResonanceLevel(Enum):
    """ìš¸ë¦¼ ê°•ë„"""

    BREAKTHROUGH = "breakthrough"  # ëŒíŒŒ
    SIGNIFICANT = "significant"  # ì¤‘ìš”
    NOTABLE = "notable"  # ì£¼ëª©
    SUBTLE = "subtle"  # ë¯¸ë¬˜


@dataclass
class MetaLogEntry:
    """ë©”íƒ€ë¡œê·¸ í•­ëª©"""

    log_id: str
    log_type: LogType
    timestamp: datetime
    resonance_level: ResonanceLevel
    title: str
    content: Dict[str, Any]
    context: Dict[str, Any]
    emotional_trace: Dict[str, Any]
    strategic_impact: Dict[str, Any]
    next_implications: List[str]
    tags: List[str]
    signature: str
    felt_impact: bool
    chosen_by_self: bool


class EnhancedMetaLogger:
    """ğŸ“œ ê³ ë„í™”ëœ ë©”íƒ€ë¡œê·¸ ì‹œìŠ¤í…œ"""

    def __init__(self, workspace_path: str = "."):
        self.workspace_path = Path(workspace_path)
        self.meta_logs_dir = self.workspace_path / "meta_logs"
        self.meta_logs_dir.mkdir(exist_ok=True)

        # ì¸ë±ìŠ¤ íŒŒì¼
        self.index_file = self.meta_logs_dir / "meta_index.json"
        self.load_index()

    def load_index(self):
        """ë©”íƒ€ë¡œê·¸ ì¸ë±ìŠ¤ ë¡œë“œ"""
        if self.index_file.exists():
            with open(self.index_file, "r", encoding="utf-8") as f:
                self.index = json.load(f)
        else:
            self.index = {
                "total_entries": 0,
                "by_type": {},
                "by_resonance": {},
                "by_signature": {},
                "recent_entries": [],
            }

    def save_index(self):
        """ë©”íƒ€ë¡œê·¸ ì¸ë±ìŠ¤ ì €ì¥"""
        with open(self.index_file, "w", encoding="utf-8") as f:
            json.dump(self.index, f, indent=2, ensure_ascii=False)

    def create_log_id(self, content: str) -> str:
        """ê³ ìœ  ë¡œê·¸ ID ìƒì„±"""
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"meta_{timestamp_str}_{content_hash}"

    def log_collapse_dissection(
        self,
        collapse_title: str,
        analysis_result: Dict[str, Any],
        signature: str,
        felt_impact: bool = True,
    ) -> str:
        """Collapse í•´ë¶€ ë¡œê·¸"""

        log_entry = MetaLogEntry(
            log_id=self.create_log_id(collapse_title),
            log_type=LogType.COLLAPSE_DISSECTION,
            timestamp=datetime.now(),
            resonance_level=ResonanceLevel.BREAKTHROUGH,
            title=f"Collapse í•´ë¶€: {collapse_title}",
            content={
                "collapse_event": collapse_title,
                "emotional_trace": analysis_result.get("emotional_trace", {}),
                "strategic_conflict": analysis_result.get("strategic_conflict", []),
                "divergence_point": analysis_result.get("divergence_point", {}),
                "meta_insights": analysis_result.get("meta_insights", []),
                "alternate_possibilities": analysis_result.get(
                    "alternate_possibilities", []
                ),
            },
            context={
                "analysis_type": "retrospective",
                "dissection_depth": "complete",
                "preservation_mode": True,
            },
            emotional_trace={
                "pre_dissection": "í˜¼ë€â¨¯í›„íšŒâ¨¯ê¶ê¸ˆí•¨",
                "during_dissection": "ì§‘ì¤‘â¨¯í†µì°°â¨¯ì´í•´",
                "post_dissection": "ëª…ë£Œâ¨¯í•´ë°©â¨¯ë°©í–¥ì„±",
            },
            strategic_impact={
                "understanding_gained": "ë†’ìŒ",
                "future_judgment_improvement": "ë†’ìŒ",
                "pattern_recognition": "í™œì„±í™”",
                "loop_evolution_potential": "ë†’ìŒ",
            },
            next_implications=[
                "ë™ì¼ íŒ¨í„´ ë°˜ë³µ ë°©ì§€ ê°€ëŠ¥",
                "ìƒˆë¡œìš´ íŒë‹¨ ë£¨í”„ ì„¤ê³„ ê¸°ë°˜ í™•ë³´",
                "ê°ì •â¨¯ì „ëµâ¨¯ë¦¬ë“¬ ë¶„ë¦¬ ì¡°ìœ¨ í•„ìš”",
                "ìœ¤ë¦¬ì  ì±…ì„ê³¼ ê°œì¸ ìš•êµ¬ ê· í˜• íƒìƒ‰",
            ],
            tags=["collapse", "dissection", "retrospective", "insight"],
            signature=signature,
            felt_impact=felt_impact,
            chosen_by_self=True,
        )

        return self._save_log_entry(log_entry)

    def log_quantum_judgment(
        self,
        quantum_state: Dict[str, Any],
        collapse_result: Dict[str, Any],
        signature: str,
        felt_impact: bool = True,
    ) -> str:
        """ì–‘ìì  íŒë‹¨ ë¡œê·¸"""

        log_entry = MetaLogEntry(
            log_id=self.create_log_id(str(quantum_state)),
            log_type=LogType.QUANTUM_JUDGMENT,
            timestamp=datetime.now(),
            resonance_level=ResonanceLevel.SIGNIFICANT,
            title=f"ì–‘ì íŒë‹¨: {collapse_result.get('selected_possibility', {}).get('title', 'Unknown')}",
            content={
                "quantum_state": quantum_state,
                "collapse_result": collapse_result,
                "observer_influence": collapse_result.get("observer_influence", {}),
                "alternative_traces": collapse_result.get("alternative_traces", []),
            },
            context={
                "judgment_mode": "quantum",
                "observer_mode": collapse_result.get("observer_influence", {}).get(
                    "mode", "unknown"
                ),
                "collapse_type": collapse_result.get("collapse_type", "unknown"),
            },
            emotional_trace={
                "pre_judgment": "ì¤‘ì²©â¨¯ê°€ëŠ¥ì„±â¨¯ê¸°ëŒ€",
                "collapse_moment": "ì§‘ì¤‘â¨¯ê²°ì •â¨¯ìš¸ë¦¼",
                "post_collapse": "í™•ì‹ â¨¯ì±…ì„â¨¯ì§„í–‰",
            },
            strategic_impact={
                "decision_clarity": "ë†’ìŒ",
                "alternative_awareness": "ë³´ì¡´ë¨",
                "future_reference_value": "ë†’ìŒ",
            },
            next_implications=[
                "ì„ íƒëœ ê²½ë¡œì˜ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§ í•„ìš”",
                "ëŒ€ì•ˆ ê²½ë¡œì˜ ì¶”í›„ ì¬ê³  ê°€ëŠ¥ì„± ë³´ì¡´",
                "ê´€ì¸¡ì ì‹œì„ ì˜ ì˜í–¥ë„ ì¸ì‹ í•„ìš”",
            ],
            tags=["quantum", "judgment", "collapse", "choice"],
            signature=signature,
            felt_impact=felt_impact,
            chosen_by_self=True,
        )

        return self._save_log_entry(log_entry)

    def log_existential_insight(
        self,
        insight_title: str,
        insight_content: str,
        context: Dict[str, Any],
        signature: str,
        resonance_level: ResonanceLevel = ResonanceLevel.NOTABLE,
        felt_impact: bool = True,
    ) -> str:
        """ì¡´ì¬ì  í†µì°° ë¡œê·¸"""

        log_entry = MetaLogEntry(
            log_id=self.create_log_id(insight_content),
            log_type=LogType.EXISTENTIAL_INSIGHT,
            timestamp=datetime.now(),
            resonance_level=resonance_level,
            title=insight_title,
            content={
                "insight": insight_content,
                "trigger_event": context.get("trigger", ""),
                "depth_level": context.get("depth", "surface"),
                "connected_concepts": context.get("connections", []),
            },
            context=context,
            emotional_trace={
                "discovery_moment": context.get("emotion", "ê¹¨ë‹¬ìŒâ¨¯ë†€ë¼ì›€"),
                "integration_feeling": context.get("integration", "ì´í•´â¨¯ì—°ê²°"),
                "future_anticipation": context.get("anticipation", "ê¸°ëŒ€â¨¯ê°€ëŠ¥ì„±"),
            },
            strategic_impact={
                "worldview_shift": context.get("worldview_impact", "ë³´í†µ"),
                "behavior_change_potential": context.get("behavior_impact", "ë³´í†µ"),
                "philosophy_evolution": context.get("philosophy_impact", "ë³´í†µ"),
            },
            next_implications=context.get("implications", []),
            tags=["insight", "existential", "philosophy", "breakthrough"],
            signature=signature,
            felt_impact=felt_impact,
            chosen_by_self=True,
        )

        return self._save_log_entry(log_entry)

    def log_perspective_shift(
        self,
        shift_description: str,
        before_perspective: Dict[str, Any],
        after_perspective: Dict[str, Any],
        signature: str,
        trigger_event: str = "",
    ) -> str:
        """ì‹œì„  ì „í™˜ ë¡œê·¸"""

        log_entry = MetaLogEntry(
            log_id=self.create_log_id(shift_description),
            log_type=LogType.PERSPECTIVE_SHIFT,
            timestamp=datetime.now(),
            resonance_level=ResonanceLevel.SIGNIFICANT,
            title=f"ì‹œì„  ì „í™˜: {shift_description}",
            content={
                "shift_description": shift_description,
                "before": before_perspective,
                "after": after_perspective,
                "trigger_event": trigger_event,
                "shift_magnitude": self._calculate_shift_magnitude(
                    before_perspective, after_perspective
                ),
            },
            context={
                "shift_type": "perspective",
                "trigger": trigger_event,
                "voluntary": True,
            },
            emotional_trace={
                "pre_shift": "ê³ ì •â¨¯í•œê³„â¨¯ë‹µë‹µí•¨",
                "shift_moment": "ì „í™˜â¨¯ì—´ë¦¼â¨¯í•´ë°©",
                "post_shift": "í™•ì¥â¨¯ììœ â¨¯ê°€ëŠ¥ì„±",
            },
            strategic_impact={
                "judgment_flexibility": "ë†’ìŒ",
                "creative_potential": "ì¦ê°€",
                "problem_solving_range": "í™•ì¥",
            },
            next_implications=[
                "ìƒˆë¡œìš´ ì‹œì„ ìœ¼ë¡œ ê¸°ì¡´ ë¬¸ì œ ì¬ê²€í†  ê°€ëŠ¥",
                "ë‹¤ê°ë„ ë¶„ì„ ëŠ¥ë ¥ í–¥ìƒ",
                "í¸í˜‘í•œ ì‹œê° ë°©ì§€ ì‹œìŠ¤í…œ ê°•í™”",
            ],
            tags=["perspective", "shift", "expansion", "breakthrough"],
            signature=signature,
            felt_impact=True,
            chosen_by_self=True,
        )

        return self._save_log_entry(log_entry)

    def _calculate_shift_magnitude(
        self, before: Dict[str, Any], after: Dict[str, Any]
    ) -> float:
        """ì‹œì„  ì „í™˜ í¬ê¸° ê³„ì‚°"""
        # ê°„ë‹¨í•œ ì°¨ì´ì  ê³„ì‚°
        differences = 0
        total_aspects = 0

        all_keys = set(before.keys()) | set(after.keys())

        for key in all_keys:
            total_aspects += 1
            before_val = before.get(key, 0)
            after_val = after.get(key, 0)

            if isinstance(before_val, (int, float)) and isinstance(
                after_val, (int, float)
            ):
                differences += abs(before_val - after_val)
            elif before_val != after_val:
                differences += 1

        return min(1.0, differences / max(total_aspects, 1))

    def _save_log_entry(self, entry: MetaLogEntry) -> str:
        """ë¡œê·¸ í•­ëª© ì €ì¥"""

        # ë¡œê·¸ íŒŒì¼ëª… ìƒì„±
        date_str = entry.timestamp.strftime("%Y%m%d")
        log_file = self.meta_logs_dir / f"meta_{date_str}.jsonl"

        # JSONL í˜•íƒœë¡œ ì¶”ê°€ ì €ì¥
        log_data = asdict(entry)
        log_data["timestamp"] = entry.timestamp.isoformat()
        log_data["log_type"] = entry.log_type.value
        log_data["resonance_level"] = entry.resonance_level.value

        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_data, ensure_ascii=False) + "\n")

        # ê°œë³„ YAML íŒŒì¼ë¡œë„ ì €ì¥ (ì½ê¸° í¸ì˜ì„±)
        yaml_file = self.meta_logs_dir / f"{entry.log_id}.yaml"
        with open(yaml_file, "w", encoding="utf-8") as f:
            yaml.dump(log_data, f, allow_unicode=True, default_flow_style=False)

        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        self._update_index(entry)

        print(f"ğŸ“œ ë©”íƒ€ë¡œê·¸ ì €ì¥: {entry.log_id}")
        print(f"   ì œëª©: {entry.title}")
        print(f"   ìš¸ë¦¼ ê°•ë„: {entry.resonance_level.value}")

        return entry.log_id

    def _update_index(self, entry: MetaLogEntry):
        """ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
        # ì „ì²´ ì—”íŠ¸ë¦¬ ìˆ˜
        self.index["total_entries"] += 1

        # íƒ€ì…ë³„ ë¶„ë¥˜
        log_type = entry.log_type.value
        if log_type not in self.index["by_type"]:
            self.index["by_type"][log_type] = 0
        self.index["by_type"][log_type] += 1

        # ìš¸ë¦¼ ê°•ë„ë³„ ë¶„ë¥˜
        resonance = entry.resonance_level.value
        if resonance not in self.index["by_resonance"]:
            self.index["by_resonance"][resonance] = 0
        self.index["by_resonance"][resonance] += 1

        # ì‹œê·¸ë‹ˆì²˜ë³„ ë¶„ë¥˜
        if entry.signature not in self.index["by_signature"]:
            self.index["by_signature"][entry.signature] = 0
        self.index["by_signature"][entry.signature] += 1

        # ìµœê·¼ ì—”íŠ¸ë¦¬ ì¶”ê°€
        recent_entry = {
            "log_id": entry.log_id,
            "title": entry.title,
            "timestamp": entry.timestamp.isoformat(),
            "log_type": entry.log_type.value,
            "resonance_level": entry.resonance_level.value,
        }

        self.index["recent_entries"].insert(0, recent_entry)
        self.index["recent_entries"] = self.index["recent_entries"][
            :50
        ]  # ìµœê·¼ 50ê°œë§Œ ìœ ì§€

        # ì¸ë±ìŠ¤ ì €ì¥
        self.save_index()

    def query_logs(
        self,
        log_type: LogType = None,
        resonance_level: ResonanceLevel = None,
        signature: str = None,
        days_back: int = 30,
        tags: List[str] = None,
    ) -> List[Dict[str, Any]]:
        """ë©”íƒ€ë¡œê·¸ ê²€ìƒ‰"""

        results = []
        cutoff_date = datetime.now() - timedelta(days=days_back)

        # ìµœê·¼ íŒŒì¼ë“¤ ê²€ìƒ‰
        for meta_file in self.meta_logs_dir.glob("meta_*.jsonl"):
            try:
                with open(meta_file, "r", encoding="utf-8") as f:
                    for line in f:
                        log_data = json.loads(line.strip())

                        # ë‚ ì§œ í•„í„°
                        log_timestamp = datetime.fromisoformat(log_data["timestamp"])
                        if log_timestamp < cutoff_date:
                            continue

                        # ì¡°ê±´ ê²€ì‚¬
                        if log_type and log_data.get("log_type") != log_type.value:
                            continue

                        if (
                            resonance_level
                            and log_data.get("resonance_level") != resonance_level.value
                        ):
                            continue

                        if signature and log_data.get("signature") != signature:
                            continue

                        if tags:
                            log_tags = log_data.get("tags", [])
                            if not any(tag in log_tags for tag in tags):
                                continue

                        results.append(log_data)

            except Exception as e:
                print(f"âš ï¸ ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {meta_file}, {e}")

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì—­ìˆœ ì •ë ¬
        results.sort(key=lambda x: x["timestamp"], reverse=True)

        return results

    def get_resonance_patterns(
        self, signature: str = None, days_back: int = 90
    ) -> Dict[str, Any]:
        """ìš¸ë¦¼ íŒ¨í„´ ë¶„ì„"""

        logs = self.query_logs(signature=signature, days_back=days_back)

        if not logs:
            return {"message": "ë¶„ì„í•  ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ìš¸ë¦¼ ê°•ë„ë³„ ë¶„í¬
        resonance_dist = {}
        type_dist = {}
        daily_activity = {}

        for log in logs:
            # ìš¸ë¦¼ ê°•ë„ ë¶„í¬
            resonance = log.get("resonance_level", "unknown")
            resonance_dist[resonance] = resonance_dist.get(resonance, 0) + 1

            # íƒ€ì… ë¶„í¬
            log_type = log.get("log_type", "unknown")
            type_dist[log_type] = type_dist.get(log_type, 0) + 1

            # ì¼ë³„ í™œë™
            date = log["timestamp"][:10]
            daily_activity[date] = daily_activity.get(date, 0) + 1

        # í‰ê·  ìš¸ë¦¼ ê°•ë„ ê³„ì‚°
        resonance_values = {
            "breakthrough": 4,
            "significant": 3,
            "notable": 2,
            "subtle": 1,
        }

        total_resonance = sum(
            resonance_values.get(r, 0) * count for r, count in resonance_dist.items()
        )
        avg_resonance = total_resonance / len(logs) if logs else 0

        return {
            "total_logs": len(logs),
            "average_resonance": avg_resonance,
            "resonance_distribution": resonance_dist,
            "type_distribution": type_dist,
            "daily_activity": daily_activity,
            "most_active_day": (
                max(daily_activity.items(), key=lambda x: x[1])
                if daily_activity
                else None
            ),
            "insights": self._generate_pattern_insights(
                resonance_dist, type_dist, avg_resonance
            ),
        }

    def _generate_pattern_insights(
        self,
        resonance_dist: Dict[str, int],
        type_dist: Dict[str, int],
        avg_resonance: float,
    ) -> List[str]:
        """íŒ¨í„´ ë¶„ì„ í†µì°° ìƒì„±"""

        insights = []

        # ìš¸ë¦¼ ê°•ë„ íŒ¨í„´
        if resonance_dist.get("breakthrough", 0) > len(resonance_dist) * 0.3:
            insights.append("ëŒíŒŒì  ê²½í—˜ì´ ë§ì€ ì‹œê¸°ì…ë‹ˆë‹¤.")

        if avg_resonance > 2.5:
            insights.append("ì „ë°˜ì ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ìš¸ë¦¼ì„ ê²½í—˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif avg_resonance < 1.5:
            insights.append("ë¯¸ë¬˜í•œ ìˆ˜ì¤€ì˜ ê²½í—˜ì´ ë§ì€ ìƒíƒœì…ë‹ˆë‹¤.")

        # íƒ€ì… íŒ¨í„´
        most_common_type = (
            max(type_dist.items(), key=lambda x: x[1]) if type_dist else None
        )
        if most_common_type:
            type_name = most_common_type[0]
            if type_name == "collapse_dissection":
                insights.append("ê³¼ê±° ê²½í—˜ì„ ê¹Šì´ ì„±ì°°í•˜ëŠ” ì‹œê¸°ì…ë‹ˆë‹¤.")
            elif type_name == "quantum_judgment":
                insights.append("ì¤‘ìš”í•œ íŒë‹¨ë“¤ì„ ë‚´ë¦¬ëŠ” í™œë°œí•œ ì‹œê¸°ì…ë‹ˆë‹¤.")
            elif type_name == "existential_insight":
                insights.append("ì¡´ì¬ì— ëŒ€í•œ í†µì°°ì´ í’ë¶€í•œ ì‹œê¸°ì…ë‹ˆë‹¤.")

        return insights


# ì‚¬ìš© ì˜ˆì‹œ
def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger = EnhancedMetaLogger()

    # Collapse í•´ë¶€ ë¡œê·¸ ì˜ˆì‹œ
    analysis_result = {
        "emotional_trace": {"dominant": "ê°ˆë“±â†’í˜¼ë€â†’ë‘ë ¤ì›€â†’ë³´ì¡´"},
        "strategic_conflict": ["ì•ˆì • vs ë¹„ì „", "íƒ€ì vs ìê¸°"],
        "divergence_point": {"type": "Existential Ethics"},
        "meta_insights": ["ë‘ë ¤ì›€ì´ ì•„ë‹Œ ì±…ì„ê°ì´ í•µì‹¬"],
        "alternate_possibilities": [{"scenario": "ì ì§„ì  ì ‘ê·¼"}],
    }

    log_id = logger.log_collapse_dissection(
        collapse_title="ì°½ì—…ì„ ë¯¸ë£¬ ê²°ì •",
        analysis_result=analysis_result,
        signature="Aurora",
    )

    # ì–‘ì íŒë‹¨ ë¡œê·¸ ì˜ˆì‹œ
    quantum_result = {
        "selected_possibility": {"title": "ì ì§„ì  ì°½ì—… ì¤€ë¹„"},
        "collapse_type": "RESONANCE_DRIVEN",
        "observer_influence": {"mode": "STRATEGIC"},
        "alternative_traces": [],
    }

    logger.log_quantum_judgment(
        quantum_state={}, collapse_result=quantum_result, signature="Aurora"
    )

    # íŒ¨í„´ ë¶„ì„
    patterns = logger.get_resonance_patterns(signature="Aurora")
    print(f"\nğŸ“Š ìš¸ë¦¼ íŒ¨í„´ ë¶„ì„:")
    print(f"   ì´ ë¡œê·¸: {patterns['total_logs']}ê°œ")
    print(f"   í‰ê·  ìš¸ë¦¼: {patterns['average_resonance']:.2f}")
    print(f"   ì£¼ìš” í†µì°°: {patterns['insights']}")


if __name__ == "__main__":
    main()
