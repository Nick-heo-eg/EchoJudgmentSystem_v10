#!/usr/bin/env python3
"""
ğŸ›ï¸ Echo Selector - LLM vs Echo íŒë‹¨ ë¶„ê¸°ê¸°
ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì²˜ë¦¬ ë°©ì‹ì„ ì„ íƒí•˜ëŠ” ì§€ëŠ¥í˜• ë¼ìš°í„°

í•µì‹¬ ê¸°ëŠ¥:
1. ì‹¤ì‹œê°„ ë³µì¡ë„ ë¶„ì„ì„ í†µí•œ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
2. ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ ê¸°ë°˜ ê°œì¸í™”ëœ ë¶„ê¸°
3. ìƒí™©ë³„ í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ëª¨ë“œ ì§€ì›
4. ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì ì‘í˜• ì„ê³„ê°’ ì¡°ì •
"""

import json
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
from collections import defaultdict, deque


class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""

    LLM_ONLY = "llm_only"  # LLMë§Œ ì‚¬ìš© (ë¹ ë¥¸ ìì—° ì‘ë‹µ)
    ECHO_LIGHT = "echo_light"  # ê²½ëŸ‰ Echo ì²˜ë¦¬ (ê¸°ë³¸ íŒë‹¨)
    ECHO_FULL = "echo_full"  # ì™„ì „ Echo ì‹œìŠ¤í…œ (ê¹Šì´ ìˆëŠ” íŒë‹¨)
    HYBRID_LLM_ECHO = "hybrid_llm_echo"  # LLM ìš°ì„  + Echo ë³´ì¡°
    HYBRID_ECHO_LLM = "hybrid_echo_llm"  # Echo ìš°ì„  + LLM ìì—°í™”
    ADAPTIVE = "adaptive"  # ìƒí™©ë³„ ì ì‘í˜•


class ComplexityLevel(Enum):
    """ë³µì¡ë„ ìˆ˜ì¤€"""

    TRIVIAL = "trivial"  # ë§¤ìš° ê°„ë‹¨ (ì¸ì‚¬, ì§§ì€ ë°˜ì‘)
    SIMPLE = "simple"  # ê°„ë‹¨ (ì¼ìƒ ëŒ€í™”)
    MODERATE = "moderate"  # ë³´í†µ (ì¼ë°˜ì ì¸ ì§ˆë¬¸/ìš”ì²­)
    COMPLEX = "complex"  # ë³µì¡ (ê°ì •ì  ì§€ì›, ê²°ì • ë„ì›€)
    CRITICAL = "critical"  # ê¸´ê¸‰ (ìœ„ê¸° ìƒí™©, ì¤‘ìš”í•œ íŒë‹¨)


@dataclass
class SelectionResult:
    """ì„ íƒ ê²°ê³¼"""

    processing_mode: ProcessingMode
    confidence: float
    complexity_level: ComplexityLevel
    reasoning: List[str]
    estimated_processing_time: float
    resource_requirements: Dict[str, float]
    fallback_mode: ProcessingMode


@dataclass
class UserProcessingProfile:
    """ì‚¬ìš©ì ì²˜ë¦¬ í”„ë¡œí•„"""

    user_id: str
    preferred_modes: Dict[str, int]
    response_quality_scores: Dict[str, List[float]]
    average_session_complexity: float
    interaction_patterns: Dict[str, Any]
    last_updated: datetime


class EchoSelector:
    """Echo vs LLM ì§€ëŠ¥í˜• ì„ íƒê¸°"""

    def __init__(self, learning_rate: float = 0.1):
        self.learning_rate = learning_rate

        # ë³µì¡ë„ ë¶„ì„ ê°€ì¤‘ì¹˜
        self.complexity_weights = self._initialize_complexity_weights()

        # ì²˜ë¦¬ ëª¨ë“œë³„ ì„ê³„ê°’ (ì ì‘í˜•)
        self.mode_thresholds = {
            ComplexityLevel.TRIVIAL: ProcessingMode.LLM_ONLY,
            ComplexityLevel.SIMPLE: ProcessingMode.LLM_ONLY,
            ComplexityLevel.MODERATE: ProcessingMode.ECHO_LIGHT,
            ComplexityLevel.COMPLEX: ProcessingMode.ECHO_FULL,
            ComplexityLevel.CRITICAL: ProcessingMode.ECHO_FULL,
        }

        # ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë¦¬
        self.user_profiles: Dict[str, UserProcessingProfile] = {}

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_history = deque(maxlen=1000)

        # ì‹œìŠ¤í…œ ë¶€í•˜ ëª¨ë‹ˆí„°ë§
        self.system_load = {
            "llm_queue": 0,
            "echo_queue": 0,
            "hybrid_queue": 0,
            "last_check": datetime.now(),
        }

        print("ğŸ›ï¸ Echo Selector ì´ˆê¸°í™” ì™„ë£Œ")

    def select_processing_mode(
        self,
        text: str,
        context: Dict[str, Any] = None,
        user_id: str = None,
        session_history: List[Dict] = None,
    ) -> SelectionResult:
        """ìµœì  ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ"""

        context = context or {}
        session_history = session_history or []

        # 1. ë³µì¡ë„ ë¶„ì„
        complexity_level, complexity_score = self._analyze_complexity(
            text, context, session_history
        )

        # 2. ê¸°ë³¸ ëª¨ë“œ ê²°ì •
        base_mode = self._determine_base_mode(complexity_level, complexity_score)

        # 3. ì‚¬ìš©ì íŒ¨í„´ ì ìš©
        if user_id:
            base_mode = self._apply_user_preferences(
                base_mode, user_id, complexity_level
            )

        # 4. ì‹œìŠ¤í…œ ë¶€í•˜ ê³ ë ¤
        final_mode = self._consider_system_load(base_mode, complexity_level)

        # 5. ì²˜ë¦¬ ì‹œê°„ ë° ìì› ìš”êµ¬ì‚¬í•­ ì¶”ì •
        estimated_time = self._estimate_processing_time(final_mode, complexity_score)
        resource_requirements = self._estimate_resource_requirements(final_mode)

        # 6. í´ë°± ëª¨ë“œ ê²°ì •
        fallback_mode = self._determine_fallback_mode(final_mode)

        # 7. ì„ íƒ ì´ìœ  ìƒì„±
        reasoning = self._generate_reasoning(
            text, complexity_level, base_mode, final_mode, context
        )

        # 8. ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_selection_confidence(
            complexity_score, final_mode, user_id
        )

        return SelectionResult(
            processing_mode=final_mode,
            confidence=confidence,
            complexity_level=complexity_level,
            reasoning=reasoning,
            estimated_processing_time=estimated_time,
            resource_requirements=resource_requirements,
            fallback_mode=fallback_mode,
        )

    def _analyze_complexity(
        self, text: str, context: Dict[str, Any], history: List[Dict]
    ) -> Tuple[ComplexityLevel, float]:
        """ë³µì¡ë„ ë¶„ì„"""

        complexity_score = 0.0

        # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³µì¡ë„
        text_features = self._extract_text_complexity_features(text)
        for feature, value in text_features.items():
            weight = self.complexity_weights.get(feature, 0.1)
            complexity_score += value * weight

        # ë§¥ë½ ê¸°ë°˜ ë³µì¡ë„
        if context:
            context_complexity = self._analyze_context_complexity(context)
            complexity_score += context_complexity * 0.3

        # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë³µì¡ë„
        if history:
            history_complexity = self._analyze_history_complexity(history)
            complexity_score += history_complexity * 0.2

        # ë³µì¡ë„ ìˆ˜ì¤€ ê²°ì •
        if complexity_score < 0.2:
            level = ComplexityLevel.TRIVIAL
        elif complexity_score < 0.4:
            level = ComplexityLevel.SIMPLE
        elif complexity_score < 0.6:
            level = ComplexityLevel.MODERATE
        elif complexity_score < 0.8:
            level = ComplexityLevel.COMPLEX
        else:
            level = ComplexityLevel.CRITICAL

        return level, min(complexity_score, 1.0)

    def _extract_text_complexity_features(self, text: str) -> Dict[str, float]:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ íŠ¹ì§• ì¶”ì¶œ"""

        features = {}

        # ê¸°ë³¸ íŠ¹ì§•
        features["length"] = min(len(text) / 200, 1.0)  # ì •ê·œí™”ëœ ê¸¸ì´
        features["word_count"] = min(len(text.split()) / 50, 1.0)
        features["sentence_count"] = min(
            len([s for s in text.split(".") if s.strip()]) / 10, 1.0
        )

        # êµ¬ì¡°ì  ë³µì¡ë„
        features["question_density"] = min(
            text.count("?") / max(len(text.split()), 1), 0.5
        )
        features["punctuation_variety"] = len(set(c for c in text if c in ".,!?;:")) / 6

        # ê°ì •ì  ë³µì¡ë„
        emotional_keywords = [
            "í˜ë“¤ì–´",
            "ìŠ¬í¼",
            "í™”ë‚˜",
            "ê±±ì •",
            "ë¶ˆì•ˆ",
            "ìš°ìš¸",
            "ê¸°ë»",
            "í–‰ë³µ",
            "ì‚¬ë‘",
            "ë¯¸ì›Œ",
            "ë¬´ì„œì›Œ",
            "ë‹µë‹µí•´",
        ]
        features["emotional_density"] = sum(
            1 for keyword in emotional_keywords if keyword in text
        ) / max(len(text.split()), 1)

        # ì¶”ìƒì  ê°œë…
        abstract_keywords = [
            "ì˜ë¯¸",
            "ëª©ì ",
            "ê°€ì¹˜",
            "ì² í•™",
            "ì¡´ì¬",
            "ë³¸ì§ˆ",
            "ë¯¸ë˜",
            "ì¸ìƒ",
            "ê¿ˆ",
            "í¬ë§",
            "í˜„ì‹¤",
            "ì´ìƒ",
        ]
        features["abstract_density"] = sum(
            1 for keyword in abstract_keywords if keyword in text
        ) / max(len(text.split()), 1)

        # ê²°ì •/íŒë‹¨ ìš”êµ¬
        decision_keywords = [
            "ì„ íƒ",
            "ê²°ì •",
            "íŒë‹¨",
            "ê³ ë¯¼",
            "ì–´ë–»ê²Œ",
            "ë°©ë²•",
            "ì¶”ì²œ",
            "ì¡°ì–¸",
            "ë„ì›€",
            "ê°€ì´ë“œ",
            "ë°©í–¥",
        ]
        features["decision_density"] = sum(
            1 for keyword in decision_keywords if keyword in text
        ) / max(len(text.split()), 1)

        # ê¸´ê¸‰ì„±
        urgency_keywords = ["ê¸‰í•´", "ë¹¨ë¦¬", "ì§€ê¸ˆ", "ë‹¹ì¥", "ì¦‰ì‹œ", "!!"]
        features["urgency"] = (
            1.0 if any(keyword in text for keyword in urgency_keywords) else 0.0
        )

        return features

    def _analyze_context_complexity(self, context: Dict[str, Any]) -> float:
        """ë§¥ë½ ë³µì¡ë„ ë¶„ì„"""

        complexity = 0.0

        # ê°ì • ê°•ë„
        emotion_intensity = context.get("emotion_intensity", 0)
        complexity += emotion_intensity * 0.5

        # ìœ„ê¸‰ë„
        urgency_level = context.get("urgency_level", 1)
        complexity += min(urgency_level / 5, 1.0) * 0.6

        # ì˜ë„ ë³µì¡ë„
        intent_type = context.get("intent_type", "")
        intent_complexity_map = {
            "casual_chat": 0.1,
            "information_seeking": 0.3,
            "emotional_support": 0.7,
            "decision_help": 0.8,
            "philosophical_inquiry": 0.9,
            "crisis_intervention": 1.0,
        }
        complexity += intent_complexity_map.get(intent_type, 0.3)

        # ë§¥ë½ì  ìš”ì†Œ ìˆ˜
        contextual_factors = context.get("contextual_factors", [])
        complexity += min(len(contextual_factors) / 5, 0.3)

        return min(complexity, 1.0)

    def _analyze_history_complexity(self, history: List[Dict]) -> float:
        """ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ë³µì¡ë„ ë¶„ì„"""

        if not history:
            return 0.0

        # ìµœê·¼ 3ê°œ ëŒ€í™”ì˜ ë³µì¡ë„ í‰ê· 
        recent_entries = history[-3:]

        complexity_sum = 0.0
        for entry in recent_entries:
            # ê° ëŒ€í™”ì˜ ë³µì¡ë„ ì§€í‘œ
            entry_complexity = 0.0

            # ì‘ë‹µ ê¸¸ì´
            response_length = len(entry.get("response", ""))
            entry_complexity += min(response_length / 100, 0.3)

            # ì²˜ë¦¬ ì‹œê°„
            processing_time = entry.get("processing_time", 0)
            entry_complexity += min(processing_time / 5, 0.3)

            # ê°ì • ë³€í™”
            emotion = entry.get("emotion", "neutral")
            if emotion in ["sadness", "anger", "anxiety"]:
                entry_complexity += 0.4

            complexity_sum += entry_complexity

        return min(complexity_sum / len(recent_entries), 1.0)

    def _determine_base_mode(
        self, complexity_level: ComplexityLevel, complexity_score: float
    ) -> ProcessingMode:
        """ê¸°ë³¸ ì²˜ë¦¬ ëª¨ë“œ ê²°ì •"""

        # ê¸°ë³¸ ì„ê³„ê°’ ë§¤í•‘
        base_mode = self.mode_thresholds.get(
            complexity_level, ProcessingMode.ECHO_LIGHT
        )

        # ê²½ê³„ì„  ìƒí™©ì—ì„œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ê³ ë ¤
        if complexity_level == ComplexityLevel.MODERATE and complexity_score > 0.55:
            base_mode = ProcessingMode.HYBRID_LLM_ECHO
        elif complexity_level == ComplexityLevel.SIMPLE and complexity_score > 0.35:
            base_mode = ProcessingMode.ECHO_LIGHT

        return base_mode

    def _apply_user_preferences(
        self, base_mode: ProcessingMode, user_id: str, complexity_level: ComplexityLevel
    ) -> ProcessingMode:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì ìš©"""

        if user_id not in self.user_profiles:
            return base_mode

        profile = self.user_profiles[user_id]

        # ì‚¬ìš©ìì˜ ì„ í˜¸ ëª¨ë“œ ë¶„ì„
        preferred_modes = profile.preferred_modes
        if not preferred_modes:
            return base_mode

        # í˜„ì¬ ë³µì¡ë„ ìˆ˜ì¤€ì—ì„œ ì‚¬ìš©ìê°€ ì„ í˜¸í•˜ëŠ” ëª¨ë“œ
        complexity_key = complexity_level.value
        user_preference_score = preferred_modes.get(base_mode.value, 0)

        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆê³  ê°•í•œ ì„ í˜¸ë„ê°€ ìˆë‹¤ë©´ ì¡°ì •
        total_interactions = sum(preferred_modes.values())
        if (
            total_interactions >= 10
            and user_preference_score < total_interactions * 0.3
        ):
            # ì‚¬ìš©ìê°€ ì´ ëª¨ë“œë¥¼ ë³„ë¡œ ì„ í˜¸í•˜ì§€ ì•ŠìŒ
            alternative_modes = [
                ProcessingMode.HYBRID_LLM_ECHO,
                ProcessingMode.ECHO_LIGHT,
                ProcessingMode.LLM_ONLY,
            ]
            for alt_mode in alternative_modes:
                if preferred_modes.get(alt_mode.value, 0) > user_preference_score:
                    return alt_mode

        return base_mode

    def _consider_system_load(
        self, preferred_mode: ProcessingMode, complexity_level: ComplexityLevel
    ) -> ProcessingMode:
        """ì‹œìŠ¤í…œ ë¶€í•˜ ê³ ë ¤"""

        # í˜„ì¬ ì‹œìŠ¤í…œ ë¶€í•˜ í™•ì¸
        current_time = datetime.now()
        if (current_time - self.system_load["last_check"]).seconds > 60:
            self._update_system_load()

        # ê³ ë¶€í•˜ ìƒí™©ì—ì„œ ëª¨ë“œ ì¡°ì •
        if preferred_mode == ProcessingMode.ECHO_FULL:
            if self.system_load["echo_queue"] > 5:  # Echo íê°€ ê³¼ë¶€í•˜
                if complexity_level in [ComplexityLevel.CRITICAL]:
                    # ê¸´ê¸‰ìƒí™©ì€ ìœ ì§€
                    return preferred_mode
                else:
                    # í•˜ì´ë¸Œë¦¬ë“œë¡œ ì „í™˜
                    return ProcessingMode.HYBRID_LLM_ECHO

        elif preferred_mode in [
            ProcessingMode.HYBRID_LLM_ECHO,
            ProcessingMode.HYBRID_ECHO_LLM,
        ]:
            if self.system_load["hybrid_queue"] > 3:
                # í•˜ì´ë¸Œë¦¬ë“œ í ê³¼ë¶€í•˜ì‹œ ë‹¨ìˆœí™”
                return (
                    ProcessingMode.LLM_ONLY
                    if complexity_level
                    in [ComplexityLevel.TRIVIAL, ComplexityLevel.SIMPLE]
                    else ProcessingMode.ECHO_LIGHT
                )

        return preferred_mode

    def _estimate_processing_time(
        self, mode: ProcessingMode, complexity_score: float
    ) -> float:
        """ì²˜ë¦¬ ì‹œê°„ ì¶”ì •"""

        base_times = {
            ProcessingMode.LLM_ONLY: 0.5,
            ProcessingMode.ECHO_LIGHT: 1.2,
            ProcessingMode.ECHO_FULL: 3.5,
            ProcessingMode.HYBRID_LLM_ECHO: 2.0,
            ProcessingMode.HYBRID_ECHO_LLM: 2.8,
            ProcessingMode.ADAPTIVE: 2.0,
        }

        base_time = base_times.get(mode, 2.0)

        # ë³µì¡ë„ì— ë”°ë¥¸ ì‹œê°„ ì¡°ì •
        complexity_multiplier = 1.0 + (complexity_score * 0.5)

        return base_time * complexity_multiplier

    def _estimate_resource_requirements(self, mode: ProcessingMode) -> Dict[str, float]:
        """ìì› ìš”êµ¬ì‚¬í•­ ì¶”ì •"""

        requirements = {
            ProcessingMode.LLM_ONLY: {"cpu": 0.3, "memory": 0.2, "network": 0.5},
            ProcessingMode.ECHO_LIGHT: {"cpu": 0.5, "memory": 0.4, "network": 0.1},
            ProcessingMode.ECHO_FULL: {"cpu": 0.9, "memory": 0.8, "network": 0.1},
            ProcessingMode.HYBRID_LLM_ECHO: {"cpu": 0.6, "memory": 0.5, "network": 0.4},
            ProcessingMode.HYBRID_ECHO_LLM: {"cpu": 0.8, "memory": 0.7, "network": 0.3},
            ProcessingMode.ADAPTIVE: {"cpu": 0.6, "memory": 0.5, "network": 0.3},
        }

        return requirements.get(mode, {"cpu": 0.5, "memory": 0.5, "network": 0.3})

    def _determine_fallback_mode(self, primary_mode: ProcessingMode) -> ProcessingMode:
        """í´ë°± ëª¨ë“œ ê²°ì •"""

        fallback_map = {
            ProcessingMode.ECHO_FULL: ProcessingMode.ECHO_LIGHT,
            ProcessingMode.ECHO_LIGHT: ProcessingMode.LLM_ONLY,
            ProcessingMode.HYBRID_ECHO_LLM: ProcessingMode.ECHO_LIGHT,
            ProcessingMode.HYBRID_LLM_ECHO: ProcessingMode.LLM_ONLY,
            ProcessingMode.ADAPTIVE: ProcessingMode.LLM_ONLY,
            ProcessingMode.LLM_ONLY: ProcessingMode.LLM_ONLY,  # ì´ë¯¸ ìµœí•˜ìœ„
        }

        return fallback_map.get(primary_mode, ProcessingMode.LLM_ONLY)

    def _generate_reasoning(
        self,
        text: str,
        complexity_level: ComplexityLevel,
        base_mode: ProcessingMode,
        final_mode: ProcessingMode,
        context: Dict[str, Any],
    ) -> List[str]:
        """ì„ íƒ ì´ìœ  ìƒì„±"""

        reasoning = []

        # ë³µì¡ë„ ê¸°ë°˜ ì´ìœ 
        complexity_reasons = {
            ComplexityLevel.TRIVIAL: "ë§¤ìš° ê°„ë‹¨í•œ ì…ë ¥ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µì´ ì í•©",
            ComplexityLevel.SIMPLE: "ì¼ìƒì  ëŒ€í™”ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì²˜ë¦¬ ì„ íƒ",
            ComplexityLevel.MODERATE: "ì ë‹¹í•œ ë³µì¡ë„ë¡œ ê· í˜• ì¡íŒ ì²˜ë¦¬ í•„ìš”",
            ComplexityLevel.COMPLEX: "ë³µì¡í•œ ë‚´ìš©ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ë¶„ì„ í•„ìš”",
            ComplexityLevel.CRITICAL: "ê¸´ê¸‰í•˜ê±°ë‚˜ ì¤‘ìš”í•œ ìƒí™©ìœ¼ë¡œ ì™„ì „í•œ ì²˜ë¦¬ í•„ìš”",
        }
        reasoning.append(complexity_reasons.get(complexity_level, "ë³µì¡ë„ ë¶„ì„ ì™„ë£Œ"))

        # ëª¨ë“œ ë³€ê²½ ì´ìœ 
        if base_mode != final_mode:
            reasoning.append(
                f"ì‹œìŠ¤í…œ ìµœì í™”ë¥¼ ìœ„í•´ {base_mode.value}ì—ì„œ {final_mode.value}ë¡œ ì¡°ì •"
            )

        # ë§¥ë½ ê¸°ë°˜ ì´ìœ 
        if context:
            if context.get("urgency_level", 1) >= 4:
                reasoning.append("ë†’ì€ ê¸´ê¸‰ë„ ê°ì§€")
            if context.get("emotion_intensity", 0) > 0.7:
                reasoning.append("ê°•í•œ ê°ì • í‘œí˜„ìœ¼ë¡œ ì„¸ì‹¬í•œ ì²˜ë¦¬ í•„ìš”")

        # íŠ¹ë³„í•œ í‚¤ì›Œë“œ ê°ì§€
        if any(word in text.lower() for word in ["ë„ì›€", "ì¡°ì–¸", "ê²°ì •", "ê³ ë¯¼"]):
            reasoning.append("ë„ì›€ ìš”ì²­ ë˜ëŠ” ê²°ì • ì§€ì› í•„ìš”")

        return reasoning

    def _calculate_selection_confidence(
        self, complexity_score: float, mode: ProcessingMode, user_id: str = None
    ) -> float:
        """ì„ íƒ ì‹ ë¢°ë„ ê³„ì‚°"""

        confidence = 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„

        # ë³µì¡ë„ ëª…í™•ì„±ì— ë”°ë¥¸ ì‹ ë¢°ë„
        if complexity_score < 0.1 or complexity_score > 0.9:
            confidence += 0.2  # ë§¤ìš° ëª…í™•í•œ ê²½ìš°
        elif 0.4 <= complexity_score <= 0.6:
            confidence -= 0.1  # ì• ë§¤í•œ ê²½ìš°

        # ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì‹ ë¢°ë„
        if user_id and user_id in self.user_profiles:
            profile = self.user_profiles[user_id]
            total_interactions = sum(profile.preferred_modes.values())
            if total_interactions >= 20:
                confidence += 0.1  # ì¶©ë¶„í•œ ë°ì´í„°

        # ì‹œìŠ¤í…œ ë¶€í•˜ ìƒí™©ì—ì„œ ì‹ ë¢°ë„ ì¡°ì •
        if self.system_load["echo_queue"] > 5 and mode == ProcessingMode.ECHO_FULL:
            confidence -= 0.15  # ë¶€í•˜ë¡œ ì¸í•œ ë¶ˆí™•ì‹¤ì„±

        return min(confidence, 1.0)

    def record_processing_result(
        self,
        user_id: str,
        mode: ProcessingMode,
        complexity_level: ComplexityLevel,
        quality_score: float,
        processing_time: float,
    ):
        """ì²˜ë¦¬ ê²°ê³¼ ê¸°ë¡ ë° í•™ìŠµ"""

        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.performance_history.append(
            {
                "timestamp": datetime.now(),
                "mode": mode.value,
                "complexity": complexity_level.value,
                "quality_score": quality_score,
                "processing_time": processing_time,
                "user_id": user_id,
            }
        )

        # ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        if user_id:
            self._update_user_profile(user_id, mode, complexity_level, quality_score)

        # ì‹œìŠ¤í…œ ì„ê³„ê°’ ì ì‘í˜• ì¡°ì •
        self._adaptive_threshold_adjustment()

    def _update_user_profile(
        self,
        user_id: str,
        mode: ProcessingMode,
        complexity_level: ComplexityLevel,
        quality_score: float,
    ):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""

        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = UserProcessingProfile(
                user_id=user_id,
                preferred_modes=defaultdict(int),
                response_quality_scores=defaultdict(list),
                average_session_complexity=0.5,
                interaction_patterns={},
                last_updated=datetime.now(),
            )

        profile = self.user_profiles[user_id]

        # ëª¨ë“œ ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
        profile.preferred_modes[mode.value] += 1

        # í’ˆì§ˆ ì ìˆ˜ ê¸°ë¡
        profile.response_quality_scores[mode.value].append(quality_score)

        # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
        if len(profile.response_quality_scores[mode.value]) > 10:
            profile.response_quality_scores[mode.value] = (
                profile.response_quality_scores[mode.value][-10:]
            )

        profile.last_updated = datetime.now()

    def _adaptive_threshold_adjustment(self):
        """ì ì‘í˜• ì„ê³„ê°’ ì¡°ì •"""

        if len(self.performance_history) < 50:
            return

        # ìµœê·¼ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„
        recent_data = list(self.performance_history)[-50:]

        # ëª¨ë“œë³„ í‰ê·  í’ˆì§ˆ ì ìˆ˜
        mode_quality = defaultdict(list)
        for record in recent_data:
            mode_quality[record["mode"]].append(record["quality_score"])

        # í’ˆì§ˆì´ ë‚®ì€ ëª¨ë“œ ì‹ë³„ ë° ì¡°ì •
        for mode, scores in mode_quality.items():
            if len(scores) >= 5:
                avg_quality = np.mean(scores)
                if avg_quality < 0.6:  # í’ˆì§ˆì´ ë‚®ìœ¼ë©´
                    # í•´ë‹¹ ëª¨ë“œ ì‚¬ìš© ë¹ˆë„ ì¤„ì´ê¸° (ë³µì¡ë„ ì„ê³„ê°’ ì¡°ì •)
                    self._adjust_mode_threshold(ProcessingMode(mode), -0.05)
                elif avg_quality > 0.8:  # í’ˆì§ˆì´ ë†’ìœ¼ë©´
                    # í•´ë‹¹ ëª¨ë“œ ì‚¬ìš© ë¹ˆë„ ëŠ˜ë¦¬ê¸°
                    self._adjust_mode_threshold(ProcessingMode(mode), 0.03)

    def _adjust_mode_threshold(self, mode: ProcessingMode, adjustment: float):
        """ëª¨ë“œ ì„ê³„ê°’ ì¡°ì •"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë³µì¡ë„-ëª¨ë“œ ë§¤í•‘ì„ ë™ì ìœ¼ë¡œ ì¡°ì •
        # ì—¬ê¸°ì„œëŠ” ê°œë…ì  êµ¬í˜„ë§Œ í‘œì‹œ
        pass

    def _update_system_load(self):
        """ì‹œìŠ¤í…œ ë¶€í•˜ ì—…ë°ì´íŠ¸ (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œê³¼ ì—°ë™)"""
        import random

        # ì‹¤ì œë¡œëŠ” ì‹¤ì œ í ìƒíƒœë¥¼ í™•ì¸
        self.system_load.update(
            {
                "llm_queue": random.randint(0, 3),
                "echo_queue": random.randint(0, 7),
                "hybrid_queue": random.randint(0, 4),
                "last_check": datetime.now(),
            }
        )

    def _initialize_complexity_weights(self) -> Dict[str, float]:
        """ë³µì¡ë„ ë¶„ì„ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        return {
            "length": 0.1,
            "word_count": 0.1,
            "sentence_count": 0.1,
            "question_density": 0.2,
            "emotional_density": 0.3,
            "abstract_density": 0.2,
            "decision_density": 0.4,
            "urgency": 0.5,
            "punctuation_variety": 0.05,
        }

    def get_system_statistics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""

        if not self.performance_history:
            return {"message": "ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}

        recent_data = list(self.performance_history)[-100:]

        # ëª¨ë“œë³„ í†µê³„
        mode_stats = defaultdict(lambda: {"count": 0, "avg_quality": 0, "avg_time": 0})

        for record in recent_data:
            mode = record["mode"]
            mode_stats[mode]["count"] += 1
            mode_stats[mode]["avg_quality"] += record["quality_score"]
            mode_stats[mode]["avg_time"] += record["processing_time"]

        # í‰ê·  ê³„ì‚°
        for mode, stats in mode_stats.items():
            if stats["count"] > 0:
                stats["avg_quality"] /= stats["count"]
                stats["avg_time"] /= stats["count"]

        return {
            "total_selections": len(recent_data),
            "mode_distribution": {
                mode: stats["count"] for mode, stats in mode_stats.items()
            },
            "quality_by_mode": {
                mode: round(stats["avg_quality"], 3)
                for mode, stats in mode_stats.items()
            },
            "processing_time_by_mode": {
                mode: round(stats["avg_time"], 3) for mode, stats in mode_stats.items()
            },
            "active_users": len(self.user_profiles),
            "system_load": self.system_load,
        }


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    selector = EchoSelector()

    test_cases = [
        {
            "text": "ì•ˆë…•í•˜ì„¸ìš”",
            "context": {"emotion_intensity": 0.2, "urgency_level": 1},
            "description": "ê°„ë‹¨í•œ ì¸ì‚¬",
        },
        {
            "text": "ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ì„œ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”. ë§¤ì¼ ìš°ìš¸í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.",
            "context": {
                "emotion_intensity": 0.8,
                "urgency_level": 3,
                "intent_type": "emotional_support",
            },
            "description": "ê°ì •ì  ì§€ì› ìš”ì²­",
        },
        {
            "text": "ì¸ìƒì˜ ì˜ë¯¸ê°€ ë­˜ê¹Œìš”? ì™œ ìš°ë¦¬ëŠ” ì‚´ì•„ê°€ëŠ” ê±´ê°€ìš”?",
            "context": {
                "emotion_intensity": 0.5,
                "urgency_level": 2,
                "intent_type": "philosophical_inquiry",
            },
            "description": "ì² í•™ì  ì§ˆë¬¸",
        },
        {
            "text": "ê¸‰í•´!! ì§€ê¸ˆ ë‹¹ì¥ ì¤‘ìš”í•œ ê²°ì •ì„ í•´ì•¼ í•˜ëŠ”ë° ë„ì™€ì£¼ì„¸ìš”!",
            "context": {
                "emotion_intensity": 0.9,
                "urgency_level": 5,
                "intent_type": "decision_help",
            },
            "description": "ê¸´ê¸‰ ìƒí™©",
        },
    ]

    print("ğŸ›ï¸ Echo Selector í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    for i, case in enumerate(test_cases):
        print(f"\n--- í…ŒìŠ¤íŠ¸ {i+1}: {case['description']} ---")
        print(f"ì…ë ¥: {case['text'][:50]}{'...' if len(case['text']) > 50 else ''}")

        result = selector.select_processing_mode(
            case["text"], case["context"], f"user_{i%2}"  # 2ëª…ì˜ ê°€ìƒ ì‚¬ìš©ì
        )

        print(f"ì„ íƒëœ ëª¨ë“œ: {result.processing_mode.value}")
        print(f"ë³µì¡ë„: {result.complexity_level.value}")
        print(f"ì‹ ë¢°ë„: {result.confidence:.2f}")
        print(f"ì˜ˆìƒ ì²˜ë¦¬ì‹œê°„: {result.estimated_processing_time:.1f}ì´ˆ")
        print(f"í´ë°± ëª¨ë“œ: {result.fallback_mode.value}")

        if result.reasoning:
            print("ì„ íƒ ì´ìœ :")
            for reason in result.reasoning:
                print(f"  â€¢ {reason}")

        # ê°€ìƒì˜ ê²°ê³¼ ê¸°ë¡ (ì‹¤ì œë¡œëŠ” ì²˜ë¦¬ ì™„ë£Œ í›„)
        quality_score = 0.7 + (i * 0.1)  # í…ŒìŠ¤íŠ¸ìš© ì ìˆ˜
        selector.record_processing_result(
            f"user_{i%2}",
            result.processing_mode,
            result.complexity_level,
            quality_score,
            result.estimated_processing_time,
        )

        print("-" * 40)

    # ì‹œìŠ¤í…œ í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ í†µê³„:")
    stats = selector.get_system_statistics()
    print(f"ì´ ì„ íƒ íšŸìˆ˜: {stats['total_selections']}")
    print("ëª¨ë“œë³„ ë¶„í¬:", stats["mode_distribution"])
    print("ëª¨ë“œë³„ í’ˆì§ˆ:", stats["quality_by_mode"])

    print("\nğŸ‰ Echo Selector í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
