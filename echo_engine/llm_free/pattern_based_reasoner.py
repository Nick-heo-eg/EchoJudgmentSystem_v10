"""
íŒ¨í„´ ê¸°ë°˜ ì¶”ë¡ ê¸°
ë‹¨ìˆœí•œ í‚¤ì›Œë“œ/íŒ¨í„´ ë§¤ì¹­ì„ í†µí•œ ì¶”ë¡  ì‹œìŠ¤í…œ
"""

import re
from typing import Dict, Any, List, Tuple, Optional
from collections import defaultdict, Counter


class PatternBasedReasoner:
    """
    íŒ¨í„´ ê¸°ë°˜ ì¶”ë¡ ê¸°
    í‚¤ì›Œë“œ ë§¤ì¹­, íŒ¨í„´ ì¸ì‹, ë¬¸ë§¥ ë¶„ì„ì„ í†µí•œ ì¶”ë¡ 
    """

    def __init__(self, ruleset: Dict[str, Any]):
        """
        ì¶”ë¡ ê¸° ì´ˆê¸°í™”

        Args:
            ruleset: ê·œì¹™ ì„¸íŠ¸ (ê°ì •, ì „ëµ, ë¬¸ë§¥ íŒ¨í„´)
        """
        self.ruleset = ruleset
        self.emotion_patterns = ruleset.get("emotion_patterns", {})
        self.strategy_patterns = ruleset.get("strategy_patterns", {})
        self.context_patterns = ruleset.get("context_patterns", {})

        # ì¶”ë¡  ê°€ì¤‘ì¹˜ ì„¤ì •
        self.weights = {"emotion": 0.4, "strategy": 0.3, "context": 0.3}

    def reason(self, text: str, context: str = "") -> Dict[str, Any]:
        """
        ë©”ì¸ ì¶”ë¡  í•¨ìˆ˜

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë¬¸ë§¥ ì •ë³´

        Returns:
            ì¶”ë¡  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        processed_text = self._preprocess_text(text)
        processed_context = self._preprocess_text(context)

        # ê° ì°¨ì›ë³„ ë¶„ì„
        emotion_analysis = self._analyze_emotion(processed_text)
        strategy_analysis = self._analyze_strategy(processed_text)
        context_analysis = self._analyze_context(processed_text, processed_context)

        # í‚¤ì›Œë“œ ë¶„ì„
        keywords = self._extract_keywords(processed_text)

        # íŒ¨í„´ ë§¤ì¹­
        matched_patterns = self._match_patterns(processed_text)

        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        scores = self._calculate_scores(
            emotion_analysis, strategy_analysis, context_analysis
        )

        # ìµœì¢… ì¶”ë¡  ê²°ê³¼ ìƒì„±
        reasoning_result = {
            "input_analysis": f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì, í‚¤ì›Œë“œ ìˆ˜: {len(keywords)}ê°œ",
            "emotion": emotion_analysis["top_emotion"],
            "emotion_score": emotion_analysis["score"],
            "strategy": strategy_analysis["top_strategy"],
            "strategy_score": strategy_analysis["score"],
            "context": context_analysis["top_context"],
            "context_score": context_analysis["score"],
            "keywords": keywords,
            "matched_patterns": matched_patterns,
            "pattern_score": scores["pattern_score"],
            "keyword_score": scores["keyword_score"],
            "overall_score": scores["overall_score"],
        }

        return reasoning_result

    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if not text:
            return ""

        # ê¸°ë³¸ ì •ë¦¬
        text = text.strip().lower()

        # íŠ¹ìˆ˜ ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€)
        text = re.sub(r"[^\w\sê°€-í£]", " ", text)

        # ì¤‘ë³µ ê³µë°± ì œê±°
        text = re.sub(r"\s+", " ", text).strip()

        return text

    def _analyze_emotion(self, text: str) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„"""
        emotion_scores = defaultdict(float)

        for emotion, keywords in self.emotion_patterns.items():
            for keyword in keywords:
                if keyword in text:
                    # í‚¤ì›Œë“œ ì¶œí˜„ íšŸìˆ˜ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
                    count = text.count(keyword)
                    emotion_scores[emotion] += count * 1.0

        # ìµœê³  ì ìˆ˜ ê°ì • ì„ íƒ
        if emotion_scores:
            top_emotion = max(emotion_scores, key=emotion_scores.get)
            max_score = emotion_scores[top_emotion]

            # ì •ê·œí™” (0.0 ~ 1.0)
            normalized_score = min(max_score / 3.0, 1.0)
        else:
            top_emotion = "neutral"
            normalized_score = 0.5

        return {
            "top_emotion": top_emotion,
            "score": normalized_score,
            "all_scores": dict(emotion_scores),
        }

    def _analyze_strategy(self, text: str) -> Dict[str, Any]:
        """ì „ëµ ë¶„ì„"""
        strategy_scores = defaultdict(float)

        for strategy, keywords in self.strategy_patterns.items():
            for keyword in keywords:
                if keyword in text:
                    count = text.count(keyword)
                    strategy_scores[strategy] += count * 1.0

        # ìµœê³  ì ìˆ˜ ì „ëµ ì„ íƒ
        if strategy_scores:
            top_strategy = max(strategy_scores, key=strategy_scores.get)
            max_score = strategy_scores[top_strategy]
            normalized_score = min(max_score / 2.0, 1.0)
        else:
            top_strategy = "balanced"
            normalized_score = 0.5

        return {
            "top_strategy": top_strategy,
            "score": normalized_score,
            "all_scores": dict(strategy_scores),
        }

    def _analyze_context(self, text: str, context: str) -> Dict[str, Any]:
        """ë¬¸ë§¥ ë¶„ì„"""
        context_scores = defaultdict(float)
        combined_text = f"{text} {context}".strip()

        for ctx_type, keywords in self.context_patterns.items():
            for keyword in keywords:
                if keyword in combined_text:
                    count = combined_text.count(keyword)
                    context_scores[ctx_type] += count * 1.0

        # ìµœê³  ì ìˆ˜ ë¬¸ë§¥ ì„ íƒ
        if context_scores:
            top_context = max(context_scores, key=context_scores.get)
            max_score = context_scores[top_context]
            normalized_score = min(max_score / 2.0, 1.0)
        else:
            top_context = "general"
            normalized_score = 0.3

        return {
            "top_context": top_context,
            "score": normalized_score,
            "all_scores": dict(context_scores),
        }

    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return []

        # ë‹¨ì–´ ë¶„ë¦¬
        words = text.split()

        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {
            "ì€",
            "ëŠ”",
            "ì´",
            "ê°€",
            "ì„",
            "ë¥¼",
            "ì˜",
            "ì—",
            "ì—ì„œ",
            "ìœ¼ë¡œ",
            "ì™€",
            "ê³¼",
            "ê·¸ë¦¬ê³ ",
            "í•˜ì§€ë§Œ",
            "ê·¸ëŸ°ë°",
        }
        keywords = [word for word in words if word not in stop_words and len(word) > 1]

        # ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ ê¸°ì¤€ ì •ë ¬
        keyword_counts = Counter(keywords)

        # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ë°˜í™˜
        return [word for word, count in keyword_counts.most_common(10)]

    def _match_patterns(self, text: str) -> List[str]:
        """íŒ¨í„´ ë§¤ì¹­"""
        matched_patterns = []

        # ì§ˆë¬¸ íŒ¨í„´
        if "?" in text or any(
            word in text for word in ["ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "ì–¸ì œ", "ì–´ë””ì„œ"]
        ):
            matched_patterns.append("question_pattern")

        # ê°ì • í‘œí˜„ íŒ¨í„´
        if any(word in text for word in ["ë„ˆë¬´", "ì •ë§", "ì•„ì£¼", "ì—„ì²­", "ì™„ì „"]):
            matched_patterns.append("emotion_intensifier")

        # ë¶€ì • í‘œí˜„ íŒ¨í„´
        if any(word in text for word in ["ì•ˆ", "ëª»", "ì•„ë‹ˆ", "ì—†", "ë§ê³ "]):
            matched_patterns.append("negative_expression")

        # ê¸ì • í‘œí˜„ íŒ¨í„´
        if any(word in text for word in ["ì¢‹", "ì˜", "ì„±ê³µ", "ì™„ì„±", "í•´ëƒˆ"]):
            matched_patterns.append("positive_expression")

        # ìš”ì²­ íŒ¨í„´
        if any(word in text for word in ["ë„ì™€ì£¼", "ë¶€íƒ", "ì¡°ì–¸", "ì¶”ì²œ", "ì œì•ˆ"]):
            matched_patterns.append("request_pattern")

        # ê³ ë¯¼ íŒ¨í„´
        if any(word in text for word in ["ê³ ë¯¼", "ê±±ì •", "ë¶ˆì•ˆ", "ì–´ë ¤ì›€", "í˜ë“¤"]):
            matched_patterns.append("concern_pattern")

        return matched_patterns

    def _calculate_scores(
        self, emotion_analysis: Dict, strategy_analysis: Dict, context_analysis: Dict
    ) -> Dict[str, float]:
        """ì ìˆ˜ ê³„ì‚°"""
        # íŒ¨í„´ ì ìˆ˜ (ê° ë¶„ì„ì˜ ì ìˆ˜ í‰ê· )
        pattern_score = (
            emotion_analysis["score"] * self.weights["emotion"]
            + strategy_analysis["score"] * self.weights["strategy"]
            + context_analysis["score"] * self.weights["context"]
        )

        # í‚¤ì›Œë“œ ì ìˆ˜ (ê°ì • + ì „ëµ í‚¤ì›Œë“œ ë§¤ì¹­ë„)
        keyword_score = (emotion_analysis["score"] + strategy_analysis["score"]) / 2.0

        # ì „ì²´ ì ìˆ˜
        overall_score = (pattern_score + keyword_score) / 2.0

        return {
            "pattern_score": round(pattern_score, 3),
            "keyword_score": round(keyword_score, 3),
            "overall_score": round(overall_score, 3),
        }

    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„ (ë‹¨ìˆœ ë²„ì „)"""
        emotion_analysis = self._analyze_emotion(self._preprocess_text(text))
        return {
            "sentiment": emotion_analysis["top_emotion"],
            "confidence": emotion_analysis["score"],
            "details": emotion_analysis["all_scores"],
        }

    def suggest_strategy(self, text: str) -> Dict[str, Any]:
        """ì „ëµ ì œì•ˆ"""
        strategy_analysis = self._analyze_strategy(self._preprocess_text(text))
        return {
            "strategy": strategy_analysis["top_strategy"],
            "confidence": strategy_analysis["score"],
            "details": strategy_analysis["all_scores"],
        }

    def detect_context(self, text: str, context: str = "") -> Dict[str, Any]:
        """ë¬¸ë§¥ ê°ì§€"""
        context_analysis = self._analyze_context(
            self._preprocess_text(text), self._preprocess_text(context)
        )
        return {
            "context": context_analysis["top_context"],
            "confidence": context_analysis["score"],
            "details": context_analysis["all_scores"],
        }


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_emotion_analysis(text: str) -> str:
    """ë¹ ë¥¸ ê°ì • ë¶„ì„"""
    # ê¸°ë³¸ ê·œì¹™ ì„¸íŠ¸
    basic_ruleset = {
        "emotion_patterns": {
            "joy": ["ê¸°ì˜", "í–‰ë³µ", "ì¢‹", "ìµœê³ ", "ì„±ê³µ"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ", "ì‹¤ë§"],
            "anger": ["í™”", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "ì–µìš¸"],
            "fear": ["ë¬´ì„œ", "ê±±ì •", "ë¶ˆì•ˆ", "ë‘ë ¤", "ê¸´ì¥"],
            "surprise": ["ë†€ë¼", "ì™€ìš°", "í—", "ëŒ€ë°•", "ê¹œì§"],
        },
        "strategy_patterns": {},
        "context_patterns": {},
    }

    reasoner = PatternBasedReasoner(basic_ruleset)
    result = reasoner.analyze_sentiment(text)
    return result["sentiment"]


def quick_strategy_suggestion(text: str) -> str:
    """ë¹ ë¥¸ ì „ëµ ì œì•ˆ"""
    basic_ruleset = {
        "emotion_patterns": {},
        "strategy_patterns": {
            "logical": ["ë¶„ì„", "ë…¼ë¦¬", "ì´ì„±", "í•©ë¦¬", "ë°ì´í„°"],
            "empathetic": ["ê°ì •", "ê³µê°", "ì´í•´", "ë§ˆìŒ", "ëŠë‚Œ"],
            "creative": ["ì°½ì˜", "ìƒˆë¡œìš´", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ë…ì°½ì "],
            "cautious": ["ì‹ ì¤‘", "ì¡°ì‹¬", "ì•ˆì „", "í™•ì‹¤", "ê²€í† "],
        },
        "context_patterns": {},
    }

    reasoner = PatternBasedReasoner(basic_ruleset)
    result = reasoner.suggest_strategy(text)
    return result["strategy"]


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ” íŒ¨í„´ ê¸°ë°˜ ì¶”ë¡ ê¸° í…ŒìŠ¤íŠ¸")

    # í…ŒìŠ¤íŠ¸ ê·œì¹™ ì„¸íŠ¸
    test_ruleset = {
        "emotion_patterns": {
            "joy": ["ê¸°ì˜", "í–‰ë³µ", "ì¢‹", "ìµœê³ ", "ì„±ê³µ", "ì¶•í•˜"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ", "ì‹¤ë§", "í¬ê¸°"],
            "anger": ["í™”", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "ì–µìš¸", "ë¶ˆë§Œ"],
            "fear": ["ë¬´ì„œ", "ê±±ì •", "ë¶ˆì•ˆ", "ë‘ë ¤", "ê¸´ì¥", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "surprise": ["ë†€ë¼", "ì™€ìš°", "í—", "ëŒ€ë°•", "ê¹œì§", "ì–´ë¨¸"],
        },
        "strategy_patterns": {
            "logical": ["ë¶„ì„", "ë…¼ë¦¬", "ì´ì„±", "í•©ë¦¬", "ë°ì´í„°", "ê°ê´€ì "],
            "empathetic": ["ê°ì •", "ê³µê°", "ì´í•´", "ë§ˆìŒ", "ëŠë‚Œ", "ë”°ëœ»"],
            "creative": ["ì°½ì˜", "ìƒˆë¡œìš´", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ë…ì°½ì ", "ì°¸ì‹ "],
            "cautious": ["ì‹ ì¤‘", "ì¡°ì‹¬", "ì•ˆì „", "í™•ì‹¤", "ê²€í† ", "ë³´ìˆ˜ì "],
        },
        "context_patterns": {
            "work": ["íšŒì˜", "ì—…ë¬´", "ì§ì¥", "ë™ë£Œ", "ìƒì‚¬", "í”„ë¡œì íŠ¸"],
            "personal": ["ì¹œêµ¬", "ê°€ì¡±", "ì—°ì¸", "ê°œì¸", "ì·¨ë¯¸", "ì—¬í–‰"],
            "academic": ["ê³µë¶€", "í•™êµ", "ì‹œí—˜", "ê³¼ì œ", "êµìˆ˜", "í•™ìŠµ"],
            "social": ["ëª¨ì„", "íŒŒí‹°", "ì‚¬ëŒë“¤", "ê´€ê³„", "ì†Œí†µ", "ë„¤íŠ¸ì›Œí‚¹"],
        },
    }

    reasoner = PatternBasedReasoner(test_ruleset)

    test_cases = [
        "ì˜¤ëŠ˜ ìŠ¹ì§„ ì†Œì‹ì„ ë“¤ì—ˆì–´ìš”! ì •ë§ ê¸°ë»ìš”!",
        "íšŒì˜ì—ì„œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.",
        "ì¹œêµ¬ì™€ ê°ˆë“±ì´ ìˆì–´ì„œ ë§ˆìŒì´ ì•„íŒŒìš”.",
        "ìƒˆë¡œìš´ ì°½ì˜ì  ì•„ì´ë””ì–´ê°€ ìƒê°ë‚¬ì–´ìš”!",
        "ì‹œí—˜ì´ ë‹¤ê°€ì™€ì„œ ë„ˆë¬´ ê±±ì •ë˜ê³  ë¶ˆì•ˆí•´ìš”.",
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\n=== í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i} ===")
        print(f"ì…ë ¥: {test_case}")

        result = reasoner.reason(test_case)

        print(f"ê°ì •: {result['emotion']} (ì‹ ë¢°ë„: {result['emotion_score']:.3f})")
        print(f"ì „ëµ: {result['strategy']} (ì‹ ë¢°ë„: {result['strategy_score']:.3f})")
        print(f"ë¬¸ë§¥: {result['context']} (ì‹ ë¢°ë„: {result['context_score']:.3f})")
        print(f"í‚¤ì›Œë“œ: {', '.join(result['keywords'])}")
        print(f"íŒ¨í„´: {', '.join(result['matched_patterns'])}")
        print(f"ì „ì²´ ì ìˆ˜: {result['overall_score']:.3f}")

    # ê°œë³„ ë¶„ì„ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ” ê°œë³„ ë¶„ì„ í…ŒìŠ¤íŠ¸:")
    test_text = "ì •ë§ ê¸°ì˜ì§€ë§Œ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ì ‘ê·¼í•´ì•¼ê² ì–´ìš”"

    emotion = reasoner.analyze_sentiment(test_text)
    strategy = reasoner.suggest_strategy(test_text)
    context = reasoner.detect_context(test_text)

    print(f"ê°ì • ë¶„ì„: {emotion}")
    print(f"ì „ëµ ì œì•ˆ: {strategy}")
    print(f"ë¬¸ë§¥ ê°ì§€: {context}")
