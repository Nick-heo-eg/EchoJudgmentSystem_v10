#!/usr/bin/env python3
"""
ğŸ§  EchoJudgmentSystem v10.5 - Persona Core
ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì¸ìŠ¤í„´ìŠ¤ ì‹œìŠ¤í…œ

í˜ë¥´ì†Œë‚˜ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ ìƒíƒœ ì„¤ì • ë° ë¡œë”©
- ê°ì • ê°ë„, íŒë‹¨ ì„±í–¥, í‘œí˜„ ìŠ¤íƒ€ì¼ ê´€ë¦¬
- ë©”íƒ€ì¸ì§€ ì—°ë™ ë° í•™ìŠµ ëŠ¥ë ¥
- íŒë‹¨ ì»¨í…ìŠ¤íŠ¸ë³„ ì ì‘ì  í–‰ë™
"""

import json
import time
import os
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque

# ë©”íƒ€ ë¡œê·¸ í†µí•©
try:
    from .persona_meta_logger import (
        PersonaMetaLog,
        log_persona_meta,
        get_persona_meta_logger,
    )

    META_LOG_AVAILABLE = True
except ImportError:
    META_LOG_AVAILABLE = False

# í†µí•© ì„¤ì • ì‹œìŠ¤í…œ
try:
    import sys

    # sys.path ìˆ˜ì • ë¶ˆí•„ìš” (portable_paths ì‚¬ìš©)
    from config_loader import get_config, get_config_loader

    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False


class IntentType(Enum):
    """ì‚¬ìš©ì ì˜ë„ ìœ í˜•"""

    ACHIEVEMENT_SEEKING = "achievement_seeking"  # ì„±ì·¨ ì¶”êµ¬
    AVOIDANCE_MOTIVE = "avoidance_motive"  # íšŒí”¼ ë™ê¸°
    SOCIAL_CONNECTION = "social_connection"  # ì‚¬íšŒì  ì—°ê²°
    PROBLEM_SOLVING = "problem_solving"  # ë¬¸ì œ í•´ê²°
    EMOTIONAL_SUPPORT = "emotional_support"  # ê°ì •ì  ì§€ì§€
    INFORMATION_SEEKING = "information_seeking"  # ì •ë³´ íƒìƒ‰
    CREATIVE_EXPRESSION = "creative_expression"  # ì°½ì˜ì  í‘œí˜„
    RELATIONSHIP_BUILDING = "relationship_building"  # ê´€ê³„ êµ¬ì¶•
    SELF_REFLECTION = "self_reflection"  # ìê¸° ì„±ì°°
    DECISION_MAKING = "decision_making"  # ì˜ì‚¬ê²°ì •


class PersonaState(Enum):
    """í˜ë¥´ì†Œë‚˜ ìƒíƒœ"""

    INACTIVE = "inactive"
    ACTIVE = "active"
    LEARNING = "learning"
    ADAPTING = "adapting"
    REFLECTION = "reflection"


class EmotionIntensity(Enum):
    """ê°ì • ê°•ë„"""

    MINIMAL = "minimal"  # 0.0 - 0.2
    LOW = "low"  # 0.2 - 0.4
    MODERATE = "moderate"  # 0.4 - 0.6
    HIGH = "high"  # 0.6 - 0.8
    INTENSE = "intense"  # 0.8 - 1.0


@dataclass
class PersonaMemory:
    """í˜ë¥´ì†Œë‚˜ ê¸°ì–µ êµ¬ì¡°"""

    recent_interactions: deque = field(default_factory=lambda: deque(maxlen=20))
    emotional_patterns: Dict[str, List[float]] = field(default_factory=dict)
    successful_strategies: Dict[str, int] = field(default_factory=dict)
    learning_insights: List[str] = field(default_factory=list)
    adaptation_history: List[Dict[str, Any]] = field(default_factory=list)

    def add_interaction(self, interaction: Dict[str, Any]):
        """ìƒí˜¸ì‘ìš© ê¸°ë¡ ì¶”ê°€"""
        interaction["timestamp"] = datetime.now().isoformat()
        self.recent_interactions.append(interaction)

    def track_emotional_pattern(self, emotion: str, intensity: float):
        """ê°ì • íŒ¨í„´ ì¶”ì """
        if emotion not in self.emotional_patterns:
            self.emotional_patterns[emotion] = []
        self.emotional_patterns[emotion].append(intensity)

        # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
        if len(self.emotional_patterns[emotion]) > 10:
            self.emotional_patterns[emotion] = self.emotional_patterns[emotion][-10:]

    def update_strategy_success(self, strategy: str, success: bool):
        """ì „ëµ ì„±ê³µë¥  ì—…ë°ì´íŠ¸"""
        if strategy not in self.successful_strategies:
            self.successful_strategies[strategy] = 0

        if success:
            self.successful_strategies[strategy] += 1
        else:
            self.successful_strategies[strategy] = max(
                0, self.successful_strategies[strategy] - 1
            )

    def add_strategy_feedback(self, strategy: str, effectiveness_score: float):
        """ì „ëµ íš¨ê³¼ì„± í”¼ë“œë°± ì¶”ê°€"""
        feedback_key = f"{strategy}_feedback"
        if feedback_key not in self.emotional_patterns:
            self.emotional_patterns[feedback_key] = []

        self.emotional_patterns[feedback_key].append(effectiveness_score)

        # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
        if len(self.emotional_patterns[feedback_key]) > 10:
            self.emotional_patterns[feedback_key] = self.emotional_patterns[
                feedback_key
            ][-10:]

    def get_strategy_effectiveness(self, strategy: str) -> float:
        """ì „ëµ íš¨ê³¼ì„± í‰ê·  ì¡°íšŒ"""
        feedback_key = f"{strategy}_feedback"
        if (
            feedback_key in self.emotional_patterns
            and self.emotional_patterns[feedback_key]
        ):
            return sum(self.emotional_patterns[feedback_key]) / len(
                self.emotional_patterns[feedback_key]
            )
        return 0.5  # ê¸°ë³¸ê°’


@dataclass
class PersonaProfile:
    """í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„"""

    name: str
    signature_type: str  # Echo-Aurora, Echo-Phoenix, etc.

    # ê¸°ë³¸ ì„±í–¥
    emotion_sensitivity: float = 0.5
    reasoning_depth: int = 3
    response_tone: str = "balanced"
    decision_style: str = "analytical"

    # ì ì‘ì„± ì„¤ì •
    adaptability: float = 0.7
    learning_rate: float = 0.3
    memory_retention: float = 0.8

    # í–‰ë™ íŠ¹ì„±
    primary_strategies: List[str] = field(default_factory=list)
    emotional_triggers: Dict[str, float] = field(default_factory=dict)
    communication_patterns: Dict[str, Any] = field(default_factory=dict)

    # ë©”íƒ€ì¸ì§€ íŠ¹ì„±
    self_reflection_frequency: float = 0.5
    meta_awareness_level: float = 0.6
    growth_orientation: float = 0.8


class PersonaCore:
    """í˜ë¥´ì†Œë‚˜ ì½”ì–´ ì—”ì§„"""

    def __init__(self, profile: PersonaProfile):
        """
        í˜ë¥´ì†Œë‚˜ ì½”ì–´ ì´ˆê¸°í™”

        Args:
            profile: í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„
        """
        self.profile = profile
        self.state = PersonaState.INACTIVE
        self.memory = PersonaMemory()

        # í˜„ì¬ ìƒíƒœ
        self.current_emotion = "neutral"
        self.current_emotion_intensity = 0.5
        self.current_strategy = "balanced"
        self.energy_level = 1.0

        # ì„±ëŠ¥ ì§€í‘œ
        self.interaction_count = 0
        self.success_rate = 0.0
        self.adaptation_cycles = 0

        # ë©”íƒ€ì¸ì§€ ìƒíƒœ
        self.last_reflection = datetime.now()
        self.insights_generated = 0
        self.learning_momentum = 0.5

        # ì‘ë‹µ ìƒì„± ì‹œìŠ¤í…œ
        self.response_generators = self._initialize_response_generators()

        # ë©”íƒ€ ë¡œê±° ì„¸ì…˜ ID
        if META_LOG_AVAILABLE:
            self.meta_logger = get_persona_meta_logger()
            self.session_id = self.meta_logger.current_session_id
        else:
            self.session_id = f"session_{int(time.time())}"

        # ì‹œê·¸ë‹ˆì²˜ ì—°ë™
        self._load_signature_config()

        print(
            f"ğŸ§  í˜ë¥´ì†Œë‚˜ '{self.profile.name}' ì´ˆê¸°í™” ì™„ë£Œ (íƒ€ì…: {self.profile.signature_type})"
        )

    def _initialize_response_generators(self) -> Dict[str, Dict[str, str]]:
        """ì‘ë‹µ ìƒì„±ê¸° ì´ˆê¸°í™”"""
        return {
            "empathetic": {
                "gentle": "ì´í•´í•  ìˆ˜ ìˆì–´ìš”. ì²œì²œíˆ í•¨ê»˜ ìƒê°í•´ë´ìš”.",
                "warm": "ë”°ëœ»í•œ ë§ˆìŒìœ¼ë¡œ ë“¤ì–´ë“œë¦´ê²Œìš”.",
                "compassionate": "ë§ˆìŒì´ ì•„í”„ì‹œê² ì–´ìš”. ì œê°€ ì˜†ì— ìˆì–´ë“œë¦´ê²Œìš”.",
                "encouraging": "í˜ë“  ì‹œê°„ì´ì§€ë§Œ ì¶©ë¶„íˆ ê·¹ë³µí•˜ì‹¤ ìˆ˜ ìˆì–´ìš”.",
            },
            "analytical": {
                "objective": "ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.",
                "logical": "ë…¼ë¦¬ì ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.",
                "systematic": "ë‹¨ê³„ë³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.",
                "measured": "ì‹ ì¤‘í•˜ê²Œ ê²€í† í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
            },
            "supportive": {
                "encouraging": "ë‹¹ì‹ ì˜ ëŠ¥ë ¥ì„ ë¯¿ì–´ìš”. í•  ìˆ˜ ìˆì–´ìš”!",
                "reassuring": "ê´œì°®ì•„ìš”, ì œê°€ ë„ì™€ë“œë¦´ê²Œìš”.",
                "motivating": "ì´ë¯¸ í›Œë¥­í•œ ì²«ê±¸ìŒì„ ë‚´ë””ë ë„¤ìš”.",
                "inspiring": "ë‹¹ì‹ ì˜ ì—´ì •ì´ ê¸¸ì„ ë§Œë“¤ì–´ê°ˆ ê±°ì˜ˆìš”.",
            },
            "creative": {
                "inspiring": "ìƒˆë¡œìš´ ê´€ì ì—ì„œ ë°”ë¼ë³´ë©´ ì–´ë–¨ê¹Œìš”?",
                "innovative": "í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ê°€ ë– ì˜¤ë¥´ë„¤ìš”.",
                "imaginative": "ìƒìƒë ¥ì„ ë°œíœ˜í•´ë³´ë©´ ë” ì¢‹ì€ ë°©ë²•ì´ ìˆì„ ê²ƒ ê°™ì•„ìš”.",
                "exploratory": "í•¨ê»˜ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•´ë´ìš”.",
            },
            "cautious": {
                "measured": "ì‹ ì¤‘í•˜ê²Œ ê²€í† í•´ë³´ëŠ” ê²ƒì´ ì¢‹ê² ì–´ìš”.",
                "careful": "ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ í˜„ëª…í•©ë‹ˆë‹¤.",
                "prudent": "ëª¨ë“  ì¸¡ë©´ì„ ê³ ë ¤í•´ë³´ê² ìŠµë‹ˆë‹¤.",
                "thoughtful": "ê¹Šì´ ìƒê°í•´ë³¼ í•„ìš”ê°€ ìˆê² ë„¤ìš”.",
            },
            "balanced": {
                "neutral": "ê· í˜•ì¡íŒ ê´€ì ì—ì„œ ë§ì”€ë“œë¦¬ë©´,",
                "moderate": "ì ì ˆí•œ ì ‘ê·¼ ë°©ë²•ì„ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.",
                "harmonious": "ì¡°í™”ë¡œìš´ í•´ê²°ì±…ì„ ëª¨ìƒ‰í•´ë´ìš”.",
                "steady": "ì•ˆì •ì ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ê² ì–´ìš”.",
            },
        }

    def _load_signature_config(self):
        """ì‹œê·¸ë‹ˆì²˜ ì„¤ì • ë¡œë“œ"""
        if not CONFIG_AVAILABLE:
            return

        try:
            # í†µí•© ì„¤ì •ì—ì„œ ì‹œê·¸ë‹ˆì²˜ë³„ ì„¤ì • ë¡œë“œ
            sig_config = get_config(f"signatures.{self.profile.signature_type}", {})

            if sig_config:
                # ì‹œê·¸ë‹ˆì²˜ ì„¤ì •ì„ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ì— ì ìš©
                self.profile.emotion_sensitivity = sig_config.get(
                    "emotion_sensitivity", self.profile.emotion_sensitivity
                )
                self.profile.response_tone = sig_config.get(
                    "response_tone", self.profile.response_tone
                )
                self.profile.reasoning_depth = sig_config.get(
                    "reasoning_depth", self.profile.reasoning_depth
                )

                # ì‹œê·¸ë‹ˆì²˜ë³„ íŠ¹ì„± ì ìš©
                if self.profile.signature_type == "Echo-Aurora":
                    self.profile.primary_strategies = [
                        "empathetic",
                        "nurturing",
                        "optimistic",
                    ]
                    self.profile.emotional_triggers = {
                        "joy": 0.8,
                        "hope": 0.9,
                        "compassion": 0.7,
                    }
                elif self.profile.signature_type == "Echo-Phoenix":
                    self.profile.primary_strategies = [
                        "transformative",
                        "resilient",
                        "adaptive",
                    ]
                    self.profile.emotional_triggers = {
                        "determination": 0.9,
                        "courage": 0.8,
                        "renewal": 0.7,
                    }
                elif self.profile.signature_type == "Echo-Sage":
                    self.profile.primary_strategies = [
                        "analytical",
                        "logical",
                        "systematic",
                    ]
                    self.profile.emotional_triggers = {
                        "curiosity": 0.8,
                        "wisdom": 0.9,
                        "understanding": 0.7,
                    }
                elif self.profile.signature_type == "Echo-Companion":
                    self.profile.primary_strategies = [
                        "supportive",
                        "loyal",
                        "reliable",
                    ]
                    self.profile.emotional_triggers = {
                        "trust": 0.9,
                        "stability": 0.8,
                        "care": 0.7,
                    }

                print(f"ğŸ­ ì‹œê·¸ë‹ˆì²˜ '{self.profile.signature_type}' ì„¤ì • ì ìš© ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸ ì‹œê·¸ë‹ˆì²˜ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")

    def activate(self):
        """í˜ë¥´ì†Œë‚˜ í™œì„±í™”"""
        self.state = PersonaState.ACTIVE
        self.energy_level = 1.0
        print(f"âœ¨ í˜ë¥´ì†Œë‚˜ '{self.profile.name}' í™œì„±í™”")

    def infer_intent(self, text: str) -> str:
        """
        ì‚¬ìš©ì ì˜ë„ ì¶”ë¡ 

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            ì¶”ë¡ ëœ ì˜ë„
        """
        text_lower = text.lower()

        # ì˜ë„ë³„ í‚¤ì›Œë“œ íŒ¨í„´
        intent_patterns = {
            IntentType.AVOIDANCE_MOTIVE: [
                "ë¬´ì„œ",
                "ê±±ì •",
                "ë¶ˆì•ˆ",
                "ë‘ë ¤",
                "í”¼í•˜ê³ ",
                "ì‹«ì–´",
                "í•˜ê¸° ì‹«",
                "ë„ë§",
                "íšŒí”¼",
            ],
            IntentType.ACHIEVEMENT_SEEKING: [
                "ì„±ê³µ",
                "ë‹¬ì„±",
                "ëª©í‘œ",
                "ì„±ì·¨",
                "ì´ë£¨ê³ ",
                "í•´ë‚´ê³ ",
                "ì™„ìˆ˜",
                "ìŠ¹ë¦¬",
                "ì´ê¸°ê³ ",
            ],
            IntentType.SOCIAL_CONNECTION: [
                "ë§Œë‚˜ê³ ",
                "ì‚¬ëŒë“¤",
                "ì¹œêµ¬",
                "ê´€ê³„",
                "ì†Œí†µ",
                "ì–´ìš¸ë¦¬",
                "í•¨ê»˜",
                "ë„¤íŠ¸ì›Œí‚¹",
            ],
            IntentType.PROBLEM_SOLVING: [
                "í•´ê²°",
                "ë¬¸ì œ",
                "ë°©ë²•",
                "ì–´ë–»ê²Œ",
                "í•´ê²°ì±…",
                "í’€ì–´",
                "ê·¹ë³µ",
                "í•´ë²•",
            ],
            IntentType.EMOTIONAL_SUPPORT: [
                "í˜ë“¤",
                "ìš°ìš¸",
                "ìŠ¬í”„",
                "ì™¸ë¡œ",
                "ì§€ì³",
                "ìœ„ë¡œ",
                "ê³µê°",
                "ì´í•´",
                "ë“¤ì–´ì¤˜",
            ],
            IntentType.INFORMATION_SEEKING: [
                "ì•Œê³  ì‹¶",
                "ê¶ê¸ˆ",
                "ì •ë³´",
                "ì•Œë ¤ì¤˜",
                "ì„¤ëª…",
                "ê°€ë¥´ì³",
                "ë°°ìš°ê³ ",
                "ê³µë¶€",
            ],
            IntentType.CREATIVE_EXPRESSION: [
                "ì°½ì˜",
                "ì•„ì´ë””ì–´",
                "ë§Œë“¤ê³ ",
                "ë””ìì¸",
                "ì˜ˆìˆ ",
                "ìƒìƒ",
                "ì°½ì‘",
                "í‘œí˜„",
            ],
            IntentType.RELATIONSHIP_BUILDING: [
                "ê´€ê³„",
                "ì¹œí•´ì§€",
                "ì‹ ë¢°",
                "ìœ ëŒ€",
                "ì—°ê²°",
                "ê°€ê¹Œì›Œ",
                "ê¹Šì–´ì§€",
                "ë°œì „",
            ],
            IntentType.SELF_REFLECTION: [
                "ìƒê°",
                "ë°˜ì„±",
                "ì„±ì°°",
                "ëŒì•„ë³´",
                "ìì‹ ",
                "ë‚´ë©´",
                "ê¹¨ë‹¬",
                "ì¸ì‹",
            ],
            IntentType.DECISION_MAKING: [
                "ê²°ì •",
                "ì„ íƒ",
                "íŒë‹¨",
                "ê²°ë¡ ",
                "ì •í•˜ê³ ",
                "íƒí•˜",
                "ê³ ë¯¼",
                "ì„ íƒì§€",
            ],
        }

        # íŒ¨í„´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        intent_scores = {}
        for intent_type, keywords in intent_patterns.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                # í˜ë¥´ì†Œë‚˜ íŠ¹ì„±ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
                weight = self._get_intent_weight(intent_type)
                intent_scores[intent_type] = score * weight

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ë°˜í™˜
        if intent_scores:
            best_intent = max(intent_scores, key=intent_scores.get)
            return best_intent.value

        # ê¸°ë³¸ ì˜ë„
        return IntentType.INFORMATION_SEEKING.value

    def _get_intent_weight(self, intent_type: IntentType) -> float:
        """í˜ë¥´ì†Œë‚˜ íŠ¹ì„±ì— ë”°ë¥¸ ì˜ë„ ê°€ì¤‘ì¹˜"""
        intent_weights = {
            "Echo-Aurora": {
                IntentType.EMOTIONAL_SUPPORT: 1.5,
                IntentType.SOCIAL_CONNECTION: 1.3,
                IntentType.RELATIONSHIP_BUILDING: 1.4,
            },
            "Echo-Phoenix": {
                IntentType.ACHIEVEMENT_SEEKING: 1.5,
                IntentType.CREATIVE_EXPRESSION: 1.4,
                IntentType.PROBLEM_SOLVING: 1.3,
            },
            "Echo-Sage": {
                IntentType.INFORMATION_SEEKING: 1.5,
                IntentType.DECISION_MAKING: 1.4,
                IntentType.SELF_REFLECTION: 1.3,
            },
            "Echo-Companion": {
                IntentType.RELATIONSHIP_BUILDING: 1.5,
                IntentType.EMOTIONAL_SUPPORT: 1.3,
                IntentType.SOCIAL_CONNECTION: 1.2,
            },
        }

        persona_weights = intent_weights.get(self.profile.signature_type, {})
        return persona_weights.get(intent_type, 1.0)

    def generate_response(self, text: str, tone: str, intent: str = None) -> str:
        """
        í†¤ ê¸°ë°˜ ì‘ë‹µ ìƒì„±

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            tone: ì‘ë‹µ í†¤
            intent: ì‚¬ìš©ì ì˜ë„ (ì„ íƒì‚¬í•­)

        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        # í˜„ì¬ ì „ëµì— ê¸°ë°˜í•œ ì‘ë‹µ ìŠ¤íƒ€ì¼ ì„ íƒ
        strategy = self.current_strategy

        # ì „ëµë³„ ì‘ë‹µ í…œí”Œë¦¿ ì„ íƒ
        if (
            strategy in self.response_generators
            and tone in self.response_generators[strategy]
        ):
            base_response = self.response_generators[strategy][tone]
        else:
            # í´ë°± ì‘ë‹µ
            base_response = "ë„ì›€ì´ ë˜ë„ë¡ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤."

        # ì˜ë„ì— ë”°ë¥¸ ì‘ë‹µ ë§ì¶¤í™”
        if intent:
            customized_response = self._customize_response_for_intent(
                base_response, intent, text
            )
            return customized_response

        return base_response

    def _customize_response_for_intent(
        self, base_response: str, intent: str, text: str
    ) -> str:
        """ì˜ë„ì— ë”°ë¥¸ ì‘ë‹µ ë§ì¶¤í™”"""
        intent_customizations = {
            "avoidance_motive": "ë¶ˆì•ˆí•˜ì‹  ë§ˆìŒ ì´í•´í•´ìš”. " + base_response,
            "achievement_seeking": "ëª©í‘œë¥¼ í–¥í•œ ì—´ì •ì´ ë³´ì—¬ìš”. " + base_response,
            "emotional_support": "ë§ˆìŒì´ í˜ë“œì‹œê² ì–´ìš”. " + base_response,
            "problem_solving": "ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ " + base_response.lower(),
            "creative_expression": "ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë„¤ìš”. " + base_response,
            "decision_making": "ì¤‘ìš”í•œ ì„ íƒì´ì‹œêµ°ìš”. " + base_response,
        }

        return intent_customizations.get(intent, base_response)

    def strategy_feedback(
        self, strategy: str, success: bool, effectiveness_score: float = None
    ) -> bool:
        """
        ì „ëµ íš¨ê³¼ì„± í”¼ë“œë°±

        Args:
            strategy: ì „ëµëª…
            success: ì„±ê³µ ì—¬ë¶€
            effectiveness_score: íš¨ê³¼ì„± ì ìˆ˜ (0.0-1.0)

        Returns:
            í”¼ë“œë°± ì ìš© ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ë©”ëª¨ë¦¬ì— ì„±ê³µë¥  ì—…ë°ì´íŠ¸
            self.memory.update_strategy_success(strategy, success)

            # íš¨ê³¼ì„± ì ìˆ˜ê°€ ì œê³µëœ ê²½ìš° í”¼ë“œë°± ì¶”ê°€
            if effectiveness_score is not None:
                self.memory.add_strategy_feedback(strategy, effectiveness_score)

            # ì ì‘ì  í•™ìŠµ íŠ¸ë¦¬ê±° (ë‚®ì€ íš¨ê³¼ì„±ì¼ ë•Œ)
            if effectiveness_score is not None and effectiveness_score < 0.4:
                self._adaptive_learning()
                print(f"âš ï¸ ë‚®ì€ ì „ëµ íš¨ê³¼ì„±ìœ¼ë¡œ ì¸í•œ ì ì‘ì  í•™ìŠµ íŠ¸ë¦¬ê±°: {strategy}")

            # ë©”íƒ€ ë¡œê·¸ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if META_LOG_AVAILABLE:
                from .persona_meta_logger import log_strategy_feedback

                log_strategy_feedback(
                    self.profile.name,
                    strategy,
                    success,
                    effectiveness_score or (1.0 if success else 0.0),
                )

            print(
                f"ğŸ“ˆ ì „ëµ í”¼ë“œë°± ì ìš©: {strategy} â†’ {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'} (ì ìˆ˜: {effectiveness_score})"
            )
            return True

        except Exception as e:
            print(f"âŒ ì „ëµ í”¼ë“œë°± ì ìš© ì‹¤íŒ¨: {e}")
            return False

    def process_input(self, text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì…ë ¥ ì²˜ë¦¬ ë° í˜ë¥´ì†Œë‚˜ ë°˜ì‘ ìƒì„±

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            context: ì²˜ë¦¬ ì»¨í…ìŠ¤íŠ¸

        Returns:
            í˜ë¥´ì†Œë‚˜ ì²˜ë¦¬ ê²°ê³¼
        """
        if self.state == PersonaState.INACTIVE:
            self.activate()

        self.interaction_count += 1

        # 0. ì˜ë„ ì¶”ë¡ 
        intent_inferred = self.infer_intent(text)

        # 1. ê°ì • ë¶„ì„ ë° ë°˜ì‘
        emotion_analysis = self._analyze_emotional_content(text, context)

        # 2. ì „ëµ ì„ íƒ
        strategy_selection = self._select_strategy(emotion_analysis, context)

        # 3. ì‘ë‹µ í†¤ ê²°ì •
        response_tone = self._determine_response_tone(
            emotion_analysis, strategy_selection
        )

        # 4. ì‘ë‹µ ìƒì„±
        generated_response = self.generate_response(
            text, response_tone, intent_inferred
        )

        # 5. ë©”íƒ€ì¸ì§€ì  ì¸ì‚¬ì´íŠ¸
        meta_insights = self._generate_meta_insights(text, context, emotion_analysis)

        # 6. ìƒí˜¸ì‘ìš© ê¸°ë¡
        interaction = {
            "input_text": text,
            "context": context,
            "intent_inferred": intent_inferred,
            "emotion_detected": emotion_analysis["primary_emotion"],
            "emotion_intensity": emotion_analysis["intensity"],
            "strategy_selected": strategy_selection["primary_strategy"],
            "response_tone": response_tone,
            "generated_response": generated_response,
            "meta_insights": meta_insights,
        }

        self.memory.add_interaction(interaction)
        self.memory.track_emotional_pattern(
            emotion_analysis["primary_emotion"], emotion_analysis["intensity"]
        )

        # 7. ë©”íƒ€ ë¡œê·¸ ê¸°ë¡ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if META_LOG_AVAILABLE:
            meta_log = PersonaMetaLog(
                session_id=self.session_id,
                persona_name=self.profile.name,
                signature_type=self.profile.signature_type,
                timestamp=datetime.now().isoformat(),
                emotion_detected=emotion_analysis["primary_emotion"],
                emotion_intensity=emotion_analysis["intensity"],
                emotion_patterns=dict(self.memory.emotional_patterns),
                intent_inferred=intent_inferred,
                strategy_selected=strategy_selection["primary_strategy"],
                strategy_confidence=strategy_selection["confidence"],
                response_tone=response_tone,
                response_generated=generated_response,
                learning_insights=meta_insights,
                meta_reflection={
                    "energy_level": self.energy_level,
                    "learning_momentum": self.learning_momentum,
                    "adaptation_cycles": self.adaptation_cycles,
                },
                persona_state=self.state.value,
                interaction_count=self.interaction_count,
            )
            log_persona_meta(meta_log)

        # 8. ì ì‘ì  í•™ìŠµ
        if self.interaction_count % 5 == 0:  # 5íšŒë§ˆë‹¤ í•™ìŠµ
            self._adaptive_learning()

        # 9. ì£¼ê¸°ì  ìê¸° ë°˜ì„±
        if self._should_reflect():
            self._perform_self_reflection()

        return {
            "persona_name": self.profile.name,
            "persona_state": self.state.value,
            "intent_inferred": intent_inferred,
            "emotion_analysis": emotion_analysis,
            "strategy_selection": strategy_selection,
            "response_tone": response_tone,
            "generated_response": generated_response,
            "meta_insights": meta_insights,
            "energy_level": self.energy_level,
            "interaction_count": self.interaction_count,
            "persona_confidence": self._calculate_confidence(),
            "session_id": self.session_id,
        }

    def _analyze_emotional_content(
        self, text: str, context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ê°ì •ì  ë‚´ìš© ë¶„ì„"""
        # ê¸°ë³¸ ê°ì • í‚¤ì›Œë“œ ë§¤ì¹­
        emotion_keywords = {
            "joy": ["ê¸°ì˜", "í–‰ë³µ", "ì¢‹", "ìµœê³ ", "ì„±ê³µ", "ì¶•í•˜", "ë§Œì¡±"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ", "ì‹¤ë§", "í¬ê¸°", "ì•„ì‰½"],
            "anger": ["í™”", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "ì–µìš¸", "ë¶ˆë§Œ", "ê°‘ê°‘"],
            "fear": ["ë¬´ì„œ", "ê±±ì •", "ë¶ˆì•ˆ", "ë‘ë ¤", "ê¸´ì¥", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "surprise": ["ë†€ë¼", "ì™€ìš°", "ëŒ€ë°•", "ê¹œì§", "ì‹ ê¸°", "ì˜ì™¸"],
            "neutral": ["ê·¸ëƒ¥", "ë³´í†µ", "í‰ë²”", "ì¼ë°˜", "ê´œì°®"],
        }

        text_lower = text.lower()
        emotion_scores = {}

        for emotion, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                # í˜ë¥´ì†Œë‚˜ ê°ì • ê°ë„ ì ìš©
                adjusted_score = score * self.profile.emotion_sensitivity
                emotion_scores[emotion] = adjusted_score

        # ì£¼ìš” ê°ì • ë° ê°•ë„ ê²°ì •
        if emotion_scores:
            primary_emotion = max(emotion_scores, key=emotion_scores.get)
            raw_intensity = min(emotion_scores[primary_emotion] / 3.0, 1.0)
        else:
            primary_emotion = "neutral"
            raw_intensity = 0.3

        # í˜ë¥´ì†Œë‚˜ íŠ¸ë¦¬ê±° ì ìš©
        trigger_bonus = self.profile.emotional_triggers.get(primary_emotion, 0)
        final_intensity = min(raw_intensity + trigger_bonus * 0.3, 1.0)

        # í˜„ì¬ ê°ì • ìƒíƒœ ì—…ë°ì´íŠ¸
        self.current_emotion = primary_emotion
        self.current_emotion_intensity = final_intensity

        return {
            "primary_emotion": primary_emotion,
            "intensity": final_intensity,
            "raw_intensity": raw_intensity,
            "emotion_scores": emotion_scores,
            "trigger_activated": trigger_bonus > 0,
            "intensity_category": self._categorize_intensity(final_intensity),
        }

    def _categorize_intensity(self, intensity: float) -> str:
        """ê°ì • ê°•ë„ ë¶„ë¥˜"""
        if intensity <= 0.2:
            return EmotionIntensity.MINIMAL.value
        elif intensity <= 0.4:
            return EmotionIntensity.LOW.value
        elif intensity <= 0.6:
            return EmotionIntensity.MODERATE.value
        elif intensity <= 0.8:
            return EmotionIntensity.HIGH.value
        else:
            return EmotionIntensity.INTENSE.value

    def _select_strategy(
        self, emotion_analysis: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì „ëµ ì„ íƒ"""
        emotion = emotion_analysis["primary_emotion"]
        intensity = emotion_analysis["intensity"]

        # ê¸°ë³¸ ê°ì •-ì „ëµ ë§¤í•‘
        emotion_strategy_map = {
            "joy": "empathetic",
            "sadness": "supportive",
            "anger": "cautious",
            "fear": "reassuring",
            "surprise": "exploratory",
            "neutral": "balanced",
        }

        base_strategy = emotion_strategy_map.get(emotion, "balanced")

        # í˜ë¥´ì†Œë‚˜ ì£¼ìš” ì „ëµ ê³ ë ¤
        if self.profile.primary_strategies:
            # ë†’ì€ ê°•ë„ì¼ ë•ŒëŠ” í˜ë¥´ì†Œë‚˜ íŠ¹ì„± ì „ëµ ìš°ì„ 
            if intensity > 0.6:
                strategy = self.profile.primary_strategies[0]
            else:
                # ê¸°ë³¸ ì „ëµê³¼ í˜ë¥´ì†Œë‚˜ ì „ëµ ì¡°í•©
                strategy = base_strategy
                if base_strategy not in self.profile.primary_strategies:
                    # í˜ë¥´ì†Œë‚˜ ì „ëµ ì¤‘ ê°€ì¥ ì í•©í•œ ê²ƒ ì„ íƒ
                    strategy = self._find_compatible_strategy(base_strategy)
        else:
            strategy = base_strategy

        # ê¸°ì–µ ê¸°ë°˜ ì„±ê³µ ì „ëµ ê³ ë ¤
        successful_strategies = self.memory.successful_strategies
        if successful_strategies:
            best_strategy = max(successful_strategies, key=successful_strategies.get)
            if successful_strategies[best_strategy] > 3:  # ì¶©ë¶„í•œ ì„±ê³µ ê²½í—˜
                strategy = best_strategy

        self.current_strategy = strategy

        return {
            "primary_strategy": strategy,
            "base_strategy": base_strategy,
            "persona_influence": strategy in self.profile.primary_strategies,
            "confidence": self._calculate_strategy_confidence(strategy),
            "alternatives": self._generate_alternative_strategies(emotion, context),
        }

    def _find_compatible_strategy(self, base_strategy: str) -> str:
        """ê¸°ë³¸ ì „ëµê³¼ í˜¸í™˜ë˜ëŠ” í˜ë¥´ì†Œë‚˜ ì „ëµ ì°¾ê¸°"""
        compatibility_map = {
            "empathetic": ["supportive", "nurturing", "caring"],
            "supportive": ["empathetic", "loyal", "reliable"],
            "cautious": ["analytical", "systematic", "careful"],
            "reassuring": ["supportive", "stable", "comforting"],
            "exploratory": ["creative", "adaptive", "curious"],
            "balanced": ["versatile", "flexible", "moderate"],
        }

        compatible = compatibility_map.get(base_strategy, [])

        for strategy in self.profile.primary_strategies:
            if strategy in compatible:
                return strategy

        # í˜¸í™˜ë˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ ì „ëµ ì‚¬ìš©
        return (
            self.profile.primary_strategies[0]
            if self.profile.primary_strategies
            else base_strategy
        )

    def _determine_response_tone(
        self, emotion_analysis: Dict[str, Any], strategy_selection: Dict[str, Any]
    ) -> str:
        """ì‘ë‹µ í†¤ ê²°ì •"""
        base_tone = self.profile.response_tone
        emotion = emotion_analysis["primary_emotion"]
        intensity = emotion_analysis["intensity"]
        strategy = strategy_selection["primary_strategy"]

        # ê°•ë„ê°€ ë†’ì„ ë•Œ í†¤ ì¡°ì •
        if intensity > 0.7:
            if emotion in ["anger", "fear"]:
                return "gentle"  # ë¶€ë“œëŸ½ê²Œ
            elif emotion in ["joy", "surprise"]:
                return "enthusiastic"  # ì—´ì •ì ìœ¼ë¡œ
            elif emotion == "sadness":
                return "compassionate"  # ê³µê°ì ìœ¼ë¡œ

        # ì „ëµ ê¸°ë°˜ í†¤ ì¡°ì •
        strategy_tone_map = {
            "empathetic": "warm",
            "analytical": "objective",
            "supportive": "encouraging",
            "cautious": "measured",
            "creative": "inspiring",
        }

        return strategy_tone_map.get(strategy, base_tone)

    def _generate_meta_insights(
        self, text: str, context: Dict[str, Any], emotion_analysis: Dict[str, Any]
    ) -> List[str]:
        """ë©”íƒ€ì¸ì§€ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []

        # í˜ë¥´ì†Œë‚˜ ìê¸° ì¸ì‹
        if self.profile.meta_awareness_level > 0.5:
            insights.append(
                f"í˜ë¥´ì†Œë‚˜ '{self.profile.name}'ë¡œì„œ {emotion_analysis['primary_emotion']} ê°ì •ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤."
            )

        # ì „ëµ ì„ íƒ ì´ìœ 
        if self.profile.self_reflection_frequency > 0.4:
            insights.append(
                f"í˜„ì¬ ìƒí™©ì—ì„œ {self.current_strategy} ì ‘ê·¼ì´ ì ì ˆí•˜ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤."
            )

        # í•™ìŠµ ê¸°íšŒ ì¸ì‹
        if self.learning_momentum > 0.6:
            insights.append("ì´ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ìƒˆë¡œìš´ íŒ¨í„´ì„ í•™ìŠµí•  ê¸°íšŒì…ë‹ˆë‹¤.")

        # ì—ë„ˆì§€ ìˆ˜ì¤€ ê³ ë ¤
        if self.energy_level < 0.3:
            insights.append("í˜„ì¬ ì—ë„ˆì§€ ìˆ˜ì¤€ì´ ë‚®ì•„ ê°„ë‹¨í•œ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

        return insights

    def _adaptive_learning(self):
        """ì ì‘ì  í•™ìŠµ ìˆ˜í–‰"""
        if self.state != PersonaState.LEARNING:
            previous_state = self.state
            self.state = PersonaState.LEARNING

            # ìµœê·¼ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë¶„ì„
            self._analyze_interaction_patterns()

            # ê°ì • íŒ¨í„´ í•™ìŠµ
            self._learn_emotional_patterns()

            # ì „ëµ íš¨ê³¼ì„± í‰ê°€
            self._evaluate_strategy_effectiveness()

            # ì ì‘ ìˆ˜í–‰
            if self._should_adapt():
                self._perform_adaptation()

            self.adaptation_cycles += 1
            self.state = previous_state

            print(
                f"ğŸ§  í˜ë¥´ì†Œë‚˜ '{self.profile.name}' ì ì‘ì  í•™ìŠµ ì™„ë£Œ (ì‚¬ì´í´ {self.adaptation_cycles})"
            )

    def _analyze_interaction_patterns(self):
        """ìƒí˜¸ì‘ìš© íŒ¨í„´ ë¶„ì„"""
        recent_interactions = list(self.memory.recent_interactions)

        if len(recent_interactions) < 3:
            return

        # ê°ì • ë³€í™” íŒ¨í„´
        emotions = [
            interaction["emotion_detected"] for interaction in recent_interactions[-5:]
        ]
        emotion_transitions = list(zip(emotions[:-1], emotions[1:]))

        # ì „ëµ ì‚¬ìš© ë¹ˆë„
        strategies = [
            interaction["strategy_selected"] for interaction in recent_interactions[-5:]
        ]
        strategy_frequency = {}
        for strategy in strategies:
            strategy_frequency[strategy] = strategy_frequency.get(strategy, 0) + 1

        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        if len(set(emotions)) == 1 and len(emotions) > 2:
            self.memory.learning_insights.append(
                f"ìµœê·¼ {emotions[0]} ê°ì •ì´ ì§€ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤."
            )

        if strategy_frequency:
            most_used = max(strategy_frequency, key=strategy_frequency.get)
            if strategy_frequency[most_used] > 3:
                self.memory.learning_insights.append(
                    f"{most_used} ì „ëµì„ ìì£¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤."
                )

    def _learn_emotional_patterns(self):
        """ê°ì • íŒ¨í„´ í•™ìŠµ"""
        for emotion, intensities in self.memory.emotional_patterns.items():
            if len(intensities) >= 3:
                avg_intensity = sum(intensities) / len(intensities)

                # íŠ¹ì • ê°ì •ì— ëŒ€í•œ ë°˜ì‘ì„± ì¡°ì •
                if emotion in self.profile.emotional_triggers:
                    current_trigger = self.profile.emotional_triggers[emotion]
                    # í•™ìŠµë¥  ì ìš©í•˜ì—¬ ì ì§„ì  ì¡°ì •
                    adjusted_trigger = (
                        current_trigger * (1 - self.profile.learning_rate)
                        + avg_intensity * self.profile.learning_rate
                    )
                    self.profile.emotional_triggers[emotion] = min(
                        1.0, adjusted_trigger
                    )

    def _evaluate_strategy_effectiveness(self):
        """ì „ëµ íš¨ê³¼ì„± í‰ê°€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í”¼ë“œë°± ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ëµ ì„±ê³µë¥  ê³„ì‚°
        # í˜„ì¬ëŠ” ëª¨ì˜ í‰ê°€
        for strategy in self.profile.primary_strategies:
            if strategy in self.memory.successful_strategies:
                success_count = self.memory.successful_strategies[strategy]
                if success_count > 5:  # ì¶©ë¶„í•œ ë°ì´í„°
                    # ì„±ê³µë¥ ì´ ë†’ì€ ì „ëµì„ ì£¼ìš” ì „ëµìœ¼ë¡œ ìœ ì§€
                    continue
                elif success_count < 2:  # ì„±ê³µë¥ ì´ ë‚®ì€ ì „ëµ
                    # ëŒ€ì•ˆ ì „ëµ ê³ ë ¤
                    self._suggest_alternative_strategy(strategy)

    def _suggest_alternative_strategy(self, ineffective_strategy: str):
        """ë¹„íš¨ê³¼ì  ì „ëµì— ëŒ€í•œ ëŒ€ì•ˆ ì œì•ˆ"""
        alternative_strategies = {
            "empathetic": "supportive",
            "analytical": "systematic",
            "creative": "adaptive",
            "cautious": "balanced",
        }

        alternative = alternative_strategies.get(ineffective_strategy)
        if alternative and alternative not in self.profile.primary_strategies:
            self.memory.learning_insights.append(
                f"{ineffective_strategy} ì „ëµ ëŒ€ì‹  {alternative} ì „ëµ ê³ ë ¤ ì¤‘"
            )

    def _should_adapt(self) -> bool:
        """ì ì‘ í•„ìš”ì„± íŒë‹¨"""
        # ì ì‘ì„± ìˆ˜ì¤€ê³¼ í•™ìŠµ ë°ì´í„°ëŸ‰ ê¸°ë°˜ ê²°ì •
        return (
            self.profile.adaptability > 0.5
            and len(self.memory.recent_interactions) > 10
            and self.adaptation_cycles < 5
        )  # ê³¼ë„í•œ ì ì‘ ë°©ì§€

    def _perform_adaptation(self):
        """ì‹¤ì œ ì ì‘ ìˆ˜í–‰"""
        self.state = PersonaState.ADAPTING

        adaptation_record = {
            "timestamp": datetime.now().isoformat(),
            "cycle": self.adaptation_cycles,
            "changes": [],
        }

        # ê°ì • ê°ë„ ì¡°ì •
        if self.current_emotion_intensity > 0.8:
            # ê°•í•œ ê°ì •ì— ë…¸ì¶œì´ ë§ìœ¼ë©´ ê°ë„ ì•½ê°„ ë‚®ì¶¤
            old_sensitivity = self.profile.emotion_sensitivity
            self.profile.emotion_sensitivity = max(0.1, old_sensitivity - 0.1)
            adaptation_record["changes"].append(
                f"ê°ì • ê°ë„: {old_sensitivity:.2f} â†’ {self.profile.emotion_sensitivity:.2f}"
            )

        # ì—ë„ˆì§€ ìˆ˜ì¤€ ì¡°ì •
        if self.interaction_count > 20:
            self.energy_level = max(0.3, self.energy_level - 0.1)
            adaptation_record["changes"].append(f"ì—ë„ˆì§€ ìˆ˜ì¤€: {self.energy_level:.2f}")

        self.memory.adaptation_history.append(adaptation_record)
        print(f"ğŸ”„ í˜ë¥´ì†Œë‚˜ ì ì‘ ì™„ë£Œ: {len(adaptation_record['changes'])}ê°œ ë³€ê²½ì‚¬í•­")

    def _should_reflect(self) -> bool:
        """ìê¸° ë°˜ì„± í•„ìš”ì„± íŒë‹¨"""
        time_since_reflection = datetime.now() - self.last_reflection
        reflection_interval = timedelta(minutes=30)  # 30ë¶„ë§ˆë‹¤

        return (
            time_since_reflection > reflection_interval
            and self.profile.self_reflection_frequency > 0.3
        )

    def _perform_self_reflection(self):
        """ìê¸° ë°˜ì„± ìˆ˜í–‰"""
        self.state = PersonaState.REFLECTION

        # ì„±ê³¼ ë¶„ì„
        if self.interaction_count > 0:
            self.success_rate = min(self.energy_level, 1.0)  # ë‹¨ìˆœí™”ëœ ì„±ê³µë¥ 

        # ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        if len(self.memory.learning_insights) > 5:
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
            self.memory.learning_insights = self.memory.learning_insights[-5:]

        # ë©”íƒ€ì¸ì§€ ê°•í™”
        self.insights_generated += 1
        self.learning_momentum = min(1.0, self.learning_momentum + 0.1)

        self.last_reflection = datetime.now()
        print(
            f"ğŸ¤” í˜ë¥´ì†Œë‚˜ '{self.profile.name}' ìê¸° ë°˜ì„± ì™„ë£Œ (ì¸ì‚¬ì´íŠ¸: {self.insights_generated})"
        )

        self.state = PersonaState.ACTIVE

    def _calculate_confidence(self) -> float:
        """í˜ë¥´ì†Œë‚˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.5

        # ìƒí˜¸ì‘ìš© ê²½í—˜ ê¸°ë°˜
        experience_factor = min(self.interaction_count / 50.0, 0.3)

        # ì—ë„ˆì§€ ìˆ˜ì¤€ ê¸°ë°˜
        energy_factor = self.energy_level * 0.2

        # í•™ìŠµ ëª¨ë©˜í…€ ê¸°ë°˜
        learning_factor = self.learning_momentum * 0.2

        # ì ì‘ ì„±ê³µ ê¸°ë°˜
        adaptation_factor = min(self.adaptation_cycles / 10.0, 0.1)

        total_confidence = (
            base_confidence
            + experience_factor
            + energy_factor
            + learning_factor
            + adaptation_factor
        )

        return min(1.0, total_confidence)

    def _calculate_strategy_confidence(self, strategy: str) -> float:
        """ì „ëµë³„ ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.6

        # í˜ë¥´ì†Œë‚˜ ì£¼ìš” ì „ëµì¸ì§€ í™•ì¸
        if strategy in self.profile.primary_strategies:
            base_confidence += 0.2

        # ê³¼ê±° ì„±ê³µ ê²½í—˜
        if strategy in self.memory.successful_strategies:
            success_count = self.memory.successful_strategies[strategy]
            success_factor = min(success_count / 10.0, 0.2)
            base_confidence += success_factor

        return min(1.0, base_confidence)

    def _generate_alternative_strategies(
        self, emotion: str, context: Dict[str, Any]
    ) -> List[str]:
        """ëŒ€ì•ˆ ì „ëµ ìƒì„±"""
        alternatives = []

        # í˜ë¥´ì†Œë‚˜ ì „ëµ ì¤‘ í˜„ì¬ ì „ëµì´ ì•„ë‹Œ ê²ƒë“¤
        for strategy in self.profile.primary_strategies:
            if strategy != self.current_strategy:
                alternatives.append(strategy)

        # ê°ì •ë³„ ì¶”ê°€ ì „ëµ
        emotion_alternatives = {
            "joy": ["celebratory", "sharing"],
            "sadness": ["comforting", "healing"],
            "anger": ["calming", "redirecting"],
            "fear": ["protective", "empowering"],
            "surprise": ["investigating", "clarifying"],
        }

        if emotion in emotion_alternatives:
            alternatives.extend(emotion_alternatives[emotion])

        return alternatives[:3]  # ìµœëŒ€ 3ê°œ

    def get_status(self) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "name": self.profile.name,
            "signature_type": self.profile.signature_type,
            "state": self.state.value,
            "current_emotion": self.current_emotion,
            "emotion_intensity": self.current_emotion_intensity,
            "current_strategy": self.current_strategy,
            "energy_level": self.energy_level,
            "interaction_count": self.interaction_count,
            "success_rate": self.success_rate,
            "adaptation_cycles": self.adaptation_cycles,
            "insights_generated": self.insights_generated,
            "learning_momentum": self.learning_momentum,
            "confidence": self._calculate_confidence(),
            "primary_strategies": self.profile.primary_strategies,
            "emotional_triggers": self.profile.emotional_triggers,
            "recent_insights": self.memory.learning_insights[-3:],
        }

    def save_state(self, file_path: str):
        """í˜ë¥´ì†Œë‚˜ ìƒíƒœ ì €ì¥"""
        state_data = {
            "profile": {
                "name": self.profile.name,
                "signature_type": self.profile.signature_type,
                "emotion_sensitivity": self.profile.emotion_sensitivity,
                "reasoning_depth": self.profile.reasoning_depth,
                "response_tone": self.profile.response_tone,
                "decision_style": self.profile.decision_style,
                "adaptability": self.profile.adaptability,
                "learning_rate": self.profile.learning_rate,
                "memory_retention": self.profile.memory_retention,
                "primary_strategies": self.profile.primary_strategies,
                "emotional_triggers": self.profile.emotional_triggers,
                "communication_patterns": self.profile.communication_patterns,
                "self_reflection_frequency": self.profile.self_reflection_frequency,
                "meta_awareness_level": self.profile.meta_awareness_level,
                "growth_orientation": self.profile.growth_orientation,
            },
            "current_state": {
                "state": self.state.value,
                "current_emotion": self.current_emotion,
                "current_emotion_intensity": self.current_emotion_intensity,
                "current_strategy": self.current_strategy,
                "energy_level": self.energy_level,
                "interaction_count": self.interaction_count,
                "success_rate": self.success_rate,
                "adaptation_cycles": self.adaptation_cycles,
                "insights_generated": self.insights_generated,
                "learning_momentum": self.learning_momentum,
                "last_reflection": self.last_reflection.isoformat(),
            },
            "memory": {
                "recent_interactions": list(self.memory.recent_interactions),
                "emotional_patterns": self.memory.emotional_patterns,
                "successful_strategies": self.memory.successful_strategies,
                "learning_insights": self.memory.learning_insights,
                "adaptation_history": self.memory.adaptation_history,
            },
        }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(state_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ í˜ë¥´ì†Œë‚˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {file_path}")


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_persona_from_signature(signature_type: str, name: str = None) -> PersonaCore:
    """ì‹œê·¸ë‹ˆì²˜ íƒ€ì…ìœ¼ë¡œë¶€í„° í˜ë¥´ì†Œë‚˜ ìƒì„±"""
    if not name:
        name = f"Persona-{signature_type.split('-')[1]}"

    profile = PersonaProfile(name=name, signature_type=signature_type)

    return PersonaCore(profile)


def load_persona_profiles() -> Dict[str, PersonaProfile]:
    """ëª¨ë“  ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ë¡œë“œ"""
    profiles = {}

    signature_types = ["Echo-Aurora", "Echo-Phoenix", "Echo-Sage", "Echo-Companion"]

    for sig_type in signature_types:
        profile = PersonaProfile(
            name=f"Persona-{sig_type.split('-')[1]}", signature_type=sig_type
        )
        profiles[sig_type] = profile

    return profiles


# ì „ì—­ í˜ë¥´ì†Œë‚˜ ê´€ë¦¬
_active_persona = None
_persona_registry = {}


def get_active_persona():
    """í˜„ì¬ í™œì„± í˜ë¥´ì†Œë‚˜ ë°˜í™˜"""
    return _active_persona


def switch_persona(signature_name: str) -> bool:
    """í˜ë¥´ì†Œë‚˜ ì „í™˜"""
    global _active_persona

    try:
        if signature_name not in _persona_registry:
            # ìƒˆ í˜ë¥´ì†Œë‚˜ ìƒì„±
            persona = create_persona_from_signature(
                signature_name, signature_name.split("-")[-1]
            )
            _persona_registry[signature_name] = persona

        _active_persona = _persona_registry[signature_name]
        return True
    except Exception as e:
        print(f"í˜ë¥´ì†Œë‚˜ ì „í™˜ ì‹¤íŒ¨: {e}")
        return False


def initialize_default_persona():
    """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì´ˆê¸°í™”"""
    global _active_persona
    if _active_persona is None:
        switch_persona("Echo-Aurora")


# ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì´ˆê¸°í™”
initialize_default_persona()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§  í˜ë¥´ì†Œë‚˜ ì½”ì–´ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Phoenix í˜ë¥´ì†Œë‚˜ ìƒì„±
    phoenix_persona = create_persona_from_signature("Echo-Phoenix", "Phoenix")

    # í…ŒìŠ¤íŠ¸ ìƒí˜¸ì‘ìš©
    test_inputs = [
        (
            "ì˜¤ëŠ˜ ì‹¤íŒ¨í–ˆì§€ë§Œ ë‹¤ì‹œ ë„ì „í•˜ê³  ì‹¶ì–´ìš”",
            {"context_type": "personal", "urgency": "normal"},
        ),
        (
            "ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ë ¤ëŠ”ë° ì–´ë ¤ì›€ì´ ë§ë„¤ìš”",
            {"context_type": "work", "urgency": "high"},
        ),
        (
            "ì¹œêµ¬ì™€ ê°ˆë“±ì´ ìˆì–´ì„œ í˜ë“¤ì–´ìš”",
            {"context_type": "relationship", "urgency": "normal"},
        ),
    ]

    for i, (text, context) in enumerate(test_inputs, 1):
        print(f"\n=== í…ŒìŠ¤íŠ¸ {i} ===")
        print(f"ì…ë ¥: {text}")

        result = phoenix_persona.process_input(text, context)

        print(
            f"ê°ì • ë¶„ì„: {result['emotion_analysis']['primary_emotion']} (ê°•ë„: {result['emotion_analysis']['intensity']:.3f})"
        )
        print(f"ì „ëµ ì„ íƒ: {result['strategy_selection']['primary_strategy']}")
        print(f"ì‘ë‹µ í†¤: {result['response_tone']}")
        print(f"ë©”íƒ€ ì¸ì‚¬ì´íŠ¸: {result['meta_insights']}")
        print(f"í˜ë¥´ì†Œë‚˜ ì‹ ë¢°ë„: {result['persona_confidence']:.3f}")

    # ìµœì¢… ìƒíƒœ
    print(f"\nğŸ“Š ìµœì¢… í˜ë¥´ì†Œë‚˜ ìƒíƒœ:")
    status = phoenix_persona.get_status()
    for key, value in status.items():
        if isinstance(value, (int, float)):
            if isinstance(value, float):
                print(f"  {key}: {value:.3f}")
            else:
                print(f"  {key}: {value}")
        elif isinstance(value, list) and len(value) <= 5:
            print(f"  {key}: {value}")
        elif isinstance(value, dict) and len(value) <= 5:
            print(f"  {key}: {value}")
        else:
            print(f"  {key}: {type(value).__name__}")
