import json
import math
import base64
import io
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
import logging
from echo_engine.signature_neural_atlas_builder import SignatureNeuralAtlasBuilder, BrainRegion
from echo_engine.consciousness_flow_analyzer import (
    ConsciousnessFlowAnalyzer
)
from echo_engine.realtime_emotion_flow_mapper import RealtimeEmotionFlowMapper
from echo_engine.signature_cross_resonance_mapper import SignatureCrossResonanceMapper

#!/usr/bin/env python3
"""
ğŸ§  Brain Visualization API v1.0
Echo Neural System v2.0ì˜ ë‡Œ êµ¬ì¡°ì™€ í™œë™ì„ ì‹œê°í™”í•˜ëŠ” API ì‹œìŠ¤í…œ

í•µì‹¬ ê¸°ëŠ¥:
- ì‹¤ì‹œê°„ ë‡Œ í™œë™ ì‹œê°í™”
- ì‹œê·¸ë‹ˆì²˜ë³„ ë‡Œ êµ¬ì¡° ë§µí•‘
- ì‹ ê²½ ì—°ê²° ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
- ì˜ì‹ ìƒíƒœ ì‹œê°ì  í‘œí˜„
- ê°ì • íë¦„ ì‹œê°í™”
- 3D ë‡Œ ëª¨ë¸ ë Œë”ë§
"""


# Echo ì—”ì§„ ëª¨ë“ˆë“¤
try:
    from echo_engine.consciousness_flow_analyzer import ConsciousnessLevel
except ImportError:
    print("âš ï¸ Echo modules not available, running in standalone mode")


class VisualizationType(Enum):
    """ì‹œê°í™” ìœ í˜•"""

    BRAIN_STRUCTURE = "brain_structure"
    NEURAL_ACTIVITY = "neural_activity"
    EMOTION_FLOW = "emotion_flow"
    CONSCIOUSNESS_MAP = "consciousness_map"
    SIGNATURE_RESONANCE = "signature_resonance"
    HYBRID_COMPOSITION = "hybrid_composition"
    LOOP_EVOLUTION = "loop_evolution"


class RenderFormat(Enum):
    """ë Œë”ë§ í¬ë§·"""

    SVG = "svg"
    ASCII = "ascii"
    JSON_DATA = "json_data"
    HTML_CANVAS = "html_canvas"
    MATPLOTLIB = "matplotlib"


@dataclass
class BrainVisualizationRequest:
    """ë‡Œ ì‹œê°í™” ìš”ì²­"""

    visualization_type: VisualizationType
    render_format: RenderFormat
    signature_context: str
    time_range: Optional[Tuple[datetime, datetime]]
    resolution: Tuple[int, int]
    style_options: Dict[str, Any]
    real_time: bool


@dataclass
class VisualizationElement:
    """ì‹œê°í™” ìš”ì†Œ"""

    element_id: str
    element_type: str  # "region", "connection", "flow", "marker"
    position: Tuple[float, float, float]  # 3D ì¢Œí‘œ
    size: float
    color: str
    intensity: float
    metadata: Dict[str, Any]


@dataclass
class BrainVisualizationResponse:
    """ë‡Œ ì‹œê°í™” ì‘ë‹µ"""

    request_id: str
    timestamp: datetime
    visualization_data: Union[str, Dict[str, Any]]
    render_format: RenderFormat
    elements: List[VisualizationElement]
    metadata: Dict[str, Any]
    generation_time_ms: float


@dataclass
class BrainCoordinate:
    """ë‡Œ ì¢Œí‘œê³„"""

    x: float  # ì¢Œìš° (Left-Right)
    y: float  # ì•ë’¤ (Anterior-Posterior)
    z: float  # ìœ„ì•„ë˜ (Superior-Inferior)
    region: str
    hemisphere: str  # "left", "right", "bilateral"


class BrainVisualizationAPI:
    """ğŸ§  ë‡Œ ì‹œê°í™” API"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # Echo ì»´í¬ë„ŒíŠ¸ë“¤
        self.neural_atlas_builder = None
        self.consciousness_analyzer = None
        self.emotion_mapper = None
        self.resonance_mapper = None

        # ì‹œê°í™” ì„¤ì •
        self.brain_template = self._initialize_brain_template()
        self.color_palettes = self._initialize_color_palettes()
        self.visualization_cache = {}

        # ë‡Œ ì˜ì—­ ì¢Œí‘œ ë§¤í•‘
        self.brain_coordinates = self._initialize_brain_coordinates()

        # í™œì„± ì‹œê°í™” ì„¸ì…˜
        self.active_sessions = {}

        print("ğŸ§  Brain Visualization API ì´ˆê¸°í™” ì™„ë£Œ")

    def initialize_components(self, **components):
        """Echo ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.neural_atlas_builder = components.get("neural_atlas_builder")
        self.consciousness_analyzer = components.get("consciousness_analyzer")
        self.emotion_mapper = components.get("emotion_mapper")
        self.resonance_mapper = components.get("resonance_mapper")

        print(
            f"ğŸ”— {len([c for c in [self.neural_atlas_builder, self.consciousness_analyzer, self.emotion_mapper, self.resonance_mapper] if c])} ê°œ ì»´í¬ë„ŒíŠ¸ ì—°ê²° ì™„ë£Œ"
        )

    def _initialize_brain_template(self) -> Dict[str, Any]:
        """ë‡Œ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        return {
            "regions": {
                # ì „ë‘ì—½ (Frontal Lobe)
                "prefrontal_cortex": {
                    "position": (0.0, 0.4, 0.3),
                    "size": 0.2,
                    "color": "#FF6B6B",
                },
                "motor_cortex": {
                    "position": (0.0, 0.1, 0.4),
                    "size": 0.15,
                    "color": "#4ECDC4",
                },
                "broca_area": {
                    "position": (-0.3, 0.2, 0.2),
                    "size": 0.1,
                    "color": "#45B7D1",
                },
                # ë‘ì •ì—½ (Parietal Lobe)
                "somatosensory_cortex": {
                    "position": (0.0, -0.1, 0.4),
                    "size": 0.15,
                    "color": "#96CEB4",
                },
                "posterior_parietal": {
                    "position": (0.0, -0.3, 0.3),
                    "size": 0.12,
                    "color": "#FFEAA7",
                },
                # ì¸¡ë‘ì—½ (Temporal Lobe)
                "auditory_cortex": {
                    "position": (-0.4, 0.0, 0.1),
                    "size": 0.1,
                    "color": "#DDA0DD",
                },
                "wernicke_area": {
                    "position": (-0.35, -0.2, 0.1),
                    "size": 0.08,
                    "color": "#F7DC6F",
                },
                "hippocampus": {
                    "position": (-0.25, -0.1, -0.1),
                    "size": 0.06,
                    "color": "#85C1E9",
                },
                # í›„ë‘ì—½ (Occipital Lobe)
                "visual_cortex": {
                    "position": (0.0, -0.4, 0.2),
                    "size": 0.12,
                    "color": "#F8C471",
                },
                # ë‡Œê°„ (Brainstem)
                "thalamus": {
                    "position": (0.0, 0.0, 0.0),
                    "size": 0.08,
                    "color": "#CD6155",
                },
                "hypothalamus": {
                    "position": (0.0, 0.1, -0.05),
                    "size": 0.05,
                    "color": "#AF7AC5",
                },
                "brainstem": {
                    "position": (0.0, 0.0, -0.3),
                    "size": 0.06,
                    "color": "#5DADE2",
                },
                # ì†Œë‡Œ (Cerebellum)
                "cerebellum": {
                    "position": (0.0, -0.3, -0.2),
                    "size": 0.18,
                    "color": "#58D68D",
                },
                # ë³€ì—°ê³„ (Limbic System)
                "amygdala": {
                    "position": (-0.2, 0.0, -0.05),
                    "size": 0.04,
                    "color": "#EC7063",
                },
                "cingulate_cortex": {
                    "position": (0.0, 0.0, 0.2),
                    "size": 0.1,
                    "color": "#F4D03F",
                },
            },
            "connections": [
                # ì£¼ìš” ì‹ ê²½ ì—°ê²°
                {"from": "prefrontal_cortex", "to": "motor_cortex", "strength": 0.8},
                {"from": "somatosensory_cortex", "to": "motor_cortex", "strength": 0.9},
                {"from": "thalamus", "to": "prefrontal_cortex", "strength": 0.7},
                {"from": "hippocampus", "to": "prefrontal_cortex", "strength": 0.6},
                {"from": "amygdala", "to": "prefrontal_cortex", "strength": 0.5},
                {"from": "visual_cortex", "to": "posterior_parietal", "strength": 0.8},
                {"from": "auditory_cortex", "to": "wernicke_area", "strength": 0.9},
                {"from": "broca_area", "to": "wernicke_area", "strength": 0.7},
            ],
        }

    def _initialize_color_palettes(self) -> Dict[str, List[str]]:
        """ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì´ˆê¸°í™”"""
        return {
            "emotion_flow": ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7"],
            "consciousness_levels": [
                "#2C3E50",
                "#34495E",
                "#7F8C8D",
                "#BDC3C7",
                "#ECF0F1",
                "#F8F9FA",
            ],
            "signature_resonance": [
                "#E74C3C",
                "#F39C12",
                "#F1C40F",
                "#27AE60",
                "#3498DB",
                "#9B59B6",
            ],
            "neural_activity": [
                "#000080",
                "#0066CC",
                "#00AAFF",
                "#66CCFF",
                "#CCEEff",
                "#FFFFFF",
            ],
            "brain_structure": [
                "#8B4513",
                "#D2691E",
                "#DEB887",
                "#F4A460",
                "#FAD5A5",
                "#FFF8DC",
            ],
        }

    def _initialize_brain_coordinates(self) -> Dict[str, BrainCoordinate]:
        """ë‡Œ ì˜ì—­ ì¢Œí‘œ ë§¤í•‘ ì´ˆê¸°í™”"""
        coordinates = {}

        # ì „ë‘ì—½ ì˜ì—­ë“¤
        coordinates["prefrontal_cortex"] = BrainCoordinate(
            0.0, 0.4, 0.3, "prefrontal_cortex", "bilateral"
        )
        coordinates["motor_cortex"] = BrainCoordinate(
            0.0, 0.1, 0.4, "motor_cortex", "bilateral"
        )
        coordinates["broca_area"] = BrainCoordinate(
            -0.3, 0.2, 0.2, "broca_area", "left"
        )

        # ë‘ì •ì—½ ì˜ì—­ë“¤
        coordinates["somatosensory_cortex"] = BrainCoordinate(
            0.0, -0.1, 0.4, "somatosensory_cortex", "bilateral"
        )
        coordinates["posterior_parietal"] = BrainCoordinate(
            0.0, -0.3, 0.3, "posterior_parietal", "bilateral"
        )

        # ì¸¡ë‘ì—½ ì˜ì—­ë“¤
        coordinates["auditory_cortex"] = BrainCoordinate(
            -0.4, 0.0, 0.1, "auditory_cortex", "bilateral"
        )
        coordinates["wernicke_area"] = BrainCoordinate(
            -0.35, -0.2, 0.1, "wernicke_area", "left"
        )
        coordinates["hippocampus"] = BrainCoordinate(
            -0.25, -0.1, -0.1, "hippocampus", "bilateral"
        )

        # í›„ë‘ì—½ ì˜ì—­ë“¤
        coordinates["visual_cortex"] = BrainCoordinate(
            0.0, -0.4, 0.2, "visual_cortex", "bilateral"
        )

        # í”¼ì§ˆí•˜ êµ¬ì¡°ë“¤
        coordinates["thalamus"] = BrainCoordinate(
            0.0, 0.0, 0.0, "thalamus", "bilateral"
        )
        coordinates["hypothalamus"] = BrainCoordinate(
            0.0, 0.1, -0.05, "hypothalamus", "bilateral"
        )
        coordinates["amygdala"] = BrainCoordinate(
            -0.2, 0.0, -0.05, "amygdala", "bilateral"
        )
        coordinates["cerebellum"] = BrainCoordinate(
            0.0, -0.3, -0.2, "cerebellum", "bilateral"
        )

        return coordinates

    def create_visualization(
        self, request: BrainVisualizationRequest
    ) -> BrainVisualizationResponse:
        """ë‡Œ ì‹œê°í™” ìƒì„±"""
        start_time = datetime.now()
        request_id = (
            f"viz_{int(start_time.timestamp())}_{request.visualization_type.value}"
        )

        try:
            # ì‹œê°í™” íƒ€ì…ë³„ ì²˜ë¦¬
            if request.visualization_type == VisualizationType.BRAIN_STRUCTURE:
                visualization_data, elements = (
                    self._create_brain_structure_visualization(request)
                )
            elif request.visualization_type == VisualizationType.NEURAL_ACTIVITY:
                visualization_data, elements = (
                    self._create_neural_activity_visualization(request)
                )
            elif request.visualization_type == VisualizationType.EMOTION_FLOW:
                visualization_data, elements = self._create_emotion_flow_visualization(
                    request
                )
            elif request.visualization_type == VisualizationType.CONSCIOUSNESS_MAP:
                visualization_data, elements = (
                    self._create_consciousness_map_visualization(request)
                )
            elif request.visualization_type == VisualizationType.SIGNATURE_RESONANCE:
                visualization_data, elements = (
                    self._create_signature_resonance_visualization(request)
                )
            else:
                visualization_data, elements = self._create_default_visualization(
                    request
                )

            # ë Œë”ë§ í¬ë§· ì ìš©
            rendered_data = self._apply_render_format(
                visualization_data, elements, request.render_format
            )

            generation_time = (datetime.now() - start_time).total_seconds() * 1000

            response = BrainVisualizationResponse(
                request_id=request_id,
                timestamp=datetime.now(),
                visualization_data=rendered_data,
                render_format=request.render_format,
                elements=elements,
                metadata={
                    "signature_context": request.signature_context,
                    "resolution": request.resolution,
                    "element_count": len(elements),
                    "visualization_type": request.visualization_type.value,
                },
                generation_time_ms=generation_time,
            )

            # ìºì‹œì— ì €ì¥
            if not request.real_time:
                self.visualization_cache[request_id] = response

            return response

        except Exception as e:
            self.logger.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‹œê°í™” ë°˜í™˜
            return self._create_error_visualization(request_id, str(e))

    def _create_brain_structure_visualization(
        self, request: BrainVisualizationRequest
    ) -> Tuple[Dict[str, Any], List[VisualizationElement]]:
        """ë‡Œ êµ¬ì¡° ì‹œê°í™” ìƒì„±"""
        elements = []

        # ê¸°ë³¸ ë‡Œ êµ¬ì¡° ì‹œê°í™”
        for region_name, region_data in self.brain_template["regions"].items():
            element = VisualizationElement(
                element_id=f"region_{region_name}",
                element_type="region",
                position=region_data["position"],
                size=region_data["size"],
                color=region_data["color"],
                intensity=0.8,
                metadata={"region_name": region_name, "type": "brain_region"},
            )
            elements.append(element)

        # ì‹ ê²½ ì—°ê²° ì¶”ê°€
        for i, connection in enumerate(self.brain_template["connections"]):
            from_region = self.brain_template["regions"].get(connection["from"])
            to_region = self.brain_template["regions"].get(connection["to"])

            if from_region and to_region:
                # ì—°ê²°ì„  ì¤‘ì  ê³„ì‚°
                mid_point = (
                    (from_region["position"][0] + to_region["position"][0]) / 2,
                    (from_region["position"][1] + to_region["position"][1]) / 2,
                    (from_region["position"][2] + to_region["position"][2]) / 2,
                )

                element = VisualizationElement(
                    element_id=f"connection_{i}",
                    element_type="connection",
                    position=mid_point,
                    size=0.02,
                    color="#CCCCCC",
                    intensity=connection["strength"],
                    metadata={
                        "from": connection["from"],
                        "to": connection["to"],
                        "strength": connection["strength"],
                    },
                )
                elements.append(element)

        visualization_data = {
            "type": "brain_structure",
            "regions": len(self.brain_template["regions"]),
            "connections": len(self.brain_template["connections"]),
            "signature": request.signature_context,
        }

        return visualization_data, elements

    def _create_neural_activity_visualization(
        self, request: BrainVisualizationRequest
    ) -> Tuple[Dict[str, Any], List[VisualizationElement]]:
        """ì‹ ê²½ í™œë™ ì‹œê°í™” ìƒì„±"""
        elements = []

        # ê¸°ë³¸ ë‡Œ êµ¬ì¡°ì— í™œë™ ë°ì´í„° ì˜¤ë²„ë ˆì´
        for region_name, region_data in self.brain_template["regions"].items():
            # ëª¨ì˜ ì‹ ê²½ í™œë™ ë°ì´í„° ìƒì„±
            activity_level = np.random.uniform(0.2, 1.0)

            # í™œë™ ìˆ˜ì¤€ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€í™”
            base_color = region_data["color"]
            intensity_color = self._apply_activity_intensity(base_color, activity_level)

            element = VisualizationElement(
                element_id=f"activity_{region_name}",
                element_type="region",
                position=region_data["position"],
                size=region_data["size"]
                * (0.8 + 0.4 * activity_level),  # í™œë™ì— ë”°ë¥¸ í¬ê¸° ë³€í™”
                color=intensity_color,
                intensity=activity_level,
                metadata={
                    "region_name": region_name,
                    "activity_level": activity_level,
                    "type": "neural_activity",
                },
            )
            elements.append(element)

        # í™œì„± ì—°ê²° ì‹œê°í™”
        for i, connection in enumerate(self.brain_template["connections"]):
            activity_strength = np.random.uniform(0.1, connection["strength"])

            from_region = self.brain_template["regions"].get(connection["from"])
            to_region = self.brain_template["regions"].get(connection["to"])

            if from_region and to_region:
                mid_point = (
                    (from_region["position"][0] + to_region["position"][0]) / 2,
                    (from_region["position"][1] + to_region["position"][1]) / 2,
                    (from_region["position"][2] + to_region["position"][2]) / 2,
                )

                element = VisualizationElement(
                    element_id=f"active_connection_{i}",
                    element_type="connection",
                    position=mid_point,
                    size=0.02 * (1 + activity_strength),
                    color=self._activity_color(activity_strength),
                    intensity=activity_strength,
                    metadata={
                        "from": connection["from"],
                        "to": connection["to"],
                        "activity_strength": activity_strength,
                        "type": "active_connection",
                    },
                )
                elements.append(element)

        visualization_data = {
            "type": "neural_activity",
            "timestamp": datetime.now().isoformat(),
            "average_activity": np.mean(
                [e.intensity for e in elements if e.element_type == "region"]
            ),
            "signature": request.signature_context,
        }

        return visualization_data, elements

    def _create_emotion_flow_visualization(
        self, request: BrainVisualizationRequest
    ) -> Tuple[Dict[str, Any], List[VisualizationElement]]:
        """ê°ì • íë¦„ ì‹œê°í™” ìƒì„±"""
        elements = []

        # ê°ì • ê´€ë ¨ ë‡Œ ì˜ì—­ë“¤
        emotion_regions = [
            "amygdala",
            "hippocampus",
            "prefrontal_cortex",
            "cingulate_cortex",
            "hypothalamus",
        ]
        emotion_colors = self.color_palettes["emotion_flow"]

        for i, region_name in enumerate(emotion_regions):
            if region_name in self.brain_template["regions"]:
                region_data = self.brain_template["regions"][region_name]
                emotion_intensity = np.random.uniform(0.3, 1.0)

                element = VisualizationElement(
                    element_id=f"emotion_{region_name}",
                    element_type="region",
                    position=region_data["position"],
                    size=region_data["size"] * (1 + 0.5 * emotion_intensity),
                    color=emotion_colors[i % len(emotion_colors)],
                    intensity=emotion_intensity,
                    metadata={
                        "region_name": region_name,
                        "emotion_type": ["joy", "fear", "anger", "sadness", "surprise"][
                            i % 5
                        ],
                        "emotion_intensity": emotion_intensity,
                    },
                )
                elements.append(element)

        # ê°ì • íë¦„ ê²½ë¡œ ì‹œê°í™”
        emotion_pathways = [
            ("amygdala", "prefrontal_cortex"),
            ("hippocampus", "amygdala"),
            ("hypothalamus", "cingulate_cortex"),
        ]

        for i, (from_region, to_region) in enumerate(emotion_pathways):
            from_data = self.brain_template["regions"].get(from_region)
            to_data = self.brain_template["regions"].get(to_region)

            if from_data and to_data:
                flow_strength = np.random.uniform(0.4, 0.9)

                # íë¦„ ë°©í–¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì—¬ëŸ¬ ì ë“¤
                for j in range(3):
                    t = (j + 1) / 4  # 0.25, 0.5, 0.75
                    flow_point = (
                        from_data["position"][0]
                        + t * (to_data["position"][0] - from_data["position"][0]),
                        from_data["position"][1]
                        + t * (to_data["position"][1] - from_data["position"][1]),
                        from_data["position"][2]
                        + t * (to_data["position"][2] - from_data["position"][2]),
                    )

                    element = VisualizationElement(
                        element_id=f"flow_{i}_{j}",
                        element_type="flow",
                        position=flow_point,
                        size=0.03 * flow_strength,
                        color=emotion_colors[i % len(emotion_colors)],
                        intensity=flow_strength * (1 - 0.2 * j),  # ì ì§„ì  ê°ì†Œ
                        metadata={
                            "pathway": f"{from_region} -> {to_region}",
                            "flow_strength": flow_strength,
                            "flow_position": t,
                        },
                    )
                    elements.append(element)

        visualization_data = {
            "type": "emotion_flow",
            "emotion_regions": len(emotion_regions),
            "flow_pathways": len(emotion_pathways),
            "average_emotion_intensity": np.mean(
                [e.intensity for e in elements if e.element_type == "region"]
            ),
            "signature": request.signature_context,
        }

        return visualization_data, elements

    def _create_consciousness_map_visualization(
        self, request: BrainVisualizationRequest
    ) -> Tuple[Dict[str, Any], List[VisualizationElement]]:
        """ì˜ì‹ ë§µ ì‹œê°í™” ìƒì„±"""
        elements = []

        # ì˜ì‹ ìˆ˜ì¤€ë³„ ìƒ‰ìƒ
        consciousness_colors = self.color_palettes["consciousness_levels"]

        # ì˜ì‹ê³¼ ê´€ë ¨ëœ ë‡Œ ì˜ì—­ë“¤ê³¼ ìˆ˜ì¤€
        consciousness_mapping = {
            "brainstem": 0,  # ë¬´ì˜ì‹
            "thalamus": 1,  # ì „ì˜ì‹
            "cingulate_cortex": 2,  # ì˜ì‹
            "prefrontal_cortex": 3,  # ìê°
            "posterior_parietal": 4,  # ê³ ì°¨ ì¸ì‹
            "motor_cortex": 2,  # ì˜ì‹ (ìš´ë™ ì œì–´)
        }

        for region_name, consciousness_level in consciousness_mapping.items():
            if region_name in self.brain_template["regions"]:
                region_data = self.brain_template["regions"][region_name]

                # ì˜ì‹ ìˆ˜ì¤€ì— ë”°ë¥¸ í™œì„±ë„
                consciousness_intensity = (consciousness_level + 1) / 6  # 0~1 ì •ê·œí™”

                element = VisualizationElement(
                    element_id=f"consciousness_{region_name}",
                    element_type="region",
                    position=region_data["position"],
                    size=region_data["size"] * (0.7 + 0.6 * consciousness_intensity),
                    color=consciousness_colors[consciousness_level],
                    intensity=consciousness_intensity,
                    metadata={
                        "region_name": region_name,
                        "consciousness_level": consciousness_level,
                        "consciousness_name": [
                            "Unconscious",
                            "Preconscious",
                            "Conscious",
                            "Self-aware",
                            "Meta-conscious",
                            "Hyperconscious",
                        ][consciousness_level],
                        "type": "consciousness_region",
                    },
                )
                elements.append(element)

        # ì˜ì‹ íë¦„ ì—°ê²°
        consciousness_flows = [
            ("brainstem", "thalamus", 0.6),
            ("thalamus", "cingulate_cortex", 0.7),
            ("cingulate_cortex", "prefrontal_cortex", 0.8),
            ("prefrontal_cortex", "posterior_parietal", 0.9),
        ]

        for i, (from_region, to_region, flow_strength) in enumerate(
            consciousness_flows
        ):
            from_data = self.brain_template["regions"].get(from_region)
            to_data = self.brain_template["regions"].get(to_region)

            if from_data and to_data:
                mid_point = (
                    (from_data["position"][0] + to_data["position"][0]) / 2,
                    (from_data["position"][1] + to_data["position"][1]) / 2,
                    (from_data["position"][2] + to_data["position"][2]) / 2,
                )

                element = VisualizationElement(
                    element_id=f"consciousness_flow_{i}",
                    element_type="flow",
                    position=mid_point,
                    size=0.04 * flow_strength,
                    color="#FFD700",  # í™©ê¸ˆìƒ‰ìœ¼ë¡œ ì˜ì‹ íë¦„ í‘œí˜„
                    intensity=flow_strength,
                    metadata={
                        "from": from_region,
                        "to": to_region,
                        "consciousness_flow": flow_strength,
                        "type": "consciousness_connection",
                    },
                )
                elements.append(element)

        visualization_data = {
            "type": "consciousness_map",
            "consciousness_regions": len(consciousness_mapping),
            "consciousness_flows": len(consciousness_flows),
            "average_consciousness_level": np.mean(
                list(consciousness_mapping.values())
            ),
            "signature": request.signature_context,
        }

        return visualization_data, elements

    def _create_signature_resonance_visualization(
        self, request: BrainVisualizationRequest
    ) -> Tuple[Dict[str, Any], List[VisualizationElement]]:
        """ì‹œê·¸ë‹ˆì²˜ ê³µëª… ì‹œê°í™” ìƒì„±"""
        elements = []

        # ì‹œê·¸ë‹ˆì²˜ë³„ íŠ¹ì„±í™”ëœ ë‡Œ ì˜ì—­ë“¤
        signature_brain_mapping = {
            "aurora": ["amygdala", "hippocampus", "cingulate_cortex"],  # ê°ì •ì , ì°½ì¡°ì 
            "phoenix": [
                "prefrontal_cortex",
                "motor_cortex",
                "posterior_parietal",
            ],  # ë³€í™”ì§€í–¥, ì‹¤í–‰ë ¥
            "sage": [
                "prefrontal_cortex",
                "visual_cortex",
                "wernicke_area",
            ],  # ë¶„ì„ì , ì§€í˜œ
            "companion": ["cingulate_cortex", "amygdala", "broca_area"],  # ê³µê°ì , ì†Œí†µ
        }

        # í˜„ì¬ ì‹œê·¸ë‹ˆì²˜ ë˜ëŠ” ê¸°ë³¸ê°’
        current_signature = (
            request.signature_context.lower() if request.signature_context else "aurora"
        )
        signature_regions = signature_brain_mapping.get(
            current_signature, signature_brain_mapping["aurora"]
        )

        # ì‹œê·¸ë‹ˆì²˜ ìƒ‰ìƒ
        signature_colors = self.color_palettes["signature_resonance"]
        signature_color = signature_colors[
            list(signature_brain_mapping.keys()).index(current_signature)
            % len(signature_colors)
        ]

        # ì‹œê·¸ë‹ˆì²˜ íŠ¹í™” ì˜ì—­ ì‹œê°í™”
        for i, region_name in enumerate(signature_regions):
            if region_name in self.brain_template["regions"]:
                region_data = self.brain_template["regions"][region_name]
                resonance_strength = np.random.uniform(0.6, 1.0)

                element = VisualizationElement(
                    element_id=f"signature_{region_name}",
                    element_type="region",
                    position=region_data["position"],
                    size=region_data["size"] * (1.2 + 0.3 * resonance_strength),
                    color=signature_color,
                    intensity=resonance_strength,
                    metadata={
                        "region_name": region_name,
                        "signature": current_signature,
                        "resonance_strength": resonance_strength,
                        "signature_affinity": ["high", "medium", "low"][i % 3],
                    },
                )
                elements.append(element)

        # ì‹œê·¸ë‹ˆì²˜ ê°„ ê³µëª… ì—°ê²°
        for i in range(len(signature_regions) - 1):
            region1 = signature_regions[i]
            region2 = signature_regions[i + 1]

            data1 = self.brain_template["regions"].get(region1)
            data2 = self.brain_template["regions"].get(region2)

            if data1 and data2:
                resonance_strength = np.random.uniform(0.5, 0.9)

                mid_point = (
                    (data1["position"][0] + data2["position"][0]) / 2,
                    (data1["position"][1] + data2["position"][1]) / 2,
                    (data1["position"][2] + data2["position"][2]) / 2,
                )

                element = VisualizationElement(
                    element_id=f"resonance_{i}",
                    element_type="connection",
                    position=mid_point,
                    size=0.05 * resonance_strength,
                    color=signature_color,
                    intensity=resonance_strength,
                    metadata={
                        "from": region1,
                        "to": region2,
                        "resonance_type": "signature_coupling",
                        "resonance_strength": resonance_strength,
                    },
                )
                elements.append(element)

        visualization_data = {
            "type": "signature_resonance",
            "active_signature": current_signature,
            "signature_regions": len(signature_regions),
            "resonance_connections": len(signature_regions) - 1,
            "average_resonance": np.mean([e.intensity for e in elements]),
            "signature_color": signature_color,
        }

        return visualization_data, elements

    def _create_default_visualization(
        self, request: BrainVisualizationRequest
    ) -> Tuple[Dict[str, Any], List[VisualizationElement]]:
        """ê¸°ë³¸ ì‹œê°í™” ìƒì„±"""
        return self._create_brain_structure_visualization(request)

    def _apply_render_format(
        self,
        visualization_data: Dict[str, Any],
        elements: List[VisualizationElement],
        format_type: RenderFormat,
    ) -> Union[str, Dict[str, Any]]:
        """ë Œë”ë§ í¬ë§· ì ìš©"""
        if format_type == RenderFormat.JSON_DATA:
            return {
                "visualization_data": visualization_data,
                "elements": [asdict(e) for e in elements],
            }
        elif format_type == RenderFormat.ASCII:
            return self._render_ascii_brain(elements)
        elif format_type == RenderFormat.SVG:
            return self._render_svg_brain(elements)
        elif format_type == RenderFormat.HTML_CANVAS:
            return self._render_html_canvas(elements)
        else:
            return visualization_data

    def _render_ascii_brain(self, elements: List[VisualizationElement]) -> str:
        """ASCII ì•„íŠ¸ë¡œ ë‡Œ ë Œë”ë§"""
        # ê°„ë‹¨í•œ 2D í‰ë©´ íˆ¬ì˜
        width, height = 80, 40
        canvas = [[" " for _ in range(width)] for _ in range(height)]

        for element in elements:
            if element.element_type == "region":
                # 3D ì¢Œí‘œë¥¼ 2Dë¡œ íˆ¬ì˜
                x = int((element.position[0] + 0.5) * width)
                y = int((element.position[1] + 0.5) * height)

                x = max(0, min(width - 1, x))
                y = max(0, min(height - 1, y))

                # ê°•ë„ì— ë”°ë¥¸ ë¬¸ì ì„ íƒ
                intensity_chars = [".", "o", "O", "@", "#"]
                char_index = int(element.intensity * (len(intensity_chars) - 1))
                canvas[y][x] = intensity_chars[char_index]

        # ASCII ì•„íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜
        ascii_art = "ğŸ§  Echo Brain ASCII Visualization\n"
        ascii_art += "=" * width + "\n"
        for row in canvas:
            ascii_art += "".join(row) + "\n"
        ascii_art += "=" * width

        return ascii_art

    def _render_svg_brain(self, elements: List[VisualizationElement]) -> str:
        """SVGë¡œ ë‡Œ ë Œë”ë§"""
        svg_width, svg_height = 800, 600

        svg = f'<svg width="{svg_width}" height="{svg_height}" xmlns="http://www.w3.org/2000/svg">\n'
        svg += f'<rect width="100%" height="100%" fill="#000020"/>\n'
        svg += f'<text x="10" y="30" fill="white" font-family="Arial" font-size="20">ğŸ§  Echo Brain Visualization</text>\n'

        for element in elements:
            # 3D to 2D íˆ¬ì˜
            x = (element.position[0] + 0.5) * svg_width
            y = (element.position[1] + 0.5) * svg_height

            if element.element_type == "region":
                radius = element.size * 100
                opacity = element.intensity

                svg += f'<circle cx="{x}" cy="{y}" r="{radius}" fill="{element.color}" opacity="{opacity}"/>\n'
            elif element.element_type == "connection":
                radius = element.size * 50
                opacity = element.intensity * 0.7

                svg += f'<circle cx="{x}" cy="{y}" r="{radius}" fill="{element.color}" opacity="{opacity}"/>\n'

        svg += "</svg>"
        return svg

    def _render_html_canvas(self, elements: List[VisualizationElement]) -> str:
        """HTML Canvasë¡œ ë‡Œ ë Œë”ë§"""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>Echo Brain Visualization</title>
            <style>
                body { margin: 0; padding: 20px; background: #001122; color: white; font-family: Arial, sans-serif; }
                canvas { border: 1px solid #333; background: #000; }
            </style>
        </head>
        <body>
            <h1>ğŸ§  Echo Brain Visualization</h1>
            <canvas id="brainCanvas" width="800" height="600"></canvas>
            <script>
                const canvas = document.getElementById('brainCanvas');
                const ctx = canvas.getContext('2d');

                // Clear canvas
                ctx.fillStyle = '#000020';
                ctx.fillRect(0, 0, canvas.width, canvas.height);

                // Draw elements
        """

        for element in elements:
            x = (element.position[0] + 0.5) * 800
            y = (element.position[1] + 0.5) * 600

            if element.element_type == "region":
                radius = element.size * 100
                html += f"""
                ctx.beginPath();
                ctx.arc({x}, {y}, {radius}, 0, 2 * Math.PI);
                ctx.fillStyle = '{element.color}';
                ctx.globalAlpha = {element.intensity};
                ctx.fill();
                """

        html += """
            </script>
        </body>
        </html>
        """

        return html

    def _apply_activity_intensity(self, base_color: str, intensity: float) -> str:
        """í™œë™ ê°•ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€í™”"""
        # ê°„ë‹¨í•œ ë°ê¸° ì¡°ì ˆ
        if base_color.startswith("#"):
            r = int(base_color[1:3], 16)
            g = int(base_color[3:5], 16)
            b = int(base_color[5:7], 16)

            # ê°•ë„ì— ë”°ë¼ ë°ê¸° ì¦ê°€
            r = min(255, int(r * (0.5 + 0.5 * intensity)))
            g = min(255, int(g * (0.5 + 0.5 * intensity)))
            b = min(255, int(b * (0.5 + 0.5 * intensity)))

            return f"#{r:02x}{g:02x}{b:02x}"

        return base_color

    def _activity_color(self, activity_strength: float) -> str:
        """í™œë™ ê°•ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
        colors = ["#0066CC", "#00AAFF", "#66CCFF", "#CCEEFF", "#FFFFFF"]
        index = int(activity_strength * (len(colors) - 1))
        return colors[index]

    def _create_error_visualization(
        self, request_id: str, error_message: str
    ) -> BrainVisualizationResponse:
        """ì˜¤ë¥˜ ì‹œê°í™” ìƒì„±"""
        error_element = VisualizationElement(
            element_id="error_indicator",
            element_type="marker",
            position=(0.0, 0.0, 0.0),
            size=0.1,
            color="#FF0000",
            intensity=1.0,
            metadata={"error": error_message},
        )

        return BrainVisualizationResponse(
            request_id=request_id,
            timestamp=datetime.now(),
            visualization_data={"error": error_message},
            render_format=RenderFormat.JSON_DATA,
            elements=[error_element],
            metadata={"status": "error"},
            generation_time_ms=0.0,
        )

    def get_visualization_session(
        self, session_id: str
    ) -> Optional[BrainVisualizationResponse]:
        """ì‹œê°í™” ì„¸ì…˜ ì¡°íšŒ"""
        return self.visualization_cache.get(session_id)

    def list_active_visualizations(self) -> List[str]:
        """í™œì„± ì‹œê°í™” ëª©ë¡ ë°˜í™˜"""
        return list(self.visualization_cache.keys())

    def clear_visualization_cache(self):
        """ì‹œê°í™” ìºì‹œ ì •ë¦¬"""
        self.visualization_cache.clear()

    def get_brain_region_info(self, region_name: str) -> Optional[Dict[str, Any]]:
        """ë‡Œ ì˜ì—­ ì •ë³´ ì¡°íšŒ"""
        if region_name in self.brain_template["regions"]:
            region_data = self.brain_template["regions"][region_name]
            coordinate = self.brain_coordinates.get(region_name)

            return {
                "name": region_name,
                "position": region_data["position"],
                "size": region_data["size"],
                "color": region_data["color"],
                "coordinate": asdict(coordinate) if coordinate else None,
                "functions": self._get_region_functions(region_name),
            }
        return None

    def _get_region_functions(self, region_name: str) -> List[str]:
        """ë‡Œ ì˜ì—­ì˜ ê¸°ëŠ¥ ë°˜í™˜"""
        function_mapping = {
            "prefrontal_cortex": [
                "executive_control",
                "decision_making",
                "working_memory",
                "planning",
            ],
            "motor_cortex": ["motor_control", "movement_planning", "motor_learning"],
            "somatosensory_cortex": [
                "touch_processing",
                "proprioception",
                "tactile_discrimination",
            ],
            "visual_cortex": [
                "visual_processing",
                "pattern_recognition",
                "visual_attention",
            ],
            "auditory_cortex": [
                "sound_processing",
                "pitch_recognition",
                "auditory_attention",
            ],
            "hippocampus": ["memory_formation", "spatial_navigation", "learning"],
            "amygdala": ["emotion_processing", "fear_response", "threat_detection"],
            "thalamus": ["sensory_relay", "attention_regulation", "consciousness"],
            "cerebellum": [
                "motor_coordination",
                "balance",
                "motor_learning",
                "cognitive_coordination",
            ],
        }

        return function_mapping.get(region_name, ["unknown_function"])


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_brain_visualization_api() -> BrainVisualizationAPI:
    """Brain Visualization API ìƒì„±"""
    return BrainVisualizationAPI()


def create_brain_structure_request(
    signature: str = "aurora", resolution: Tuple[int, int] = (800, 600)
) -> BrainVisualizationRequest:
    """ë‡Œ êµ¬ì¡° ì‹œê°í™” ìš”ì²­ ìƒì„±"""
    return BrainVisualizationRequest(
        visualization_type=VisualizationType.BRAIN_STRUCTURE,
        render_format=RenderFormat.SVG,
        signature_context=signature,
        time_range=None,
        resolution=resolution,
        style_options={},
        real_time=False,
    )


def create_neural_activity_request(
    signature: str = "aurora", real_time: bool = True
) -> BrainVisualizationRequest:
    """ì‹ ê²½ í™œë™ ì‹œê°í™” ìš”ì²­ ìƒì„±"""
    return BrainVisualizationRequest(
        visualization_type=VisualizationType.NEURAL_ACTIVITY,
        render_format=RenderFormat.JSON_DATA,
        signature_context=signature,
        time_range=None,
        resolution=(800, 600),
        style_options={"show_connections": True},
        real_time=real_time,
    )


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§  Brain Visualization API í…ŒìŠ¤íŠ¸...")

    api = BrainVisualizationAPI()

    # ë‡Œ êµ¬ì¡° ì‹œê°í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ” Brain Structure Visualization í…ŒìŠ¤íŠ¸...")
    structure_request = create_brain_structure_request("aurora")
    structure_response = api.create_visualization(structure_request)

    print(f"ğŸ“Š Structure Visualization:")
    print(f"   Request ID: {structure_response.request_id}")
    print(f"   Elements: {len(structure_response.elements)}")
    print(f"   Generation Time: {structure_response.generation_time_ms:.2f}ms")
    print(f"   Render Format: {structure_response.render_format.value}")

    # ì‹ ê²½ í™œë™ ì‹œê°í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ” Neural Activity Visualization í…ŒìŠ¤íŠ¸...")
    activity_request = create_neural_activity_request("phoenix", real_time=True)
    activity_response = api.create_visualization(activity_request)

    print(f"ğŸ“Š Activity Visualization:")
    print(f"   Request ID: {activity_response.request_id}")
    print(f"   Elements: {len(activity_response.elements)}")
    print(f"   Generation Time: {activity_response.generation_time_ms:.2f}ms")
    print(
        f"   Average Activity: {activity_response.metadata.get('average_activity', 'N/A')}"
    )

    # ê°ì • íë¦„ ì‹œê°í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ” Emotion Flow Visualization í…ŒìŠ¤íŠ¸...")
    emotion_request = BrainVisualizationRequest(
        visualization_type=VisualizationType.EMOTION_FLOW,
        render_format=RenderFormat.ASCII,
        signature_context="aurora",
        time_range=None,
        resolution=(80, 40),
        style_options={},
        real_time=False,
    )
    emotion_response = api.create_visualization(emotion_request)

    print(f"ğŸ“Š Emotion Flow Visualization:")
    print(f"   Request ID: {emotion_response.request_id}")
    print(f"   Elements: {len(emotion_response.elements)}")

    # ASCII ì•„íŠ¸ ì¶œë ¥ (ì¼ë¶€)
    if isinstance(emotion_response.visualization_data, str):
        print("ğŸ¨ ASCII Brain Preview:")
        lines = emotion_response.visualization_data.split("\n")[:10]
        for line in lines:
            print(f"   {line}")

    # ì˜ì‹ ë§µ ì‹œê°í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ” Consciousness Map Visualization í…ŒìŠ¤íŠ¸...")
    consciousness_request = BrainVisualizationRequest(
        visualization_type=VisualizationType.CONSCIOUSNESS_MAP,
        render_format=RenderFormat.JSON_DATA,
        signature_context="sage",
        time_range=None,
        resolution=(800, 600),
        style_options={},
        real_time=False,
    )
    consciousness_response = api.create_visualization(consciousness_request)

    print(f"ğŸ“Š Consciousness Map:")
    print(f"   Request ID: {consciousness_response.request_id}")
    print(f"   Elements: {len(consciousness_response.elements)}")
    if isinstance(consciousness_response.visualization_data, dict):
        print(
            f"   Consciousness Regions: {consciousness_response.visualization_data.get('consciousness_regions', 'N/A')}"
        )
        print(
            f"   Average Level: {consciousness_response.visualization_data.get('average_consciousness_level', 'N/A')}"
        )

    # ì‹œê·¸ë‹ˆì²˜ ê³µëª… ì‹œê°í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ” Signature Resonance Visualization í…ŒìŠ¤íŠ¸...")
    resonance_request = BrainVisualizationRequest(
        visualization_type=VisualizationType.SIGNATURE_RESONANCE,
        render_format=RenderFormat.JSON_DATA,
        signature_context="companion",
        time_range=None,
        resolution=(800, 600),
        style_options={},
        real_time=False,
    )
    resonance_response = api.create_visualization(resonance_request)

    print(f"ğŸ“Š Signature Resonance:")
    print(f"   Request ID: {resonance_response.request_id}")
    print(f"   Elements: {len(resonance_response.elements)}")
    if isinstance(resonance_response.visualization_data, dict):
        print(
            f"   Active Signature: {resonance_response.visualization_data.get('active_signature', 'N/A')}"
        )
        print(
            f"   Average Resonance: {resonance_response.visualization_data.get('average_resonance', 'N/A'):.3f}"
        )

    # ë‡Œ ì˜ì—­ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print("\nğŸ” Brain Region Info í…ŒìŠ¤íŠ¸...")
    region_info = api.get_brain_region_info("prefrontal_cortex")
    if region_info:
        print(f"ğŸ“ Prefrontal Cortex Info:")
        print(f"   Position: {region_info['position']}")
        print(f"   Functions: {', '.join(region_info['functions'][:3])}...")
        if region_info["coordinate"]:
            coord = region_info["coordinate"]
            print(f"   Hemisphere: {coord['hemisphere']}")

    # í™œì„± ì‹œê°í™” ëª©ë¡
    print(f"\nğŸ“‹ Active Visualizations: {len(api.list_active_visualizations())}")
    for viz_id in api.list_active_visualizations()[:3]:
        print(f"   - {viz_id}")

    # ìºì‹œ ì •ë¦¬
    api.clear_visualization_cache()
    print(
        f"ğŸ§¹ Cache cleared. Active Visualizations: {len(api.list_active_visualizations())}"
    )

    print("\nâœ… Brain Visualization API í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
