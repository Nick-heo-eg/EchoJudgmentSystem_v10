"""
Score Model - T/S/P ì ìˆ˜ ê³„ì‚° ì—”ì§„
===============================

Technical, Strategic, Potential ê°€ì¹˜ ì ìˆ˜ ê³„ì‚°
"""

from typing import Tuple, Dict, Any
from echo_engine.inspectors.asset_value_judger.schemas import AssetMetrics


def compute_tsp_scores(
    file_path: str, metrics: AssetMetrics, weights: Dict[str, Any]
) -> Tuple[float, float, float, float]:
    """
    T/S/P ì ìˆ˜ ê³„ì‚°

    Args:
        file_path: íŒŒì¼ ê²½ë¡œ
        metrics: ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­
        weights: ê°€ì¤‘ì¹˜ ì„¤ì •

    Returns:
        Tuple[Tì ìˆ˜, Sì ìˆ˜, Pì ìˆ˜, ì´ì ]
    """

    # T (Technical Value) ê³„ì‚°
    t_score = _compute_technical_score(file_path, metrics, weights.get("T", {}))

    # S (Strategic Value) ê³„ì‚°
    s_score = _compute_strategic_score(file_path, metrics, weights.get("S", {}))

    # P (Potential Value) ê³„ì‚°
    p_score = _compute_potential_score(file_path, metrics, weights.get("P", {}))

    # ì´ì  ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    total_weights = weights.get("total_weights", {"T": 0.4, "S": 0.4, "P": 0.2})
    total_score = (
        t_score * total_weights.get("T", 0.4)
        + s_score * total_weights.get("S", 0.4)
        + p_score * total_weights.get("P", 0.2)
    )

    return t_score, s_score, p_score, total_score


def _compute_technical_score(
    file_path: str, metrics: AssetMetrics, weights: Dict[str, float]
) -> float:
    """
    Technical Value (ê¸°ìˆ ì  ê°€ì¹˜) ê³„ì‚°
    - ê³ ìœ ì„±: ë‹¤ë¥¸ ì½”ë“œì™€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ì •ë„
    - ì¬í˜„ ë‚œì´ë„: ë‹¤ì‹œ ë§Œë“¤ê¸° ì–´ë ¤ìš´ ì •ë„
    - ë³µì¡ë„ ê°€ì¹˜: ì˜ë¯¸ ìˆëŠ” ë³µì¡í•œ êµ¬í˜„
    - ì˜ì¡´ì„± ì˜í–¥ë„: ë‹¤ë¥¸ ëª¨ë“ˆë“¤ì´ ì˜ì¡´í•˜ëŠ” ì •ë„
    """

    # ê¸°ë³¸ ê°€ì¤‘ì¹˜
    w = {
        "uniqueness": weights.get("uniqueness", 0.3),
        "rebuild_cost": weights.get("rebuild_cost", 0.3),
        "complexity": weights.get("complexity", 0.2),
        "dependency": weights.get("dependency", 0.2),
    }

    # 1. ê³ ìœ ì„± ì ìˆ˜ (0-100)
    uniqueness_score = _calculate_uniqueness(file_path, metrics)

    # 2. ì¬í˜„ ë‚œì´ë„ ì ìˆ˜ (0-100)
    rebuild_cost_score = _calculate_rebuild_cost(file_path, metrics)

    # 3. ë³µì¡ë„ ê°€ì¹˜ ì ìˆ˜ (0-100)
    complexity_score = _calculate_complexity_value(metrics)

    # 4. ì˜ì¡´ì„± ì˜í–¥ë„ ì ìˆ˜ (0-100)
    dependency_score = _calculate_dependency_impact(metrics)

    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    total_score = (
        uniqueness_score * w["uniqueness"]
        + rebuild_cost_score * w["rebuild_cost"]
        + complexity_score * w["complexity"]
        + dependency_score * w["dependency"]
    )

    return min(max(total_score, 0), 100)


def _compute_strategic_score(
    file_path: str, metrics: AssetMetrics, weights: Dict[str, float]
) -> float:
    """
    Strategic Value (ì „ëµì  ê°€ì¹˜) ê³„ì‚°
    - Echo ì² í•™ ì í•©ì„±: Echo ì‹œìŠ¤í…œ ì² í•™ê³¼ì˜ ë¶€í•©ë„
    - ë¡œë“œë§µ ë§¤ì¹­: í–¥í›„ ê³„íšê³¼ì˜ ì—°ê´€ì„±
    - ê²½ìŸë ¥ ì°¨ë³„ì : ë‹¤ë¥¸ ì‹œìŠ¤í…œê³¼ì˜ ì°¨ë³„í™”
    """

    # ê¸°ë³¸ ê°€ì¤‘ì¹˜
    w = {
        "philosophy": weights.get("philosophy", 0.4),
        "roadmap": weights.get("roadmap", 0.4),
        "edge": weights.get("edge", 0.2),
    }

    # 1. Echo ì² í•™ ì í•©ì„± (0-100)
    philosophy_score = _calculate_echo_philosophy_fit(file_path, metrics)

    # 2. ë¡œë“œë§µ ë§¤ì¹­ ì ìˆ˜ (0-100)
    roadmap_score = _calculate_roadmap_match(metrics)

    # 3. ê²½ìŸë ¥ ì°¨ë³„ì  (0-100)
    edge_score = _calculate_competitive_edge(file_path, metrics)

    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    total_score = (
        philosophy_score * w["philosophy"]
        + roadmap_score * w["roadmap"]
        + edge_score * w["edge"]
    )

    return min(max(total_score, 0), 100)


def _compute_potential_score(
    file_path: str, metrics: AssetMetrics, weights: Dict[str, float]
) -> float:
    """
    Potential Value (í™œìš© ì ì¬ë ¥) ê³„ì‚°
    - ë¸Œë¦¿ì§€ ì—°ê²° ê°€ëŠ¥ì„±: ì‰½ê²Œ ì™¸ë¶€ ì—°ê²° ê°€ëŠ¥í•œ ì •ë„
    - ë„ë©”ì¸ ì¬ì‚¬ìš©ì„±: ë‹¤ë¥¸ ë¶„ì•¼ì—ì„œ í™œìš© ê°€ëŠ¥ì„±
    - í™œì„±í™” ìš©ì´ì„±: ë°ì´í„°ë‚˜ UIë§Œ ë¶™ì´ë©´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
    """

    # ê¸°ë³¸ ê°€ì¤‘ì¹˜
    w = {
        "bridge": weights.get("bridge", 0.4),
        "reuse": weights.get("reuse", 0.3),
        "activation": weights.get("activation", 0.3),
    }

    # 1. ë¸Œë¦¿ì§€ ì—°ê²° ì¤€ë¹„ë„ (0-100)
    bridge_score = _calculate_bridge_readiness(file_path, metrics)

    # 2. ë„ë©”ì¸ ì¬ì‚¬ìš©ì„± (0-100)
    reuse_score = _calculate_cross_domain_reuse(file_path, metrics)

    # 3. í™œì„±í™” ìš©ì´ì„± (0-100)
    activation_score = _calculate_activation_ease(metrics)

    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    total_score = (
        bridge_score * w["bridge"]
        + reuse_score * w["reuse"]
        + activation_score * w["activation"]
    )

    return min(max(total_score, 0), 100)


# Technical Score ì„¸ë¶€ ê³„ì‚° í•¨ìˆ˜ë“¤


def _calculate_uniqueness(file_path: str, metrics: AssetMetrics) -> float:
    """ê³ ìœ ì„± ê³„ì‚°"""
    score = 50  # ê¸°ë³¸ ì ìˆ˜

    # ê³ ìœ  íŒ¨í„´ì´ ë§ì„ìˆ˜ë¡ ì ìˆ˜ ì¦ê°€
    if metrics.unique_patterns > 0:
        score += min(metrics.unique_patterns * 10, 30)

    # ì¼ë°˜ì ì¸ ìœ í‹¸ë¦¬í‹°ë‚˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ì€ ê³ ìœ ì„± ë‚®ìŒ
    if any(
        keyword in file_path.lower() for keyword in ["util", "helper", "test", "common"]
    ):
        score -= 20

    # Echo íŠ¹í™” êµ¬ì¡°ë©´ ê³ ìœ ì„± ë†’ìŒ
    if any(
        keyword in file_path.lower()
        for keyword in ["signature", "judgment", "quantum", "liminal"]
    ):
        score += 20

    return min(max(score, 0), 100)


def _calculate_rebuild_cost(file_path: str, metrics: AssetMetrics) -> float:
    """ì¬í˜„ ë‚œì´ë„ ê³„ì‚°"""
    score = 30  # ê¸°ë³¸ ì ìˆ˜

    # LOCì— ë”°ë¥¸ ì ìˆ˜ (ë„ˆë¬´ ì‘ê±°ë‚˜ ë„ˆë¬´ í¬ë©´ ê°ì )
    if 50 <= metrics.loc <= 500:
        score += 20
    elif metrics.loc > 500:
        score += 30  # í° íŒŒì¼ì€ ì¬í˜„ ë¹„ìš© ë†’ìŒ

    # ë³µì¡ë„ì— ë”°ë¥¸ ì ìˆ˜
    if metrics.complexity > 10:
        score += min(metrics.complexity * 2, 30)

    # ì˜ì¡´ì„±ì´ ë³µì¡í• ìˆ˜ë¡ ì¬í˜„ ì–´ë ¤ì›€
    if metrics.deps_out > 5:
        score += min(metrics.deps_out * 3, 20)

    return min(max(score, 0), 100)


def _calculate_complexity_value(metrics: AssetMetrics) -> float:
    """ë³µì¡ë„ ê°€ì¹˜ ê³„ì‚°"""
    score = 20  # ê¸°ë³¸ ì ìˆ˜

    # ì ì ˆí•œ ë³µì¡ë„ëŠ” ê°€ì¹˜ ìˆìŒ
    if 5 <= metrics.complexity <= 25:
        score += 40
    elif metrics.complexity > 25:
        score += 30  # ë†’ì€ ë³µì¡ë„ë„ ê°€ì¹˜ ìˆì§€ë§Œ ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´

    # í•¨ìˆ˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì‘ì§‘ë„ ë¬¸ì œë¡œ ê°ì 
    function_count = getattr(metrics, "function_count", 0)
    if function_count > 20:
        score -= 15

    # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ê°€ ë§ìœ¼ë©´ ê°ì 
    if metrics.unused_functions > 3:
        score -= metrics.unused_functions * 5

    return min(max(score, 0), 100)


def _calculate_dependency_impact(metrics: AssetMetrics) -> float:
    """ì˜ì¡´ì„± ì˜í–¥ë„ ê³„ì‚°"""
    score = 10  # ê¸°ë³¸ ì ìˆ˜

    # ë‹¤ë¥¸ ëª¨ë“ˆë“¤ì´ ì´ íŒŒì¼ì— ì˜ì¡´í• ìˆ˜ë¡ ì¤‘ìš”
    if metrics.deps_in > 0:
        score += min(metrics.deps_in * 15, 60)

    # í•˜ì§€ë§Œ ë„ˆë¬´ ë§ì´ ì˜ì¡´ë°›ìœ¼ë©´ ê²°í•©ë„ ë¬¸ì œ
    if metrics.deps_in > 10:
        score -= 10

    # ì•„ë¬´ë„ ì˜ì¡´í•˜ì§€ ì•Šìœ¼ë©´ ê³ ë¦½ëœ ì½”ë“œ
    if metrics.deps_in == 0:
        score = 5

    return min(max(score, 0), 100)


# Strategic Score ì„¸ë¶€ ê³„ì‚° í•¨ìˆ˜ë“¤


def _calculate_echo_philosophy_fit(file_path: str, metrics: AssetMetrics) -> float:
    """Echo ì² í•™ ì í•©ì„± ê³„ì‚°"""
    score = 20  # ê¸°ë³¸ ì ìˆ˜

    # ì‹œê·¸ë‹ˆì²˜ ì—°ê´€ì„±
    if metrics.has_signature_link:
        score += 30

    # íŒë‹¨ ì—”ì§„ ì—°ê´€ì„±
    if metrics.has_judgment_link:
        score += 25

    # Echo ì² í•™ ì—°ê´€ì„± (ì‹œê·¸ë‹ˆì²˜ë‚˜ íŒë‹¨ ì—”ì§„ ì—°ê²°ë¡œ ëŒ€ì²´)
    if metrics.has_signature_link and metrics.has_judgment_link:
        score += 20

    # íŒŒì¼ ê²½ë¡œ ê¸°ë°˜ Echo ì í•©ì„±
    echo_indicators = [
        "echo",
        "signature",
        "judgment",
        "quantum",
        "meta",
        "liminal",
        "cosmos",
    ]
    if any(indicator in file_path.lower() for indicator in echo_indicators):
        score += 15

    return min(max(score, 0), 100)


def _calculate_roadmap_match(metrics: AssetMetrics) -> float:
    """ë¡œë“œë§µ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
    score = 10  # ê¸°ë³¸ ì ìˆ˜

    # ë¡œë“œë§µê³¼ ë§¤ì¹­ë˜ë©´ ì „ëµì  ê°€ì¹˜ ë†’ìŒ
    if metrics.roadmap_matched:
        score += 50

        # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì¶”ê°€ ì ìˆ˜
        priority_bonus = {"high": 30, "medium": 20, "low": 10}
        score += priority_bonus.get(metrics.roadmap_priority, 10)

    return min(max(score, 0), 100)


def _calculate_competitive_edge(file_path: str, metrics: AssetMetrics) -> float:
    """ê²½ìŸë ¥ ì°¨ë³„ì  ê³„ì‚°"""
    score = 30  # ê¸°ë³¸ ì ìˆ˜

    # Echoë§Œì˜ ê³ ìœ í•œ ì ‘ê·¼ë²•ë“¤
    unique_approaches = [
        "existence_based",
        "signature_",
        "emotion_rhythm",
        "quantum_judgment",
        "meta_cognitive",
        "liminal",
    ]

    # íŒŒì¼ëª…ì´ë‚˜ êµ¬ì¡°ì—ì„œ ê³ ìœ  ì ‘ê·¼ë²• í™•ì¸
    for approach in unique_approaches:
        if approach in file_path.lower():
            score += 15
            break

    # ê³ ìœ  íŒ¨í„´ì´ ë§ì„ìˆ˜ë¡ ì°¨ë³„ì  ìˆìŒ
    if metrics.unique_patterns > 2:
        score += 20

    # ë³µì¡í•œ êµ¬ì¡°ì¼ìˆ˜ë¡ ì°¨ë³„í™” ìš”ì†Œ
    if metrics.complexity > 15:
        score += 10

    return min(max(score, 0), 100)


# Potential Score ì„¸ë¶€ ê³„ì‚° í•¨ìˆ˜ë“¤


def _calculate_bridge_readiness(file_path: str, metrics: AssetMetrics) -> float:
    """ë¸Œë¦¿ì§€ ì—°ê²° ì¤€ë¹„ë„ ê³„ì‚°"""
    score = 20  # ê¸°ë³¸ ì ìˆ˜

    # ì´ë¯¸ ë¸Œë¦¿ì§€ì—ì„œ í˜¸ì¶œë˜ê³  ìˆìœ¼ë©´ ì—°ê²° ì¤€ë¹„ë¨
    if metrics.bridge_called:
        score += 40

    # APIë‚˜ í•¸ë“¤ëŸ¬ ì„±ê²©ì˜ íŒŒì¼ë“¤ì€ ë¸Œë¦¿ì§€ ì—°ê²° ìš©ì´
    if any(
        keyword in file_path.lower()
        for keyword in ["api", "handler", "router", "endpoint"]
    ):
        score += 25

    # í•¨ìˆ˜ê°€ ì ì ˆíˆ êµ¬ì¡°í™”ë˜ì–´ ìˆìœ¼ë©´ ì—°ê²° ìš©ì´
    function_count = getattr(metrics, "function_count", 0)
    if 2 <= function_count <= 10:
        score += 15

    # ì˜ì¡´ì„±ì´ ì ì„ìˆ˜ë¡ ë…ë¦½ì  ì—°ê²° ê°€ëŠ¥
    if metrics.deps_out <= 3:
        score += 10

    return min(max(score, 0), 100)


def _calculate_cross_domain_reuse(file_path: str, metrics: AssetMetrics) -> float:
    """ë„ë©”ì¸ ì¬ì‚¬ìš©ì„± ê³„ì‚°"""
    score = 25  # ê¸°ë³¸ ì ìˆ˜

    # ìœ í‹¸ë¦¬í‹°ë‚˜ ê³µí†µ ëª¨ë“ˆì€ ì¬ì‚¬ìš©ì„± ë†’ìŒ
    if any(
        keyword in file_path.lower() for keyword in ["util", "common", "helper", "tool"]
    ):
        score += 30

    # ì˜ì¡´ì„±ì´ ì ì„ìˆ˜ë¡ ì¬ì‚¬ìš© ìš©ì´
    if metrics.deps_out <= 2:
        score += 20

    # ë³µì¡ë„ê°€ ì ë‹¹í•˜ë©´ ì´í•´/ì¬ì‚¬ìš© ìš©ì´
    if 3 <= metrics.complexity <= 15:
        score += 15

    # Echo íŠ¹í™”ëœ ê²ƒë“¤ì€ ì¬ì‚¬ìš©ì„± ë‚®ìŒ
    if any(
        keyword in file_path.lower() for keyword in ["signature", "judgment", "quantum"]
    ):
        score -= 10

    return min(max(score, 0), 100)


def _calculate_activation_ease(metrics: AssetMetrics) -> float:
    """í™œì„±í™” ìš©ì´ì„± ê³„ì‚°"""
    score = 30  # ê¸°ë³¸ ì ìˆ˜

    # ì»¤ë²„ë¦¬ì§€ê°€ ìˆìœ¼ë©´ ì´ë¯¸ ì‘ë™ ê²€ì¦ë¨
    if metrics.covered:
        score += 25

    # ìµœê·¼ ìˆ˜ì •ë˜ì—ˆìœ¼ë©´ í™œì„± ìƒíƒœ
    if metrics.last_modified_days <= 30:
        score += 20
    elif metrics.last_modified_days <= 90:
        score += 10

    # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ê°€ ì ì„ìˆ˜ë¡ ì •ë¦¬ëœ ìƒíƒœ
    if metrics.unused_functions <= 1:
        score += 15

    # ì˜ì¡´ì„± ì…ë ¥ì´ ìˆìœ¼ë©´ ì´ë¯¸ ì—°ê²°ëœ ìƒíƒœ
    if metrics.deps_in > 0:
        score += 10

    return min(max(score, 0), 100)


# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
if __name__ == "__main__":
    # ìƒ˜í”Œ ë©”íŠ¸ë¦­ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    from echo_engine.inspectors.asset_value_judger.schemas import AssetMetrics

    sample_metrics = AssetMetrics(
        loc=150,
        complexity=8,
        deps_in=3,
        deps_out=5,
        last_modified_days=45,
        covered=True,
        bridge_called=False,
        has_signature_link=True,
        has_judgment_link=False,
        roadmap_matched=True,
        roadmap_priority="high",
        unique_patterns=2,
        unused_functions=1,
    )

    sample_weights = {
        "total_weights": {"T": 0.4, "S": 0.4, "P": 0.2},
        "T": {
            "uniqueness": 0.3,
            "rebuild_cost": 0.3,
            "complexity": 0.2,
            "dependency": 0.2,
        },
        "S": {"philosophy": 0.4, "roadmap": 0.4, "edge": 0.2},
        "P": {"bridge": 0.4, "reuse": 0.3, "activation": 0.3},
    }

    t_score, s_score, p_score, total = compute_tsp_scores(
        "echo_engine/signature_mapper.py", sample_metrics, sample_weights
    )

    print("ğŸ§ª Score Model Test")
    print(f"T Score (Technical): {t_score:.1f}")
    print(f"S Score (Strategic): {s_score:.1f}")
    print(f"P Score (Potential): {p_score:.1f}")
    print(f"Total Score: {total:.1f}")
