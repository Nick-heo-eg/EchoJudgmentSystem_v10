"""
Roadmap Linker - ë¡œë“œë§µ ê¸°ëŠ¥ ë§¤ì¹­ ë¶„ì„
==================================

íŒŒì¼ê³¼ ë¡œë“œë§µ ê¸°ëŠ¥ë“¤ì˜ ì—°ê´€ì„± ë¶„ì„
"""

import os
import re
from typing import Dict, List, Optional, Set
from pathlib import Path


def match_roadmap_features(
    file_paths: List[str], roadmap_config: Dict
) -> Dict[str, Dict]:
    """
    íŒŒì¼ë“¤ê³¼ ë¡œë“œë§µ ê¸°ëŠ¥ë“¤ì˜ ë§¤ì¹­ ë¶„ì„

    Args:
        file_paths: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        roadmap_config: ë¡œë“œë§µ ì„¤ì • ë”•ì…”ë„ˆë¦¬

    Returns:
        Dict[str, Dict]: íŒŒì¼ë³„ ë¡œë“œë§µ ë§¤ì¹­ ê²°ê³¼
    """
    print("ðŸ—ºï¸ Analyzing roadmap feature matching...")

    features = roadmap_config.get("features", [])
    results = {}

    for file_path in file_paths:
        try:
            match_data = _analyze_file_roadmap_match(file_path, features)
            results[file_path] = match_data
        except Exception as e:
            print(f"âš ï¸ Error analyzing roadmap match for {file_path}: {e}")
            results[file_path] = _get_default_roadmap_data()

    return results


def _analyze_file_roadmap_match(file_path: str, features: List[Dict]) -> Dict:
    """ë‹¨ì¼ íŒŒì¼ì˜ ë¡œë“œë§µ ë§¤ì¹­ ë¶„ì„"""

    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read()
    except Exception:
        return _get_default_roadmap_data()

    matched_features = []
    best_match_score = 0
    best_match_priority = "low"
    best_match_eta = None

    content_lower = content.lower()
    file_path_lower = file_path.lower()

    for feature in features:
        feature_name = feature.get("name", "")
        keywords = feature.get("keywords", [])
        priority = feature.get("priority", "low")
        eta = feature.get("eta", "")
        description = feature.get("description", "")

        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        match_score = _calculate_feature_match_score(
            content_lower, file_path_lower, keywords, feature_name
        )

        if match_score > 0:
            matched_features.append(
                {
                    "name": feature_name,
                    "score": match_score,
                    "priority": priority,
                    "eta": eta,
                    "matched_keywords": _get_matched_keywords(
                        content_lower, file_path_lower, keywords
                    ),
                }
            )

            # ìµœê³  ì ìˆ˜ ê¸°ëŠ¥ ì¶”ì 
            if match_score > best_match_score:
                best_match_score = match_score
                best_match_priority = priority
                best_match_eta = eta

    # ë§¤ì¹­ ê°•ë„ ê³„ì‚°
    match_strength = min(best_match_score * 10, 100)  # 0-100 ìŠ¤ì¼€ì¼

    # ë¯¸ëž˜ ê°€ì¹˜ í‰ê°€
    future_value = _assess_future_value(matched_features, best_match_priority)

    return {
        "matched": len(matched_features) > 0,
        "match_count": len(matched_features),
        "best_match_score": best_match_score,
        "match_strength": match_strength,
        "priority": best_match_priority,
        "eta": best_match_eta,
        "matched_features": matched_features,
        "future_value": future_value,
        "strategic_importance": _calculate_strategic_importance(matched_features),
        "development_readiness": _assess_development_readiness(
            content, matched_features
        ),
    }


def _calculate_feature_match_score(
    content: str, file_path: str, keywords: List[str], feature_name: str
) -> float:
    """ê¸°ëŠ¥ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
    score = 0.0

    # í‚¤ì›Œë“œ ë§¤ì¹­ (ê¸°ë³¸ ì ìˆ˜)
    for keyword in keywords:
        keyword_lower = keyword.lower()

        # íŒŒì¼ ê²½ë¡œì—ì„œ ë§¤ì¹­ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
        if keyword_lower in file_path:
            score += 3.0

        # ë‚´ìš©ì—ì„œ ë§¤ì¹­
        content_matches = content.count(keyword_lower)
        if content_matches > 0:
            score += min(content_matches * 0.5, 2.0)  # ìµœëŒ€ 2ì 

    # ê¸°ëŠ¥ëª… ì§ì ‘ ë§¤ì¹­ (ë³´ë„ˆìŠ¤)
    feature_name_lower = feature_name.lower().replace("_", " ")
    feature_keywords = feature_name_lower.split()

    for keyword in feature_keywords:
        if keyword in content or keyword in file_path:
            score += 1.5

    # í´ëž˜ìŠ¤/í•¨ìˆ˜ëª… ë§¤ì¹­ (ê³ ì •ë°€ ë§¤ì¹­)
    class_function_patterns = [
        rf"class.*{re.escape(keyword)}",
        rf"def.*{re.escape(keyword)}",
        rf"{re.escape(keyword)}.*class",
        rf"{re.escape(keyword)}.*def",
    ]

    for keyword in keywords:
        keyword_escaped = re.escape(keyword.lower())
        for pattern in class_function_patterns:
            pattern_filled = pattern.format(keyword=keyword_escaped)
            if re.search(pattern_filled, content, re.IGNORECASE):
                score += 2.0

    return score


def _get_matched_keywords(
    content: str, file_path: str, keywords: List[str]
) -> List[str]:
    """ë§¤ì¹­ëœ í‚¤ì›Œë“œë“¤ ë°˜í™˜"""
    matched = []

    for keyword in keywords:
        keyword_lower = keyword.lower()
        if keyword_lower in content or keyword_lower in file_path:
            matched.append(keyword)

    return matched


def _assess_future_value(matched_features: List[Dict], priority: str) -> int:
    """ë¯¸ëž˜ ê°€ì¹˜ í‰ê°€ (0-100)"""
    if not matched_features:
        return 0

    base_score = 30  # ê¸°ë³¸ ì ìˆ˜

    # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
    priority_weights = {"high": 40, "medium": 25, "low": 10}
    priority_score = priority_weights.get(priority, 10)

    # ë§¤ì¹­ëœ ê¸°ëŠ¥ ìˆ˜ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
    feature_count_bonus = min(len(matched_features) * 5, 20)

    # ë†’ì€ ì ìˆ˜ ê¸°ëŠ¥ì´ ìžˆìœ¼ë©´ ì¶”ê°€ ë³´ë„ˆìŠ¤
    max_score = max(feature.get("score", 0) for feature in matched_features)
    score_bonus = min(max_score * 2, 10)

    total_score = base_score + priority_score + feature_count_bonus + score_bonus
    return min(total_score, 100)


def _calculate_strategic_importance(matched_features: List[Dict]) -> str:
    """ì „ëžµì  ì¤‘ìš”ë„ ê³„ì‚°"""
    if not matched_features:
        return "low"

    # ìµœê³  ìš°ì„ ìˆœìœ„ ê¸°ëŠ¥ ê¸°ì¤€
    priorities = [feature.get("priority", "low") for feature in matched_features]

    if "high" in priorities:
        return "high"
    elif "medium" in priorities:
        return "medium"
    else:
        return "low"


def _assess_development_readiness(content: str, matched_features: List[Dict]) -> str:
    """ê°œë°œ ì¤€ë¹„ë„ í‰ê°€"""
    if not matched_features:
        return "not_ready"

    # ì½”ë“œ ì™„ì„±ë„ ì§€í‘œë“¤
    readiness_indicators = {
        "implemented": [
            r"class\s+\w+",
            r"def\s+\w+",
            r"return\s+",
            r"if\s+.*:",
            r"for\s+.*:",
            r"while\s+.*:",
            r"try:",
            r"except:",
        ],
        "partial": [
            r"TODO",
            r"FIXME",
            r"XXX",
            r"NotImplemented",
            r"pass\s*$",
            r"raise\s+NotImplementedError",
        ],
        "planned": [
            r"# Plan:",
            r"# Design:",
            r"# Architecture:",
            r"# TODO:",
            r'""".*plan.*"""',
            r'""".*design.*"""',
        ],
    }

    content_lower = content.lower()

    implemented_count = sum(
        len(re.findall(pattern, content, re.IGNORECASE | re.MULTILINE))
        for pattern in readiness_indicators["implemented"]
    )

    partial_count = sum(
        len(re.findall(pattern, content, re.IGNORECASE | re.MULTILINE))
        for pattern in readiness_indicators["partial"]
    )

    planned_count = sum(
        len(re.findall(pattern, content, re.IGNORECASE | re.MULTILINE))
        for pattern in readiness_indicators["planned"]
    )

    # ì¤€ë¹„ë„ íŒë‹¨
    if implemented_count > 5 and partial_count < 3:
        return "ready"
    elif implemented_count > 2 or partial_count > 0:
        return "partial"
    elif planned_count > 0:
        return "planned"
    else:
        return "not_ready"


def _get_default_roadmap_data() -> Dict:
    """ê¸°ë³¸ ë¡œë“œë§µ ë°ì´í„° (ì˜¤ë¥˜ ì‹œ)"""
    return {
        "matched": False,
        "match_count": 0,
        "best_match_score": 0,
        "match_strength": 0,
        "priority": "low",
        "eta": None,
        "matched_features": [],
        "future_value": 0,
        "strategic_importance": "low",
        "development_readiness": "not_ready",
    }


def create_sample_roadmap() -> Dict:
    """ìƒ˜í”Œ ë¡œë“œë§µ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
    return {
        "features": [
            {
                "name": "multi_signature_routing",
                "keywords": ["signature", "router", "multi", "vote", "consensus"],
                "priority": "high",
                "eta": "2025-Q2",
                "description": "Multiple signature voting and routing system",
            },
            {
                "name": "policy_impact_simulation",
                "keywords": ["policy", "simulator", "impact", "scenario", "prediction"],
                "priority": "medium",
                "eta": "2025-Q3",
                "description": "Policy decision impact simulation framework",
            },
            {
                "name": "quantum_judgment_engine",
                "keywords": ["quantum", "judgment", "superposition", "uncertainty"],
                "priority": "high",
                "eta": "2025-Q4",
                "description": "Quantum-enhanced judgment processing",
            },
            {
                "name": "emotional_rhythm_analyzer",
                "keywords": ["emotion", "rhythm", "flow", "pattern", "analysis"],
                "priority": "medium",
                "eta": "2025-Q2",
                "description": "Advanced emotional rhythm pattern analysis",
            },
            {
                "name": "bridge_integration_framework",
                "keywords": ["bridge", "integration", "api", "connector", "interface"],
                "priority": "high",
                "eta": "2025-Q1",
                "description": "Universal bridge integration framework",
            },
            {
                "name": "meta_cognitive_loops",
                "keywords": ["meta", "cognitive", "loop", "reflection", "awareness"],
                "priority": "medium",
                "eta": "2025-Q3",
                "description": "Advanced meta-cognitive processing loops",
            },
        ]
    }


# CLI í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    import sys

    # ìƒ˜í”Œ ë¡œë“œë§µ ì‚¬ìš©
    sample_roadmap = create_sample_roadmap()

    if len(sys.argv) > 1:
        test_files = [sys.argv[1]]
    else:
        test_files = [__file__]

    print("ðŸ§ª Roadmap Linker Test")
    print(f"Testing with {len(sample_roadmap['features'])} roadmap features")

    result = match_roadmap_features(test_files, sample_roadmap)

    for file_path, analysis in result.items():
        print(f"\nFile: {file_path}")
        for key, value in analysis.items():
            if key == "matched_features" and value:
                print(f"  {key}:")
                for feature in value:
                    print(
                        f"    - {feature['name']} (score: {feature['score']}, priority: {feature['priority']})"
                    )
            else:
                print(f"  {key}: {value}")
