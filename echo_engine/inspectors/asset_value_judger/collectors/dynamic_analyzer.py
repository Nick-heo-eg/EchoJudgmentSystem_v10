"""
Dynamic Analyzer - ë™ì  ì‹¤í–‰ ë¶„ì„
==============================

ì»¤ë²„ë¦¬ì§€, ë¸Œë¦¿ì§€ í˜¸ì¶œ ë¡œê·¸ ë“± ì‹¤í–‰ ì‹œ ë°ì´í„° ë¶„ì„
"""

import os
import json
import xml.etree.ElementTree as ET
from typing import Dict, List, Optional
from pathlib import Path


def analyze_dynamic_metrics(
    coverage_xml: Optional[str] = None, bridge_log: Optional[str] = None
) -> Dict[str, Dict]:
    """
    ë™ì  ì‹¤í–‰ ë©”íŠ¸ë¦­ ë¶„ì„

    Args:
        coverage_xml: coverage.xml íŒŒì¼ ê²½ë¡œ
        bridge_log: ë¸Œë¦¿ì§€ í˜¸ì¶œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ

    Returns:
        Dict[str, Dict]: íŒŒì¼ë³„ ë™ì  ë¶„ì„ ê²°ê³¼
    """
    print("âš¡ Running dynamic analysis...")

    # ì»¤ë²„ë¦¬ì§€ ë°ì´í„° ë¶„ì„
    coverage_data = _analyze_coverage(coverage_xml) if coverage_xml else {}

    # ë¸Œë¦¿ì§€ í˜¸ì¶œ ë¡œê·¸ ë¶„ì„
    bridge_data = _analyze_bridge_calls(bridge_log) if bridge_log else {}

    # ì‹¤í–‰ ë¹ˆë„ ë¶„ì„ (ë¡œê·¸ ê¸°ë°˜)
    execution_data = _analyze_execution_frequency(bridge_log) if bridge_log else {}

    # ê²°ê³¼ í†µí•©
    all_files = (
        set(coverage_data.keys()) | set(bridge_data.keys()) | set(execution_data.keys())
    )

    results = {}
    for file_path in all_files:
        results[file_path] = {
            "covered": coverage_data.get(file_path, {}).get("covered", False),
            "line_coverage": coverage_data.get(file_path, {}).get("line_rate", 0.0),
            "branch_coverage": coverage_data.get(file_path, {}).get("branch_rate", 0.0),
            "bridge_called": bridge_data.get(file_path, {}).get("called", False),
            "call_frequency": bridge_data.get(file_path, {}).get("frequency", 0),
            "last_execution": execution_data.get(file_path, {}).get(
                "last_execution", None
            ),
            "execution_count": execution_data.get(file_path, {}).get("count", 0),
            "is_hot_path": execution_data.get(file_path, {}).get("is_hot", False),
        }

    return results


def _analyze_coverage(coverage_xml: str) -> Dict[str, Dict]:
    """coverage.xml íŒŒì¼ ë¶„ì„"""
    coverage_data = {}

    if not os.path.exists(coverage_xml):
        print(f"âš ï¸ Coverage file not found: {coverage_xml}")
        return coverage_data

    try:
        tree = ET.parse(coverage_xml)
        root = tree.getroot()

        # packages/classes/methods êµ¬ì¡° íŒŒì‹±
        for package in root.findall(".//package"):
            for class_elem in package.findall("classes/class"):
                filename = class_elem.get("filename", "")

                if filename:
                    # ìƒëŒ€ ê²½ë¡œë¡œ ì •ê·œí™”
                    normalized_path = _normalize_path(filename)

                    line_rate = float(class_elem.get("line-rate", 0))
                    branch_rate = float(class_elem.get("branch-rate", 0))

                    coverage_data[normalized_path] = {
                        "covered": line_rate > 0,
                        "line_rate": line_rate,
                        "branch_rate": branch_rate,
                        "lines_covered": int(class_elem.get("lines-covered", 0)),
                        "lines_valid": int(class_elem.get("lines-valid", 0)),
                    }

        print(f"âœ… Parsed coverage for {len(coverage_data)} files")

    except Exception as e:
        print(f"âš ï¸ Error parsing coverage XML: {e}")

    return coverage_data


def _analyze_bridge_calls(bridge_log: str) -> Dict[str, Dict]:
    """ë¸Œë¦¿ì§€ í˜¸ì¶œ ë¡œê·¸ ë¶„ì„"""
    bridge_data = {}

    if not os.path.exists(bridge_log):
        print(f"âš ï¸ Bridge log not found: {bridge_log}")
        return bridge_data

    try:
        call_counts = {}

        # JSON Lines í˜•ì‹ì´ë¼ê³  ê°€ì •
        with open(bridge_log, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                try:
                    log_entry = json.loads(line)

                    # ë¡œê·¸ì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
                    module_path = _extract_module_path_from_log(log_entry)
                    if module_path:
                        call_counts[module_path] = call_counts.get(module_path, 0) + 1

                except json.JSONDecodeError:
                    # í”Œë ˆì¸ í…ìŠ¤íŠ¸ ë¡œê·¸ ì²˜ë¦¬
                    module_path = _extract_module_path_from_text(line)
                    if module_path:
                        call_counts[module_path] = call_counts.get(module_path, 0) + 1

        # ê²°ê³¼ êµ¬ì„±
        for file_path, count in call_counts.items():
            normalized_path = _normalize_path(file_path)
            bridge_data[normalized_path] = {
                "called": True,
                "frequency": count,
                "is_frequent": count > 10,  # 10íšŒ ì´ìƒ í˜¸ì¶œë˜ë©´ ìžì£¼ ì‚¬ìš©ë¨
            }

        print(f"âœ… Analyzed bridge calls for {len(bridge_data)} files")

    except Exception as e:
        print(f"âš ï¸ Error analyzing bridge log: {e}")

    return bridge_data


def _analyze_execution_frequency(bridge_log: str) -> Dict[str, Dict]:
    """ì‹¤í–‰ ë¹ˆë„ ë° í•«íŒ¨ìŠ¤ ë¶„ì„"""
    execution_data = {}

    if not os.path.exists(bridge_log):
        return execution_data

    try:
        file_executions = {}
        recent_executions = {}

        with open(bridge_log, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                try:
                    log_entry = json.loads(line)
                    timestamp = log_entry.get("timestamp")
                    module_path = _extract_module_path_from_log(log_entry)

                    if module_path:
                        normalized_path = _normalize_path(module_path)

                        # ì‹¤í–‰ íšŸìˆ˜ ì¹´ìš´íŠ¸
                        file_executions[normalized_path] = (
                            file_executions.get(normalized_path, 0) + 1
                        )

                        # ìµœê·¼ ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
                        if timestamp:
                            if (
                                normalized_path not in recent_executions
                                or timestamp > recent_executions[normalized_path]
                            ):
                                recent_executions[normalized_path] = timestamp

                except (json.JSONDecodeError, KeyError):
                    continue

        # í•«íŒ¨ìŠ¤ ì‹ë³„ (ìƒìœ„ 20% ì‹¤í–‰ ë¹ˆë„)
        if file_executions:
            execution_counts = list(file_executions.values())
            execution_counts.sort(reverse=True)
            hot_threshold = (
                execution_counts[int(len(execution_counts) * 0.2)]
                if execution_counts
                else 0
            )

            for file_path, count in file_executions.items():
                execution_data[file_path] = {
                    "count": count,
                    "last_execution": recent_executions.get(file_path),
                    "is_hot": count >= hot_threshold and count > 5,
                }

        print(f"âœ… Analyzed execution frequency for {len(execution_data)} files")

    except Exception as e:
        print(f"âš ï¸ Error analyzing execution frequency: {e}")

    return execution_data


def _extract_module_path_from_log(log_entry: Dict) -> Optional[str]:
    """ë¡œê·¸ ì—”íŠ¸ë¦¬ì—ì„œ ëª¨ë“ˆ ê²½ë¡œ ì¶”ì¶œ"""

    # ì¼ë°˜ì ì¸ ë¡œê·¸ í•„ë“œë“¤ í™•ì¸
    path_fields = ["module", "file", "source", "path", "filename"]

    for field in path_fields:
        if field in log_entry:
            path = log_entry[field]
            if isinstance(path, str) and path.endswith(".py"):
                return path

    # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ì—ì„œ ì¶”ì¶œ
    if "stack" in log_entry or "traceback" in log_entry:
        stack_data = log_entry.get("stack") or log_entry.get("traceback")
        if isinstance(stack_data, str):
            # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ ì°¾ê¸°
            import re

            paths = re.findall(r'File "([^"]+\.py)"', stack_data)
            if paths:
                return paths[0]

    # ë©”ì‹œì§€ì—ì„œ ì¶”ì¶œ
    message = log_entry.get("message", "") or log_entry.get("msg", "")
    if isinstance(message, str):
        import re

        # ì¼ë°˜ì ì¸ íŒŒì¼ ê²½ë¡œ íŒ¨í„´
        paths = re.findall(r"([a-zA-Z_][a-zA-Z0-9_/]*\.py)", message)
        if paths:
            return paths[0]

    return None


def _extract_module_path_from_text(text_line: str) -> Optional[str]:
    """í”Œë ˆì¸ í…ìŠ¤íŠ¸ ë¡œê·¸ì—ì„œ ëª¨ë“ˆ ê²½ë¡œ ì¶”ì¶œ"""
    import re

    # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ë“¤
    patterns = [
        r'File "([^"]+\.py)"',
        r"module=([a-zA-Z_][a-zA-Z0-9_/]*\.py)",
        r"path=([a-zA-Z_][a-zA-Z0-9_/]*\.py)",
        r"([a-zA-Z_][a-zA-Z0-9_/]*\.py):",
        r"\b([a-zA-Z_][a-zA-Z0-9_/]*\.py)\b",
    ]

    for pattern in patterns:
        matches = re.findall(pattern, text_line)
        if matches:
            return matches[0]

    return None


def _normalize_path(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œ ì •ê·œí™”"""
    # ì ˆëŒ€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    path = Path(file_path)

    # í˜„ìž¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ìƒì„±
    try:
        current_dir = Path.cwd()
        if path.is_absolute():
            try:
                relative_path = path.relative_to(current_dir)
                return str(relative_path).replace("\\", "/")
            except ValueError:
                # ë‹¤ë¥¸ ë“œë¼ì´ë¸Œë‚˜ ê²½ë¡œì¸ ê²½ìš°
                return str(path).replace("\\", "/")
        else:
            return str(path).replace("\\", "/")
    except Exception:
        return str(path).replace("\\", "/")


# í…ŒìŠ¤íŠ¸ìš© ë¸Œë¦¿ì§€ ë¡œê·¸ ìƒì„±
def generate_sample_bridge_log(output_file: str = "sample_bridge.log"):
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë¸Œë¦¿ì§€ ë¡œê·¸ ìƒì„±"""
    import json
    from datetime import datetime, timedelta

    sample_logs = [
        {
            "timestamp": (datetime.now() - timedelta(hours=1)).isoformat(),
            "module": "echo_engine/judgment_engine.py",
            "message": "Processing judgment request",
            "level": "INFO",
        },
        {
            "timestamp": (datetime.now() - timedelta(minutes=30)).isoformat(),
            "module": "echo_engine/signature_mapper.py",
            "message": "Signature mapping completed",
            "level": "INFO",
        },
        {
            "timestamp": (datetime.now() - timedelta(minutes=15)).isoformat(),
            "file": "echo_engine/handlers/echo_decide.py",
            "message": "Echo decide handler called",
            "level": "INFO",
        },
    ]

    with open(output_file, "w") as f:
        for log in sample_logs:
            f.write(json.dumps(log) + "\n")

    print(f"ðŸ“ Sample bridge log created: {output_file}")


# CLI í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    import sys

    print("ðŸ§ª Dynamic Analyzer Test")

    # ìƒ˜í”Œ ë¡œê·¸ ìƒì„±
    generate_sample_bridge_log()

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    coverage_file = sys.argv[1] if len(sys.argv) > 1 else None
    bridge_file = sys.argv[2] if len(sys.argv) > 2 else "sample_bridge.log"

    result = analyze_dynamic_metrics(coverage_file, bridge_file)

    print(f"\nAnalyzed {len(result)} files:")
    for file_path, metrics in result.items():
        print(f"\nFile: {file_path}")
        for key, value in metrics.items():
            print(f"  {key}: {value}")

    # ì •ë¦¬
    if os.path.exists("sample_bridge.log"):
        os.remove("sample_bridge.log")
