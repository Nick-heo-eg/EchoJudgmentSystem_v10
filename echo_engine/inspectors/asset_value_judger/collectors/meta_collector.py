"""
Meta Collector - íŒŒì¼ ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
=======================================

íŒŒì¼ í¬ê¸°, ìˆ˜ì •ì¼, LOC ë“± ê¸°ë³¸ì ì¸ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
"""

import os
import re
from pathlib import Path
from typing import Dict, List
from datetime import datetime


def collect_file_metadata(file_paths: List[str]) -> Dict[str, Dict]:
    """
    íŒŒì¼ë“¤ì˜ ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘

    Args:
        file_paths: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

    Returns:
        Dict[str, Dict]: íŒŒì¼ë³„ ë©”íƒ€ë°ì´í„°
    """
    metadata = {}

    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                metadata[file_path] = _collect_single_file_metadata(file_path)
            else:
                metadata[file_path] = _get_default_metadata()
        except Exception as e:
            print(f"âš ï¸ Error collecting metadata for {file_path}: {e}")
            metadata[file_path] = _get_default_metadata()

    return metadata


def _collect_single_file_metadata(file_path: str) -> Dict:
    """ë‹¨ì¼ íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘"""

    file_stats = os.stat(file_path)

    # íŒŒì¼ í¬ê¸° ë° ìˆ˜ì •ì¼
    file_size = file_stats.st_size
    modified_time = datetime.fromtimestamp(file_stats.st_mtime)
    last_modified_days = (datetime.now() - modified_time).days

    # LOC ê³„ì‚°
    loc, sloc = _count_lines_of_code(file_path)

    # íŒŒì¼ íƒ€ì… ë¶„ì„
    file_type = _analyze_file_type(file_path)

    # ë³µì¡ì„± ì§€í‘œ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    complexity_indicators = _count_complexity_indicators(file_path)

    return {
        "file_size": file_size,
        "loc": loc,
        "sloc": sloc,  # Source Lines of Code (ì£¼ì„/ë¹ˆì¤„ ì œì™¸)
        "last_modified_days": last_modified_days,
        "last_modified": modified_time.isoformat(),
        "file_type": file_type,
        **complexity_indicators,
    }


def _count_lines_of_code(file_path: str) -> tuple[int, int]:
    """LOCì™€ SLOC ê³„ì‚°"""
    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            lines = f.readlines()

        total_lines = len(lines)
        source_lines = 0

        in_multiline_comment = False

        for line in lines:
            stripped = line.strip()

            # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            if not stripped:
                continue

            # ë©€í‹°ë¼ì¸ ì£¼ì„ ì²˜ë¦¬ (Python docstring)
            if '"""' in stripped or "'''" in stripped:
                if in_multiline_comment:
                    in_multiline_comment = False
                    continue
                else:
                    in_multiline_comment = True
                    continue

            if in_multiline_comment:
                continue

            # ë‹¨ì¼ ë¼ì¸ ì£¼ì„ ê±´ë„ˆë›°ê¸°
            if stripped.startswith("#"):
                continue

            source_lines += 1

        return total_lines, source_lines

    except Exception as e:
        print(f"âš ï¸ Error counting LOC for {file_path}: {e}")
        return 0, 0


def _analyze_file_type(file_path: str) -> str:
    """íŒŒì¼ íƒ€ì… ë¶„ì„"""

    path = Path(file_path)

    # íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ íƒ€ì… ì¶”ì •
    if path.name.startswith("test_") or "_test.py" in path.name:
        return "test"
    elif path.name in ["__init__.py"]:
        return "module_init"
    elif "config" in path.name.lower():
        return "config"
    elif any(keyword in path.name.lower() for keyword in ["util", "helper", "tool"]):
        return "utility"
    elif any(keyword in str(path) for keyword in ["api", "server", "router"]):
        return "api"
    elif any(keyword in str(path) for keyword in ["engine", "core"]):
        return "core"
    elif any(keyword in str(path) for keyword in ["ui", "dashboard", "web"]):
        return "interface"
    else:
        return "module"


def _count_complexity_indicators(file_path: str) -> Dict:
    """ë³µì¡ì„± ì§€í‘œë“¤ ê³„ì‚°"""
    try:
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read()

        # í•¨ìˆ˜/í´ë˜ìŠ¤ ê°œìˆ˜
        function_count = len(re.findall(r"^def\s+\w+", content, re.MULTILINE))
        class_count = len(re.findall(r"^class\s+\w+", content, re.MULTILINE))

        # import ê°œìˆ˜ (ì˜ì¡´ì„± ì¶”ì •)
        import_count = len(re.findall(r"^(import|from)\s+", content, re.MULTILINE))

        # ì¡°ê±´ë¬¸/ë°˜ë³µë¬¸ ê°œìˆ˜ (ë³µì¡ë„ ì¶”ì •)
        control_structures = len(
            re.findall(r"\b(if|elif|else|for|while|try|except|finally)\b", content)
        )

        # TODO/FIXME/XXX ì£¼ì„ (ê¸°ìˆ ë¶€ì±„ ì§€í‘œ)
        todo_count = len(
            re.findall(r"#.*\b(TODO|FIXME|XXX|HACK)\b", content, re.IGNORECASE)
        )

        # ê¸´ í•¨ìˆ˜ ê°œìˆ˜ (20ì¤„ ì´ìƒ)
        long_functions = _count_long_functions(content)

        return {
            "function_count": function_count,
            "class_count": class_count,
            "import_count": import_count,
            "control_structures": control_structures,
            "todo_count": todo_count,
            "long_functions": long_functions,
        }

    except Exception as e:
        print(f"âš ï¸ Error analyzing complexity for {file_path}: {e}")
        return {
            "function_count": 0,
            "class_count": 0,
            "import_count": 0,
            "control_structures": 0,
            "todo_count": 0,
            "long_functions": 0,
        }


def _count_long_functions(content: str) -> int:
    """20ì¤„ ì´ìƒì˜ ê¸´ í•¨ìˆ˜ ê°œìˆ˜ ì„¸ê¸°"""
    lines = content.split("\n")
    long_function_count = 0
    current_function_lines = 0
    in_function = False
    base_indent = 0

    for line in lines:
        stripped = line.strip()

        # í•¨ìˆ˜ ì‹œì‘ ê°ì§€
        if re.match(r"^def\s+\w+", stripped):
            if in_function and current_function_lines > 20:
                long_function_count += 1

            in_function = True
            current_function_lines = 1
            base_indent = len(line) - len(line.lstrip())
            continue

        if in_function:
            if stripped:  # ë¹„ì–´ìˆì§€ ì•Šì€ ì¤„
                current_indent = len(line) - len(line.lstrip())

                # í•¨ìˆ˜ ë ê°ì§€ (ì¸ë´íŠ¸ê°€ í•¨ìˆ˜ ë ˆë²¨ê³¼ ê°™ê±°ë‚˜ ì‘ìŒ)
                if current_indent <= base_indent:
                    if current_function_lines > 20:
                        long_function_count += 1
                    in_function = False
                else:
                    current_function_lines += 1

    # íŒŒì¼ ëì—ì„œ í•¨ìˆ˜ê°€ ëë‚˜ëŠ” ê²½ìš°
    if in_function and current_function_lines > 20:
        long_function_count += 1

    return long_function_count


def _get_default_metadata() -> Dict:
    """ê¸°ë³¸ ë©”íƒ€ë°ì´í„° (íŒŒì¼ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ)"""
    return {
        "file_size": 0,
        "loc": 0,
        "sloc": 0,
        "last_modified_days": 9999,
        "last_modified": "1970-01-01T00:00:00",
        "file_type": "unknown",
        "function_count": 0,
        "class_count": 0,
        "import_count": 0,
        "control_structures": 0,
        "todo_count": 0,
        "long_functions": 0,
    }


# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
if __name__ == "__main__":
    # í˜„ì¬ íŒŒì¼ ìì²´ë¥¼ í…ŒìŠ¤íŠ¸
    test_files = [__file__]
    result = collect_file_metadata(test_files)

    print("ğŸ§ª Meta Collector Test")
    for file_path, metadata in result.items():
        print(f"\nFile: {file_path}")
        for key, value in metadata.items():
            print(f"  {key}: {value}")
