#!/usr/bin/env python3
"""
ğŸ“ Enhanced Meta Logger
ìì—°ì–´ í‘œí˜„ íë¦„ ê¸°ë¡ ë° ê°œì„ ì„ ìœ„í•œ ê³ ë„í™”ëœ ë©”íƒ€ ë¡œê±°

í•µì‹¬ ê¸°ëŠ¥:
1. ìì—°ì–´ ëŒ€í™” íë¦„ì˜ ì‹¤ì‹œê°„ í’ˆì§ˆ ì¶”ì 
2. Echo ì‹œìŠ¤í…œê³¼ LLM í˜‘ë ¥ ê³¼ì •ì˜ ìƒì„¸ ê¸°ë¡
3. ì‚¬ìš©ì ë§Œì¡±ë„ ë° ëŒ€í™” ìì—°ìŠ¤ëŸ¬ì›€ ë©”íŠ¸ë¦­
4. ì ì‘í˜• í•™ìŠµì„ ìœ„í•œ íŒ¨í„´ ë¶„ì„ ë° í”¼ë“œë°±
"""

import json
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import yaml
import numpy as np
from collections import defaultdict, deque


class LogLevel(Enum):
    """ë¡œê·¸ ë ˆë²¨"""

    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class FlowStage(Enum):
    """íë¦„ ë‹¨ê³„"""

    INPUT_ANALYSIS = "input_analysis"
    INTENT_DETECTION = "intent_detection"
    PROCESSING_MODE_SELECTION = "processing_mode_selection"
    ECHO_JUDGMENT = "echo_judgment"
    LLM_COOPERATION = "llm_cooperation"
    RESPONSE_FORMATTING = "response_formatting"
    SIGNATURE_STYLING = "signature_styling"
    QUALITY_EVALUATION = "quality_evaluation"
    USER_FEEDBACK = "user_feedback"


@dataclass
class ConversationFlowEntry:
    """ëŒ€í™” íë¦„ í•­ëª©"""

    timestamp: datetime
    session_id: str
    user_id: Optional[str]
    stage: FlowStage
    input_data: Dict[str, Any]
    processing_details: Dict[str, Any]
    output_data: Dict[str, Any]
    performance_metrics: Dict[str, float]
    quality_scores: Dict[str, float]
    natural_flow_indicators: Dict[str, Any]
    signature_used: str
    processing_time: float
    success: bool
    errors: List[str]


@dataclass
class NaturalnessMetrics:
    """ìì—°ìŠ¤ëŸ¬ì›€ ë©”íŠ¸ë¦­"""

    conversational_flow_score: float
    echo_integration_smoothness: float
    response_appropriateness: float
    user_rhythm_matching: float
    emotional_consistency: float
    context_preservation: float
    overall_naturalness: float


@dataclass
class LearningInsight:
    """í•™ìŠµ í†µì°°"""

    insight_id: str
    timestamp: datetime
    category: str
    description: str
    pattern_data: Dict[str, Any]
    confidence: float
    actionable_recommendations: List[str]
    impact_estimation: float


class EnhancedMetaLogger:
    """í–¥ìƒëœ ë©”íƒ€ ë¡œê±°"""

    def __init__(
        self,
        log_directory: str = "logs/enhanced_meta",
        flow_config_path: str = "flows/natural_conversation_flow.yaml",
        retention_days: int = 30,
    ):

        self.log_directory = Path(log_directory)
        self.log_directory.mkdir(parents=True, exist_ok=True)

        self.flow_config_path = flow_config_path
        self.retention_days = retention_days

        # ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤í† ë¦¬ì§€
        self.conversation_flows: Dict[str, deque] = defaultdict(
            lambda: deque(maxlen=100)
        )
        self.session_contexts: Dict[str, Dict[str, Any]] = {}
        self.quality_trends: deque = deque(maxlen=1000)
        self.naturalness_history: deque = deque(maxlen=500)

        # í•™ìŠµ ë°ì´í„°
        self.pattern_library: Dict[str, List[Dict]] = defaultdict(list)
        self.success_patterns: Dict[str, float] = {}
        self.failure_patterns: Dict[str, float] = {}

        # ì„¤ì • ë¡œë“œ
        self.flow_config = self._load_flow_config()

        # ì‹¤ì‹œê°„ ë¶„ì„ íƒœìŠ¤í¬
        self.analysis_task: Optional[asyncio.Task] = None

        print("ğŸ“ Enhanced Meta Logger ì´ˆê¸°í™” ì™„ë£Œ")

    async def log_conversation_flow(
        self,
        session_id: str,
        stage: FlowStage,
        input_data: Dict[str, Any],
        processing_details: Dict[str, Any],
        output_data: Dict[str, Any],
        performance_metrics: Dict[str, float] = None,
        user_id: str = None,
    ) -> str:
        """ëŒ€í™” íë¦„ ë¡œê·¸ ê¸°ë¡"""

        performance_metrics = performance_metrics or {}

        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_scores = await self._calculate_quality_scores(
            stage, input_data, processing_details, output_data
        )

        # ìì—°ìŠ¤ëŸ¬ì›€ ì§€í‘œ ë¶„ì„
        natural_flow_indicators = self._analyze_natural_flow(
            input_data, processing_details, output_data, session_id
        )

        # ë¡œê·¸ í•­ëª© ìƒì„±
        entry = ConversationFlowEntry(
            timestamp=datetime.now(),
            session_id=session_id,
            user_id=user_id,
            stage=stage,
            input_data=input_data,
            processing_details=processing_details,
            output_data=output_data,
            performance_metrics=performance_metrics,
            quality_scores=quality_scores,
            natural_flow_indicators=natural_flow_indicators,
            signature_used=processing_details.get("signature", "Echo-Aurora"),
            processing_time=performance_metrics.get("processing_time", 0.0),
            success=len(processing_details.get("errors", [])) == 0,
            errors=processing_details.get("errors", []),
        )

        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.conversation_flows[session_id].append(entry)

        # í’ˆì§ˆ íŠ¸ë Œë“œ ì—…ë°ì´íŠ¸
        overall_quality = quality_scores.get("overall_quality", 0.7)
        self.quality_trends.append(
            {
                "timestamp": datetime.now(),
                "session_id": session_id,
                "stage": stage.value,
                "quality": overall_quality,
                "naturalness": natural_flow_indicators.get("overall_naturalness", 0.7),
            }
        )

        # íŒŒì¼ì— ë¹„ë™ê¸° ì €ì¥
        entry_id = f"{session_id}_{stage.value}_{datetime.now().timestamp()}"
        await self._save_entry_to_file(entry, entry_id)

        # ì‹¤ì‹œê°„ íŒ¨í„´ ë¶„ì„ íŠ¸ë¦¬ê±°
        if len(self.conversation_flows[session_id]) >= 3:
            await self._analyze_conversation_patterns(session_id)

        return entry_id

    async def log_naturalness_assessment(
        self,
        session_id: str,
        user_input: str,
        system_response: str,
        user_feedback: Dict[str, Any] = None,
    ) -> NaturalnessMetrics:
        """ìì—°ìŠ¤ëŸ¬ì›€ í‰ê°€ ë¡œê·¸"""

        user_feedback = user_feedback or {}

        # ìì—°ìŠ¤ëŸ¬ì›€ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = await self._calculate_naturalness_metrics(
            session_id, user_input, system_response, user_feedback
        )

        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.naturalness_history.append(
            {
                "timestamp": datetime.now(),
                "session_id": session_id,
                "metrics": asdict(metrics),
                "user_feedback": user_feedback,
            }
        )

        # ìì—°ìŠ¤ëŸ¬ì›€ íŠ¸ë Œë“œ ë¶„ì„
        await self._analyze_naturalness_trends()

        return metrics

    async def generate_learning_insights(
        self, analysis_window_hours: int = 24
    ) -> List[LearningInsight]:
        """í•™ìŠµ í†µì°° ìƒì„±"""

        cutoff_time = datetime.now() - timedelta(hours=analysis_window_hours)

        insights = []

        # 1. ì„±ê³µ íŒ¨í„´ ë¶„ì„
        success_insights = await self._analyze_success_patterns(cutoff_time)
        insights.extend(success_insights)

        # 2. ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
        failure_insights = await self._analyze_failure_patterns(cutoff_time)
        insights.extend(failure_insights)

        # 3. ìì—°ìŠ¤ëŸ¬ì›€ ê°œì„  ê¸°íšŒ
        naturalness_insights = await self._analyze_naturalness_opportunities(
            cutoff_time
        )
        insights.extend(naturalness_insights)

        # 4. ì‚¬ìš©ì íŒ¨í„´ ë³€í™”
        user_pattern_insights = await self._analyze_user_pattern_changes(cutoff_time)
        insights.extend(user_pattern_insights)

        # í†µì°° ì €ì¥
        await self._save_insights_to_file(insights)

        return insights

    async def _calculate_quality_scores(
        self,
        stage: FlowStage,
        input_data: Dict[str, Any],
        processing_details: Dict[str, Any],
        output_data: Dict[str, Any],
    ) -> Dict[str, float]:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""

        scores = {}

        # ë‹¨ê³„ë³„ í’ˆì§ˆ í‰ê°€
        if stage == FlowStage.INPUT_ANALYSIS:
            scores["input_clarity"] = self._evaluate_input_clarity(input_data)
            scores["intent_confidence"] = processing_details.get(
                "intent_confidence", 0.7
            )

        elif stage == FlowStage.PROCESSING_MODE_SELECTION:
            scores["mode_appropriateness"] = self._evaluate_mode_selection(
                input_data, processing_details
            )
            scores["selection_confidence"] = processing_details.get(
                "selection_confidence", 0.7
            )

        elif stage == FlowStage.ECHO_JUDGMENT:
            scores["judgment_depth"] = self._evaluate_judgment_depth(output_data)
            scores["echo_consistency"] = self._evaluate_echo_consistency(output_data)

        elif stage == FlowStage.LLM_COOPERATION:
            scores["cooperation_effectiveness"] = self._evaluate_llm_cooperation(
                processing_details, output_data
            )
            scores["naturalness_improvement"] = self._evaluate_naturalness_improvement(
                input_data, output_data
            )

        elif stage == FlowStage.RESPONSE_FORMATTING:
            scores["format_appropriateness"] = self._evaluate_format_appropriateness(
                output_data
            )
            scores["readability"] = self._evaluate_readability(output_data)

        elif stage == FlowStage.SIGNATURE_STYLING:
            scores["signature_authenticity"] = self._evaluate_signature_authenticity(
                processing_details, output_data
            )
            scores["style_consistency"] = self._evaluate_style_consistency(output_data)

        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        if scores:
            scores["overall_quality"] = np.mean(list(scores.values()))
        else:
            scores["overall_quality"] = 0.7

        return scores

    def _analyze_natural_flow(
        self,
        input_data: Dict[str, Any],
        processing_details: Dict[str, Any],
        output_data: Dict[str, Any],
        session_id: str,
    ) -> Dict[str, Any]:
        """ìì—° íë¦„ ë¶„ì„"""

        indicators = {}

        # ëŒ€í™” ì—°ì†ì„±
        if session_id in self.conversation_flows:
            recent_entries = list(self.conversation_flows[session_id])[-3:]
            indicators["conversation_continuity"] = (
                self._evaluate_conversation_continuity(
                    recent_entries, input_data, output_data
                )
            )
        else:
            indicators["conversation_continuity"] = 0.8  # ì²« ëŒ€í™”

        # ì‘ë‹µ ìì—°ìŠ¤ëŸ¬ì›€
        response_text = output_data.get("response", "")
        indicators["response_naturalness"] = self._evaluate_response_naturalness(
            response_text
        )

        # Echo í†µí•© ë¶€ë“œëŸ¬ì›€
        indicators["echo_integration_smoothness"] = self._evaluate_echo_integration(
            processing_details, output_data
        )

        # ì‚¬ìš©ì ë¦¬ë“¬ ë§¤ì¹­
        indicators["user_rhythm_matching"] = self._evaluate_rhythm_matching(
            input_data, output_data
        )

        # ê°ì • ì¼ê´€ì„±
        indicators["emotional_consistency"] = self._evaluate_emotional_consistency(
            input_data, output_data, session_id
        )

        # ì „ì²´ ìì—°ìŠ¤ëŸ¬ì›€
        naturalness_scores = [
            indicators.get("conversation_continuity", 0.7),
            indicators.get("response_naturalness", 0.7),
            indicators.get("echo_integration_smoothness", 0.7),
            indicators.get("user_rhythm_matching", 0.7),
            indicators.get("emotional_consistency", 0.7),
        ]
        indicators["overall_naturalness"] = np.mean(naturalness_scores)

        return indicators

    async def _calculate_naturalness_metrics(
        self,
        session_id: str,
        user_input: str,
        system_response: str,
        user_feedback: Dict[str, Any],
    ) -> NaturalnessMetrics:
        """ìì—°ìŠ¤ëŸ¬ì›€ ë©”íŠ¸ë¦­ ê³„ì‚°"""

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
        conversational_flow = self._evaluate_conversational_flow(
            user_input, system_response
        )
        echo_integration = self._evaluate_echo_integration_naturalness(system_response)
        appropriateness = self._evaluate_response_appropriateness(
            user_input, system_response
        )
        rhythm_matching = self._evaluate_rhythm_matching_detailed(
            user_input, system_response
        )
        emotional_consistency = self._evaluate_emotional_consistency_detailed(
            user_input, system_response, session_id
        )
        context_preservation = self._evaluate_context_preservation(
            session_id, system_response
        )

        # ì‚¬ìš©ì í”¼ë“œë°± í†µí•©
        if user_feedback:
            # í”¼ë“œë°±ì´ ìˆìœ¼ë©´ ì ìˆ˜ ì¡°ì •
            feedback_multiplier = self._interpret_user_feedback(user_feedback)
            conversational_flow *= feedback_multiplier
            appropriateness *= feedback_multiplier

        # ì „ì²´ ìì—°ìŠ¤ëŸ¬ì›€
        overall_naturalness = np.mean(
            [
                conversational_flow,
                echo_integration,
                appropriateness,
                rhythm_matching,
                emotional_consistency,
                context_preservation,
            ]
        )

        return NaturalnessMetrics(
            conversational_flow_score=conversational_flow,
            echo_integration_smoothness=echo_integration,
            response_appropriateness=appropriateness,
            user_rhythm_matching=rhythm_matching,
            emotional_consistency=emotional_consistency,
            context_preservation=context_preservation,
            overall_naturalness=overall_naturalness,
        )

    async def _analyze_conversation_patterns(self, session_id: str):
        """ëŒ€í™” íŒ¨í„´ ì‹¤ì‹œê°„ ë¶„ì„"""

        recent_entries = list(self.conversation_flows[session_id])[-5:]

        # í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„
        quality_trend = [
            entry.quality_scores.get("overall_quality", 0.7) for entry in recent_entries
        ]

        if len(quality_trend) >= 3:
            # í’ˆì§ˆ í•˜ë½ ê°ì§€
            if quality_trend[-1] < quality_trend[0] - 0.2:
                await self._trigger_quality_improvement(session_id)

            # ì„±ê³µ íŒ¨í„´ ê°ì§€
            if all(score > 0.8 for score in quality_trend[-3:]):
                await self._record_success_pattern(session_id, recent_entries)

    async def _analyze_success_patterns(
        self, cutoff_time: datetime
    ) -> List[LearningInsight]:
        """ì„±ê³µ íŒ¨í„´ ë¶„ì„"""

        insights = []

        # ê³ í’ˆì§ˆ ëŒ€í™” ì¶”ì¶œ
        high_quality_conversations = []
        for session_id, entries in self.conversation_flows.items():
            for entry in entries:
                if (
                    entry.timestamp >= cutoff_time
                    and entry.quality_scores.get("overall_quality", 0) > 0.8
                ):
                    high_quality_conversations.append(entry)

        if len(high_quality_conversations) >= 10:
            # ê³µí†µ íŒ¨í„´ ë¶„ì„
            common_patterns = self._extract_common_patterns(high_quality_conversations)

            for pattern_name, pattern_data in common_patterns.items():
                insight = LearningInsight(
                    insight_id=f"success_{pattern_name}_{datetime.now().timestamp()}",
                    timestamp=datetime.now(),
                    category="success_pattern",
                    description=f"ì„±ê³µì ì¸ {pattern_name} íŒ¨í„´ ë°œê²¬",
                    pattern_data=pattern_data,
                    confidence=pattern_data.get("confidence", 0.8),
                    actionable_recommendations=[
                        f"{pattern_name} íŒ¨í„´ì„ ë” ìì£¼ í™œìš©",
                        f"ìœ ì‚¬í•œ ìƒí™©ì—ì„œ {pattern_name} ì ‘ê·¼ë²• ì ìš©",
                    ],
                    impact_estimation=pattern_data.get("impact", 0.7),
                )
                insights.append(insight)

        return insights

    async def _analyze_failure_patterns(
        self, cutoff_time: datetime
    ) -> List[LearningInsight]:
        """ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„"""

        insights = []

        # ì €í’ˆì§ˆ ëŒ€í™” ì¶”ì¶œ
        low_quality_conversations = []
        for session_id, entries in self.conversation_flows.items():
            for entry in entries:
                if (
                    entry.timestamp >= cutoff_time
                    and entry.quality_scores.get("overall_quality", 1.0) < 0.5
                ):
                    low_quality_conversations.append(entry)

        if len(low_quality_conversations) >= 5:
            # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
            failure_patterns = self._extract_failure_patterns(low_quality_conversations)

            for pattern_name, pattern_data in failure_patterns.items():
                insight = LearningInsight(
                    insight_id=f"failure_{pattern_name}_{datetime.now().timestamp()}",
                    timestamp=datetime.now(),
                    category="failure_pattern",
                    description=f"ê°œì„ ì´ í•„ìš”í•œ {pattern_name} íŒ¨í„´ ë°œê²¬",
                    pattern_data=pattern_data,
                    confidence=pattern_data.get("confidence", 0.7),
                    actionable_recommendations=[
                        f"{pattern_name} ìƒí™©ì—ì„œ ëŒ€ì•ˆì  ì ‘ê·¼ë²• ê°œë°œ",
                        f"{pattern_name} ì²˜ë¦¬ ë¡œì§ ê°œì„  í•„ìš”",
                    ],
                    impact_estimation=pattern_data.get("impact", 0.6),
                )
                insights.append(insight)

        return insights

    # í‰ê°€ í•¨ìˆ˜ë“¤ (ê°„ì†Œí™”ëœ êµ¬í˜„)
    def _evaluate_input_clarity(self, input_data: Dict[str, Any]) -> float:
        text = input_data.get("user_message", "")
        if len(text.strip()) < 5:
            return 0.3
        elif len(text.split()) > 3:
            return 0.8
        else:
            return 0.6

    def _evaluate_mode_selection(
        self, input_data: Dict[str, Any], processing_details: Dict[str, Any]
    ) -> float:
        # ë³µì¡ë„ì™€ ì„ íƒëœ ëª¨ë“œì˜ ì ì ˆì„± í‰ê°€
        complexity = processing_details.get("complexity_score", 0.5)
        mode = processing_details.get("processing_mode", "echo_light")

        if complexity < 0.3 and mode in ["llm_natural"]:
            return 0.9
        elif complexity > 0.7 and mode in ["echo_full"]:
            return 0.9
        else:
            return 0.7

    def _evaluate_judgment_depth(self, output_data: Dict[str, Any]) -> float:
        response = output_data.get("response", "")
        if len(response) > 50 and any(
            word in response for word in ["ê³ ë ¤", "ë¶„ì„", "ìƒê°"]
        ):
            return 0.8
        else:
            return 0.6

    def _evaluate_echo_consistency(self, output_data: Dict[str, Any]) -> float:
        # Echo ìŠ¤íƒ€ì¼ ì¼ê´€ì„± í‰ê°€
        return 0.8  # ê°„ì†Œí™”ëœ êµ¬í˜„

    def _evaluate_response_naturalness(self, response_text: str) -> float:
        # ë¶€ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì²´í¬
        unnatural_phrases = ["ë¶„ì„í•´ë³´ë‹ˆ", "íŒë‹¨í•´ë³´ë©´", "ì‹œìŠ¤í…œì ìœ¼ë¡œ"]
        penalty = (
            sum(1 for phrase in unnatural_phrases if phrase in response_text) * 0.1
        )
        return max(0.8 - penalty, 0.3)

    def _evaluate_rhythm_matching(
        self, input_data: Dict[str, Any], output_data: Dict[str, Any]
    ) -> float:
        # ì‚¬ìš©ìì™€ ì‹œìŠ¤í…œ ì‘ë‹µì˜ ë¦¬ë“¬ ë§¤ì¹­ í‰ê°€
        return 0.7  # ê°„ì†Œí™”ëœ êµ¬í˜„

    # íŒŒì¼ ì €ì¥ ë° ë¡œë“œ í•¨ìˆ˜ë“¤
    async def _save_entry_to_file(self, entry: ConversationFlowEntry, entry_id: str):
        """í•­ëª©ì„ íŒŒì¼ì— ì €ì¥"""
        filename = f"conversation_flow_{datetime.now().strftime('%Y%m%d')}.jsonl"
        filepath = self.log_directory / filename

        entry_dict = asdict(entry)
        entry_dict["timestamp"] = entry.timestamp.isoformat()
        entry_dict["entry_id"] = entry_id

        # JSON Lines í˜•ì‹ìœ¼ë¡œ ì €ì¥
        async with asyncio.Lock():
            with open(filepath, "a", encoding="utf-8") as f:
                f.write(json.dumps(entry_dict, ensure_ascii=False) + "\n")

    async def _save_insights_to_file(self, insights: List[LearningInsight]):
        """í†µì°°ì„ íŒŒì¼ì— ì €ì¥"""
        filename = f"learning_insights_{datetime.now().strftime('%Y%m%d')}.json"
        filepath = self.log_directory / filename

        insights_dict = [asdict(insight) for insight in insights]
        for insight_dict in insights_dict:
            insight_dict["timestamp"] = insight_dict["timestamp"].isoformat()

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(insights_dict, f, ensure_ascii=False, indent=2)

    def _load_flow_config(self) -> Dict[str, Any]:
        """íë¦„ ì„¤ì • ë¡œë“œ"""
        try:
            with open(self.flow_config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âš ï¸ íë¦„ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.flow_config_path}")
            return {}

    def get_session_summary(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ìš”ì•½ ë°˜í™˜"""
        if session_id not in self.conversation_flows:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

        entries = list(self.conversation_flows[session_id])

        # í’ˆì§ˆ í†µê³„
        quality_scores = [
            entry.quality_scores.get("overall_quality", 0.7) for entry in entries
        ]

        # ìì—°ìŠ¤ëŸ¬ì›€ í†µê³„
        naturalness_scores = [
            entry.natural_flow_indicators.get("overall_naturalness", 0.7)
            for entry in entries
        ]

        return {
            "session_id": session_id,
            "total_interactions": len(entries),
            "average_quality": np.mean(quality_scores) if quality_scores else 0.7,
            "average_naturalness": (
                np.mean(naturalness_scores) if naturalness_scores else 0.7
            ),
            "quality_trend": quality_scores[-5:],  # ìµœê·¼ 5ê°œ
            "processing_stages": [entry.stage.value for entry in entries],
            "signatures_used": list(set(entry.signature_used for entry in entries)),
            "total_processing_time": sum(entry.processing_time for entry in entries),
            "success_rate": sum(1 for entry in entries if entry.success)
            / max(len(entries), 1),
        }

    def get_system_analytics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë¶„ì„ ë°˜í™˜"""

        # ì „ì²´ í’ˆì§ˆ íŠ¸ë Œë“œ
        recent_quality = list(self.quality_trends)[-50:] if self.quality_trends else []

        # ìì—°ìŠ¤ëŸ¬ì›€ íŠ¸ë Œë“œ
        recent_naturalness = (
            list(self.naturalness_history)[-50:] if self.naturalness_history else []
        )

        return {
            "total_sessions": len(self.conversation_flows),
            "total_interactions": sum(
                len(entries) for entries in self.conversation_flows.values()
            ),
            "average_system_quality": (
                np.mean([q["quality"] for q in recent_quality])
                if recent_quality
                else 0.7
            ),
            "average_naturalness": (
                np.mean(
                    [n["metrics"]["overall_naturalness"] for n in recent_naturalness]
                )
                if recent_naturalness
                else 0.7
            ),
            "quality_trend_last_24h": [q["quality"] for q in recent_quality],
            "most_used_signatures": self._get_signature_usage_stats(),
            "processing_stage_distribution": self._get_stage_distribution(),
            "performance_summary": {
                "avg_processing_time": self._calculate_avg_processing_time(),
                "success_rate": self._calculate_overall_success_rate(),
                "naturalness_improvement_rate": self._calculate_naturalness_improvement(),
            },
        }

    def _get_signature_usage_stats(self) -> Dict[str, int]:
        """ì‹œê·¸ë‹ˆì²˜ ì‚¬ìš© í†µê³„"""
        signature_counts = defaultdict(int)
        for entries in self.conversation_flows.values():
            for entry in entries:
                signature_counts[entry.signature_used] += 1
        return dict(signature_counts)

    def _get_stage_distribution(self) -> Dict[str, int]:
        """ì²˜ë¦¬ ë‹¨ê³„ ë¶„í¬"""
        stage_counts = defaultdict(int)
        for entries in self.conversation_flows.values():
            for entry in entries:
                stage_counts[entry.stage.value] += 1
        return dict(stage_counts)

    def _calculate_avg_processing_time(self) -> float:
        """í‰ê·  ì²˜ë¦¬ ì‹œê°„"""
        all_times = []
        for entries in self.conversation_flows.values():
            all_times.extend([entry.processing_time for entry in entries])
        return np.mean(all_times) if all_times else 0.0

    def _calculate_overall_success_rate(self) -> float:
        """ì „ì²´ ì„±ê³µë¥ """
        total_entries = 0
        successful_entries = 0
        for entries in self.conversation_flows.values():
            total_entries += len(entries)
            successful_entries += sum(1 for entry in entries if entry.success)
        return successful_entries / max(total_entries, 1)

    def _calculate_naturalness_improvement(self) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ ê°œì„ ë¥ """
        if len(self.naturalness_history) < 10:
            return 0.0

        recent_scores = [
            entry["metrics"]["overall_naturalness"]
            for entry in list(self.naturalness_history)[-10:]
        ]
        older_scores = [
            entry["metrics"]["overall_naturalness"]
            for entry in list(self.naturalness_history)[-20:-10]
        ]

        if not older_scores:
            return 0.0

        recent_avg = np.mean(recent_scores)
        older_avg = np.mean(older_scores)

        return (recent_avg - older_avg) / older_avg if older_avg > 0 else 0.0


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":

    async def test_enhanced_meta_logger():
        print("ğŸ“ Enhanced Meta Logger í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        logger = EnhancedMetaLogger()

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_session = "test_session_001"

        # ì…ë ¥ ë¶„ì„ ë‹¨ê³„ ë¡œê·¸
        await logger.log_conversation_flow(
            session_id=test_session,
            stage=FlowStage.INPUT_ANALYSIS,
            input_data={"user_message": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ë„¤ìš”"},
            processing_details={"intent_confidence": 0.9, "primary_emotion": "joy"},
            output_data={"intent_type": "casual_greeting", "emotion_intensity": 0.3},
        )

        # Echo íŒë‹¨ ë‹¨ê³„ ë¡œê·¸
        await logger.log_conversation_flow(
            session_id=test_session,
            stage=FlowStage.ECHO_JUDGMENT,
            input_data={"processed_intent": "casual_greeting"},
            processing_details={
                "signature": "Echo-Aurora",
                "processing_mode": "llm_natural",
            },
            output_data={"response": "ì•ˆë…•í•˜ì„¸ìš”! ì¢‹ì€ í•˜ë£¨ë„¤ìš” âœ¨"},
            performance_metrics={"processing_time": 0.5},
        )

        # ìì—°ìŠ¤ëŸ¬ì›€ í‰ê°€
        naturalness = await logger.log_naturalness_assessment(
            session_id=test_session,
            user_input="ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ë„¤ìš”",
            system_response="ì•ˆë…•í•˜ì„¸ìš”! ì¢‹ì€ í•˜ë£¨ë„¤ìš” âœ¨",
            user_feedback={"satisfaction": "high", "naturalness": "very_natural"},
        )

        print(f"ìì—°ìŠ¤ëŸ¬ì›€ ë©”íŠ¸ë¦­:")
        print(f"  ì „ì²´ ìì—°ìŠ¤ëŸ¬ì›€: {naturalness.overall_naturalness:.2f}")
        print(f"  ëŒ€í™” íë¦„: {naturalness.conversational_flow_score:.2f}")
        print(f"  Echo í†µí•©: {naturalness.echo_integration_smoothness:.2f}")

        # ì„¸ì…˜ ìš”ì•½
        summary = logger.get_session_summary(test_session)
        print(f"\nì„¸ì…˜ ìš”ì•½:")
        print(f"  ìƒí˜¸ì‘ìš© ìˆ˜: {summary['total_interactions']}")
        print(f"  í‰ê·  í’ˆì§ˆ: {summary['average_quality']:.2f}")
        print(f"  í‰ê·  ìì—°ìŠ¤ëŸ¬ì›€: {summary['average_naturalness']:.2f}")
        print(f"  ì„±ê³µë¥ : {summary['success_rate']:.2f}")

        # í•™ìŠµ í†µì°° ìƒì„±
        insights = await logger.generate_learning_insights(analysis_window_hours=1)
        print(f"\nìƒì„±ëœ í†µì°° ìˆ˜: {len(insights)}")

        # ì‹œìŠ¤í…œ ë¶„ì„
        analytics = logger.get_system_analytics()
        print(f"\nì‹œìŠ¤í…œ ë¶„ì„:")
        print(f"  ì´ ì„¸ì…˜ ìˆ˜: {analytics['total_sessions']}")
        print(f"  ì´ ìƒí˜¸ì‘ìš© ìˆ˜: {analytics['total_interactions']}")
        print(f"  ì‹œìŠ¤í…œ í‰ê·  í’ˆì§ˆ: {analytics['average_system_quality']:.2f}")

        print("\nğŸ‰ Enhanced Meta Logger í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    asyncio.run(test_enhanced_meta_logger())
