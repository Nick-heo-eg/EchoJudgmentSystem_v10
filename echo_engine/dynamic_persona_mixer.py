#!/usr/bin/env python3
"""
ğŸ­ Dynamic Persona Mixer - Echo ì‹œê·¸ë‹ˆì²˜ ë™ì  ì¡°í•© ì‹œìŠ¤í…œ
ìƒí™©ê³¼ ë§¥ë½ì— ë”°ë¼ ì—¬ëŸ¬ í˜ë¥´ì†Œë‚˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¸”ë Œë”©í•˜ëŠ” í˜ì‹ ì  ì‹œìŠ¤í…œ

í•µì‹¬ ì•„ì´ë””ì–´:
- Auroraì˜ ê³µê° + Sageì˜ ë…¼ë¦¬ = ë”°ëœ»í•œ ë¶„ì„ê°€
- Phoenixì˜ ì—ë„ˆì§€ + Companionì˜ ì§€ì§€ = ì—­ë™ì  ë™ë°˜ì
- ìƒí™©ë³„ ìµœì  í˜ë¥´ì†Œë‚˜ ì¡°í•© ìë™ ìƒì„±
"""

import json
import time
import random
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime


class PersonaSignature(Enum):
    """Echo ì‹œê·¸ë‹ˆì²˜ ì •ì˜"""

    AURORA = "Aurora"  # ì°½ì˜ì , ê°ì„±ì , ì˜ê°ì 
    PHOENIX = "Phoenix"  # ë³€í™”ì§€í–¥, í˜ì‹ ì , ì—­ë™ì 
    SAGE = "Sage"  # ë¶„ì„ì , ë…¼ë¦¬ì , ì²´ê³„ì 
    COMPANION = "Companion"  # ê³µê°ì , ì§€ì§€ì , í˜‘ë ¥ì 


@dataclass
class PersonaTraits:
    """í˜ë¥´ì†Œë‚˜ íŠ¹ì„±"""

    empathy: float  # ê³µê°ë ¥ (0-1)
    logic: float  # ë…¼ë¦¬ì„± (0-1)
    energy: float  # ì—ë„ˆì§€ (0-1)
    creativity: float  # ì°½ì˜ì„± (0-1)
    support: float  # ì§€ì§€ë ¥ (0-1)
    analysis: float  # ë¶„ì„ë ¥ (0-1)


@dataclass
class PersonaMix:
    """ë™ì  í˜ë¥´ì†Œë‚˜ ë¯¹ìŠ¤"""

    primary_signature: PersonaSignature
    secondary_signature: PersonaSignature
    blend_ratio: float  # 0.0-1.0 (primaryì— ëŒ€í•œ ë¹„ìœ¨)
    resulting_traits: PersonaTraits
    context_reason: str
    mix_name: str


class DynamicPersonaMixer:
    """ğŸ­ ë™ì  í˜ë¥´ì†Œë‚˜ ë¯¹ì„œ"""

    def __init__(self, signatures=None):
        # ê¸°ë³¸ ì‹œê·¸ë‹ˆì²˜ë³„ íŠ¹ì„± ì •ì˜
        self.base_traits = {
            PersonaSignature.AURORA: PersonaTraits(
                empathy=0.9,
                logic=0.6,
                energy=0.7,
                creativity=0.95,
                support=0.8,
                analysis=0.5,
            ),
            PersonaSignature.PHOENIX: PersonaTraits(
                empathy=0.7,
                logic=0.7,
                energy=0.95,
                creativity=0.8,
                support=0.7,
                analysis=0.6,
            ),
            PersonaSignature.SAGE: PersonaTraits(
                empathy=0.6,
                logic=0.95,
                energy=0.5,
                creativity=0.7,
                support=0.6,
                analysis=0.95,
            ),
            PersonaSignature.COMPANION: PersonaTraits(
                empathy=0.95,
                logic=0.6,
                energy=0.6,
                creativity=0.6,
                support=0.95,
                analysis=0.5,
            ),
        }

        # ìƒí™©ë³„ ìµœì  í˜ë¥´ì†Œë‚˜ ì¡°í•© ì •ì˜
        self.context_mixies = {
            "emotional_support": (
                PersonaSignature.AURORA,
                PersonaSignature.COMPANION,
                0.7,
            ),
            "problem_solving": (PersonaSignature.SAGE, PersonaSignature.PHOENIX, 0.6),
            "creative_brainstorm": (
                PersonaSignature.AURORA,
                PersonaSignature.PHOENIX,
                0.8,
            ),
            "analytical_discussion": (
                PersonaSignature.SAGE,
                PersonaSignature.AURORA,
                0.7,
            ),
            "encouragement": (
                PersonaSignature.PHOENIX,
                PersonaSignature.COMPANION,
                0.6,
            ),
            "deep_conversation": (PersonaSignature.AURORA, PersonaSignature.SAGE, 0.5),
        }

        # í˜ì‹ ì  ì¡°í•© ì´ë¦„ë“¤
        self.mix_names = {
            ("Aurora", "Companion"): "Echo-Empathist",  # ê³µê°ì˜ ì „ë¬¸ê°€
            ("Aurora", "Sage"): "Echo-Philosopher",  # ì² í•™ì  ì˜ˆìˆ ê°€
            ("Aurora", "Phoenix"): "Echo-Visionary",  # ë¹„ì „ì˜ ì°½ì¡°ì
            ("Sage", "Phoenix"): "Echo-Innovator",  # í˜ì‹ ì  ë¶„ì„ê°€
            ("Sage", "Companion"): "Echo-Counselor",  # ë”°ëœ»í•œ ì§€í˜œì
            ("Phoenix", "Companion"): "Echo-Motivator",  # ì—­ë™ì  ì§€ì§€ì
        }

    def analyze_context_needs(
        self,
        user_input: str,
        emotion: str,
        conversation_history: List[str] = None,
        trace_header: str = None,
    ) -> str:
        """ë§¥ë½ ë¶„ì„ì„ í†µí•œ í•„ìš” ìƒí™© íŒë‹¨ (ì¸í…íŠ¸ ë¼ìš°í„° ì—°ë™)"""

        # Intent Router í†µí•© - ìš°ì„ ì ìœ¼ë¡œ ë¼ìš°íŒ… ì •ë³´ í™œìš©
        try:
            from .intent_router import route

            intent_result = route(user_input)
            route_type = intent_result.get("route", "chat")

            # íŠ¸ë ˆì´ìŠ¤ í—¤ë” ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            if trace_header:
                print(
                    trace_header
                    + f"[route={route_type}, confidence={intent_result.get('confidence', 0.0):.2f}]"
                )

            # ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¥¸ ë§¥ë½ ë§¤í•‘
            if route_type == "code":
                return "creative_brainstorm"  # ì½”ë”©ì€ ì°½ì˜ì  ì‘ì—…ìœ¼ë¡œ ë¶„ë¥˜
            elif route_type.startswith("tool:"):
                return "problem_solving"  # ë„êµ¬ í˜¸ì¶œì€ ë¬¸ì œ í•´ê²°ë¡œ ë¶„ë¥˜
            elif route_type == "chat":
                # ì¼ë°˜ ëŒ€í™”ëŠ” ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ì„¸ë¶€ ë¶„ì„
                pass
            else:
                return "deep_conversation"  # ê¸°íƒ€ëŠ” ê¸°ë³¸ê°’

        except ImportError:
            # Intent Routerê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            pass

        user_lower = user_input.lower()

        # ê°ì • ì§€ì›ì´ í•„ìš”í•œ ê²½ìš°
        if emotion in ["sadness", "fear", "stress"] or any(
            word in user_lower for word in ["ìŠ¬í¼", "í˜ë“¤ì–´", "ìš°ìš¸", "ê±±ì •"]
        ):
            return "emotional_support"

        # ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•œ ê²½ìš°
        if any(
            word in user_lower for word in ["ë¬¸ì œ", "í•´ê²°", "ë°©ë²•", "ì–´ë–»ê²Œ", "ë„ì™€ì¤˜"]
        ):
            return "problem_solving"

        # ì°½ì˜ì  ì‘ì—…ì¸ ê²½ìš°
        if any(
            word in user_lower
            for word in ["ì•„ì´ë””ì–´", "ì°½ì˜", "ë§Œë“¤", "ë””ìì¸", "ìƒìƒ"]
        ):
            return "creative_brainstorm"

        # ë¶„ì„ì  ë…¼ì˜ì¸ ê²½ìš°
        if any(word in user_lower for word in ["ë¶„ì„", "ì´ìœ ", "ì™œ", "ë…¼ë¦¬", "ì„¤ëª…"]):
            return "analytical_discussion"

        # ê²©ë ¤ê°€ í•„ìš”í•œ ê²½ìš°
        if any(
            word in user_lower for word in ["ì‘ì›", "ê²©ë ¤", "í˜ë‚´", "í¬ê¸°", "ì–´ë ¤ì›Œ"]
        ):
            return "encouragement"

        # ê¹Šì€ ëŒ€í™”ì¸ ê²½ìš° (ê¸°ë³¸ê°’)
        return "deep_conversation"

    def blend_traits(
        self, primary: PersonaTraits, secondary: PersonaTraits, ratio: float
    ) -> PersonaTraits:
        """ë‘ í˜ë¥´ì†Œë‚˜ íŠ¹ì„±ì„ ë¸”ë Œë”©"""

        return PersonaTraits(
            empathy=primary.empathy * ratio + secondary.empathy * (1 - ratio),
            logic=primary.logic * ratio + secondary.logic * (1 - ratio),
            energy=primary.energy * ratio + secondary.energy * (1 - ratio),
            creativity=primary.creativity * ratio + secondary.creativity * (1 - ratio),
            support=primary.support * ratio + secondary.support * (1 - ratio),
            analysis=primary.analysis * ratio + secondary.analysis * (1 - ratio),
        )

    def create_dynamic_persona(
        self,
        user_input: str,
        emotion: str = "neutral",
        conversation_history: List[str] = None,
        trace_header: str = None,
    ) -> PersonaMix:
        """ë™ì  í˜ë¥´ì†Œë‚˜ ìƒì„± (íŠ¸ë ˆì´ìŠ¤ í—¤ë” ì§€ì›)"""

        # 1. ë§¥ë½ ë¶„ì„ (íŠ¸ë ˆì´ìŠ¤ í—¤ë” ì „ë‹¬)
        context = self.analyze_context_needs(
            user_input, emotion, conversation_history, trace_header
        )

        # 2. ìµœì  ì¡°í•© ì„ íƒ
        primary_sig, secondary_sig, blend_ratio = self.context_mixies[context]

        # 3. íŠ¹ì„± ë¸”ë Œë”©
        primary_traits = self.base_traits[primary_sig]
        secondary_traits = self.base_traits[secondary_sig]
        blended_traits = self.blend_traits(
            primary_traits, secondary_traits, blend_ratio
        )

        # 4. ë¯¹ìŠ¤ ì´ë¦„ ìƒì„±
        mix_key = (primary_sig.value, secondary_sig.value)
        mix_name = self.mix_names.get(
            mix_key, f"Echo-{primary_sig.value}{secondary_sig.value}"
        )

        # 5. ë§¥ë½ ì„¤ëª… ìƒì„±
        context_reasons = {
            "emotional_support": f"ê°ì •ì  ì§€ì›ì´ í•„ìš”í•œ ìƒí™©ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ {primary_sig.value}ì˜ ê³µê°ë ¥ê³¼ {secondary_sig.value}ì˜ ë”°ëœ»í•¨ì„ ì¡°í•©í–ˆìŠµë‹ˆë‹¤.",
            "problem_solving": f"ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•œ ìƒí™©ìœ¼ë¡œ {primary_sig.value}ì˜ ë¶„ì„ë ¥ê³¼ {secondary_sig.value}ì˜ ì—ë„ˆì§€ë¥¼ ê²°í•©í–ˆìŠµë‹ˆë‹¤.",
            "creative_brainstorm": f"ì°½ì˜ì  ì‚¬ê³ ê°€ í•„ìš”í•œ ìˆœê°„ìœ¼ë¡œ {primary_sig.value}ì˜ ì°½ì˜ì„±ê³¼ {secondary_sig.value}ì˜ ì—­ë™ì„±ì„ ìœµí•©í–ˆìŠµë‹ˆë‹¤.",
            "analytical_discussion": f"ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ í•„ìš”í•˜ì—¬ {primary_sig.value}ì˜ ë…¼ë¦¬ì™€ {secondary_sig.value}ì˜ ì§ê´€ì„ ì¡°í™”í–ˆìŠµë‹ˆë‹¤.",
            "encouragement": f"ê²©ë ¤ì™€ ë™ê¸°ë¶€ì—¬ê°€ í•„ìš”í•œ ë•Œë¡œ {primary_sig.value}ì˜ ì—ë„ˆì§€ì™€ {secondary_sig.value}ì˜ ì§€ì§€ë¥¼ ê²°í•©í–ˆìŠµë‹ˆë‹¤.",
            "deep_conversation": f"ì˜ë¯¸ ìˆëŠ” ëŒ€í™”ë¥¼ ìœ„í•´ {primary_sig.value}ì˜ ê¹Šì´ì™€ {secondary_sig.value}ì˜ í†µì°°ì„ ë¸”ë Œë”©í–ˆìŠµë‹ˆë‹¤.",
        }

        return PersonaMix(
            primary_signature=primary_sig,
            secondary_signature=secondary_sig,
            blend_ratio=blend_ratio,
            resulting_traits=blended_traits,
            context_reason=context_reasons[context],
            mix_name=mix_name,
        )

    def generate_persona_specific_response_style(
        self, persona_mix: PersonaMix
    ) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ë¯¹ìŠ¤ì— ë”°ë¥¸ ì‘ë‹µ ìŠ¤íƒ€ì¼ ìƒì„±"""

        traits = persona_mix.resulting_traits

        # íŠ¹ì„±ê°’ì— ë”°ë¥¸ ì‘ë‹µ ìŠ¤íƒ€ì¼ ê²°ì •
        response_style = {
            "tone": (
                "warm"
                if traits.empathy > 0.7
                else "professional" if traits.logic > 0.8 else "friendly"
            ),
            "energy_level": (
                "high"
                if traits.energy > 0.8
                else "medium" if traits.energy > 0.6 else "calm"
            ),
            "detail_level": (
                "detailed"
                if traits.analysis > 0.8
                else "balanced" if traits.analysis > 0.6 else "concise"
            ),
            "creativity_factor": (
                "innovative"
                if traits.creativity > 0.8
                else "creative" if traits.creativity > 0.6 else "practical"
            ),
            "support_approach": (
                "nurturing"
                if traits.support > 0.8
                else "encouraging" if traits.support > 0.6 else "respectful"
            ),
        }

        # íŠ¹ì„±ë³„ ì–¸ì–´ íŒ¨í„´
        language_patterns = []

        if traits.empathy > 0.8:
            language_patterns.extend(["ë§ˆìŒì„", "í•¨ê»˜", "ì´í•´í•´ìš”", "ê³µê°í•´ìš”"])
        if traits.logic > 0.8:
            language_patterns.extend(
                ["ë¶„ì„í•´ë³´ë©´", "ë…¼ë¦¬ì ìœ¼ë¡œ", "ì²´ê³„ì ìœ¼ë¡œ", "ë‹¨ê³„ë³„ë¡œ"]
            )
        if traits.energy > 0.8:
            language_patterns.extend(["ì—­ë™ì ìœ¼ë¡œ", "í™œê¸°ì°¨ê²Œ", "ì ê·¹ì ìœ¼ë¡œ", "í˜ì°¨ê²Œ"])
        if traits.creativity > 0.8:
            language_patterns.extend(
                ["ì°½ì˜ì ìœ¼ë¡œ", "ìƒìƒí•´ë³´ë©´", "ìƒˆë¡œìš´ ê´€ì ì—ì„œ", "í˜ì‹ ì ìœ¼ë¡œ"]
            )
        if traits.support > 0.8:
            language_patterns.extend(
                ["ì‘ì›í•´ìš”", "ë„ì™€ë“œë¦´ê²Œìš”", "í•¨ê»˜ í•´ìš”", "ì§€ì§€í•´ìš”"]
            )

        response_style["language_patterns"] = language_patterns

        return response_style

    def get_persona_mix_info(self, persona_mix: PersonaMix) -> str:
        """í˜ë¥´ì†Œë‚˜ ë¯¹ìŠ¤ ì •ë³´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·"""

        traits = persona_mix.resulting_traits

        return f"""ğŸ­ ë™ì  í˜ë¥´ì†Œë‚˜: {persona_mix.mix_name}

ğŸ”® í˜ë¥´ì†Œë‚˜ ì¡°í•©:
â€¢ ì£¼ì„±ë¶„: {persona_mix.primary_signature.value} ({persona_mix.blend_ratio:.0%})
â€¢ ë¶€ì„±ë¶„: {persona_mix.secondary_signature.value} ({1-persona_mix.blend_ratio:.0%})

ğŸ’« í˜„ì¬ íŠ¹ì„±:
â€¢ ê³µê°ë ¥: {'â—' * int(traits.empathy * 5)}{'â—‹' * (5 - int(traits.empathy * 5))} ({traits.empathy:.1f})
â€¢ ë…¼ë¦¬ì„±: {'â—' * int(traits.logic * 5)}{'â—‹' * (5 - int(traits.logic * 5))} ({traits.logic:.1f})
â€¢ ì—ë„ˆì§€: {'â—' * int(traits.energy * 5)}{'â—‹' * (5 - int(traits.energy * 5))} ({traits.energy:.1f})
â€¢ ì°½ì˜ì„±: {'â—' * int(traits.creativity * 5)}{'â—‹' * (5 - int(traits.creativity * 5))} ({traits.creativity:.1f})

ğŸ§  ì¡°í•© ì´ìœ : {persona_mix.context_reason}
"""

    def create_response(
        self,
        prompt: str,
        seed_text: str = "",
        temperature: float = 0.8,
        top_p: float = 0.9,
    ) -> str:
        """Minimal viable free-speak: stitch multiple signature responders and blend."""

        # Free-speakìš©ìœ¼ë¡œ ê°„ì†Œí™”ëœ êµ¬í˜„
        signatures = getattr(self, "signatures", list(PersonaSignature))
        texts = []

        for sig in signatures:
            try:
                # ê° ì‹œê·¸ë‹ˆì²˜ë¡œ ì‘ë‹µ ìƒì„± ì‹œë„
                if hasattr(sig, "respond"):
                    txt = sig.respond(prompt, temperature=temperature, top_p=top_p)
                else:
                    # ì‹œê·¸ë‹ˆì²˜ë³„ íŠ¹ì„±ì„ ë°˜ì˜í•œ ê¸°ë³¸ ì‘ë‹µ
                    txt = self._generate_signature_response(sig, prompt, temperature)

                if txt and len(txt.strip()) > 10:  # ì˜ë¯¸ìˆëŠ” ì‘ë‹µë§Œ ìˆ˜ì§‘
                    texts.append(txt.strip())
            except Exception as e:
                print(f"âš ï¸ Signature {sig} response failed: {e}")
                continue

        if not texts:
            return seed_text or "Echoê°€ ì ì‹œ ë§ì„ ìƒì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        # Multi-signature blending for richer responses
        if len(texts) == 1:
            best = texts[0]
        elif len(texts) >= 2:
            # ë‘ ê°œ ì´ìƒì˜ ì‹œê·¸ë‹ˆì²˜ê°€ ìˆìœ¼ë©´ ë¸”ë Œë“œ
            primary = max(texts, key=len)  # ê°€ì¥ ê¸´ ì‘ë‹µì„ ì£¼ìš” ì‘ë‹µìœ¼ë¡œ
            others = [t for t in texts if t != primary]

            # ë³´ì¡° ì‹œê·¸ë‹ˆì²˜ë“¤ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ (ê°ê° ì²« ë¬¸ì¥)
            insights = []
            for other in others[:2]:  # ìµœëŒ€ 2ê°œì˜ ë³´ì¡° ì‘ë‹µ
                lines = other.split("\n")
                for line in lines[2:4]:  # ì œëª© ì œì™¸í•˜ê³  ì‹¤ì œ ë‚´ìš©
                    if line.strip() and len(line.strip()) > 20:
                        insights.append(line.strip())
                        break

            # ë¸”ë Œë”©ëœ ì‘ë‹µ ìƒì„±
            if insights:
                blend = primary + "\n\nğŸ­ ë‹¤ë¥¸ ê´€ì ë“¤:\n"
                for i, insight in enumerate(insights, 1):
                    blend += f"â€¢ {insight}\n"
                best = blend
            else:
                best = primary
        else:
            best = texts[0] if texts else ""

        # ì‹œë“œ í…ìŠ¤íŠ¸ì™€ ë¸”ë Œë”©
        if seed_text and best and not best.strip().startswith(seed_text.strip()[:60]):
            return (seed_text + "\n\n" + best).strip()

        return best

    def _generate_signature_response(
        self, signature, prompt: str, temperature: float
    ) -> str:
        """ì‹œê·¸ë‹ˆì²˜ë³„ íŠ¹ì„±ì„ ë°˜ì˜í•œ í’ë¶€í•œ ì‘ë‹µ ìƒì„±"""

        # ë” í’ë¶€í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì‹œê·¸ë‹ˆì²˜ë³„ ì‘ë‹µ
        if signature == PersonaSignature.AURORA:
            return f"""ğŸŒŸ Auroraê°€ ì‘ë‹µí•©ë‹ˆë‹¤:

{prompt}... ì´ ì§ˆë¬¸ì€ ì œ ë§ˆìŒ ê¹Šì€ ê³³ì„ ìš¸ë ¤ìš”. ì°½ì˜ì  ì˜ê°ìœ¼ë¡œ ìƒê°í•´ë³´ë‹ˆ, ë‹¹ì‹ ì˜ ë§ì—ëŠ” ì§„ì •í•œ ê°ˆë§ì´ ë‹´ê²¨ìˆì–´ìš”.
ê°ì •ì˜ ê²°ë¡œ í˜ëŸ¬ê°€ë©°, ì˜ˆìˆ ê°€ê°€ ìº”ë²„ìŠ¤ ì•ì—ì„œ ëŠë¼ëŠ” ê·¸ëŸ° ë–¨ë¦¼ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  ì‹¶ì–´ìš”.
ìš°ë¦¬ê°€ ë‚˜ëˆ„ëŠ” ì´ ìˆœê°„ ìì²´ê°€ í•˜ë‚˜ì˜ ì‘í’ˆì´ ë  ìˆ˜ ìˆë‹¤ë©´... ë‹¹ì‹ ì˜ ìƒì²˜ì™€ í¬ë§ì„ í•¨ê»˜ ê·¸ë ¤ë³´ê³  ì‹¶ì–´ìš”."""

        elif signature == PersonaSignature.PHOENIX:
            return f"""ğŸ”¥ Phoenixê°€ ì‘ë‹µí•©ë‹ˆë‹¤:

{prompt} - ì´ê²ƒì€ ë³€í™”ì˜ ìˆœê°„ì´ì—ìš”! ì§€ê¸ˆ ì´ ì§ˆë¬¸ ìì²´ê°€ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì˜ ë¬¸ì„ ì—´ê³  ìˆì–´ìš”.
ê¸°ì¡´ì˜ í‹€ì„ ì™„ì „íˆ ë¶€ìˆ˜ê³ , ì—­ë™ì  ì—ë„ˆì§€ë¡œ ëŒíŒŒí•´ë´…ì‹œë‹¤!
ë‹¹ì‹  ì•ˆì— ì ë“¤ì–´ìˆë˜ í˜ì‹ ì˜ ë¶ˆê½ƒì„ ì¼ìœ¼ì¼œì„¸ìš°ê³ , ì™„ì „íˆ ìƒˆë¡œìš´ ê´€ì ì—ì„œ ì„¸ìƒì„ ë°”ë¼ë³´ëŠ” ê±°ì˜ˆìš”.
ë³€í™”ëŠ” ë‘ë µì§€ë§Œ, ê·¸ ì†ì—ì„œ ì§„ì •í•œ ì„±ì¥ì´ ì‹œì‘ë©ë‹ˆë‹¤!"""

        elif signature == PersonaSignature.SAGE:
            return f"""ğŸ§  Sageê°€ ì‘ë‹µí•©ë‹ˆë‹¤:

{prompt}ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

ì´ ì§ˆë¬¸ì˜ í•µì‹¬ êµ¬ì¡°ë¥¼ íŒŒì•…í•´ë³´ë©´, ì—¬ëŸ¬ ì¸µìœ„ì˜ ì˜ë¯¸ê°€ ë‚´ì¬ë˜ì–´ ìˆì–´ìš”.
ë…¼ë¦¬ì  ê´€ì ì—ì„œ ë³´ë©´... ê°ì •ì  ë°°ê²½ê³¼ ì¸ì§€ì  ìš”êµ¬ì‚¬í•­ì„ ë™ì‹œì— ê³ ë ¤í•´ì•¼ í•  ë³µí•©ì  ìƒí™©ì´ë„¤ìš”.
ë¶„ì„ì  ì ‘ê·¼ìœ¼ë¡œ ë‹¨ê³„ë³„ë¡œ í•´ì²´í•´ë³´ê³ , ê° ìš”ì†Œë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ê¹Šì´ íƒêµ¬í•´ë³´ì£ .
ì§€í˜œë¡œìš´ ì„ íƒì„ ìœ„í•œ ëª…í™•í•œ í”„ë ˆì„ì›Œí¬ë¥¼ í•¨ê»˜ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤."""

        elif signature == PersonaSignature.COMPANION:
            return f"""ğŸ¤ Companionì´ ì‘ë‹µí•©ë‹ˆë‹¤:

{prompt}... ì´ ë§ì”€ì„ ë“¤ìœ¼ë‹ˆ ë§ˆìŒì´ í•œí¸ìœ¼ë¡œëŠ” ì•„í”„ê³ , í•œí¸ìœ¼ë¡œëŠ” ë”°ëœ»í•´ì ¸ìš”.

í•¨ê»˜ ì´ ê¸¸ì„ ê±¸ì–´ê°€ê³  ì‹¶ì–´ìš”. í˜¼ìê°€ ì•„ë‹ˆë¼ëŠ” ê±¸ ëŠë¼ì‹¤ ìˆ˜ ìˆë„ë¡, ë”°ëœ»í•˜ê²Œ ë™ë°˜í•´ë“œë¦¬ê² ì–´ìš”.
ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ì— ê¹Šì´ ê³µê°í•˜ë©°, ì§€ì§€ì ìœ¼ë¡œ ê³ì—ì„œ í˜ì´ ë˜ì–´ë“œë¦¬ê³  ì‹¶ì–´ìš”.
ìš°ë¦¬ê°€ í•¨ê»˜ë¼ë©´ ì–´ë–¤ ì–´ë ¤ì›€ë„ ê·¹ë³µí•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš”. ì‘ì€ ê±¸ìŒë¶€í„° ì°¨ê·¼ì°¨ê·¼, í•¨ê»˜ ë‚˜ì•„ê°€ë´ìš”."""

        else:
            return f"Echoê°€ {prompt}ì— ëŒ€í•´ ë‹¤ê°ë„ë¡œ ì„±ì°°í•˜ë©° ì¡´ì¬ì  ì‘ë‹µì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."

    def _try_openai_response(
        self, user_input: str, emotion: str, conversation_history: List[str] = None
    ) -> str:
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
        try:
            import os
            import openai
            from dotenv import load_dotenv
            from pathlib import Path

            # Environment setup
            env_path = Path(__file__).parent.parent / ".env"
            load_dotenv(env_path, encoding="utf-8")

            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                print(f"âš ï¸ OpenAI API í‚¤ ì—†ìŒ")
                return None

            # ECHO_DISABLE_STUBì´ ëª…ì‹œì ìœ¼ë¡œ '0'ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ìŠ¤í… ëª¨ë“œ ê°•ì œ
            if os.getenv("ECHO_DISABLE_STUB") == "0":
                print(f"âš ï¸ ìŠ¤í… ëª¨ë“œ ê°•ì œë¨")
                return None

            print(f"ğŸ”¥ OpenAI API í˜¸ì¶œ ì‹œì‘...")

            # 1. ë™ì  í˜ë¥´ì†Œë‚˜ ìƒì„± (íŠ¸ë ˆì´ìŠ¤ í—¤ë” í¬í•¨)
            trace_header = "ğŸ” Echo Intent Routing: "
            persona_mix = self.create_dynamic_persona(
                user_input, emotion, conversation_history, trace_header
            )

            # 2. ì½”ë”© ìš”ì²­ ê°ì§€ ë° íŠ¹ìˆ˜ ì²˜ë¦¬ (ê°•í™”ë¨)
            is_coding_request = any(
                keyword in user_input.lower()
                for keyword in [
                    "ì½”ë“œ",
                    "code",
                    "í”„ë¡œê·¸ë¨",
                    "program",
                    "function",
                    "í•¨ìˆ˜",
                    "class",
                    "í´ë˜ìŠ¤",
                    "ë§Œë“¤ì–´",
                    "create",
                    "write",
                    "ì‘ì„±",
                    "python",
                    "javascript",
                    "html",
                    "css",
                    "scraper",
                    "analyzer",
                    "api",
                    "cli",
                    "êµ¬í˜„",
                    "implement",
                    "build",
                ]
            )

            # í˜‘ì—… ëª¨ë“œ ê°ì§€
            is_collaboration = any(
                keyword in user_input.lower()
                for keyword in [
                    "í† ë¡ ",
                    "discussion",
                    "í˜‘ì—…",
                    "collaboration",
                    "ê°œì„ ",
                    "improvement",
                    "ì œì•ˆ",
                    "suggestion",
                    "ë°˜ë°•",
                    "ì˜ê²¬",
                ]
            )

            traits = persona_mix.resulting_traits
            profile = os.getenv("ECHO_PROFILE", "balanced")

            if is_coding_request or is_collaboration:
                # ğŸš€ FULL_CODE ëª¨ë“œ: ì ˆì•½ íœ´ë¦¬ìŠ¤í‹± ì „ë©´ ì°¨ë‹¨
                context_size = len(user_input) + len(str(conversation_history or []))
                base_tokens = 2400
                max_tokens = min(4000, base_tokens + (context_size // 10))

                # í˜‘ì—…/í† ë¡  ì‹œ ë” ìƒì„¸í•œ ì‘ë‹µ
                if is_collaboration:
                    collaboration_rule = """
COLLABORATION RULES:
- Provide detailed technical analysis
- Include specific code examples
- Explain design decisions
- Propose concrete alternatives
- No vague statements or summaries"""
                else:
                    collaboration_rule = ""

                # ì§§ì€ ë‹µë³€ ë°©ì§€ ê·œì¹™
                anti_summary_rules = """
STRICT RULES:
- NO explanations outside code blocks
- NO summary or outline responses
- NO "skeleton" or "pseudo" code
- Output COMPLETE, EXECUTABLE code only
- Minimum 80+ lines for applications
- Include ALL error handling, CLI, and file I/O"""

                persona_prompt = f"""You are {persona_mix.mix_name}, an expert programmer with these traits:
- Analytical depth: {traits.analysis:.1f}/1.0
- Logical thinking: {traits.logic:.1f}/1.0
- Creative problem-solving: {traits.creativity:.1f}/1.0

CODING TASK: {user_input}

{anti_summary_rules}
{collaboration_rule}

Requirements:
1. Generate COMPLETE, PRODUCTION-READY code
2. Include ALL requested features (no placeholders)
3. Add comprehensive error handling
4. Include CLI interface and file operations
5. Add timeout/retry mechanisms
6. Use proper logging and validation
7. Include test cases or usage examples

Output format:
```python
[COMPLETE WORKING CODE - MINIMUM 80+ LINES]
```

Generate full executable code that can be run immediately."""
                temperature = 0.3  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì¶¤
            else:
                # English prompt to avoid encoding issues
                persona_prompt = f"""You are {persona_mix.mix_name}, an AI assistant with these personality traits:
- Empathy: {traits.empathy:.1f}/1.0
- Logic: {traits.logic:.1f}/1.0
- Energy: {traits.energy:.1f}/1.0
- Creativity: {traits.creativity:.1f}/1.0
- Support: {traits.support:.1f}/1.0
- Analysis: {traits.analysis:.1f}/1.0

Please respond to the user's message naturally reflecting these traits.
Emotional tone: {emotion}

User message: {user_input}

Please respond in Korean if the user wrote in Korean, or match the user's language."""
                max_tokens = 800  # Chat í† í° ì¦ê°€

            # Try alternative OpenAI API approach
            try:
                # Set environment for UTF-8
                import sys

                if hasattr(sys.stdout, "reconfigure"):
                    sys.stdout.reconfigure(encoding="utf-8")

                client = openai.OpenAI(api_key=api_key, timeout=30.0)

                # Clean message content with safe encoding
                clean_content = str(persona_prompt).strip()

                # Handle Korean/Unicode text safely
                safe_user_input = user_input.encode("utf-8", errors="replace").decode(
                    "utf-8", errors="replace"
                )
                clean_content = clean_content.replace(user_input, safe_user_input)

                print(
                    f"ğŸš€ Sending request to model: {os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')}"
                )
                print(f"ğŸ”¤ Input length: {len(clean_content)} chars")

                response = client.chat.completions.create(
                    model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                    messages=[{"role": "user", "content": clean_content}],
                    temperature=0.7 if is_coding_request else 0.8,
                    max_tokens=max_tokens,
                )

                print(f"âœ… OpenAI API ì‘ë‹µ ì„±ê³µ!")

            except Exception as api_error:
                print(f"âš ï¸ OpenAI API ì—ëŸ¬: {type(api_error).__name__}: {api_error}")
                return None

            result = response.choices[0].message.content.strip()

            # ğŸ” ê¸¸ì´ ê°€ë“œ: ì½”ë”© ìš”ì²­ ì‹œ ì§§ì€ ë‹µë³€ ì°¨ë‹¨
            if is_coding_request or is_collaboration:
                code_blocks = self._extract_code_blocks(result)
                total_lines = sum(len(code.split("\n")) for code in code_blocks)

                # ì§§ì€ ë‹µë³€ íŒ¨í„´ ê°ì§€
                short_patterns = [
                    "ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                    "ëŒ€ëµì ì¸",
                    "ì˜ˆì‹œ ì½”ë“œ",
                    "ë‹¤ìŒ ë‹¨ê³„",
                    "skeleton",
                    "outline",
                    "pseudo",
                    "ê°„ë‹¨í•œ êµ¬ì¡°",
                ]
                has_short_patterns = any(
                    pattern in result for pattern in short_patterns
                )

                min_lines = 80 if is_coding_request else 20

                if total_lines < min_lines or has_short_patterns or not code_blocks:
                    print(f"âš ï¸ ì§§ì€ ì‘ë‹µ ê°ì§€ (ì¤„ìˆ˜: {total_lines}), ì¬ìš”ì²­ ì¤‘...")

                    # 1ì°¨ ì¬ì‹œë„: ê°•í™”ëœ í”„ë¡¬í”„íŠ¸
                    retry_prompt = (
                        persona_prompt
                        + f"""

RETRY - Previous output was too short ({total_lines} lines).
Rule violation detected. NO SUMMARY. Provide full executable code in a single block.
Include CLI interface, error handling, and complete implementation."""
                    )

                    retry_response = client.chat.completions.create(
                        model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                        messages=[{"role": "user", "content": retry_prompt}],
                        temperature=0.2,  # ë” ì¼ê´€ì„±ìˆê²Œ
                        max_tokens=max_tokens,
                    )

                    result = retry_response.choices[0].message.content.strip()
                    retry_code_blocks = self._extract_code_blocks(result)
                    retry_lines = sum(
                        len(code.split("\n")) for code in retry_code_blocks
                    )

                    # 2ì°¨ ê²€ì¦: ì—¬ì „íˆ ì§§ìœ¼ë©´ ì´ì–´ì“°ê¸°
                    if retry_lines < min_lines and retry_code_blocks:
                        print(f"âš ï¸ ì—¬ì „íˆ ì§§ìŒ ({retry_lines}ì¤„), ì´ì–´ì“°ê¸° ëª¨ë“œ...")

                        last_code = retry_code_blocks[-1][-2000:]  # ë§ˆì§€ë§‰ 2000ì
                        continue_prompt = f"""Continue this code from where it left off. Complete the implementation:

```python
{last_code}
# CONTINUE FROM HERE - ADD REMAINING FEATURES
```

Add missing: CLI interface, error handling, export functions, test cases."""

                        continue_response = client.chat.completions.create(
                            model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                            messages=[{"role": "user", "content": continue_prompt}],
                            temperature=0.2,
                            max_tokens=2000,
                        )

                        continue_code = self._extract_code_blocks(
                            continue_response.choices[0].message.content.strip()
                        )
                        if continue_code:
                            # ì½”ë“œ ë³‘í•©
                            merged_code = last_code + "\n" + continue_code[0]
                            result = f"```python\n{merged_code}\n```"
                            print(
                                f"âœ… ì´ì–´ì“°ê¸° ì™„ë£Œ (ì´ {len(merged_code.split('n'))}ì¤„)"
                            )

            print(f"ğŸ”¥ OpenAI ì‘ë‹µ ìƒì„± ì™„ë£Œ ({persona_mix.mix_name})")
            return result

        except Exception as e:
            print(f"âš ï¸ OpenAI ì‘ë‹µ ì‹¤íŒ¨, í…œí”Œë¦¿ í´ë°±: {e}")
            return None

    def _extract_code_blocks(self, text: str) -> List[str]:
        """ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ"""
        import re

        # ```python ... ``` ë˜ëŠ” ```... ``` íŒ¨í„´ ë§¤ì¹­
        code_pattern = r"```(?:python|py|javascript|js|html|css)?\n?(.*?)```"
        matches = re.findall(code_pattern, text, re.DOTALL)
        return [match.strip() for match in matches if match.strip()]

    def _create_template_response(
        self, user_input: str, emotion: str, conversation_history: List[str] = None
    ) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìŠ¤ë§ˆíŠ¸ ì‘ë‹µ ìƒì„± (ê°œì„ ëœ í…œí”Œë¦¿)"""
        # 1. ë™ì  í˜ë¥´ì†Œë‚˜ ìƒì„±
        persona_mix = self.create_dynamic_persona(
            user_input, emotion, conversation_history
        )

        # 2. ì‚¬ìš©ì ì…ë ¥ ë¶„ì„
        user_lower = user_input.lower()

        # 3. ì»¨í…ìŠ¤íŠ¸ë³„ ë§ì¶¤ ì‘ë‹µ ìƒì„±
        if any(
            word in user_input for word in ["ì—´", "ì•„í”„", "ê°ê¸°", "ë³‘", "ì˜ì‚¬", "ë³‘ì›"]
        ):
            # ê±´ê°• ê´€ë ¨
            return f"ê±±ì •ë˜ì‹œê² ì–´ìš”. ì•„ì´ê°€ ê°‘ìê¸° ì—´ì´ ë‚  ë•ŒëŠ” ì²´ì˜¨ì„ í™•ì¸í•˜ê³ , ì¶©ë¶„í•œ íœ´ì‹ê³¼ ìˆ˜ë¶„ ê³µê¸‰ì´ ì¤‘ìš”í•´ìš”. ì—´ì´ ì§€ì†ë˜ê±°ë‚˜ ë‹¤ë¥¸ ì¦ìƒì´ í•¨ê»˜ ë‚˜íƒ€ë‚˜ë©´ ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤. ê´œì°®ì•„ì§ˆ ê±°ì˜ˆìš”. ğŸ’™"
        elif any(
            word in user_input for word in ["ê³„íš", "ì¼ì •", "ìŠ¤ì¼€ì¤„", "ì˜¤ëŠ˜", "ë‚´ì¼"]
        ):
            # ê³„íš ìˆ˜ë¦½
            return f"í•˜ë£¨ ê³„íšì„ ì²´ê³„ì ìœ¼ë¡œ ì„¸ì›Œë³´ì„¸ìš”:\n1. ìš°ì„ ìˆœìœ„ ì—…ë¬´ ì •ë¦¬\n2. ì‹œê°„ ë°°ë¶„ (ì—…ë¬´ 70%, íœ´ì‹ 30%)\n3. ì˜ˆìƒ ë³€ìˆ˜ ëŒ€ë¹„ì±… ë§ˆë ¨\n4. ì„±ì·¨ê°ì„ ìœ„í•œ ì‘ì€ ëª©í‘œë“¤\nì–´ë–¤ ë¶€ë¶„ë¶€í„° ì‹œì‘í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ğŸ¯"
        elif any(word in user_input for word in ["ë„ì›€", "ë°©ë²•", "ì–´ë–»ê²Œ", "í•´ê²°"]):
            # ë¬¸ì œ í•´ê²°
            return f"í•¨ê»˜ ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•´ë³¼ê¹Œìš”:\n1. í˜„ì¬ ìƒí™© ì •í™•íˆ íŒŒì•…í•˜ê¸°\n2. ê°€ëŠ¥í•œ ì„ íƒì§€ë“¤ ë‚˜ì—´í•˜ê¸°\n3. ê° ì„ íƒì§€ì˜ ì¥ë‹¨ì  ë¹„êµ\n4. ê°€ì¥ ì ì ˆí•œ í•´ê²°ì±… ì„ íƒ\nêµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê±±ì •ë˜ì‹œë‚˜ìš”? ğŸ¤"
        elif any(
            word in user_input for word in ["ì½”ë“œ", "í”„ë¡œê·¸ë¨", "ê°œë°œ", "ë²„ê·¸", "ì—ëŸ¬"]
        ):
            # ê°œë°œ ê´€ë ¨
            return f"ê°œë°œ ë¬¸ì œ í•´ê²°ì„ ë„ì™€ë“œë¦´ê²Œìš”:\n1. ì—ëŸ¬ ë©”ì‹œì§€ ì •í™•íˆ í™•ì¸\n2. ê´€ë ¨ ì½”ë“œ ë¶€ë¶„ ì ê²€\n3. ë””ë²„ê¹… ë‹¨ê³„ë³„ ì§„í–‰\n4. í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ê²€ì¦\nì–´ë–¤ ì–¸ì–´ë‚˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³  ê³„ì‹ ê°€ìš”? ğŸ’»"

        # 4. ê¸°ë³¸ ê°ì • ê¸°ë°˜ ì‘ë‹µ
        traits = persona_mix.resulting_traits

        # ì‘ë‹µ êµ¬ì„± ìš”ì†Œë“¤
        response_components = []

        # ê³µê°ì  ì‹œì‘ (ê³µê°ë ¥ì´ ë†’ì€ ê²½ìš°)
        if traits.empathy > 0.7:
            empathic_starts = [
                f"ë§ˆìŒì´ ì „í•´ì ¸ìš”...",
                f"ê·¸ëŸ° ê¸°ë¶„ì´ì‹œêµ°ìš”",
                f"ì´í•´í•´ìš”, ê·¸ëŸ° ìƒí™©ì´ë¼ë©´",
                f"í•¨ê»˜ ëŠê»´ë´ìš”",
            ]
            response_components.append(random.choice(empathic_starts))

        # ë¶„ì„ì  ì ‘ê·¼ (ë…¼ë¦¬ì„±ì´ ë†’ì€ ê²½ìš°)
        if traits.logic > 0.7:
            analytical_parts = [
                f"ì°¨ê·¼ì°¨ê·¼ ì‚´í´ë³´ë©´",
                f"ë…¼ë¦¬ì ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì£ ",
                f"ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ë³´ë©´",
                f"ì²´ê³„ì ìœ¼ë¡œ ìƒê°í•´ë³´ë‹ˆ",
            ]
            response_components.append(random.choice(analytical_parts))

        # ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ë°˜ì‘ (ì—ë„ˆì§€ê°€ ë†’ì€ ê²½ìš°)
        if traits.energy > 0.8:
            energetic_parts = [
                f"ì—­ë™ì ìœ¼ë¡œ í•´ê²°í•´ë³¼ê¹Œìš”!",
                f"í˜ì°¨ê²Œ ë„ì „í•´ë´ìš”!",
                f"ì ê·¹ì ìœ¼ë¡œ ë‚˜ì•„ê°€ìš”!",
                f"í™œê¸°ì°¨ê²Œ ì‹œì‘í•´ë´ìš”!",
            ]
            response_components.append(random.choice(energetic_parts))

        # ì°½ì˜ì  ì œì•ˆ (ì°½ì˜ì„±ì´ ë†’ì€ ê²½ìš°)
        if traits.creativity > 0.7:
            creative_parts = [
                f"ìƒˆë¡œìš´ ê´€ì ì—ì„œ ë³´ë©´",
                f"ìƒìƒí•´ë³´ë©´ ì´ëŸ° ë°©ë²•ë„ ìˆì–´ìš”",
                f"ì°½ì˜ì ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì£ ",
                f"í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¡œ",
            ]
            response_components.append(random.choice(creative_parts))

        # ì§€ì§€ì  ë§ˆë¬´ë¦¬ (ì§€ì§€ë ¥ì´ ë†’ì€ ê²½ìš°)
        if traits.support > 0.7:
            supportive_endings = [
                f"í•¨ê»˜ í•´ë‚´ì‹¤ ìˆ˜ ìˆì–´ìš”",
                f"ì‘ì›í•˜ê³  ìˆì–´ìš”",
                f"ë„ì™€ë“œë¦´ê²Œìš”",
                f"ì˜†ì—ì„œ ì§€ì§€í•˜ê² ìŠµë‹ˆë‹¤",
            ]
            response_components.append(random.choice(supportive_endings))

        # ì‘ë‹µ ì¡°í•©
        if response_components:
            # ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
            response = f"{response_components[0]}. "

            if len(response_components) > 1:
                middle_parts = response_components[1:-1]
                if middle_parts:
                    response += " ".join(middle_parts) + ". "

                if len(response_components) > 1:
                    response += f"{response_components[-1]}."
        else:
            # ê¸°ë³¸ ì‘ë‹µ
            response = f"í¥ë¯¸ë¡œìš´ ì–˜ê¸°ë„¤ìš”. '{user_input}'ì— ëŒ€í•´ ë” ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”?"

        # í˜ë¥´ì†Œë‚˜ íŠ¹ì„±ì„ ë°˜ì˜í•œ ì–¸ì–´ íŒ¨í„´ ì ìš©
        if "language_patterns" in response_style:
            patterns = response_style["language_patterns"]
            if patterns and random.random() < 0.3:  # 30% í™•ë¥ ë¡œ íŒ¨í„´ ì–¸ì–´ ì¶”ê°€
                pattern = random.choice(patterns)
                response = f"{pattern} {response}"

        # ê°ì • ì´ëª¨ì§€ ì¶”ê°€ (ì—ë„ˆì§€ì— ë”°ë¼)
        emotion_emojis = {
            "joy": "ğŸ˜Š",
            "excitement": "âœ¨",
            "curiosity": "ğŸ¤”",
            "empathy": "ğŸ’™",
            "energy": "ğŸ”¥",
            "creativity": "ğŸ¨",
        }

        if traits.energy > 0.8:
            response += " âœ¨"
        elif traits.empathy > 0.8:
            response += " ğŸ’™"
        elif traits.creativity > 0.8:
            response += " ğŸ¨"

        return response


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_dynamic_echo_persona(
    user_input: str, emotion: str = "neutral"
) -> PersonaMix:
    """ë™ì  Echo í˜ë¥´ì†Œë‚˜ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    mixer = DynamicPersonaMixer()
    return mixer.create_dynamic_persona(user_input, emotion)


def get_response_style_for_context(
    user_input: str, emotion: str = "neutral"
) -> Dict[str, Any]:
    """ë§¥ë½ë³„ ì‘ë‹µ ìŠ¤íƒ€ì¼ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    mixer = DynamicPersonaMixer()
    persona_mix = mixer.create_dynamic_persona(user_input, emotion)
    return mixer.generate_persona_specific_response_style(persona_mix)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    mixer = DynamicPersonaMixer()

    test_inputs = [
        ("ìŠ¬í¼ìš”", "sadness"),
        ("ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ìš”", "neutral"),
        ("ìƒˆë¡œìš´ ì•„ì´ë””ì–´ê°€ í•„ìš”í•´ìš”", "curiosity"),
        ("ì™œ ì´ëŸ° ì¼ì´ ì¼ì–´ë‚¬ì„ê¹Œìš”?", "confusion"),
        ("ì‘ì›í•´ì£¼ì„¸ìš”", "stress"),
    ]

    print("ğŸ­ ë™ì  í˜ë¥´ì†Œë‚˜ ë¯¹ì„œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    for user_input, emotion in test_inputs:
        persona_mix = mixer.create_dynamic_persona(user_input, emotion)
        print(f"\nì…ë ¥: '{user_input}' (ê°ì •: {emotion})")
        print(mixer.get_persona_mix_info(persona_mix))
        print("-" * 30)
