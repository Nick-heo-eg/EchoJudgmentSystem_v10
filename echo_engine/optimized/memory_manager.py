#!/usr/bin/env python3
"""
ğŸ§  Memory Manager - ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ
íš¨ìœ¨ì ì¸ ìƒí˜¸ì‘ìš© ê¸°ì–µ ë° íŒ¨í„´ í•™ìŠµ
"""

import time
from collections import deque, defaultdict
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Any, Deque

@dataclass 
class OptimizedPersonaMemory:
    """ìµœì í™”ëœ í˜ë¥´ì†Œë‚˜ ë©”ëª¨ë¦¬"""
    
    # ê³ ì • í¬ê¸° íë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
    recent_interactions: Deque = field(default_factory=lambda: deque(maxlen=20))
    emotional_patterns: Dict[str, Deque] = field(default_factory=lambda: defaultdict(lambda: deque(maxlen=10)))
    strategy_success_counts: Dict[str, int] = field(default_factory=dict)
    strategy_effectiveness: Dict[str, Deque] = field(default_factory=lambda: defaultdict(lambda: deque(maxlen=10)))
    
    def add_interaction(self, interaction: Dict[str, Any]) -> None:
        """ìƒí˜¸ì‘ìš© ê¸°ë¡ (O(1) ë³µì¡ë„)"""
        interaction["timestamp"] = time.time()  # floatê°€ datetimeë³´ë‹¤ ë¹ ë¦„
        self.recent_interactions.append(interaction)
    
    def track_emotion(self, emotion: str, intensity: float) -> None:
        """ê°ì • íŒ¨í„´ ì¶”ì  (O(1) ë³µì¡ë„)"""
        self.emotional_patterns[emotion].append(intensity)
    
    def update_strategy_success(self, strategy: str, success: bool) -> None:
        """ì „ëµ ì„±ê³µë¥  ì—…ë°ì´íŠ¸ (O(1) ë³µì¡ë„)"""
        if strategy not in self.strategy_success_counts:
            self.strategy_success_counts[strategy] = 0
            
        if success:
            self.strategy_success_counts[strategy] += 1
        else:
            self.strategy_success_counts[strategy] = max(0, self.strategy_success_counts[strategy] - 1)
    
    def add_strategy_feedback(self, strategy: str, effectiveness: float) -> None:
        """ì „ëµ íš¨ê³¼ì„± í”¼ë“œë°± (O(1) ë³µì¡ë„)"""
        self.strategy_effectiveness[strategy].append(effectiveness)
    
    def get_strategy_effectiveness(self, strategy: str) -> float:
        """ì „ëµ íš¨ê³¼ì„± í‰ê·  (ìºì‹œë¨)"""
        effectiveness_scores = self.strategy_effectiveness.get(strategy)
        if effectiveness_scores:
            return sum(effectiveness_scores) / len(effectiveness_scores)
        return 0.5
    
    def get_emotion_average(self, emotion: str) -> float:
        """ê°ì • í‰ê·  ê°•ë„"""
        pattern = self.emotional_patterns.get(emotion)
        if pattern:
            return sum(pattern) / len(pattern)
        return 0.0
    
    def get_recent_emotions(self, limit: int = 5) -> List[Dict[str, Any]]:
        """ìµœê·¼ ê°ì • íŒ¨í„´"""
        emotions = []
        for interaction in list(self.recent_interactions)[-limit:]:
            if "emotion_detected" in interaction:
                emotions.append({
                    "emotion": interaction["emotion_detected"],
                    "intensity": interaction.get("emotion_intensity", 0.0),
                    "timestamp": interaction.get("timestamp", 0)
                })
        return emotions
    
    def get_best_strategies(self, top_k: int = 3) -> List[tuple]:
        """ê°€ì¥ ì„±ê³µì ì¸ ì „ëµë“¤"""
        return sorted(
            self.strategy_success_counts.items(),
            key=lambda x: x[1], 
            reverse=True
        )[:top_k]
    
    def cleanup_old_data(self, max_age_seconds: int = 86400) -> None:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ (24ì‹œê°„ ì´ìƒ)"""
        current_time = time.time()
        cutoff_time = current_time - max_age_seconds
        
        # ì˜¤ë˜ëœ ìƒí˜¸ì‘ìš© ì œê±°  
        while (self.recent_interactions and 
               self.recent_interactions[0].get("timestamp", 0) < cutoff_time):
            self.recent_interactions.popleft()

class OptimizedMemoryManager:
    """ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.memory = OptimizedPersonaMemory()
        self._last_cleanup = time.time()
        
    def record_interaction(self, emotion: str, intensity: float, strategy: str,
                          success: bool, effectiveness: float = None) -> None:
        """ìƒí˜¸ì‘ìš© ì¢…í•© ê¸°ë¡"""
        # ëª¨ë“  ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬ (íš¨ìœ¨ì„±)
        interaction = {
            "emotion": emotion,
            "intensity": intensity,
            "strategy": strategy,
            "success": success,
            "effectiveness": effectiveness or (1.0 if success else 0.0)
        }
        
        self.memory.add_interaction(interaction)
        self.memory.track_emotion(emotion, intensity)
        self.memory.update_strategy_success(strategy, success)
        
        if effectiveness:
            self.memory.add_strategy_feedback(strategy, effectiveness)
            
        # ì£¼ê¸°ì  ì²­ì†Œ (1ì‹œê°„ë§ˆë‹¤)
        if time.time() - self._last_cleanup > 3600:
            self.memory.cleanup_old_data()
            self._last_cleanup = time.time()
    
    def get_learning_insights(self) -> Dict[str, Any]:
        """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        return {
            "best_strategies": self.memory.get_best_strategies(),
            "recent_emotions": self.memory.get_recent_emotions(),
            "interaction_count": len(self.memory.recent_interactions),
            "emotional_stability": self._calculate_emotional_stability(),
            "strategy_diversity": len(self.memory.strategy_success_counts)
        }
    
    def _calculate_emotional_stability(self) -> float:
        """ê°ì • ì•ˆì •ì„± ê³„ì‚°"""
        recent_emotions = self.memory.get_recent_emotions()
        if len(recent_emotions) < 2:
            return 0.5
            
        intensities = [e["intensity"] for e in recent_emotions]
        variance = sum((x - sum(intensities)/len(intensities))**2 for x in intensities) / len(intensities)
        
        # ë‚®ì€ ë¶„ì‚° = ë†’ì€ ì•ˆì •ì„±
        return max(0.0, min(1.0, 1.0 - variance))

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_memory_manager = OptimizedMemoryManager()

def record_interaction_fast(emotion: str, intensity: float, strategy: str,
                           success: bool, effectiveness: float = None) -> None:
    """ë¹ ë¥¸ ìƒí˜¸ì‘ìš© ê¸°ë¡ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤)"""
    _memory_manager.record_interaction(emotion, intensity, strategy, success, effectiveness)

def get_learning_insights_fast() -> Dict[str, Any]:
    """ë¹ ë¥¸ í•™ìŠµ ì¸ì‚¬ì´íŠ¸ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤)"""
    return _memory_manager.get_learning_insights()
