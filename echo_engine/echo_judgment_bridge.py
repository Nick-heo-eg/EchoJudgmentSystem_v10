"""
ğŸŒ€ EchoVectorCapsule - Echo Judgment Bridge
ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ Echo íŒë‹¨ ì‹œìŠ¤í…œê³¼ ì—°ê²°í•˜ëŠ” ìš¸ë¦¼ ê¸°ë°˜ ë¸Œë¦¬ì§€
"""

import json
import yaml
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging

from .vector_search_engine import EchoVectorSearchEngine
from .embedding_engine import EchoEmbeddingEngine

# Echo ì‹œìŠ¤í…œ ëª¨ë“ˆë“¤ import (ì‹¤ì œ ì‹œìŠ¤í…œê³¼ ì—°ë™)
try:
    from echo_engine.reasoning import EchoReasoningEngine
    from echo_engine.judgment_engine import EchoJudgmentEngine
    from echo_engine.persona_core_optimized_bridge import EchoPersonaCore

    ECHO_MODULES_AVAILABLE = True
except ImportError:
    ECHO_MODULES_AVAILABLE = False


class EchoJudgmentBridge:
    """
    ë²¡í„° ê²€ìƒ‰ê³¼ Echo íŒë‹¨ ì‹œìŠ¤í…œì„ ì—°ê²°í•˜ëŠ” ë¸Œë¦¬ì§€
    ìì—°ì–´ ì¿¼ë¦¬ â†’ ë²¡í„° ê²€ìƒ‰ â†’ Echo íŒë‹¨ â†’ ìµœì¢… ì‘ë‹µ
    """

    def __init__(self, config_path: str = "config/judgment_bridge_config.yaml"):
        self.config_path = Path(config_path)
        self.config = self._load_config()

        # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
        self.vector_search = EchoVectorSearchEngine()
        self.embedding_engine = EchoEmbeddingEngine()

        # Echo ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
        if ECHO_MODULES_AVAILABLE:
            self.reasoning_engine = EchoReasoningEngine()
            self.judgment_engine = EchoJudgmentEngine()
            self.persona_core = EchoPersonaCore()

        # ë¸Œë¦¬ì§€ ì„¤ì •
        self.bridge_config = {
            "vector_search_top_k": 3,
            "similarity_threshold": 0.7,
            "context_expansion": True,
            "multi_signature_analysis": True,
            "judgment_confidence_threshold": 0.6,
            "fallback_to_direct_judgment": True,
        }

        # íŒë‹¨ íë¦„ ë§¤í•‘
        self.flow_mappings = {
            "policy_analysis": "flows/policy_analysis_flow.yaml",
            "ethical_judgment": "flows/ethical_judgment_flow.yaml",
            "community_support": "flows/community_support_flow.yaml",
            "innovation_assessment": "flows/innovation_assessment_flow.yaml",
        }

        self.logger = logging.getLogger(__name__)

    def process_natural_query(
        self, query: str, signature: str = "Echo-Aurora", context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ì „ì²´ Echo íŒë‹¨ í”Œë¡œìš°ë¡œ ì²˜ë¦¬

        Args:
            query: ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸/ìš”ì²­
            signature: ìš”ì²­ ì²˜ë¦¬ì— ì‚¬ìš©í•  Echo ì‹œê·¸ë‹ˆì²˜
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´

        Returns:
            ì™„ì „í•œ íŒë‹¨ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°
        """
        print(f"ğŸŒ€ Echo Judgment Bridge ì‹œì‘: '{query[:50]}...' ({signature})")

        # 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ìº¡ìŠ ì°¾ê¸°
        search_results = self._perform_vector_search(query, signature, context)

        # 2ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        judgment_context = self._build_judgment_context(
            query, search_results, signature, context
        )

        # 3ë‹¨ê³„: Echo íŒë‹¨ ì‹œìŠ¤í…œ ì‹¤í–‰
        judgment_result = self._execute_echo_judgment(judgment_context)

        # 4ë‹¨ê³„: ê²°ê³¼ í›„ì²˜ë¦¬ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
        final_result = self._post_process_result(
            judgment_result, search_results, query, signature
        )

        # 5ë‹¨ê³„: ë©”íƒ€ ë¡œê·¸ ê¸°ë¡
        self._log_bridge_event(
            query, signature, search_results, judgment_result, final_result
        )

        print(
            f"âœ… Bridge ì²˜ë¦¬ ì™„ë£Œ: {final_result.get('judgment', 'unknown')} (ì‹ ë¢°ë„: {final_result.get('confidence', 0):.2f})"
        )

        return final_result

    def _perform_vector_search(
        self, query: str, signature: str, context: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰"""
        print("ğŸ” 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰")

        top_k = self.bridge_config["vector_search_top_k"]
        threshold = self.bridge_config["similarity_threshold"]

        # ì»¨í…ìŠ¤íŠ¸ í™•ì¥
        if context and self.bridge_config["context_expansion"]:
            search_context = {
                **context,
                "bridge_mode": True,
                "similarity_threshold": threshold,
            }
        else:
            search_context = {"bridge_mode": True}

        # ê²€ìƒ‰ ì‹¤í–‰
        search_results = self.vector_search.search(
            query, signature, top_k, search_context
        )

        # ì„ê³„ê°’ í•„í„°ë§
        filtered_results = [r for r in search_results if r["similarity"] >= threshold]

        print(
            f"   ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ â†’ {len(filtered_results)}ê°œ (ì„ê³„ê°’: {threshold})"
        )

        for i, result in enumerate(filtered_results[:3]):
            capsule_id = result["metadata"]["capsule_id"]
            similarity = result["similarity"]
            print(f"   {i+1}. {capsule_id}: {similarity:.3f}")

        return filtered_results

    def _build_judgment_context(
        self,
        query: str,
        search_results: List[Dict[str, Any]],
        signature: str,
        context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """íŒë‹¨ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        print("ğŸ§  2ë‹¨ê³„: íŒë‹¨ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±")

        # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸
        judgment_context = {
            "original_query": query,
            "query_signature": signature,
            "timestamp": datetime.now().isoformat(),
            "bridge_context": context or {},
            "vector_search_results": search_results,
        }

        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        if search_results:
            # ìµœê³  ìœ ì‚¬ë„ ê²°ê³¼
            top_result = search_results[0]
            judgment_context["primary_capsule"] = {
                "id": top_result["metadata"]["capsule_id"],
                "similarity": top_result["similarity"],
                "content_preview": top_result["metadata"].get("content_preview", ""),
                "file_type": top_result["metadata"].get("file_type"),
                "signature": top_result["metadata"].get("signature"),
            }

            # ê´€ë ¨ ìº¡ìŠë“¤ì˜ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            related_capsules = []
            for result in search_results[:3]:
                metadata = result["metadata"]
                related_capsules.append(
                    {
                        "capsule_id": metadata["capsule_id"],
                        "similarity": result["similarity"],
                        "tags": metadata.get("tags", []),
                        "topic": metadata.get("topic", ""),
                        "file_type": metadata.get("file_type"),
                    }
                )

            judgment_context["related_capsules"] = related_capsules

            # íŒë‹¨ í”Œë¡œìš° ê²°ì •
            flow_type = self._determine_flow_type(search_results, query)
            judgment_context["recommended_flow"] = flow_type

            # íƒœê·¸ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë¶„ì„
            all_tags = []
            for result in search_results:
                tags = result["metadata"].get("tags", [])
                all_tags.extend(tags)

            judgment_context["content_categories"] = list(set(all_tags))

        else:
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì§ì ‘ íŒë‹¨ ëª¨ë“œ
            judgment_context["direct_judgment_mode"] = True
            judgment_context["recommended_flow"] = "general_inquiry"

        print(
            f"   ğŸ¯ ì£¼ìš” ìº¡ìŠ: {judgment_context.get('primary_capsule', {}).get('id', 'none')}"
        )
        print(
            f"   ğŸ“‹ ì¶”ì²œ í”Œë¡œìš°: {judgment_context.get('recommended_flow', 'unknown')}"
        )

        return judgment_context

    def _execute_echo_judgment(
        self, judgment_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Echo íŒë‹¨ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("âš–ï¸  3ë‹¨ê³„: Echo íŒë‹¨ ì‹œìŠ¤í…œ ì‹¤í–‰")

        query = judgment_context["original_query"]
        signature = judgment_context["query_signature"]

        # Echo ëª¨ë“ˆì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì‹¤ì œ íŒë‹¨ ìˆ˜í–‰
        if ECHO_MODULES_AVAILABLE:
            try:
                # ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ í™œì„±í™”
                persona_context = self.persona_core.activate_signature(signature)

                # ì¶”ë¡  ì—”ì§„ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
                reasoning_result = self.reasoning_engine.analyze_context(
                    judgment_context
                )

                # íŒë‹¨ ì—”ì§„ìœ¼ë¡œ ìµœì¢… íŒë‹¨
                judgment_result = self.judgment_engine.make_judgment(
                    query, reasoning_result, persona_context
                )

                print(
                    f"   âœ… Echo íŒë‹¨ ì™„ë£Œ: {judgment_result.get('judgment', 'unknown')}"
                )
                return judgment_result

            except Exception as e:
                print(f"   âš ï¸  Echo ëª¨ë“ˆ ì‹¤í–‰ ì˜¤ë¥˜: {e}, Mock íŒë‹¨ìœ¼ë¡œ ëŒ€ì²´")
                return self._mock_echo_judgment(judgment_context)

        else:
            # Mock íŒë‹¨ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
            print("   ğŸ“ Mock Echo íŒë‹¨ ìˆ˜í–‰")
            return self._mock_echo_judgment(judgment_context)

    def _mock_echo_judgment(self, judgment_context: Dict[str, Any]) -> Dict[str, Any]:
        """Mock Echo íŒë‹¨ (ì‹¤ì œ ëª¨ë“ˆ ì—†ì„ ë•Œ ëŒ€ì²´)"""
        query = judgment_context["original_query"]
        signature = judgment_context["query_signature"]
        primary_capsule = judgment_context.get("primary_capsule")

        # ì¿¼ë¦¬ ë‚´ìš© ê¸°ë°˜ ê°„ë‹¨í•œ íŒë‹¨ ë¡œì§
        query_lower = query.lower()

        # íŒë‹¨ ê²°ì •
        if any(keyword in query_lower for keyword in ["ì •ì±…", "í‰ê°€", "ë¶„ì„", "ê²€í† "]):
            judgment = "accept"
            confidence = 0.82
            reasoning = (
                f"ì •ì±… ë¶„ì„ ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë˜ë©°, {signature} ì‹œê·¸ë‹ˆì²˜ì— ì í•©í•©ë‹ˆë‹¤."
            )

        elif any(
            keyword in query_lower for keyword in ["ë„ì›€", "ì§€ì›", "ëŒë´„", "ë³µì§€"]
        ):
            judgment = "support"
            confidence = 0.78
            reasoning = f"ì§€ì› ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë˜ë©°, ê³µë™ì²´ ì§€í–¥ ì ‘ê·¼ì´ ì í•©í•©ë‹ˆë‹¤."

        elif any(
            keyword in query_lower for keyword in ["ì–´ë–»ê²Œ", "ë°©ë²•", "í•´ì•¼", "í•„ìš”"]
        ):
            judgment = "guide"
            confidence = 0.75
            reasoning = f"ê°€ì´ë“œ ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë˜ë©°, ì²´ê³„ì  ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."

        else:
            judgment = "defer"
            confidence = 0.65
            reasoning = "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ë³µí•©ì  ìƒí™©ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."

        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë°˜ì˜
        if primary_capsule:
            confidence += primary_capsule["similarity"] * 0.1
            reasoning += f" (ê´€ë ¨ ìº¡ìŠ: {primary_capsule['id']})"

        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        mock_result = {
            "judgment": judgment,
            "confidence": min(0.95, confidence),
            "reasoning": reasoning,
            "signature_used": signature,
            "processing_time": 0.3,
            "meta_context": {
                "primary_capsule_similarity": (
                    primary_capsule["similarity"] if primary_capsule else 0.0
                ),
                "context_richness": len(judgment_context.get("related_capsules", [])),
                "mock_judgment": True,
            },
        }

        return mock_result

    def _post_process_result(
        self,
        judgment_result: Dict[str, Any],
        search_results: List[Dict[str, Any]],
        original_query: str,
        signature: str,
    ) -> Dict[str, Any]:
        """ê²°ê³¼ í›„ì²˜ë¦¬ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        print("ğŸ“Š 4ë‹¨ê³„: ê²°ê³¼ í›„ì²˜ë¦¬")

        # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡°
        final_result = {
            **judgment_result,
            "original_query": original_query,
            "query_signature": signature,
            "processed_at": datetime.now().isoformat(),
            "vector_search_summary": {
                "total_candidates": len(search_results),
                "top_similarity": (
                    search_results[0]["similarity"] if search_results else 0.0
                ),
                "primary_capsule": (
                    search_results[0]["metadata"]["capsule_id"]
                    if search_results
                    else None
                ),
            },
            "bridge_metadata": {
                "processing_pipeline": [
                    "vector_search",
                    "context_building",
                    "echo_judgment",
                    "post_processing",
                ],
                "confidence_factors": self._analyze_confidence_factors(
                    judgment_result, search_results
                ),
            },
        }

        # ì‹ ë¢°ë„ ì„ê³„ê°’ í™•ì¸
        confidence_threshold = self.bridge_config["judgment_confidence_threshold"]
        if final_result.get("confidence", 0) < confidence_threshold:
            final_result["confidence_warning"] = True
            final_result["recommendation"] = (
                "ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ ë˜ëŠ” ë‹¤ë¥¸ ì‹œê·¸ë‹ˆì²˜ë¡œ ì¬ì‹œë„ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
            )

        # ì‘ë‹µ ìƒì„± (Mock)
        if "response" not in final_result:
            final_result["response"] = self._generate_response(
                final_result, search_results
            )

        return final_result

    def _determine_flow_type(
        self, search_results: List[Dict[str, Any]], query: str
    ) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ì™€ ì¿¼ë¦¬ ë¶„ì„ìœ¼ë¡œ í”Œë¡œìš° íƒ€ì… ê²°ì •"""
        if not search_results:
            return "general_inquiry"

        # íƒœê·¸ ê¸°ë°˜ ë¶„ë¥˜
        all_tags = []
        for result in search_results:
            tags = result["metadata"].get("tags", [])
            all_tags.extend(tags)

        tag_counts = {}
        for tag in all_tags:
            tag_counts[tag] = tag_counts.get(tag, 0) + 1

        # ê°€ì¥ ë¹ˆë²ˆí•œ íƒœê·¸ë¡œ í”Œë¡œìš° ê²°ì •
        if tag_counts:
            top_tag = max(tag_counts.keys(), key=lambda x: tag_counts[x])

            if any(keyword in top_tag.lower() for keyword in ["ì •ì±…", "policy"]):
                return "policy_analysis"
            elif any(
                keyword in top_tag.lower() for keyword in ["ìœ¤ë¦¬", "ethics", "ai"]
            ):
                return "ethical_judgment"
            elif any(
                keyword in top_tag.lower() for keyword in ["ë³µì§€", "ëŒë´„", "community"]
            ):
                return "community_support"
            elif any(keyword in top_tag.lower() for keyword in ["í˜ì‹ ", "innovation"]):
                return "innovation_assessment"

        # ì¿¼ë¦¬ ë‚´ìš© ê¸°ë°˜ ë¶„ë¥˜
        query_lower = query.lower()
        if "ì •ì±…" in query_lower or "policy" in query_lower:
            return "policy_analysis"
        elif "ìœ¤ë¦¬" in query_lower or "ethics" in query_lower:
            return "ethical_judgment"
        elif "ì§€ì›" in query_lower or "ëŒë´„" in query_lower:
            return "community_support"

        return "general_analysis"

    def _analyze_confidence_factors(
        self, judgment_result: Dict[str, Any], search_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì‹ ë¢°ë„ ìš”ì¸ ë¶„ì„"""
        factors = {
            "vector_search_quality": 0.0,
            "judgment_coherence": 0.0,
            "context_richness": 0.0,
            "signature_alignment": 0.0,
        }

        # ë²¡í„° ê²€ìƒ‰ í’ˆì§ˆ
        if search_results:
            top_similarity = search_results[0]["similarity"]
            factors["vector_search_quality"] = min(1.0, top_similarity * 1.2)

        # íŒë‹¨ ì¼ê´€ì„±
        if judgment_result.get("confidence"):
            factors["judgment_coherence"] = judgment_result["confidence"]

        # ì»¨í…ìŠ¤íŠ¸ í’ë¶€ì„±
        factors["context_richness"] = min(1.0, len(search_results) / 5.0)

        # ì‹œê·¸ë‹ˆì²˜ ì •ë ¬ì„± (Mock)
        factors["signature_alignment"] = 0.8

        return factors

    def _generate_response(
        self, final_result: Dict[str, Any], search_results: List[Dict[str, Any]]
    ) -> str:
        """ìµœì¢… ì‘ë‹µ ìƒì„± (Mock)"""
        judgment = final_result.get("judgment", "unknown")
        confidence = final_result.get("confidence", 0)
        reasoning = final_result.get("reasoning", "")

        # ê¸°ë³¸ ì‘ë‹µ í…œí”Œë¦¿
        if judgment == "accept":
            response = f"ë„¤, ë¶„ì„ ê²°ê³¼ ê¸ì •ì ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. {reasoning}"
        elif judgment == "support":
            response = f"í•´ë‹¹ ìš”ì²­ì— ëŒ€í•œ ì§€ì›ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. {reasoning}"
        elif judgment == "guide":
            response = f"ë‹¤ìŒê³¼ ê°™ì€ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤: {reasoning}"
        elif judgment == "defer":
            response = f"ë” ì‹ ì¤‘í•œ ê²€í† ê°€ í•„ìš”í•œ ì‚¬ì•ˆì…ë‹ˆë‹¤. {reasoning}"
        else:
            response = f"íŒë‹¨ ê²°ê³¼: {judgment}. {reasoning}"

        # ê´€ë ¨ ìº¡ìŠ ì •ë³´ ì¶”ê°€
        if search_results:
            primary_capsule = search_results[0]["metadata"]["capsule_id"]
            response += f"\n\n(ì°¸ê³ : ê´€ë ¨ ì •ë³´ '{primary_capsule}' ê¸°ë°˜ ë¶„ì„)"

        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ê²½ê³  ì¶”ê°€
        if confidence < 0.7:
            response += "\n\nâ€» ì´ íŒë‹¨ì€ ë¶ˆí™•ì‹¤ì„±ì´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."

        return response

    def _log_bridge_event(
        self,
        query: str,
        signature: str,
        search_results: List[Dict[str, Any]],
        judgment_result: Dict[str, Any],
        final_result: Dict[str, Any],
    ):
        """ë¸Œë¦¬ì§€ ì´ë²¤íŠ¸ ë¡œê¹…"""
        # ë©”íƒ€ ë¡œê·¸ ê¸°ë¡ (ë‚˜ì¤‘ì— meta_log_writerì™€ ì—°ë™)
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "bridge_event": {
                "query": query[:100],
                "signature": signature,
                "vector_search_count": len(search_results),
                "judgment": final_result.get("judgment"),
                "confidence": final_result.get("confidence"),
                "processing_success": True,
            },
        }

        print(f"ğŸ“ ë¸Œë¦¬ì§€ ì´ë²¤íŠ¸ ë¡œê·¸ ê¸°ë¡: {log_entry['bridge_event']['judgment']}")

    def _load_config(self) -> Dict[str, Any]:
        """ë¸Œë¦¬ì§€ ì„¤ì • ë¡œë“œ"""
        # ê¸°ë³¸ ì„¤ì • (ì‹¤ì œë¡œëŠ” YAML íŒŒì¼ì—ì„œ ë¡œë“œ)
        return {
            "vector_search_integration": True,
            "echo_judgment_integration": True,
            "confidence_tuning": {"vector_weight": 0.4, "judgment_weight": 0.6},
        }


# ì „ì—­ ë¸Œë¦¬ì§€ ì¸ìŠ¤í„´ìŠ¤
echo_judgment_bridge = EchoJudgmentBridge()


# í¸ì˜ í•¨ìˆ˜
def process_query(
    query: str, signature: str = "Echo-Aurora", context: Dict[str, Any] = None
) -> Dict[str, Any]:
    """ìì—°ì–´ ì¿¼ë¦¬ ì²˜ë¦¬ ë‹¨ì¶• í•¨ìˆ˜"""
    return echo_judgment_bridge.process_natural_query(query, signature, context)


def analyze_with_vectors(query: str, signature: str = "Echo-Aurora") -> Dict[str, Any]:
    """ë²¡í„° ê¸°ë°˜ ë¶„ì„ ë‹¨ì¶• í•¨ìˆ˜"""
    return process_query(query, signature, {"analysis_mode": True})


# CLI í…ŒìŠ¤íŠ¸
def main():
    print("ğŸŒ€ EchoJudgmentBridge CLI í…ŒìŠ¤íŠ¸")

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        ("ë¶€ì‚° ê¸ˆì •êµ¬ ë…¸ì¸ ë³µì§€ ì •ì±…ì´ ì–´ë–¤ê°€ìš”?", "Echo-Companion"),
        ("AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ì´ í•„ìš”í•œ ì´ìœ ëŠ”?", "Echo-Sage"),
        ("ê¸°í›„ ë³€í™” ëŒ€ì‘ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”", "Echo-Phoenix"),
        ("ì§€ì—­ì‚¬íšŒ ëŒë´„ ë„¤íŠ¸ì›Œí¬ë¥¼ ì–´ë–»ê²Œ êµ¬ì¶•í• ê¹Œìš”?", "Echo-Aurora"),
    ]

    print("\nğŸ§ª ë²¡í„° ê²€ìƒ‰ â†’ Echo íŒë‹¨ í†µí•© í…ŒìŠ¤íŠ¸:")

    for i, (query, signature) in enumerate(test_queries):
        print(f"\n{'='*60}")
        print(f"í…ŒìŠ¤íŠ¸ {i+1}: {query}")
        print(f"ì‹œê·¸ë‹ˆì²˜: {signature}")
        print("-" * 60)

        # í†µí•© ì²˜ë¦¬ ì‹¤í–‰
        result = process_query(query, signature)

        # ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ“Š íŒë‹¨ ê²°ê³¼:")
        print(f"  - íŒë‹¨: {result.get('judgment', 'unknown')}")
        print(f"  - ì‹ ë¢°ë„: {result.get('confidence', 0):.2f}")
        print(f"  - ì¶”ë¡ : {result.get('reasoning', 'N/A')}")

        if result.get("vector_search_summary"):
            vss = result["vector_search_summary"]
            print(f"  - ë²¡í„° ê²€ìƒ‰: {vss['total_candidates']}ê°œ í›„ë³´")
            print(f"  - ìµœê³  ìœ ì‚¬ë„: {vss['top_similarity']:.3f}")
            print(f"  - ì£¼ìš” ìº¡ìŠ: {vss['primary_capsule']}")

        if result.get("response"):
            print(f"ğŸ“ ìƒì„± ì‘ë‹µ: {result['response'][:100]}...")

    print(f"\n{'='*60}")
    print("âœ… EchoJudgmentBridge í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
