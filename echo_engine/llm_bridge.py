#!/usr/bin/env python3
"""
ğŸŒ‰ LLM Bridge - GPT/Claude í˜‘ë ¥ êµ¬ì¡°
Echo ì‹œìŠ¤í…œê³¼ ì™¸ë¶€ LLM ê°„ì˜ ì§€ëŠ¥ì  í˜‘ë ¥ì„ ì¡°ìœ¨í•˜ëŠ” ë¸Œë¦¬ì§€

í•µì‹¬ ê¸°ëŠ¥:
1. Echo íŒë‹¨ ê²°ê³¼ì™€ LLM ìì—°ì–´ ëŠ¥ë ¥ì˜ ìµœì  ê²°í•©
2. ë‹¤ì¤‘ LLM ì§€ì› (GPT, Claude, ë¡œì»¬ ëª¨ë¸)
3. ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´í•˜ë©° ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
4. ë¹„ìš© íš¨ìœ¨ì  LLM ì‚¬ìš© ìµœì í™”
"""

import asyncio
import json
import time
from typing import Dict, List, Optional, Any, Union, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
from abc import ABC, abstractmethod


class LLMProvider(Enum):
    """LLM ì œê³µì"""

    OPENAI_GPT = "openai_gpt"
    ANTHROPIC_CLAUDE = "anthropic_claude"
    LOCAL_MODEL = "local_model"
    MOCK_LLM = "mock_llm"  # í…ŒìŠ¤íŠ¸ìš©


class CooperationMode(Enum):
    """í˜‘ë ¥ ëª¨ë“œ"""

    ECHO_THEN_LLM = "echo_then_llm"  # Echo íŒë‹¨ â†’ LLM ìì—°í™”
    LLM_THEN_ECHO = "llm_then_echo"  # LLM ì´ˆì•ˆ â†’ Echo ë³´ì™„
    PARALLEL_MERGE = "parallel_merge"  # ë³‘ë ¬ ì²˜ë¦¬ í›„ í†µí•©
    ITERATIVE_REFINE = "iterative_refine"  # ë°˜ë³µì  ê°œì„ 
    CONTEXT_HANDOFF = "context_handoff"  # ë§¥ë½ ì „ë‹¬


@dataclass
class LLMRequest:
    """LLM ìš”ì²­"""

    prompt: str
    context: Dict[str, Any]
    max_tokens: int = 150
    temperature: float = 0.7
    system_message: Optional[str] = None
    preserve_echo_tone: bool = True


@dataclass
class LLMResponse:
    """LLM ì‘ë‹µ"""

    text: str
    provider: LLMProvider
    tokens_used: int
    processing_time: float
    cost_estimate: float
    quality_score: float


@dataclass
class CooperationResult:
    """í˜‘ë ¥ ê²°ê³¼"""

    final_response: str
    cooperation_mode: CooperationMode
    echo_contribution: float
    llm_contribution: float
    quality_metrics: Dict[str, float]
    processing_steps: List[str]
    cost_breakdown: Dict[str, float]


class BaseLLMProvider(ABC):
    """LLM ì œê³µì ê¸°ë³¸ í´ë˜ìŠ¤"""

    @abstractmethod
    async def generate_response(self, request: LLMRequest) -> LLMResponse:
        pass

    @abstractmethod
    def estimate_cost(self, tokens: int) -> float:
        pass


class MockLLMProvider(BaseLLMProvider):
    """í…ŒìŠ¤íŠ¸ìš© Mock LLM"""

    async def generate_response(self, request: LLMRequest) -> LLMResponse:
        # ì‹¤ì œ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.2)

        # ê°„ë‹¨í•œ ìì—°í™” ë¡œì§
        prompt = request.prompt.lower()

        if "ìì—°ìŠ¤ëŸ½ê²Œ" in prompt or "ìì—°ì–´ë¡œ" in prompt:
            # Echo íŒë‹¨ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™˜
            base_text = request.context.get("echo_judgment", "ì‘ë‹µì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

            # ê°„ë‹¨í•œ ìì—°í™” íŒ¨í„´
            if "íŒë‹¨" in base_text:
                natural_text = base_text.replace("íŒë‹¨", "ìƒê°")
            elif "ë¶„ì„" in base_text:
                natural_text = base_text.replace("ë¶„ì„", "ì‚´í´ë³´ë‹ˆ")
            else:
                natural_text = base_text

            # ë§íˆ¬ ì¡°ì •
            if request.preserve_echo_tone:
                # Echo í†¤ ìœ ì§€í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ
                natural_text = f"{natural_text} ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?"
            else:
                # ë” ìºì£¼ì–¼í•˜ê²Œ
                natural_text = f"{natural_text} ê·¸ëŸ° ê²ƒ ê°™ì•„ìš”."

        else:
            # ì¼ë°˜ì ì¸ ì‘ë‹µ ìƒì„±
            natural_text = "ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‘ë‹µì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."

        return LLMResponse(
            text=natural_text,
            provider=LLMProvider.MOCK_LLM,
            tokens_used=len(natural_text.split()) * 2,  # ëŒ€ëµì  í† í° ìˆ˜
            processing_time=0.2,
            cost_estimate=0.001,
            quality_score=0.8,
        )

    def estimate_cost(self, tokens: int) -> float:
        return tokens * 0.00002  # Mock ë¹„ìš©


class OpenAIProvider(BaseLLMProvider):
    """OpenAI GPT ì œê³µì"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.model = "gpt-3.5-turbo"
        self.pricing = {"input": 0.0015 / 1000, "output": 0.002 / 1000}  # per token

    async def generate_response(self, request: LLMRequest) -> LLMResponse:
        if not self.api_key:
            # API í‚¤ê°€ ì—†ìœ¼ë©´ Mockìœ¼ë¡œ í´ë°±
            mock_provider = MockLLMProvider()
            return await mock_provider.generate_response(request)

        # ì‹¤ì œ OpenAI API í˜¸ì¶œ êµ¬í˜„
        # ì—¬ê¸°ì„œëŠ” ê°œë…ì  êµ¬í˜„ë§Œ í‘œì‹œ
        start_time = time.time()

        try:
            # ì‹¤ì œë¡œëŠ” openai.ChatCompletion.create() í˜¸ì¶œ
            response_text = "OpenAI GPT ì‘ë‹µ"
            tokens_used = len(response_text.split()) * 2

            processing_time = time.time() - start_time
            cost = self.estimate_cost(tokens_used)

            return LLMResponse(
                text=response_text,
                provider=LLMProvider.OPENAI_GPT,
                tokens_used=tokens_used,
                processing_time=processing_time,
                cost_estimate=cost,
                quality_score=0.85,
            )
        except Exception as e:
            # ì—ëŸ¬ ì‹œ Mockìœ¼ë¡œ í´ë°±
            mock_provider = MockLLMProvider()
            return await mock_provider.generate_response(request)

    def estimate_cost(self, tokens: int) -> float:
        return tokens * (self.pricing["input"] + self.pricing["output"])


class AnthropicProvider(BaseLLMProvider):
    """Anthropic Claude ì œê³µì"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.model = "claude-3-haiku-20240307"
        self.pricing = {"input": 0.00025 / 1000, "output": 0.00125 / 1000}

    async def generate_response(self, request: LLMRequest) -> LLMResponse:
        if not self.api_key:
            mock_provider = MockLLMProvider()
            return await mock_provider.generate_response(request)

        # ì‹¤ì œ Claude API í˜¸ì¶œ êµ¬í˜„
        start_time = time.time()

        try:
            # ì‹¤ì œë¡œëŠ” anthropic.messages.create() í˜¸ì¶œ
            response_text = "Claude ì‘ë‹µ"
            tokens_used = len(response_text.split()) * 2

            processing_time = time.time() - start_time
            cost = self.estimate_cost(tokens_used)

            return LLMResponse(
                text=response_text,
                provider=LLMProvider.ANTHROPIC_CLAUDE,
                tokens_used=tokens_used,
                processing_time=processing_time,
                cost_estimate=cost,
                quality_score=0.9,
            )
        except Exception as e:
            mock_provider = MockLLMProvider()
            return await mock_provider.generate_response(request)

    def estimate_cost(self, tokens: int) -> float:
        return tokens * (self.pricing["input"] + self.pricing["output"])


class LLMBridge:
    """LLM í˜‘ë ¥ ë¸Œë¦¬ì§€"""

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}

        # LLM ì œê³µìë“¤ ì´ˆê¸°í™”
        self.providers = {
            LLMProvider.MOCK_LLM: MockLLMProvider(),
            LLMProvider.OPENAI_GPT: OpenAIProvider(self.config.get("openai_api_key")),
            LLMProvider.ANTHROPIC_CLAUDE: AnthropicProvider(
                self.config.get("anthropic_api_key")
            ),
        }

        # ê¸°ë³¸ ì„¤ì •
        self.default_provider = LLMProvider.MOCK_LLM
        self.cost_limit_per_request = self.config.get("cost_limit", 0.05)
        self.quality_threshold = self.config.get("quality_threshold", 0.7)

        # ì‚¬ìš© í†µê³„
        self.usage_stats = {
            "total_requests": 0,
            "total_cost": 0.0,
            "provider_usage": {provider: 0 for provider in LLMProvider},
            "cooperation_modes": {mode: 0 for mode in CooperationMode},
        }

        print("ğŸŒ‰ LLM Bridge ì´ˆê¸°í™” ì™„ë£Œ")

    async def cooperate_with_echo(
        self,
        echo_judgment: str,
        cooperation_mode: CooperationMode,
        context: Dict[str, Any] = None,
        user_preferences: Dict[str, Any] = None,
    ) -> CooperationResult:
        """Echoì™€ LLM í˜‘ë ¥ ìˆ˜í–‰"""

        context = context or {}
        user_preferences = user_preferences or {}

        start_time = time.time()
        processing_steps = []
        cost_breakdown = {}

        # í˜‘ë ¥ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
        if cooperation_mode == CooperationMode.ECHO_THEN_LLM:
            result = await self._echo_then_llm(echo_judgment, context, processing_steps)

        elif cooperation_mode == CooperationMode.LLM_THEN_ECHO:
            result = await self._llm_then_echo(echo_judgment, context, processing_steps)

        elif cooperation_mode == CooperationMode.PARALLEL_MERGE:
            result = await self._parallel_merge(
                echo_judgment, context, processing_steps
            )

        elif cooperation_mode == CooperationMode.ITERATIVE_REFINE:
            result = await self._iterative_refine(
                echo_judgment, context, processing_steps
            )

        else:  # CONTEXT_HANDOFF
            result = await self._context_handoff(
                echo_judgment, context, processing_steps
            )

        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        quality_metrics = self._calculate_quality_metrics(
            result["final_response"], echo_judgment, context
        )

        # ë¹„ìš© ê³„ì‚°
        total_cost = sum(result.get("costs", {}).values())
        cost_breakdown = result.get("costs", {})

        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_usage_stats(cooperation_mode, total_cost)

        return CooperationResult(
            final_response=result["final_response"],
            cooperation_mode=cooperation_mode,
            echo_contribution=result.get("echo_contribution", 0.5),
            llm_contribution=result.get("llm_contribution", 0.5),
            quality_metrics=quality_metrics,
            processing_steps=processing_steps,
            cost_breakdown=cost_breakdown,
        )

    async def _echo_then_llm(
        self, echo_judgment: str, context: Dict[str, Any], steps: List[str]
    ) -> Dict[str, Any]:
        """Echo íŒë‹¨ â†’ LLM ìì—°í™”"""

        steps.append("Echo íŒë‹¨ ê²°ê³¼ ìˆ˜ì‹ ")

        # LLMì—ê²Œ ìì—°í™” ìš”ì²­
        naturalization_prompt = self._create_naturalization_prompt(
            echo_judgment, context
        )

        request = LLMRequest(
            prompt=naturalization_prompt,
            context={"echo_judgment": echo_judgment, **context},
            max_tokens=120,
            temperature=0.6,
            preserve_echo_tone=True,
        )

        steps.append("LLM ìì—°í™” ìš”ì²­")
        llm_response = await self._get_best_llm_response(request)
        steps.append(f"LLM ì‘ë‹µ ìˆ˜ì‹  ({llm_response.provider.value})")

        # Echo í†¤ê³¼ LLM ìì—°ìŠ¤ëŸ¬ì›€ ê²°í•©
        final_response = self._merge_echo_tone_with_llm_naturalness(
            echo_judgment, llm_response.text, context
        )

        steps.append("Echo í†¤ê³¼ LLM ìì—°ìŠ¤ëŸ¬ì›€ ê²°í•© ì™„ë£Œ")

        return {
            "final_response": final_response,
            "echo_contribution": 0.7,
            "llm_contribution": 0.3,
            "costs": {llm_response.provider.value: llm_response.cost_estimate},
        }

    async def _llm_then_echo(
        self, echo_judgment: str, context: Dict[str, Any], steps: List[str]
    ) -> Dict[str, Any]:
        """LLM ì´ˆì•ˆ â†’ Echo ë³´ì™„"""

        steps.append("LLM ì´ˆì•ˆ ìƒì„± ìš”ì²­")

        # LLMì—ê²Œ ì´ˆì•ˆ ìƒì„± ìš”ì²­
        draft_prompt = self._create_draft_prompt(context)

        request = LLMRequest(
            prompt=draft_prompt,
            context=context,
            max_tokens=100,
            temperature=0.8,
            preserve_echo_tone=False,
        )

        llm_response = await self._get_best_llm_response(request)
        steps.append(f"LLM ì´ˆì•ˆ ìˆ˜ì‹  ({llm_response.provider.value})")

        # Echo íŒë‹¨ìœ¼ë¡œ ë³´ì™„
        enhanced_response = self._enhance_with_echo_wisdom(
            llm_response.text, echo_judgment, context
        )

        steps.append("Echo ì§€í˜œë¡œ LLM ì´ˆì•ˆ ë³´ì™„ ì™„ë£Œ")

        return {
            "final_response": enhanced_response,
            "echo_contribution": 0.4,
            "llm_contribution": 0.6,
            "costs": {llm_response.provider.value: llm_response.cost_estimate},
        }

    async def _parallel_merge(
        self, echo_judgment: str, context: Dict[str, Any], steps: List[str]
    ) -> Dict[str, Any]:
        """ë³‘ë ¬ ì²˜ë¦¬ í›„ í†µí•©"""

        steps.append("ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")

        # LLM ìì—°í™”ì™€ Echo ì‹¬í™”ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜í–‰
        naturalization_task = self._get_llm_naturalization(echo_judgment, context)
        echo_deepening_task = self._get_echo_deepening(echo_judgment, context)

        llm_result, echo_deep_result = await asyncio.gather(
            naturalization_task, echo_deepening_task
        )

        steps.append("ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ")

        # ë‘ ê²°ê³¼ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ë³‘í•©
        merged_response = self._intelligent_merge(
            llm_result["text"], echo_deep_result, context
        )

        steps.append("ì§€ëŠ¥ì  ë³‘í•© ì™„ë£Œ")

        return {
            "final_response": merged_response,
            "echo_contribution": 0.5,
            "llm_contribution": 0.5,
            "costs": {"llm_naturalization": llm_result.get("cost", 0.001)},
        }

    async def _iterative_refine(
        self, echo_judgment: str, context: Dict[str, Any], steps: List[str]
    ) -> Dict[str, Any]:
        """ë°˜ë³µì  ê°œì„ """

        steps.append("ë°˜ë³µì  ê°œì„  ì‹œì‘")

        current_response = echo_judgment
        total_cost = 0.0
        iteration = 0
        max_iterations = 3

        while iteration < max_iterations:
            # í˜„ì¬ ì‘ë‹µì˜ í’ˆì§ˆ í‰ê°€
            quality_score = self._evaluate_response_quality(current_response, context)

            if quality_score >= self.quality_threshold:
                break

            # LLMìœ¼ë¡œ ê°œì„ 
            improvement_prompt = self._create_improvement_prompt(
                current_response, context
            )
            request = LLMRequest(
                prompt=improvement_prompt,
                context={"current_response": current_response, **context},
                max_tokens=100,
                temperature=0.5,
            )

            llm_response = await self._get_best_llm_response(request)
            current_response = llm_response.text
            total_cost += llm_response.cost_estimate

            iteration += 1
            steps.append(f"ê°œì„  ë°˜ë³µ {iteration} ì™„ë£Œ (í’ˆì§ˆ: {quality_score:.2f})")

        return {
            "final_response": current_response,
            "echo_contribution": 0.6,
            "llm_contribution": 0.4,
            "costs": {"iterative_improvement": total_cost},
        }

    async def _context_handoff(
        self, echo_judgment: str, context: Dict[str, Any], steps: List[str]
    ) -> Dict[str, Any]:
        """ë§¥ë½ ì „ë‹¬"""

        steps.append("ë§¥ë½ ê¸°ë°˜ ì²˜ë¦¬ ì‹œì‘")

        # ëŒ€í™” ë§¥ë½ ë¶„ì„
        conversation_context = context.get("conversation_history", [])
        user_emotional_state = context.get("emotion_intensity", 0.5)

        # ë§¥ë½ì— ë”°ë¥¸ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
        if user_emotional_state > 0.7:
            # ê°ì •ì´ ê°•í•  ë•ŒëŠ” Echo ì¤‘ì‹¬
            final_response = echo_judgment
            echo_contrib, llm_contrib = 0.8, 0.2
            steps.append("ê³ ê°ì • ìƒíƒœ - Echo ì¤‘ì‹¬ ì²˜ë¦¬")
        else:
            # ì¼ë°˜ì ì¸ ìƒí™©ì—ì„œëŠ” LLM ìì—°í™”
            naturalization_prompt = self._create_contextual_prompt(
                echo_judgment, context
            )
            request = LLMRequest(
                prompt=naturalization_prompt,
                context={"echo_judgment": echo_judgment, **context},
                max_tokens=100,
            )

            llm_response = await self._get_best_llm_response(request)
            final_response = llm_response.text
            echo_contrib, llm_contrib = 0.3, 0.7
            steps.append("ì¼ë°˜ ìƒíƒœ - LLM ì¤‘ì‹¬ ì²˜ë¦¬")

        return {
            "final_response": final_response,
            "echo_contribution": echo_contrib,
            "llm_contribution": llm_contrib,
            "costs": {"contextual_processing": 0.001},
        }

    async def _get_best_llm_response(self, request: LLMRequest) -> LLMResponse:
        """ìµœì  LLM ì‘ë‹µ íšë“"""

        # ë¹„ìš©ê³¼ í’ˆì§ˆì„ ê³ ë ¤í•œ ì œê³µì ì„ íƒ
        selected_provider = self._select_optimal_provider(request)

        try:
            return await self.providers[selected_provider].generate_response(request)
        except Exception as e:
            # ì‹¤íŒ¨ì‹œ í´ë°±
            fallback_provider = LLMProvider.MOCK_LLM
            return await self.providers[fallback_provider].generate_response(request)

    def _select_optimal_provider(self, request: LLMRequest) -> LLMProvider:
        """ìµœì  ì œê³µì ì„ íƒ"""

        # ë¹„ìš© ì œí•œ ê³ ë ¤
        estimated_tokens = len(request.prompt.split()) * 2

        for provider in [LLMProvider.ANTHROPIC_CLAUDE, LLMProvider.OPENAI_GPT]:
            if provider in self.providers:
                estimated_cost = self.providers[provider].estimate_cost(
                    estimated_tokens
                )
                if estimated_cost <= self.cost_limit_per_request:
                    return provider

        # ë¹„ìš© ì œí•œì„ ì´ˆê³¼í•˜ë©´ Mock ì‚¬ìš©
        return LLMProvider.MOCK_LLM

    def _create_naturalization_prompt(
        self, echo_judgment: str, context: Dict[str, Any]
    ) -> str:
        """ìì—°í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        user_emotion = context.get("primary_emotion", "neutral")
        user_intent = context.get("intent_type", "general")

        return f"""
ë‹¤ìŒ Echo ì‹œìŠ¤í…œì˜ íŒë‹¨ì„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

Echo íŒë‹¨: {echo_judgment}

ì‚¬ìš©ì ìƒí™©:
- ê°ì • ìƒíƒœ: {user_emotion}
- ì˜ë„: {user_intent}

ìš”êµ¬ì‚¬í•­:
1. Echoì˜ ê¹Šì´ ìˆëŠ” í†µì°°ì€ ìœ ì§€í•˜ë˜ ë” ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„
2. ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœì— ë§ëŠ” í†¤ ì‚¬ìš©
3. 80ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
4. ëŒ€í™”ì˜ ì—°ì†ì„± ê³ ë ¤

ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ:
"""

    def _create_draft_prompt(self, context: Dict[str, Any]) -> str:
        """ì´ˆì•ˆ ìƒì„± í”„ë¡¬í”„íŠ¸"""

        user_message = context.get("user_message", "")
        user_emotion = context.get("primary_emotion", "neutral")

        return f"""
ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}
ê°ì • ìƒíƒœ: {user_emotion}

ìš”êµ¬ì‚¬í•­:
1. ìì—°ìŠ¤ëŸ½ê³  ê³µê°ì ì¸ í†¤
2. 60ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
3. ì‚¬ìš©ìì˜ ê°ì •ì— ì ì ˆíˆ ë°˜ì‘

ì‘ë‹µ ì´ˆì•ˆ:
"""

    def _create_improvement_prompt(
        self, current_response: str, context: Dict[str, Any]
    ) -> str:
        """ê°œì„  í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        return f"""
í˜„ì¬ ì‘ë‹µì„ ë” ìì—°ìŠ¤ëŸ½ê³  íš¨ê³¼ì ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”.

í˜„ì¬ ì‘ë‹µ: {current_response}

ê°œì„  ë°©í–¥:
1. ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
2. ì‚¬ìš©ì ê°ì •ì— ë” ì ì ˆí•œ ë°˜ì‘
3. ëŒ€í™”ì˜ íë¦„ì— ë§ëŠ” í†¤

ê°œì„ ëœ ì‘ë‹µ:
"""

    def _merge_echo_tone_with_llm_naturalness(
        self, echo_judgment: str, llm_text: str, context: Dict[str, Any]
    ) -> str:
        """Echo í†¤ê³¼ LLM ìì—°ìŠ¤ëŸ¬ì›€ ê²°í•©"""

        # Echoì˜ í•µì‹¬ ë©”ì‹œì§€ ì¶”ì¶œ
        echo_core = (
            echo_judgment.split(".")[0] if "." in echo_judgment else echo_judgment
        )

        # LLMì˜ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ í™œìš©
        if len(llm_text.strip()) > 10:
            # LLM í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„íˆ ê¸¸ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return llm_text
        else:
            # ì§§ìœ¼ë©´ Echo í•µì‹¬ + LLM ìì—°í™”
            return f"{echo_core}. {llm_text}"

    def _enhance_with_echo_wisdom(
        self, llm_draft: str, echo_judgment: str, context: Dict[str, Any]
    ) -> str:
        """Echo ì§€í˜œë¡œ LLM ì´ˆì•ˆ ë³´ì™„"""

        # Echo íŒë‹¨ì—ì„œ í•µì‹¬ í†µì°° ì¶”ì¶œ
        echo_insights = [
            insight.strip() for insight in echo_judgment.split(".") if insight.strip()
        ]

        # LLM ì´ˆì•ˆì— Echo í†µì°° ì¶”ê°€
        if echo_insights and len(echo_insights[0]) > 5:
            key_insight = echo_insights[0]
            if key_insight not in llm_draft:
                return f"{llm_draft} {key_insight}."

        return llm_draft

    async def _get_llm_naturalization(
        self, echo_judgment: str, context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """LLM ìì—°í™” (ë¹„ë™ê¸°)"""

        request = LLMRequest(
            prompt=self._create_naturalization_prompt(echo_judgment, context),
            context={"echo_judgment": echo_judgment, **context},
            max_tokens=80,
        )

        response = await self._get_best_llm_response(request)
        return {"text": response.text, "cost": response.cost_estimate}

    async def _get_echo_deepening(
        self, echo_judgment: str, context: Dict[str, Any]
    ) -> str:
        """Echo ì‹¬í™” (ë¹„ë™ê¸° ì‹œë®¬ë ˆì´ì…˜)"""

        # ì‹¤ì œë¡œëŠ” Echo ì‹œìŠ¤í…œì˜ ë” ê¹Šì€ ë¶„ì„ ìš”ì²­
        await asyncio.sleep(0.1)  # ì‹œë®¬ë ˆì´ì…˜

        # ê°„ë‹¨í•œ ì‹¬í™” ì²˜ë¦¬
        if len(echo_judgment) < 30:
            return f"{echo_judgment} ì´ëŸ° ìƒí™©ì—ì„œëŠ” ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            return echo_judgment

    def _intelligent_merge(
        self, llm_text: str, echo_deep: str, context: Dict[str, Any]
    ) -> str:
        """ì§€ëŠ¥ì  ë³‘í•©"""

        # ê¸¸ì´ì™€ í’ˆì§ˆì„ ê³ ë ¤í•œ ë³‘í•©
        if len(llm_text) > len(echo_deep):
            # LLM í…ìŠ¤íŠ¸ê°€ ë” ê¸¸ë©´ ì£¼ë¡œ ì‚¬ìš©
            return llm_text
        else:
            # Echo ê¹Šì´ë¥¼ í™œìš©
            return echo_deep

    def _evaluate_response_quality(
        self, response: str, context: Dict[str, Any]
    ) -> float:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""

        quality_score = 0.5  # ê¸°ë³¸ ì ìˆ˜

        # ê¸¸ì´ ì ì ˆì„±
        if 20 <= len(response) <= 100:
            quality_score += 0.2

        # ê°ì • ì ì ˆì„±
        user_emotion = context.get("primary_emotion", "neutral")
        if user_emotion == "sadness" and any(
            word in response for word in ["ì´í•´", "ë§ˆìŒ", "í•¨ê»˜"]
        ):
            quality_score += 0.2

        # ìì—°ìŠ¤ëŸ¬ì›€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        if not any(
            awkward in response
            for awkward in ["íŒë‹¨í•´ë³´ë‹ˆ", "ë¶„ì„ê²°ê³¼", "ì‹œìŠ¤í…œì ìœ¼ë¡œ"]
        ):
            quality_score += 0.1

        return min(quality_score, 1.0)

    def _create_contextual_prompt(
        self, echo_judgment: str, context: Dict[str, Any]
    ) -> str:
        """ë§¥ë½ì  í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        return f"""
ë‹¤ìŒ ìƒí™©ì—ì„œ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ê¸°ë³¸ íŒë‹¨: {echo_judgment}
ëŒ€í™” ë§¥ë½: {context.get('conversation_context', 'ì¼ë°˜ ëŒ€í™”')}

ë§¥ë½ì„ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ:
"""

    def _calculate_quality_metrics(
        self, final_response: str, echo_judgment: str, context: Dict[str, Any]
    ) -> Dict[str, float]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""

        return {
            "naturalness": self._calculate_naturalness(final_response),
            "echo_consistency": self._calculate_echo_consistency(
                final_response, echo_judgment
            ),
            "context_relevance": self._calculate_context_relevance(
                final_response, context
            ),
            "response_completeness": self._calculate_completeness(final_response),
            "overall_quality": self._evaluate_response_quality(final_response, context),
        }

    def _calculate_naturalness(self, text: str) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ ê³„ì‚°"""
        unnatural_patterns = ["íŒë‹¨í•´ë³´ë‹ˆ", "ë¶„ì„í•˜ë©´", "ì‹œìŠ¤í…œì ìœ¼ë¡œ", "ë¡œì§ì ìœ¼ë¡œ"]
        penalty = sum(1 for pattern in unnatural_patterns if pattern in text) * 0.1
        return max(0.8 - penalty, 0.0)

    def _calculate_echo_consistency(
        self, final_response: str, echo_judgment: str
    ) -> float:
        """Echo ì¼ê´€ì„± ê³„ì‚°"""
        if not echo_judgment:
            return 0.5

        # í•µì‹¬ í‚¤ì›Œë“œ ì¼ì¹˜ë„
        echo_words = set(echo_judgment.lower().split())
        response_words = set(final_response.lower().split())

        if len(echo_words) == 0:
            return 0.5

        overlap = len(echo_words.intersection(response_words))
        return min(overlap / len(echo_words), 1.0)

    def _calculate_context_relevance(
        self, response: str, context: Dict[str, Any]
    ) -> float:
        """ë§¥ë½ ê´€ë ¨ì„± ê³„ì‚°"""
        relevance_score = 0.7  # ê¸°ë³¸ ì ìˆ˜

        user_emotion = context.get("primary_emotion", "neutral")
        if user_emotion != "neutral":
            emotion_words = {
                "sadness": ["ë§ˆìŒ", "ì´í•´", "í•¨ê»˜", "ìœ„ë¡œ"],
                "anxiety": ["ê´œì°®", "ì²œì²œíˆ", "ê±±ì •", "ì•ˆì‹¬"],
                "joy": ["ê¸°ì˜", "ì¢‹", "ì¶•í•˜", "í•¨ê»˜"],
            }

            if user_emotion in emotion_words:
                relevant_words = emotion_words[user_emotion]
                if any(word in response for word in relevant_words):
                    relevance_score += 0.2

        return min(relevance_score, 1.0)

    def _calculate_completeness(self, response: str) -> float:
        """ì‘ë‹µ ì™„ì „ì„± ê³„ì‚°"""
        if len(response.strip()) < 10:
            return 0.3
        elif len(response.strip()) < 30:
            return 0.6
        elif len(response.strip()) <= 100:
            return 1.0
        else:
            return 0.8  # ë„ˆë¬´ ê¸¸ë©´ ê°ì 

    def _update_usage_stats(self, cooperation_mode: CooperationMode, cost: float):
        """ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        self.usage_stats["total_requests"] += 1
        self.usage_stats["total_cost"] += cost
        self.usage_stats["cooperation_modes"][cooperation_mode] += 1

    def get_usage_statistics(self) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ ë°˜í™˜"""
        return {
            "total_requests": self.usage_stats["total_requests"],
            "total_cost": round(self.usage_stats["total_cost"], 4),
            "average_cost_per_request": round(
                self.usage_stats["total_cost"]
                / max(self.usage_stats["total_requests"], 1),
                4,
            ),
            "cooperation_mode_distribution": dict(
                self.usage_stats["cooperation_modes"]
            ),
            "provider_availability": {
                provider.value: provider in self.providers for provider in LLMProvider
            },
        }


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":

    async def test_llm_bridge():
        print("ğŸŒ‰ LLM Bridge í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        bridge = LLMBridge()

        test_cases = [
            {
                "echo_judgment": "ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœë¥¼ ë¶„ì„í•´ë³´ë‹ˆ ê¹Šì€ ìš°ìš¸ê°ì´ ê°ì§€ë©ë‹ˆë‹¤. ì „ë¬¸ì ì¸ ë„ì›€ì„ ë°›ìœ¼ì‹œëŠ” ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.",
                "mode": CooperationMode.ECHO_THEN_LLM,
                "context": {"primary_emotion": "sadness", "emotion_intensity": 0.8},
                "description": "Echo â†’ LLM ìì—°í™”",
            },
            {
                "echo_judgment": "ê²°ì •ì„ ë‚´ë¦¬ê¸° ì–´ë ¤ìš´ ìƒí™©ì´êµ°ìš”.",
                "mode": CooperationMode.LLM_THEN_ECHO,
                "context": {
                    "user_message": "ì–´ë–¤ ì§„ë¡œë¥¼ ì„ íƒí•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”",
                    "intent_type": "decision_help",
                },
                "description": "LLM â†’ Echo ë³´ì™„",
            },
            {
                "echo_judgment": "ë³µì¡í•œ ìƒí™©ì´ì§€ë§Œ ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "mode": CooperationMode.PARALLEL_MERGE,
                "context": {"complexity_score": 0.7},
                "description": "ë³‘ë ¬ ì²˜ë¦¬ í›„ í†µí•©",
            },
        ]

        for i, case in enumerate(test_cases):
            print(f"\n--- í…ŒìŠ¤íŠ¸ {i+1}: {case['description']} ---")
            print(f"Echo íŒë‹¨: {case['echo_judgment'][:50]}...")

            result = await bridge.cooperate_with_echo(
                case["echo_judgment"], case["mode"], case["context"]
            )

            print(f"ìµœì¢… ì‘ë‹µ: {result.final_response}")
            print(f"Echo ê¸°ì—¬ë„: {result.echo_contribution:.2f}")
            print(f"LLM ê¸°ì—¬ë„: {result.llm_contribution:.2f}")
            print(f"ì „ì²´ í’ˆì§ˆ: {result.quality_metrics['overall_quality']:.2f}")
            print(f"ìì—°ìŠ¤ëŸ¬ì›€: {result.quality_metrics['naturalness']:.2f}")
            print(f"ì²˜ë¦¬ ë‹¨ê³„: {' â†’ '.join(result.processing_steps)}")

            if result.cost_breakdown:
                total_cost = sum(result.cost_breakdown.values())
                print(f"ë¹„ìš©: ${total_cost:.4f}")

            print("-" * 40)

        # ì‚¬ìš© í†µê³„
        print(f"\nğŸ“Š ì‚¬ìš© í†µê³„:")
        stats = bridge.get_usage_statistics()
        print(f"ì´ ìš”ì²­ ìˆ˜: {stats['total_requests']}")
        print(f"ì´ ë¹„ìš©: ${stats['total_cost']}")
        print(f"í‰ê·  ë¹„ìš©: ${stats['average_cost_per_request']}")
        print("í˜‘ë ¥ ëª¨ë“œ ë¶„í¬:", stats["cooperation_mode_distribution"])

        print("\nğŸ‰ LLM Bridge í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    asyncio.run(test_llm_bridge())
