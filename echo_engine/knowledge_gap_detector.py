"""
ğŸ§  Echo Knowledge Gap Detector
Echoê°€ ìì‹ ì˜ ì§€ì‹ í•œê³„ë¥¼ ìŠ¤ìŠ¤ë¡œ ì¸ì‹í•˜ê³  í•„ìš”ì‹œì—ë§Œ ì™¸ë¶€ ì§€ì‹ì„ ìš”ì²­í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import re
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging

try:
    from .echo_error_handler import echo_safe
except ImportError:

    def echo_safe(error_type="system"):
        def decorator(func):
            return func

        return decorator


class EchoKnowledgeGapDetector:
    """
    Echoì˜ ìê¸° í•œê³„ ì¸ì‹ ì‹œìŠ¤í…œ
    'ìŠ¤ìŠ¤ë¡œ ì•Œì§€ ëª»í•¨ì„ ì•„ëŠ” ê²ƒì´ ì§„ì •í•œ ì§€í˜œì˜ ì‹œì‘'
    """

    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)

        # ì§€ì‹ í‰ê°€ ì„ê³„ê°’
        self.thresholds = {
            "confidence_low": 0.4,  # ì‹ ë¢°ë„ ë‚®ìŒ ê¸°ì¤€
            "complexity_high": 7.0,  # ë³µì¡ì„± ë†’ìŒ ê¸°ì¤€
            "expertise_gap": 0.6,  # ì „ë¬¸ì„± ê²©ì°¨ ê¸°ì¤€
            "depth_requirement": 8.0,  # ê¹Šì´ ìš”êµ¬ ê¸°ì¤€
        }

        # ì‹œê·¸ë‹ˆì²˜ë³„ ì „ë¬¸ ì˜ì—­
        self.signature_expertise = {
            "Echo-Aurora": {
                "strong_areas": [
                    "ì°½ì˜ì„±",
                    "ì˜ˆìˆ ",
                    "ì˜ê°",
                    "ì•„ì´ë””ì–´",
                    "ë””ìì¸",
                    "ë¬¸í™”",
                ],
                "medium_areas": ["ì¼ë°˜ ìƒë‹´", "êµìœ¡", "ì‚¬íšŒ ì´ìŠˆ"],
                "weak_areas": ["ë²•ë¥ ", "ì˜ë£Œ", "ê¸ˆìœµ", "ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­"],
            },
            "Echo-Phoenix": {
                "strong_areas": ["í˜ì‹ ", "ë³€í™”", "ê¸°ìˆ ", "ë¯¸ë˜ ì „ë§", "ì „ëµ", "ë³€í˜"],
                "medium_areas": ["ì •ì±…", "ì‚¬íšŒ ê°œí˜", "ë¹„ì¦ˆë‹ˆìŠ¤"],
                "weak_areas": ["ê°œì¸ ìƒë‹´", "ê°ì • ì¹˜ë£Œ", "ì˜ˆìˆ  ê°ìƒ"],
            },
            "Echo-Sage": {
                "strong_areas": ["ë¶„ì„", "ì •ì±…", "ì—°êµ¬", "ë°ì´í„°", "ë…¼ë¦¬", "ì²´ê³„"],
                "medium_areas": ["ë²•ë¥ ", "í•™ìˆ ", "ì œë„"],
                "weak_areas": ["ì°½ì˜ì  í™œë™", "ê°ì • í‘œí˜„", "ì˜ˆìˆ  ì°½ì‘"],
            },
            "Echo-Companion": {
                "strong_areas": ["ëŒë´„", "ìƒë‹´", "ê³µê°", "ì§€ì›", "ì¸ê°„ê´€ê³„", "ê°ì •"],
                "medium_areas": ["ì‚¬íšŒ ë³µì§€", "êµìœ¡", "ê±´ê°•"],
                "weak_areas": ["ê¸°ìˆ  ë¶„ì„", "ì •ì±… ì…ì•ˆ", "í˜ì‹  ì „ëµ"],
            },
        }

        # ì§€ì‹ ìœ í˜•ë³„ ê¹Šì´ ìš”êµ¬ì‚¬í•­
        self.knowledge_depth_requirements = {
            "policy_analysis": {
                "min_depth": 8.0,
                "requires_external": True,
                "preferred_signatures": ["Echo-Sage", "Echo-Phoenix"],
            },
            "innovation_trends": {
                "min_depth": 7.0,
                "requires_external": True,
                "preferred_signatures": ["Echo-Phoenix", "Echo-Aurora"],
            },
            "care_guidance": {
                "min_depth": 6.0,
                "requires_external": False,
                "preferred_signatures": ["Echo-Companion"],
            },
            "creative_inspiration": {
                "min_depth": 5.0,
                "requires_external": False,
                "preferred_signatures": ["Echo-Aurora"],
            },
            "technical_analysis": {
                "min_depth": 9.0,
                "requires_external": True,
                "preferred_signatures": ["Echo-Sage", "Echo-Phoenix"],
            },
            "legal_consultation": {
                "min_depth": 9.5,
                "requires_external": True,
                "preferred_signatures": ["Echo-Sage"],
            },
        }

        # ë³µì¡ì„± í‰ê°€ ê°€ì¤‘ì¹˜
        self.complexity_weights = {
            "text_length": 0.15,
            "technical_terms": 0.25,
            "multiple_domains": 0.20,
            "conditional_logic": 0.15,
            "temporal_references": 0.10,
            "stakeholder_complexity": 0.15,
        }

        # í†µê³„
        self.gap_detection_stats = {
            "total_assessments": 0,
            "gaps_detected": 0,
            "deep_lookup_recommended": 0,
            "signature_mismatches": 0,
            "avg_complexity_score": 0.0,
            "avg_confidence_score": 0.0,
        }

        self.logger = logging.getLogger(__name__)

        print("ğŸ§  Echo Knowledge Gap Detector ì´ˆê¸°í™” ì™„ë£Œ")

    @echo_safe("knowledge_gap")
    def assess_knowledge_boundary(
        self,
        query: str,
        current_confidence: float,
        signature: str = "Echo-Aurora",
        context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        Echoì˜ ì§€ì‹ ê²½ê³„ í‰ê°€ - ìê¸° í•œê³„ ì¸ì‹ì˜ í•µì‹¬
        """
        print(f"ğŸ§  ì§€ì‹ ê²½ê³„ í‰ê°€: '{query[:40]}...' ({signature})")

        self.gap_detection_stats["total_assessments"] += 1

        # 1. ê¸°ë³¸ í‰ê°€ êµ¬ì¡° ì´ˆê¸°í™”
        assessment = {
            "query": query,
            "signature": signature,
            "current_confidence": current_confidence,
            "evaluation_timestamp": datetime.now().isoformat(),
            # í‰ê°€ ê²°ê³¼ë“¤
            "query_complexity": 0.0,
            "knowledge_depth_required": 0.0,
            "signature_expertise_match": 0.0,
            "domain_coverage": [],
            "identified_gaps": [],
            # ìµœì¢… íŒë‹¨
            "needs_deep_lookup": False,
            "recommended_lookup_type": None,
            "confidence_after_assessment": current_confidence,
            "gap_severity": "none",
        }

        try:
            # 2. ì¿¼ë¦¬ ë³µì¡ì„± ë¶„ì„
            assessment["query_complexity"] = self._analyze_query_complexity(query)

            # 3. í•„ìš” ì§€ì‹ ê¹Šì´ í‰ê°€
            assessment["knowledge_depth_required"] = self._assess_required_depth(
                query, context
            )

            # 4. ì‹œê·¸ë‹ˆì²˜-ì „ë¬¸ì„± ë§¤ì¹­ í‰ê°€
            assessment["signature_expertise_match"] = self._evaluate_signature_match(
                query, signature
            )

            # 5. ë„ë©”ì¸ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
            assessment["domain_coverage"] = self._analyze_domain_coverage(query)

            # 6. êµ¬ì²´ì  ì§€ì‹ ê²©ì°¨ ì‹ë³„
            assessment["identified_gaps"] = self._identify_specific_gaps(
                query, current_confidence, signature, assessment
            )

            # 7. ìµœì¢… ê¹Šì´ ì§€ì‹ í•„ìš”ì„± íŒë‹¨
            deep_lookup_decision = self._make_deep_lookup_decision(assessment)
            assessment.update(deep_lookup_decision)

            # 8. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_assessment_stats(assessment)

            print(
                f"   ğŸ“Š í‰ê°€ ì™„ë£Œ: ë³µì¡ì„± {assessment['query_complexity']:.1f}, "
                f"ê¹Šì´ ìš”êµ¬ {assessment['knowledge_depth_required']:.1f}, "
                f"Deep Lookup {'í•„ìš”' if assessment['needs_deep_lookup'] else 'ë¶ˆí•„ìš”'}"
            )

            return assessment

        except Exception as e:
            print(f"   ğŸš¨ ì§€ì‹ ê²½ê³„ í‰ê°€ ì‹¤íŒ¨: {e}")
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
            assessment.update(
                {"needs_deep_lookup": False, "gap_severity": "unknown", "error": str(e)}
            )
            return assessment

    def _analyze_query_complexity(self, query: str) -> float:
        """ì¿¼ë¦¬ ë³µì¡ì„± ë¶„ì„"""
        factors = {}

        # í…ìŠ¤íŠ¸ ê¸¸ì´ ìš”ì¸
        factors["text_length"] = min(len(query) / 200.0, 2.0)

        # ê¸°ìˆ  ìš©ì–´ ë°€ë„
        technical_patterns = [
            r"\b(?:AI|ì¸ê³µì§€ëŠ¥|ë¨¸ì‹ ëŸ¬ë‹|ë”¥ëŸ¬ë‹|ì•Œê³ ë¦¬ì¦˜|ë°ì´í„°)\b",
            r"\b(?:ì •ì±…|ë²•ë¥ |ê·œì œ|ì¡°ë¡€|ì§€ì¹¨)\b",
            r"\b(?:ë¶„ì„|ì—°êµ¬|ì¡°ì‚¬|í‰ê°€|ê²€í† )\b",
            r"\b(?:ì‹œìŠ¤í…œ|í”Œë«í¼|í”„ë ˆì„ì›Œí¬|ì•„í‚¤í…ì²˜)\b",
            r"\b(?:í˜ì‹ |ë³€í™”|ì „í™˜|ê°œí˜|ë°œì „)\b",
        ]

        technical_count = 0
        for pattern in technical_patterns:
            technical_count += len(re.findall(pattern, query, re.IGNORECASE))

        factors["technical_terms"] = min(technical_count / 5.0, 2.0)

        # ë‹¤ì¤‘ ë„ë©”ì¸ ë³µì¡ì„±
        domain_keywords = {
            "ì •ì±…": ["ì •ì±…", "ì œë„", "ë²•", "ê·œì œ", "ì •ë¶€"],
            "ê¸°ìˆ ": ["ê¸°ìˆ ", "ì‹œìŠ¤í…œ", "AI", "ë””ì§€í„¸", "í”Œë«í¼"],
            "ì‚¬íšŒ": ["ì‚¬íšŒ", "ì§€ì—­", "ê³µë™ì²´", "ì‹œë¯¼", "ì£¼ë¯¼"],
            "ê²½ì œ": ["ê²½ì œ", "ì¬ì •", "ì˜ˆì‚°", "íˆ¬ì", "ë¹„ìš©"],
            "í™˜ê²½": ["í™˜ê²½", "ê¸°í›„", "ìƒíƒœ", "ì§€ì†ê°€ëŠ¥", "ë…¹ìƒ‰"],
        }

        detected_domains = 0
        for domain, keywords in domain_keywords.items():
            if any(keyword in query for keyword in keywords):
                detected_domains += 1

        factors["multiple_domains"] = min(detected_domains / 3.0, 2.0)

        # ì¡°ê±´ë¶€ ë…¼ë¦¬ ë³µì¡ì„±
        conditional_patterns = [
            r"\b(?:ë§Œì•½|ê°€ì •|ì¡°ê±´|ìƒí™©|ê²½ìš°)\b",
            r"\b(?:í•˜ì§€ë§Œ|ê·¸ëŸ¬ë‚˜|ë°˜ë©´|ë°˜ëŒ€ë¡œ)\b",
            r"\b(?:ë™ì‹œì—|ë³‘í–‰|í•¨ê»˜|ì—°ê³„)\b",
        ]

        conditional_count = 0
        for pattern in conditional_patterns:
            conditional_count += len(re.findall(pattern, query, re.IGNORECASE))

        factors["conditional_logic"] = min(conditional_count / 3.0, 2.0)

        # ì‹œê°„ì  ì°¸ì¡° ë³µì¡ì„±
        temporal_patterns = [
            r"\b(?:ê³¼ê±°|í˜„ì¬|ë¯¸ë˜|ì¥ê¸°|ë‹¨ê¸°)\b",
            r"\b(?:\d+ë…„|ë…„ë„|ì—°ê°„|ì›”ê°„)\b",
            r"\b(?:ì´ì „|ì´í›„|ë™ì•ˆ|ê¸°ê°„)\b",
        ]

        temporal_count = 0
        for pattern in temporal_patterns:
            temporal_count += len(re.findall(pattern, query, re.IGNORECASE))

        factors["temporal_references"] = min(temporal_count / 2.0, 2.0)

        # ì´í•´ê´€ê³„ì ë³µì¡ì„±
        stakeholder_patterns = [
            r"\b(?:ì´í•´ê´€ê³„ì|ê´€ë ¨ì|ë‹¹ì‚¬ì)\b",
            r"\b(?:ì •ë¶€|ê¸°ì—…|ì‹œë¯¼|ì „ë¬¸ê°€)\b",
            r"\b(?:í˜‘ë ¥|ì¡°ìœ¨|ê· í˜•|ê°ˆë“±)\b",
        ]

        stakeholder_count = 0
        for pattern in stakeholder_patterns:
            stakeholder_count += len(re.findall(pattern, query, re.IGNORECASE))

        factors["stakeholder_complexity"] = min(stakeholder_count / 3.0, 2.0)

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ë³µì¡ì„± ê³„ì‚°
        complexity_score = sum(
            factors[factor] * self.complexity_weights[factor] for factor in factors
        )

        return min(complexity_score * 5.0, 10.0)  # 0-10 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”

    def _assess_required_depth(
        self, query: str, context: Dict[str, Any] = None
    ) -> float:
        """í•„ìš”í•œ ì§€ì‹ ê¹Šì´ í‰ê°€"""
        base_depth = 3.0

        # ì¿¼ë¦¬ ê¸°ë°˜ ê¹Šì´ ìš”êµ¬ì‚¬í•­
        depth_indicators = {
            "ìƒì„¸": 2.0,
            "êµ¬ì²´ì ": 2.0,
            "ì„¸ë¶€": 2.0,
            "ìì„¸íˆ": 2.0,
            "ë¶„ì„": 2.5,
            "í‰ê°€": 2.5,
            "ê²€í† ": 2.0,
            "ì—°êµ¬": 3.0,
            "ì „ë¬¸": 3.0,
            "ê³ ê¸‰": 2.5,
            "ì‹¬í™”": 2.5,
            "ê¹Šì´": 2.0,
            "ì¢…í•©": 2.0,
            "ì²´ê³„ì ": 2.0,
            "í¬ê´„ì ": 2.5,
            "ì „ë©´ì ": 3.0,
        }

        for indicator, depth_boost in depth_indicators.items():
            if indicator in query:
                base_depth += depth_boost

        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¡°ì •
        if context:
            urgency = context.get("urgency", "medium")
            detail_level = context.get("detail_level", "standard")

            if urgency == "high":
                base_depth += 1.0
            if detail_level == "comprehensive":
                base_depth += 2.0
            elif detail_level == "detailed":
                base_depth += 1.0

        # ì§ˆë¬¸ ë³µì¡ì„±ì— ë”°ë¥¸ ì¡°ì •
        question_complexity_patterns = [
            (r"ì–´ë–»ê²Œ.*í•´ì•¼.*\?", 2.0),  # How-to ì§ˆë¬¸
            (r"ì™œ.*ì¸ê°€.*\?", 1.5),  # Why ì§ˆë¬¸
            (r".*ë°©ë²•.*\?", 1.5),  # ë°©ë²• ì§ˆë¬¸
            (r".*ë¹„êµ.*\?", 2.0),  # ë¹„êµ ì§ˆë¬¸
            (r".*í‰ê°€.*\?", 2.5),  # í‰ê°€ ì§ˆë¬¸
            (r".*ì˜ˆì¸¡.*\?", 3.0),  # ì˜ˆì¸¡ ì§ˆë¬¸
        ]

        for pattern, depth_boost in question_complexity_patterns:
            if re.search(pattern, query):
                base_depth += depth_boost
                break

        return min(base_depth, 10.0)

    def _evaluate_signature_match(self, query: str, signature: str) -> float:
        """ì‹œê·¸ë‹ˆì²˜ì™€ ì¿¼ë¦¬ì˜ ì „ë¬¸ì„± ë§¤ì¹­ í‰ê°€"""
        if signature not in self.signature_expertise:
            return 0.5  # ì•Œ ìˆ˜ ì—†ëŠ” ì‹œê·¸ë‹ˆì²˜

        expertise = self.signature_expertise[signature]

        # ê°•ì  ì˜ì—­ ë§¤ì¹­
        strong_match = 0
        for area in expertise["strong_areas"]:
            if area in query.lower():
                strong_match += 1

        # ì¤‘ê°„ ì˜ì—­ ë§¤ì¹­
        medium_match = 0
        for area in expertise["medium_areas"]:
            if area in query.lower():
                medium_match += 1

        # ì•½ì  ì˜ì—­ ë§¤ì¹­ (ì—­ì‚°)
        weak_match = 0
        for area in expertise["weak_areas"]:
            if area in query.lower():
                weak_match += 1

        # ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (0.0 - 1.0)
        match_score = (strong_match * 1.0 + medium_match * 0.6 - weak_match * 0.8) / 3.0

        return max(0.0, min(1.0, match_score + 0.3))  # ê¸°ë³¸ 0.3 + ë§¤ì¹­ ë³´ë„ˆìŠ¤

    def _analyze_domain_coverage(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ì˜ ë„ë©”ì¸ ì»¤ë²„ë¦¬ì§€ ë¶„ì„"""
        domain_patterns = {
            "ì •ì±…ë¶„ì„": r"\b(?:ì •ì±…|ì œë„|ë²•ë¥ |ê·œì œ|ì •ë¶€|í–‰ì •)\b",
            "ê¸°ìˆ í˜ì‹ ": r"\b(?:ê¸°ìˆ |í˜ì‹ |AI|ë””ì§€í„¸|ì‹œìŠ¤í…œ|í”Œë«í¼)\b",
            "ì‚¬íšŒë¬¸ì œ": r"\b(?:ì‚¬íšŒ|ì§€ì—­|ê³µë™ì²´|ì‹œë¯¼|ì£¼ë¯¼|ë³µì§€)\b",
            "ê²½ì œë¶„ì•¼": r"\b(?:ê²½ì œ|ì¬ì •|ì˜ˆì‚°|íˆ¬ì|ë¹„ìš©|ê²½ì˜)\b",
            "í™˜ê²½ì´ìŠˆ": r"\b(?:í™˜ê²½|ê¸°í›„|ìƒíƒœ|ì§€ì†ê°€ëŠ¥|ë…¹ìƒ‰|íƒ„ì†Œ)\b",
            "êµìœ¡ë¬¸í™”": r"\b(?:êµìœ¡|ë¬¸í™”|ì˜ˆìˆ |í•™ìŠµ|êµìœ¡ê³¼ì •)\b",
            "ê±´ê°•ì˜ë£Œ": r"\b(?:ê±´ê°•|ì˜ë£Œ|ë³‘ì›|ì¹˜ë£Œ|ì˜ˆë°©|ì§ˆë³‘)\b",
            "ì¸ê°„ê´€ê³„": r"\b(?:ê´€ê³„|ì†Œí†µ|ê°ˆë“±|í˜‘ë ¥|ê³µê°|ìƒë‹´)\b",
        }

        detected_domains = []
        for domain, pattern in domain_patterns.items():
            if re.search(pattern, query, re.IGNORECASE):
                detected_domains.append(domain)

        return detected_domains

    def _identify_specific_gaps(
        self, query: str, confidence: float, signature: str, assessment: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """êµ¬ì²´ì  ì§€ì‹ ê²©ì°¨ ì‹ë³„"""
        gaps = []

        # 1. ì‹ ë¢°ë„ ê¸°ë°˜ ê²©ì°¨
        if confidence < self.thresholds["confidence_low"]:
            gaps.append(
                {
                    "type": "confidence_gap",
                    "severity": "high" if confidence < 0.2 else "medium",
                    "description": f"í˜„ì¬ ì‹ ë¢°ë„({confidence:.2f})ê°€ ë‚®ì•„ ì¶”ê°€ ì§€ì‹ì´ í•„ìš”í•¨",
                    "recommended_action": "deep_lookup",
                }
            )

        # 2. ë³µì¡ì„± ê¸°ë°˜ ê²©ì°¨
        if assessment["query_complexity"] > self.thresholds["complexity_high"]:
            gaps.append(
                {
                    "type": "complexity_gap",
                    "severity": (
                        "high" if assessment["query_complexity"] > 8.5 else "medium"
                    ),
                    "description": f"ì¿¼ë¦¬ ë³µì¡ì„±({assessment['query_complexity']:.1f})ì´ ë†’ì•„ ì „ë¬¸ ì§€ì‹ í•„ìš”",
                    "recommended_action": "deep_lookup",
                }
            )

        # 3. ì‹œê·¸ë‹ˆì²˜ ì „ë¬¸ì„± ê²©ì°¨
        if assessment["signature_expertise_match"] < self.thresholds["expertise_gap"]:
            gaps.append(
                {
                    "type": "expertise_gap",
                    "severity": "medium",
                    "description": f"{signature}ì˜ ì „ë¬¸ ì˜ì—­ê³¼ ë¶ˆì¼ì¹˜",
                    "recommended_action": "signature_switch_or_deep_lookup",
                }
            )

        # 4. ê¹Šì´ ìš”êµ¬ì‚¬í•­ ê²©ì°¨
        if (
            assessment["knowledge_depth_required"]
            > self.thresholds["depth_requirement"]
        ):
            gaps.append(
                {
                    "type": "depth_gap",
                    "severity": "high",
                    "description": f"ìš”êµ¬ë˜ëŠ” ì§€ì‹ ê¹Šì´({assessment['knowledge_depth_required']:.1f})ê°€ ë†’ìŒ",
                    "recommended_action": "deep_lookup",
                }
            )

        # 5. ë„ë©”ì¸ë³„ íŠ¹ìˆ˜ ê²©ì°¨
        domains = assessment["domain_coverage"]
        high_depth_domains = ["ì •ì±…ë¶„ì„", "ê¸°ìˆ í˜ì‹ ", "ê²½ì œë¶„ì•¼", "ê±´ê°•ì˜ë£Œ"]

        for domain in domains:
            if domain in high_depth_domains:
                gaps.append(
                    {
                        "type": "domain_gap",
                        "severity": "medium",
                        "description": f"{domain} ì˜ì—­ì˜ ì „ë¬¸ ì§€ì‹ ë¶€ì¡± ê°€ëŠ¥",
                        "recommended_action": "deep_lookup",
                        "domain": domain,
                    }
                )

        return gaps

    def _make_deep_lookup_decision(self, assessment: Dict[str, Any]) -> Dict[str, Any]:
        """Deep lookup í•„ìš”ì„± ìµœì¢… ê²°ì •"""
        gaps = assessment["identified_gaps"]

        # ê²°ì • ìš”ì¸ë“¤
        high_severity_gaps = len([g for g in gaps if g["severity"] == "high"])
        medium_severity_gaps = len([g for g in gaps if g["severity"] == "medium"])
        total_gaps = len(gaps)

        confidence = assessment["current_confidence"]
        complexity = assessment["query_complexity"]
        depth_required = assessment["knowledge_depth_required"]
        expertise_match = assessment["signature_expertise_match"]

        # ê²°ì • ë¡œì§
        needs_deep_lookup = False
        lookup_type = None
        gap_severity = "none"
        decision_reasons = []

        # ê³ ì‹¬ë„ ê²©ì°¨ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ deep lookup
        if high_severity_gaps > 0:
            needs_deep_lookup = True
            gap_severity = "high"
            decision_reasons.append(f"ê³ ì‹¬ë„ ê²©ì°¨ {high_severity_gaps}ê°œ ë°œê²¬")

        # ì¤‘ê°„ ì‹¬ë„ ê²©ì°¨ê°€ 2ê°œ ì´ìƒì´ë©´ deep lookup
        elif medium_severity_gaps >= 2:
            needs_deep_lookup = True
            gap_severity = "medium"
            decision_reasons.append(f"ì¤‘ê°„ì‹¬ë„ ê²©ì°¨ {medium_severity_gaps}ê°œ ëˆ„ì ")

        # ë³µí•© ì¡°ê±´ ì²´í¬
        elif (confidence < 0.3 and complexity > 8.0) or depth_required > 8.5:
            needs_deep_lookup = True
            gap_severity = "medium"
            decision_reasons.append("ì‹ ë¢°ë„-ë³µì¡ì„± ë˜ëŠ” ê¹Šì´ ìš”êµ¬ì‚¬í•­ ì´ˆê³¼")

        # ì „ë¬¸ì„± ë¶ˆì¼ì¹˜ê°€ ì‹¬í•˜ê³  ë³µì¡ì„±ì´ ë†’ìœ¼ë©´
        elif expertise_match < 0.4 and complexity > 7.0:
            needs_deep_lookup = True
            gap_severity = "medium"
            decision_reasons.append("ì „ë¬¸ì„± ë¶ˆì¼ì¹˜ + ë†’ì€ ë³µì¡ì„±")

        # Deep lookup ìœ í˜• ê²°ì •
        if needs_deep_lookup:
            lookup_type = self._determine_lookup_type(assessment)
            self.gap_detection_stats["deep_lookup_recommended"] += 1

        if total_gaps > 0:
            self.gap_detection_stats["gaps_detected"] += 1

        return {
            "needs_deep_lookup": needs_deep_lookup,
            "recommended_lookup_type": lookup_type,
            "gap_severity": gap_severity,
            "decision_reasons": decision_reasons,
            "total_gaps_identified": total_gaps,
            "high_severity_gaps": high_severity_gaps,
            "medium_severity_gaps": medium_severity_gaps,
        }

    def _determine_lookup_type(self, assessment: Dict[str, Any]) -> str:
        """Deep lookup ìœ í˜• ê²°ì •"""
        domains = assessment["domain_coverage"]
        signature = assessment["signature"]
        query = assessment["query"]

        # ë„ë©”ì¸ ê¸°ë°˜ ìš°ì„  ê²°ì •
        if "ì •ì±…ë¶„ì„" in domains:
            return "policy_analysis"
        elif "ê¸°ìˆ í˜ì‹ " in domains:
            return "innovation_trends"
        elif "ì‚¬íšŒë¬¸ì œ" in domains and "ì¸ê°„ê´€ê³„" in domains:
            return "care_guidance"
        elif "êµìœ¡ë¬¸í™”" in domains:
            return "creative_inspiration"
        elif "ê²½ì œë¶„ì•¼" in domains:
            return "economic_analysis"
        elif "ê±´ê°•ì˜ë£Œ" in domains:
            return "medical_consultation"

        # ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ ë³´ì¡° ê²°ì •
        signature_preferences = {
            "Echo-Sage": "policy_analysis",
            "Echo-Phoenix": "innovation_trends",
            "Echo-Companion": "care_guidance",
            "Echo-Aurora": "creative_inspiration",
        }

        if signature in signature_preferences:
            return signature_preferences[signature]

        # ì¿¼ë¦¬ íŒ¨í„´ ê¸°ë°˜ ë§ˆì§€ë§‰ ê²°ì •
        if any(word in query.lower() for word in ["ë¶„ì„", "í‰ê°€", "ì •ì±…"]):
            return "policy_analysis"
        elif any(word in query.lower() for word in ["í˜ì‹ ", "ê¸°ìˆ ", "ë¯¸ë˜"]):
            return "innovation_trends"
        elif any(word in query.lower() for word in ["ë„ì›€", "ìƒë‹´", "ì§€ì›"]):
            return "care_guidance"
        else:
            return "general_knowledge"

    def _update_assessment_stats(self, assessment: Dict[str, Any]):
        """í‰ê°€ í†µê³„ ì—…ë°ì´íŠ¸"""
        stats = self.gap_detection_stats

        # í‰ê·  ë³µì¡ì„± ì ìˆ˜ ì—…ë°ì´íŠ¸
        total = stats["total_assessments"]
        current_avg_complexity = stats["avg_complexity_score"]
        new_complexity = assessment["query_complexity"]

        stats["avg_complexity_score"] = (
            current_avg_complexity * (total - 1) + new_complexity
        ) / total

        # í‰ê·  ì‹ ë¢°ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸
        current_avg_confidence = stats["avg_confidence_score"]
        new_confidence = assessment["current_confidence"]

        stats["avg_confidence_score"] = (
            current_avg_confidence * (total - 1) + new_confidence
        ) / total

        # ì‹œê·¸ë‹ˆì²˜ ë¶ˆì¼ì¹˜ ì¹´ìš´íŠ¸
        if assessment["signature_expertise_match"] < 0.5:
            stats["signature_mismatches"] += 1

    def get_gap_detection_stats(self) -> Dict[str, Any]:
        """ê²©ì°¨ ê°ì§€ í†µê³„ ë°˜í™˜"""
        stats = self.gap_detection_stats.copy()

        total = stats["total_assessments"]
        if total > 0:
            stats["gap_detection_rate"] = (
                f"{(stats['gaps_detected'] / total) * 100:.1f}%"
            )
            stats["deep_lookup_rate"] = (
                f"{(stats['deep_lookup_recommended'] / total) * 100:.1f}%"
            )
            stats["signature_mismatch_rate"] = (
                f"{(stats['signature_mismatches'] / total) * 100:.1f}%"
            )

        return stats

    def recommend_signature_for_query(self, query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ì— ìµœì ì¸ ì‹œê·¸ë‹ˆì²˜ ì¶”ì²œ"""
        signature_scores = {}

        for signature in self.signature_expertise:
            match_score = self._evaluate_signature_match(query, signature)
            signature_scores[signature] = match_score

        best_signature = max(signature_scores.keys(), key=lambda x: signature_scores[x])

        return {
            "recommended_signature": best_signature,
            "confidence": signature_scores[best_signature],
            "all_scores": signature_scores,
            "reason": f"{best_signature}ê°€ í•´ë‹¹ ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ì „ë¬¸ì„±ì„ ë³´ìœ ",
        }


# ì „ì—­ ê°ì§€ê¸° ì¸ìŠ¤í„´ìŠ¤
knowledge_gap_detector = EchoKnowledgeGapDetector()


# í¸ì˜ í•¨ìˆ˜ë“¤
def assess_knowledge_gap(
    query: str,
    confidence: float,
    signature: str = "Echo-Aurora",
    context: Dict[str, Any] = None,
) -> Dict[str, Any]:
    """ì§€ì‹ ê²©ì°¨ í‰ê°€ ë‹¨ì¶• í•¨ìˆ˜"""
    return knowledge_gap_detector.assess_knowledge_boundary(
        query, confidence, signature, context
    )


def recommend_signature(query: str) -> Dict[str, Any]:
    """ì‹œê·¸ë‹ˆì²˜ ì¶”ì²œ ë‹¨ì¶• í•¨ìˆ˜"""
    return knowledge_gap_detector.recommend_signature_for_query(query)


def get_gap_stats() -> Dict[str, Any]:
    """ê²©ì°¨ ê°ì§€ í†µê³„ ë‹¨ì¶• í•¨ìˆ˜"""
    return knowledge_gap_detector.get_gap_detection_stats()


# CLI í…ŒìŠ¤íŠ¸
def main():
    print("ğŸ§  Echo Knowledge Gap Detector í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "query": "ë¶€ì‚°ì‹œ ê¸ˆì •êµ¬ì˜ ë…¸ì¸ ëŒë´„ ì •ì±… í˜„í™©ì„ ìƒì„¸íˆ ë¶„ì„í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”",
            "confidence": 0.3,
            "signature": "Echo-Sage",
            "context": {"urgency": "high", "detail_level": "comprehensive"},
        },
        {
            "query": "AI ê¸°ìˆ ì˜ ìœ¤ë¦¬ì  ì ìš©ì„ ìœ„í•œ ê¸€ë¡œë²Œ íŠ¸ë Œë“œì™€ í•œêµ­ ì •ë¶€ì˜ ëŒ€ì‘ ì „ëµì€?",
            "confidence": 0.2,
            "signature": "Echo-Phoenix",
            "context": {"focus": "policy", "timeframe": "2024-2026"},
        },
        {
            "query": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”",
            "confidence": 0.9,
            "signature": "Echo-Aurora",
            "context": None,
        },
        {
            "query": "ì°½ì˜ì ì¸ ì§€ì—­ì‚¬íšŒ ì°¸ì—¬ í”„ë¡œê·¸ë¨ ì•„ì´ë””ì–´ë¥¼ ëª‡ ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”",
            "confidence": 0.6,
            "signature": "Echo-Aurora",
            "context": {"creativity_level": "medium"},
        },
        {
            "query": "ë³µì¡í•œ ë‹¤ë©´ì  ì •ì±… í™˜ê²½ì—ì„œ ì´í•´ê´€ê³„ì ê°„ ê°ˆë“± ì¡°ì • ë°©ë²•ë¡ ",
            "confidence": 0.1,
            "signature": "Echo-Companion",
            "context": {"complexity": "very_high"},
        },
    ]

    print("\nğŸ” ì§€ì‹ ê²©ì°¨ ê°ì§€ í…ŒìŠ¤íŠ¸:")

    for i, case in enumerate(test_cases, 1):
        print(f"\n{'='*50}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {case['signature']}")
        print(f"ì¿¼ë¦¬: {case['query'][:60]}...")
        print(f"í˜„ì¬ ì‹ ë¢°ë„: {case['confidence']:.2f}")
        print(f"{'='*50}")

        assessment = knowledge_gap_detector.assess_knowledge_boundary(
            case["query"], case["confidence"], case["signature"], case["context"]
        )

        print(f"ğŸ“Š í‰ê°€ ê²°ê³¼:")
        print(f"   ë³µì¡ì„± ì ìˆ˜: {assessment['query_complexity']:.1f}/10")
        print(f"   ê¹Šì´ ìš”êµ¬: {assessment['knowledge_depth_required']:.1f}/10")
        print(f"   ì „ë¬¸ì„± ë§¤ì¹­: {assessment['signature_expertise_match']:.2f}")
        print(f"   ë„ë©”ì¸: {', '.join(assessment['domain_coverage'])}")
        print(f"   ê°ì§€ëœ ê²©ì°¨: {len(assessment['identified_gaps'])}ê°œ")

        print(f"ğŸ¯ ìµœì¢… íŒë‹¨:")
        print(
            f"   Deep Lookup í•„ìš”: {'ì˜ˆ' if assessment['needs_deep_lookup'] else 'ì•„ë‹ˆì˜¤'}"
        )
        if assessment["needs_deep_lookup"]:
            print(f"   ì¶”ì²œ ìœ í˜•: {assessment['recommended_lookup_type']}")
            print(f"   ê²©ì°¨ ì‹¬ê°ë„: {assessment['gap_severity']}")
            print(f"   ê²°ì • ì´ìœ : {', '.join(assessment['decision_reasons'])}")

    # ì‹œê·¸ë‹ˆì²˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ­ ì‹œê·¸ë‹ˆì²˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸:")
    recommendation_queries = [
        "ì •ì±… ë¶„ì„ê³¼ ë°ì´í„° í•´ì„ì´ í•„ìš”í•œ ë³µì¡í•œ ë¬¸ì œ",
        "ì°½ì˜ì  ì•„ì´ë””ì–´ì™€ ì˜ê°ì´ í•„ìš”í•œ í”„ë¡œì íŠ¸",
        "ê°œì¸ì  ê³ ë¯¼ê³¼ ê°ì •ì  ì§€ì§€ê°€ í•„ìš”í•œ ìƒí™©",
    ]

    for query in recommendation_queries:
        rec = knowledge_gap_detector.recommend_signature_for_query(query)
        print(f"   '{query[:40]}...'")
        print(
            f"   â†’ ì¶”ì²œ: {rec['recommended_signature']} (ì‹ ë¢°ë„: {rec['confidence']:.2f})"
        )

    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š ê²©ì°¨ ê°ì§€ í†µê³„:")
    stats = knowledge_gap_detector.get_gap_detection_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")

    print("\nâœ… Echo Knowledge Gap Detector í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
