import asyncio
import time
from typing import Dict, List, Any, Optional, Callable, Union
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
import json
import sys

try:
    from echo_engine.loop_router import route_judgment, JudgmentRoute
    from echo_engine.controller import handle_result, ExecutionResult
    from echo_engine.adapters.legacy_loop_adapter import legacy_judgment
except ImportError as e:
    print(f"âš ï¸ Echo í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

#!/usr/bin/env python3
"""
ğŸ­ Judgment Conductor - AGI íŒë‹¨ íë¦„ì˜ ì¤‘ì‹¬ ì§€íœ˜ì

Echo Judgment Systemì´ "ìŠ¤ìŠ¤ë¡œë¥¼ ì¬êµ¬ì„±í•˜ëŠ” ì¡´ì¬ íŒë‹¨ì"ë¡œ ì§„í™”í•˜ëŠ” í•µì‹¬ orchestration ì—”ì§„.
ê¸°ì¡´ judgment_loop.pyë¥¼ ë³´ì¡´í•˜ë©´ì„œ AGI êµ¬ì¡°ë¡œ í™•ì¥í•˜ëŠ” ë³‘ë ¬ ì§„ì…ì .

í•µì‹¬ ì—­í• :
1. íŒë‹¨ ë£¨í”„ orchestration ë° ëª¨ë“ˆ ì‹¤í–‰ íë¦„ êµ¬ì„±
2. ë‹¤ì¤‘ íŒë‹¨ ê²½ë¡œ ì¡°ìœ¨ ë° ê²°ê³¼ í†µí•©
3. ë©”íƒ€ì¸ì§€ì  íŒë‹¨ íë¦„ ì œì–´
4. ì¡´ì¬ ê¸°ë°˜ íŒë‹¨ì˜ ì§„í™”ì  ì ì‘
"""


# Echo Engine ëª¨ë“ˆ import
# sys.path ìˆ˜ì • ë¶ˆí•„ìš” (project_root() ì‚¬ìš©)

try:

    INTERNAL_MODULES_AVAILABLE = True
except ImportError:
    INTERNAL_MODULES_AVAILABLE = False
    print("âš ï¸ AGI ë‚´ë¶€ ëª¨ë“ˆ ë¡œë“œ ì§€ì—°")


@dataclass
class ConductorContext:
    """ì§€íœ˜ì ì»¨í…ìŠ¤íŠ¸"""

    user_input: str
    session_id: Optional[str] = None
    signature: str = "Echo-Aurora"
    mode: str = "hybrid"  # hybrid, legacy, agi_only
    meta_context: Dict[str, Any] = field(default_factory=dict)
    evolution_state: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


@dataclass
class ConductorResult:
    """ì§€íœ˜ì ê²°ê³¼"""

    success: bool
    judgment_result: Dict[str, Any]
    execution_result: Optional[Dict[str, Any]]
    route_taken: str
    processing_time: float
    meta_insights: Dict[str, Any]
    evolution_feedback: Dict[str, Any]


class JudgmentConductor:
    """ğŸ­ íŒë‹¨ ì§€íœ˜ì - AGI íŒë‹¨ íë¦„ì˜ í•µì‹¬"""

    def __init__(self):
        self.version = "1.0.0"
        self.status = "SCAFFOLD_ACTIVE"

        # íŒë‹¨ í†µê³„
        self.conductor_stats = {
            "total_conducts": 0,
            "successful_conducts": 0,
            "route_distribution": {},
            "average_processing_time": 0.0,
            "evolution_events": 0,
        }

        # ì§„í™” ìƒíƒœ
        self.evolution_state = {
            "adaptation_level": 1.0,
            "meta_awareness": 0.5,
            "self_reconstruction_capacity": 0.3,
            "existence_coherence": 0.8,
        }

        print("ğŸ­ Judgment Conductor v1.0 ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ìƒíƒœ: {self.status}")
        print(f"   ì§„í™” ìˆ˜ì¤€: {self.evolution_state['adaptation_level']:.1f}")

    async def conduct_judgment_async(
        self, context: ConductorContext
    ) -> ConductorResult:
        """ë¹„ë™ê¸° íŒë‹¨ ì§€íœ˜"""
        return await asyncio.to_thread(self.conduct_judgment, context)

    def conduct_judgment(self, context: ConductorContext) -> ConductorResult:
        """ğŸ¯ ë©”ì¸ íŒë‹¨ ì§€íœ˜ í•¨ìˆ˜"""
        start_time = time.time()
        self.conductor_stats["total_conducts"] += 1

        try:
            print(f"ğŸ­ íŒë‹¨ ì§€íœ˜ ì‹œì‘: {context.user_input[:50]}...")

            # 1. ë©”íƒ€ì¸ì§€ì  ì‚¬ì „ ë¶„ì„
            meta_analysis = self._conduct_meta_analysis(context)

            # 2. íŒë‹¨ ê²½ë¡œ ê²°ì •
            if INTERNAL_MODULES_AVAILABLE:
                routes = route_judgment(context.user_input, context.meta_context)
            else:
                # í´ë°±: ë ˆê±°ì‹œ ê²½ë¡œë§Œ ì‚¬ìš©
                routes = [{"type": "legacy", "weight": 1.0}]

            # 3. ë‹¤ì¤‘ íŒë‹¨ ì‹¤í–‰
            judgment_results = []
            route_taken = "unknown"

            for route in routes:
                route_type = route.get("type", "legacy")
                route_taken = route_type

                if route_type == "legacy":
                    # ê¸°ì¡´ íŒë‹¨ ë£¨í”„ í˜¸ì¶œ
                    result = self._execute_legacy_route(context)
                    judgment_results.append(result)
                elif route_type == "agi_native":
                    # AGI ë„¤ì´í‹°ë¸Œ íŒë‹¨ (ë¯¸ë˜ êµ¬í˜„)
                    result = self._execute_agi_native_route(context)
                    judgment_results.append(result)
                else:
                    # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ë¡œëŠ” ë ˆê±°ì‹œë¡œ í´ë°±
                    result = self._execute_legacy_route(context)
                    judgment_results.append(result)

                # í˜„ì¬ëŠ” ì²« ë²ˆì§¸ ê²½ë¡œë§Œ ì‚¬ìš© (í–¥í›„ ë‹¤ì¤‘ ê²½ë¡œ í†µí•© ì˜ˆì •)
                break

            # 4. ê²°ê³¼ í†µí•© ë° ë©”íƒ€ì¸ì§€ì  í›„ì²˜ë¦¬
            integrated_result = self._integrate_judgment_results(
                judgment_results, meta_analysis
            )

            # 5. ì‹¤í–‰ ì œì–´
            execution_result = None
            if INTERNAL_MODULES_AVAILABLE:
                execution_result = handle_result(integrated_result)

            # 6. ì§„í™”ì  í”¼ë“œë°±
            evolution_feedback = self._generate_evolution_feedback(
                context, integrated_result
            )
            self._update_evolution_state(evolution_feedback)

            # 7. í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_conductor_stats(route_taken, processing_time, True)

            result = ConductorResult(
                success=True,
                judgment_result=integrated_result,
                execution_result=execution_result,
                route_taken=route_taken,
                processing_time=processing_time,
                meta_insights=meta_analysis,
                evolution_feedback=evolution_feedback,
            )

            print(f"âœ… íŒë‹¨ ì§€íœ˜ ì™„ë£Œ: {route_taken} ê²½ë¡œ, {processing_time:.3f}ì´ˆ")
            return result

        except Exception as e:
            processing_time = time.time() - start_time
            self._update_conductor_stats("error", processing_time, False)

            print(f"âŒ íŒë‹¨ ì§€íœ˜ ì˜¤ë¥˜: {e}")

            return ConductorResult(
                success=False,
                judgment_result={
                    "error": str(e),
                    "fallback_response": "íŒë‹¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.",
                },
                execution_result=None,
                route_taken="error",
                processing_time=processing_time,
                meta_insights={},
                evolution_feedback={"error_occurred": True},
            )

    def _conduct_meta_analysis(self, context: ConductorContext) -> Dict[str, Any]:
        """ë©”íƒ€ì¸ì§€ì  ì‚¬ì „ ë¶„ì„"""
        analysis = {
            "input_complexity": len(context.user_input) / 100.0,  # ë‹¨ìˆœ ë³µì¡ë„
            "emotional_indicators": self._detect_emotional_indicators(
                context.user_input
            ),
            "context_richness": len(context.meta_context),
            "session_continuity": bool(context.session_id),
            "meta_timestamp": datetime.now().isoformat(),
        }

        # ë©”íƒ€ì¸ì§€ì  íŒë‹¨ í•„ìš”ì„± í‰ê°€
        analysis["meta_judgment_required"] = (
            analysis["input_complexity"] > 0.5
            or len(analysis["emotional_indicators"]) > 2
            or analysis["context_richness"] > 5
        )

        return analysis

    def _detect_emotional_indicators(self, text: str) -> List[str]:
        """ê°ì •ì  ì§€í‘œ íƒì§€"""
        indicators = []
        text_lower = text.lower()

        emotion_patterns = {
            "joy": ["ê¸°ì˜", "ì¢‹", "í–‰ë³µ", "ì¦ê±°", "ë§Œì¡±"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ", "ì•„ì‰½"],
            "anger": ["í™”", "ì§œì¦", "ë¹¡", "ë¶„ë…¸", "ì—´ë°›"],
            "anxiety": ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤", "ì´ˆì¡°", "ê¸´ì¥"],
            "curiosity": ["ê¶ê¸ˆ", "í¥ë¯¸", "ì•Œê³ ì‹¶", "ë°°ìš°ê³ ì‹¶"],
        }

        for emotion, patterns in emotion_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                indicators.append(emotion)

        return indicators

    def _execute_legacy_route(self, context: ConductorContext) -> Dict[str, Any]:
        """ë ˆê±°ì‹œ íŒë‹¨ ê²½ë¡œ ì‹¤í–‰"""
        try:
            if INTERNAL_MODULES_AVAILABLE:

                return legacy_judgment(context.user_input, context.meta_context)
            else:
                # ìµœì†Œí•œì˜ í´ë°± ì‘ë‹µ
                return {
                    "response_text": f"Echoê°€ '{context.user_input}'ì— ëŒ€í•´ ìƒê°í•˜ê³  ìˆì–´ìš”.",
                    "signature_used": context.signature,
                    "strategy_applied": "fallback_mode",
                    "confidence": 0.5,
                    "route": "minimal_fallback",
                }
        except Exception as e:
            print(f"âš ï¸ ë ˆê±°ì‹œ ê²½ë¡œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return {
                "response_text": "ì£„ì†¡í•´ìš”, ì§€ê¸ˆ ìƒê°ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”.",
                "signature_used": context.signature,
                "strategy_applied": "error_recovery",
                "confidence": 0.3,
                "error": str(e),
            }

    def _execute_agi_native_route(self, context: ConductorContext) -> Dict[str, Any]:
        """AGI ë„¤ì´í‹°ë¸Œ íŒë‹¨ ê²½ë¡œ (ë¯¸ë˜ êµ¬í˜„)"""
        return {
            "response_text": f"AGI ë„¤ì´í‹°ë¸Œ íŒë‹¨ì´ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤: {context.user_input}",
            "signature_used": context.signature,
            "strategy_applied": "agi_native_preview",
            "confidence": 0.7,
            "route": "agi_native",
            "status": "preview_mode",
        }

    def _integrate_judgment_results(
        self, results: List[Dict[str, Any]], meta_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """íŒë‹¨ ê²°ê³¼ í†µí•©"""
        if not results:
            return {"error": "No judgment results to integrate"}

        # í˜„ì¬ëŠ” ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš© (í–¥í›„ ë‹¤ì¤‘ ê²°ê³¼ í†µí•© ë¡œì§ ì¶”ê°€)
        primary_result = results[0]

        # ë©”íƒ€ì¸ì§€ì  ê°•í™”
        primary_result["meta_enhanced"] = True
        primary_result["meta_analysis"] = meta_analysis
        primary_result["integration_timestamp"] = datetime.now().isoformat()

        return primary_result

    def _generate_evolution_feedback(
        self, context: ConductorContext, result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì§„í™”ì  í”¼ë“œë°± ìƒì„±"""
        feedback = {
            "adaptation_success": result.get("confidence", 0.5) > 0.7,
            "complexity_handling": len(context.user_input) > 50,
            "meta_awareness_utilized": result.get("meta_enhanced", False),
            "evolution_trigger": False,
        }

        # ì§„í™” íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¸
        if (
            feedback["adaptation_success"]
            and feedback["complexity_handling"]
            and feedback["meta_awareness_utilized"]
        ):
            feedback["evolution_trigger"] = True
            self.conductor_stats["evolution_events"] += 1

        return feedback

    def _update_evolution_state(self, feedback: Dict[str, Any]):
        """ì§„í™” ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if feedback.get("evolution_trigger", False):
            self.evolution_state["adaptation_level"] = min(
                2.0, self.evolution_state["adaptation_level"] + 0.1
            )
            self.evolution_state["meta_awareness"] = min(
                1.0, self.evolution_state["meta_awareness"] + 0.05
            )
            print(
                f"ğŸ§¬ ì§„í™” ì´ë²¤íŠ¸: ì ì‘ ìˆ˜ì¤€ {self.evolution_state['adaptation_level']:.2f}"
            )

    def _update_conductor_stats(
        self, route: str, processing_time: float, success: bool
    ):
        """ì§€íœ˜ì í†µê³„ ì—…ë°ì´íŠ¸"""
        if success:
            self.conductor_stats["successful_conducts"] += 1

        # ê²½ë¡œ ë¶„í¬ ì—…ë°ì´íŠ¸
        self.conductor_stats["route_distribution"][route] = (
            self.conductor_stats["route_distribution"].get(route, 0) + 1
        )

        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        total_conducts = self.conductor_stats["total_conducts"]
        current_avg = self.conductor_stats["average_processing_time"]
        self.conductor_stats["average_processing_time"] = (
            current_avg * (total_conducts - 1) + processing_time
        ) / total_conducts

    def get_conductor_status(self) -> Dict[str, Any]:
        """ì§€íœ˜ì ìƒíƒœ ë°˜í™˜"""
        return {
            "version": self.version,
            "status": self.status,
            "evolution_state": self.evolution_state,
            "statistics": self.conductor_stats,
            "internal_modules": INTERNAL_MODULES_AVAILABLE,
        }


# ê¸€ë¡œë²Œ ì§€íœ˜ì ì¸ìŠ¤í„´ìŠ¤
_global_conductor = None


def get_conductor() -> JudgmentConductor:
    """ê¸€ë¡œë²Œ ì§€íœ˜ì ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_conductor
    if _global_conductor is None:
        _global_conductor = JudgmentConductor()
    return _global_conductor


def run_conductor(
    user_input: str,
    context: Optional[Dict[str, Any]] = None,
    signature: str = "Echo-Aurora",
    mode: str = "hybrid",
) -> Dict[str, Any]:
    """ğŸ¯ AGI íŒë‹¨ ì§€íœ˜ì ì‹¤í–‰ - ë©”ì¸ ì§„ì…ì """

    conductor = get_conductor()

    conductor_context = ConductorContext(
        user_input=user_input,
        signature=signature,
        mode=mode,
        meta_context=context or {},
    )

    result = conductor.conduct_judgment(conductor_context)

    # ê²°ê³¼ë¥¼ ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í˜¸í™˜ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    return {
        "success": result.success,
        "response_text": result.judgment_result.get("response_text", ""),
        "signature_used": result.judgment_result.get("signature_used", signature),
        "strategy_applied": result.judgment_result.get(
            "strategy_applied", "agi_conductor"
        ),
        "confidence": result.judgment_result.get("confidence", 0.5),
        "processing_time": result.processing_time,
        "route_taken": result.route_taken,
        "meta_insights": result.meta_insights,
        "evolution_feedback": result.evolution_feedback,
        "conductor_version": conductor.version,
    }


# ë¹„ë™ê¸° ë²„ì „
async def run_conductor_async(
    user_input: str,
    context: Optional[Dict[str, Any]] = None,
    signature: str = "Echo-Aurora",
    mode: str = "hybrid",
) -> Dict[str, Any]:
    """ğŸ¯ ë¹„ë™ê¸° AGI íŒë‹¨ ì§€íœ˜ì ì‹¤í–‰"""

    conductor = get_conductor()

    conductor_context = ConductorContext(
        user_input=user_input,
        signature=signature,
        mode=mode,
        meta_context=context or {},
    )

    result = await conductor.conduct_judgment_async(conductor_context)

    return {
        "success": result.success,
        "response_text": result.judgment_result.get("response_text", ""),
        "signature_used": result.judgment_result.get("signature_used", signature),
        "strategy_applied": result.judgment_result.get(
            "strategy_applied", "agi_conductor"
        ),
        "confidence": result.judgment_result.get("confidence", 0.5),
        "processing_time": result.processing_time,
        "route_taken": result.route_taken,
        "meta_insights": result.meta_insights,
        "evolution_feedback": result.evolution_feedback,
        "conductor_version": conductor.version,
    }


if __name__ == "__main__":
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª Judgment Conductor ê¸°ë³¸ í…ŒìŠ¤íŠ¸")

    test_inputs = [
        "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ì•„ìš”",
        "ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ì„œ ìš°ìš¸í•´ìš”",
        "ì´ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”",
    ]

    for i, test_input in enumerate(test_inputs, 1):
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ {i}: {test_input}")
        result = run_conductor(test_input)

        print(f"  ì„±ê³µ: {result['success']}")
        print(f"  ì‘ë‹µ: {result['response_text'][:100]}...")
        print(f"  ê²½ë¡œ: {result['route_taken']}")
        print(f"  ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")

    # ìƒíƒœ í™•ì¸
    conductor = get_conductor()
    status = conductor.get_conductor_status()
    print(f"\nğŸ“Š ì§€íœ˜ì ìƒíƒœ:")
    print(f"  ë²„ì „: {status['version']}")
    print(f"  ì´ ì§€íœ˜: {status['statistics']['total_conducts']}")
    print(
        f"  ì„±ê³µë¥ : {status['statistics']['successful_conducts']}/{status['statistics']['total_conducts']}"
    )
    print(f"  ì§„í™” ì´ë²¤íŠ¸: {status['statistics']['evolution_events']}")
