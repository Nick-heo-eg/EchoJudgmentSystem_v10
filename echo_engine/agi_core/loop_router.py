#!/usr/bin/env python3
"""
ğŸ§­ Loop Router - íŒë‹¨ íë¦„ ë¶„ê¸° ë° ê²½ë¡œ ê²°ì •

ì…ë ¥ ë° ìƒí™©ì— ë”°ë¥¸ ìµœì  íŒë‹¨ íë¦„ì„ ê²°ì •í•˜ëŠ” ë¼ìš°íŒ… ì—”ì§„.
í˜„ì¬ëŠ” legacy adapter ì¤‘ì‹¬ì´ì§€ë§Œ, í–¥í›„ ë‹¤ì–‘í•œ AGI íŒë‹¨ ê²½ë¡œë¡œ í™•ì¥ ì˜ˆì •.

í•µì‹¬ ì—­í• :
1. ì…ë ¥ ë¶„ì„ì„ í†µí•œ íŒë‹¨ ë³µì¡ë„ í‰ê°€
2. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìµœì  íŒë‹¨ ê²½ë¡œ ì„ íƒ
3. ë‹¤ì¤‘ íŒë‹¨ ê²½ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°
4. ë™ì  ë¼ìš°íŒ… ê·œì¹™ ì ìš©
"""

import re
from typing import Dict, List, Any, Optional, Callable, Tuple
from dataclasses import dataclass
from datetime import datetime
from enum import Enum


class RouteType(Enum):
    """íŒë‹¨ ê²½ë¡œ íƒ€ì…"""

    LEGACY = "legacy"  # ê¸°ì¡´ judgment_loop ì‚¬ìš©
    AGI_NATIVE = "agi_native"  # AGI ë„¤ì´í‹°ë¸Œ íŒë‹¨ (ë¯¸ë˜)
    HYBRID = "hybrid"  # í˜¼í•© íŒë‹¨
    META_COGNITIVE = "meta_cognitive"  # ë©”íƒ€ì¸ì§€ì  íŒë‹¨
    EMOTIONAL_DEEP = "emotional_deep"  # ê°ì • ì‹¬ì¸µ ë¶„ì„
    CREATIVE_FLOW = "creative_flow"  # ì°½ì˜ì  ì‚¬ê³  íë¦„


@dataclass
class JudgmentRoute:
    """íŒë‹¨ ê²½ë¡œ ì •ì˜"""

    route_type: RouteType
    weight: float
    confidence: float
    reasoning: str
    parameters: Dict[str, Any]
    estimated_time: float


class LoopRouter:
    """ğŸ§­ íŒë‹¨ ë£¨í”„ ë¼ìš°í„°"""

    def __init__(self):
        self.version = "1.0.0"
        self.routing_stats = {
            "total_routes": 0,
            "route_distribution": {},
            "successful_routes": 0,
            "routing_time_total": 0.0,
        }

        # ë¼ìš°íŒ… ê·œì¹™ ì„¤ì •
        self.routing_rules = self._initialize_routing_rules()

        print("ğŸ§­ Loop Router v1.0 ì´ˆê¸°í™” ì™„ë£Œ")

    def route_judgment(
        self, user_input: str, context: Dict[str, Any]
    ) -> List[JudgmentRoute]:
        """ğŸ¯ ë©”ì¸ ë¼ìš°íŒ… í•¨ìˆ˜"""
        self.routing_stats["total_routes"] += 1

        # 1. ì…ë ¥ ë¶„ì„
        input_analysis = self._analyze_input(user_input)

        # 2. ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context_analysis = self._analyze_context(context)

        # 3. ë¼ìš°íŒ… ê·œì¹™ ì ìš©
        candidate_routes = self._apply_routing_rules(input_analysis, context_analysis)

        # 4. ê²½ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°
        weighted_routes = self._calculate_route_weights(
            candidate_routes, input_analysis, context_analysis
        )

        # 5. ìµœì  ê²½ë¡œ ì„ íƒ (í˜„ì¬ëŠ” ìƒìœ„ 1ê°œ, í–¥í›„ ë‹¤ì¤‘ ê²½ë¡œ ì§€ì›)
        selected_routes = self._select_optimal_routes(weighted_routes, max_routes=1)

        # 6. í†µê³„ ì—…ë°ì´íŠ¸
        for route in selected_routes:
            route_name = route.route_type.value
            self.routing_stats["route_distribution"][route_name] = (
                self.routing_stats["route_distribution"].get(route_name, 0) + 1
            )

        print(f"ğŸ§­ ë¼ìš°íŒ… ê²°ê³¼: {[r.route_type.value for r in selected_routes]}")
        return selected_routes

    def _analyze_input(self, user_input: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ë¶„ì„"""
        text_lower = user_input.lower()

        analysis = {
            "length": len(user_input),
            "complexity": self._calculate_text_complexity(user_input),
            "emotional_intensity": self._detect_emotional_intensity(text_lower),
            "question_markers": self._count_question_markers(user_input),
            "emotional_keywords": self._extract_emotional_keywords(text_lower),
            "creativity_indicators": self._detect_creativity_indicators(text_lower),
            "urgency_level": self._assess_urgency(text_lower),
        }

        return analysis

    def _analyze_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        analysis = {
            "context_richness": len(context),
            "has_history": bool(context.get("conversation_history")),
            "has_emotion_context": bool(context.get("emotion_context")),
            "has_meta_info": bool(context.get("meta_info")),
            "session_continuity": bool(context.get("session_id")),
            "specialized_context": self._detect_specialized_context(context),
        }

        return analysis

    def _calculate_text_complexity(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ ê³„ì‚°"""
        factors = []

        # ê¸¸ì´ ê¸°ë°˜ ë³µì¡ë„
        length_complexity = min(1.0, len(text) / 200.0)
        factors.append(length_complexity)

        # ë¬¸ì¥ êµ¬ì¡° ë³µì¡ë„
        sentence_count = len([s for s in text.split(".") if s.strip()])
        structure_complexity = min(1.0, sentence_count / 5.0)
        factors.append(structure_complexity)

        # ì–´íœ˜ ë‹¤ì–‘ì„±
        words = text.split()
        unique_words = len(set(words))
        vocab_complexity = min(1.0, unique_words / max(len(words), 1))
        factors.append(vocab_complexity)

        return sum(factors) / len(factors)

    def _detect_emotional_intensity(self, text: str) -> float:
        """ê°ì • ê°•ë„ íƒì§€"""
        high_intensity_markers = [
            "ì§„ì§œ",
            "ì •ë§",
            "ë„ˆë¬´",
            "ì™„ì „",
            "ì—„ì²­",
            "ë§¤ìš°",
            "ì •ë§ë¡œ",
            "!",
            "!!",
            "!!!",
            "ã… ã… ",
            "ã…œã…œ",
            "ã…ã…",
            "ã…‹ã…‹",
        ]

        intensity_score = 0.0
        for marker in high_intensity_markers:
            intensity_score += text.count(marker) * 0.1

        return min(1.0, intensity_score)

    def _count_question_markers(self, text: str) -> int:
        """ì§ˆë¬¸ ë§ˆì»¤ ê°œìˆ˜"""
        return (
            text.count("?") + text.count("ë­") + text.count("ì–´ë–»") + text.count("ì™œ")
        )

    def _extract_emotional_keywords(self, text: str) -> List[str]:
        """ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ"""
        emotion_patterns = {
            "joy": ["ê¸°ì˜", "ì¢‹", "í–‰ë³µ", "ì¦ê±°", "ë§Œì¡±", "ì‹ ë‚˜", "ì¬ë¯¸"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ", "ì•„ì‰½", "ì™¸ë¡œ", "í—ˆë¬´"],
            "anger": ["í™”", "ì§œì¦", "ë¹¡", "ë¶„ë…¸", "ì—´ë°›", "ì–µìš¸", "ë‹µë‹µ"],
            "anxiety": ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤", "ì´ˆì¡°", "ê¸´ì¥", "ë¬´ì„œ", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "curiosity": ["ê¶ê¸ˆ", "í¥ë¯¸", "ì•Œê³ ì‹¶", "ë°°ìš°ê³ ì‹¶", "ì‹ ê¸°", "ë†€ë¼"],
        }

        found_emotions = []
        for emotion, patterns in emotion_patterns.items():
            if any(pattern in text for pattern in patterns):
                found_emotions.append(emotion)

        return found_emotions

    def _detect_creativity_indicators(self, text: str) -> List[str]:
        """ì°½ì˜ì„± ì§€í‘œ íƒì§€"""
        creativity_markers = [
            "ì°½ì˜",
            "ì•„ì´ë””ì–´",
            "ìƒìƒ",
            "ìƒˆë¡œìš´",
            "ë…íŠ¹",
            "í˜ì‹ ",
            "ë°œëª…",
            "ì˜ˆìˆ ",
            "ë””ìì¸",
            "ë§Œë“¤",
            "ê·¸ë ¤",
            "ì¨",
        ]

        found_markers = []
        for marker in creativity_markers:
            if marker in text:
                found_markers.append(marker)

        return found_markers

    def _assess_urgency(self, text: str) -> float:
        """ê¸´ê¸‰ë„ í‰ê°€"""
        urgency_markers = [
            "ê¸‰í•´",
            "ë¹¨ë¦¬",
            "ë‹¹ì¥",
            "ì§€ê¸ˆ",
            "ì¦‰ì‹œ",
            "ê¸´ê¸‰",
            "ì–´ì„œ",
            "ì‹œê¸‰",
            "ë°”ë¡œ",
            "ë¨¼ì €",
        ]

        urgency_score = 0.0
        for marker in urgency_markers:
            if marker in text:
                urgency_score += 0.2

        return min(1.0, urgency_score)

    def _detect_specialized_context(self, context: Dict[str, Any]) -> List[str]:
        """íŠ¹í™”ëœ ì»¨í…ìŠ¤íŠ¸ íƒì§€"""
        specialized = []

        if context.get("coding_context"):
            specialized.append("coding")
        if context.get("creative_context"):
            specialized.append("creative")
        if context.get("emotional_support_context"):
            specialized.append("emotional_support")
        if context.get("analytical_context"):
            specialized.append("analytical")

        return specialized

    def _initialize_routing_rules(self) -> List[Dict[str, Any]]:
        """ë¼ìš°íŒ… ê·œì¹™ ì´ˆê¸°í™”"""
        return [
            {
                "name": "high_emotional_intensity",
                "condition": lambda inp, ctx: inp["emotional_intensity"] > 0.7,
                "target_route": RouteType.EMOTIONAL_DEEP,
                "weight_bonus": 0.3,
            },
            {
                "name": "creative_request",
                "condition": lambda inp, ctx: len(inp["creativity_indicators"]) > 2,
                "target_route": RouteType.CREATIVE_FLOW,
                "weight_bonus": 0.2,
            },
            {
                "name": "complex_analysis",
                "condition": lambda inp, ctx: inp["complexity"] > 0.8
                and inp["question_markers"] > 2,
                "target_route": RouteType.META_COGNITIVE,
                "weight_bonus": 0.25,
            },
            {
                "name": "standard_interaction",
                "condition": lambda inp, ctx: True,  # í•­ìƒ ì ìš© (ê¸°ë³¸)
                "target_route": RouteType.LEGACY,
                "weight_bonus": 0.0,
            },
        ]

    def _apply_routing_rules(
        self, input_analysis: Dict[str, Any], context_analysis: Dict[str, Any]
    ) -> List[Tuple[RouteType, float]]:
        """ë¼ìš°íŒ… ê·œì¹™ ì ìš©"""
        candidate_routes = []

        for rule in self.routing_rules:
            try:
                if rule["condition"](input_analysis, context_analysis):
                    candidate_routes.append(
                        (rule["target_route"], rule["weight_bonus"])
                    )
            except Exception as e:
                print(f"âš ï¸ ë¼ìš°íŒ… ê·œì¹™ '{rule['name']}' ì ìš© ì˜¤ë¥˜: {e}")

        return candidate_routes

    def _calculate_route_weights(
        self,
        candidate_routes: List[Tuple[RouteType, float]],
        input_analysis: Dict[str, Any],
        context_analysis: Dict[str, Any],
    ) -> List[JudgmentRoute]:
        """ê²½ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weighted_routes = []

        for route_type, base_weight in candidate_routes:
            # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ê³„ì‚°
            weight = 0.5 + base_weight

            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
            if context_analysis["context_richness"] > 5:
                weight += 0.1

            if context_analysis["has_history"]:
                weight += 0.05

            # ì…ë ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
            if input_analysis["complexity"] > 0.6:
                weight += 0.1

            if input_analysis["emotional_intensity"] > 0.5:
                weight += 0.05

            # ê²½ë¡œë³„ íŠ¹í™” ì¡°ì •
            if route_type == RouteType.LEGACY:
                # ë ˆê±°ì‹œëŠ” í•­ìƒ ì•ˆì •ì ì¸ ì„ íƒ
                weight += 0.2
                confidence = 0.8
                estimated_time = 0.5
            elif route_type == RouteType.AGI_NATIVE:
                # AGI ë„¤ì´í‹°ë¸ŒëŠ” ì•„ì§ ì‹¤í—˜ì 
                confidence = 0.6
                estimated_time = 1.0
            else:
                # ê¸°íƒ€ ê²½ë¡œë“¤
                confidence = 0.7
                estimated_time = 0.8

            weighted_route = JudgmentRoute(
                route_type=route_type,
                weight=min(1.0, weight),
                confidence=confidence,
                reasoning=f"ê·œì¹™ ê¸°ë°˜ ì„ íƒ: {route_type.value}",
                parameters={
                    "input_analysis": input_analysis,
                    "context_analysis": context_analysis,
                },
                estimated_time=estimated_time,
            )

            weighted_routes.append(weighted_route)

        return weighted_routes

    def _select_optimal_routes(
        self, weighted_routes: List[JudgmentRoute], max_routes: int = 1
    ) -> List[JudgmentRoute]:
        """ìµœì  ê²½ë¡œ ì„ íƒ"""
        if not weighted_routes:
            # í´ë°±: ë ˆê±°ì‹œ ê²½ë¡œ
            return [
                JudgmentRoute(
                    route_type=RouteType.LEGACY,
                    weight=1.0,
                    confidence=0.8,
                    reasoning="í´ë°± ê²½ë¡œ",
                    parameters={},
                    estimated_time=0.5,
                )
            ]

        # ê°€ì¤‘ì¹˜ ê¸°ì¤€ ì •ë ¬
        sorted_routes = sorted(
            weighted_routes, key=lambda r: r.weight * r.confidence, reverse=True
        )

        return sorted_routes[:max_routes]

    def get_routing_stats(self) -> Dict[str, Any]:
        """ë¼ìš°íŒ… í†µê³„ ë°˜í™˜"""
        stats = self.routing_stats.copy()

        if stats["total_routes"] > 0:
            stats["success_rate"] = stats["successful_routes"] / stats["total_routes"]
            stats["average_routing_time"] = (
                stats["routing_time_total"] / stats["total_routes"]
            )

        return stats


# ê¸€ë¡œë²Œ ë¼ìš°í„° ì¸ìŠ¤í„´ìŠ¤
_global_router = None


def get_router() -> LoopRouter:
    """ê¸€ë¡œë²Œ ë¼ìš°í„° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_router
    if _global_router is None:
        _global_router = LoopRouter()
    return _global_router


def route_judgment(user_input: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ğŸ§­ íŒë‹¨ ë¼ìš°íŒ… - ë©”ì¸ ì§„ì…ì """
    router = get_router()
    routes = router.route_judgment(user_input, context)

    # JudgmentRoute ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (í˜¸í™˜ì„±)
    return [
        {
            "type": route.route_type.value,
            "weight": route.weight,
            "confidence": route.confidence,
            "reasoning": route.reasoning,
            "parameters": route.parameters,
            "estimated_time": route.estimated_time,
        }
        for route in routes
    ]


if __name__ == "__main__":
    # ë¼ìš°í„° í…ŒìŠ¤íŠ¸
    print("ğŸ§ª Loop Router í…ŒìŠ¤íŠ¸")

    test_cases = [
        {"input": "ì•ˆë…•í•˜ì„¸ìš”!", "context": {}, "expected": "legacy"},
        {
            "input": "ë„ˆë¬´ ìŠ¬í¼ì„œ ì£½ì„ ê²ƒ ê°™ì•„ìš” ã… ã… ",
            "context": {},
            "expected": "emotional_deep",
        },
        {
            "input": "ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ìƒê°í•´ë‚´ê³  ì‹¶ì–´ìš”. ì°½ì˜ì ì¸ ë°©ë²•ì´ ìˆì„ê¹Œìš”?",
            "context": {},
            "expected": "creative_flow",
        },
        {
            "input": "ì´ ë³µì¡í•œ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ë¶„ì„í•´ì•¼ í• ê¹Œìš”? ì—¬ëŸ¬ ê´€ì ì—ì„œ ì‚´í´ë´ì•¼ í•  ê²ƒ ê°™ì€ë°...",
            "context": {"context_richness": 10},
            "expected": "meta_cognitive",
        },
    ]

    router = get_router()

    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ {i}: {case['input'][:50]}...")
        routes = route_judgment(case["input"], case["context"])

        if routes:
            primary_route = routes[0]
            print(f"  ì„ íƒëœ ê²½ë¡œ: {primary_route['type']}")
            print(f"  ê°€ì¤‘ì¹˜: {primary_route['weight']:.2f}")
            print(f"  ì‹ ë¢°ë„: {primary_route['confidence']:.2f}")
            print(
                f"  ì˜ˆìƒê³¼ ì¼ì¹˜: {'âœ…' if primary_route['type'] == case['expected'] else 'âŒ'}"
            )
        else:
            print("  âŒ ê²½ë¡œ ì„ íƒ ì‹¤íŒ¨")

    # í†µê³„ ì¶œë ¥
    stats = router.get_routing_stats()
    print(f"\nğŸ“Š ë¼ìš°í„° í†µê³„:")
    print(f"  ì´ ë¼ìš°íŒ…: {stats['total_routes']}")
    print(f"  ê²½ë¡œ ë¶„í¬: {stats['route_distribution']}")
