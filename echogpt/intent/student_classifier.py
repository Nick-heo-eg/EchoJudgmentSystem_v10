#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EchoGPT Student Classifier
Local intent classifier (Student in Teacher-Student architecture)
"""
import os
import threading
from typing import Dict, Any, Optional
from pathlib import Path

try:
    import joblib

    JOBLIB_AVAILABLE = True
except ImportError:
    JOBLIB_AVAILABLE = False


class StudentClassifier:
    """ë¡œì»¬ Intent ë¶„ë¥˜ê¸° (Student) - í•«ìŠ¤ì™‘ ì§€ì›"""

    def __init__(self, model_dir: str = "models/intent_student"):
        self.model_dir = Path(model_dir)
        self.model_path = self.model_dir / "student.joblib"
        self.pipe = None
        self._lock = threading.RLock()  # í•«ìŠ¤ì™‘ì„ ìœ„í•œ ìŠ¤ë ˆë“œ ì„¸ì´í”„

        # ì´ˆê¸° ëª¨ë¸ ë¡œë“œ ì‹œë„
        self._load_model()

    def _load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        if not JOBLIB_AVAILABLE:
            # joblibì´ ì—†ìœ¼ë©´ ëª¨ë¸ ë¡œë”© ê±´ë„ˆë›°ê¸°
            self.pipe = None
            return False

        try:
            if self.model_path.exists():
                with self._lock:
                    self.pipe = joblib.load(self.model_path)
                return True
        except Exception as e:
            print(f"âš ï¸ Failed to load student model: {e}")

        self.pipe = None
        return False

    def classify(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ë¶„ë¥˜"""
        with self._lock:
            if self.pipe is None:
                # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
                return {
                    "intent": "general_chat",
                    "confidence": 0.33,
                    "summary": "No trained model available",
                    "tags": [],
                    "safety": [],
                    "_source": "student",
                    "_model_available": False,
                }

            try:
                # ì˜ˆì¸¡ ì‹¤í–‰
                predicted_label = self.pipe.predict([text])[0]

                # ì‹ ë¢°ë„ ê³„ì‚° (predict_proba ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
                confidence = self._calculate_confidence(text, predicted_label)

                return {
                    "intent": predicted_label,
                    "confidence": confidence,
                    "summary": f"Local classification: {predicted_label}",
                    "tags": self._extract_tags(text, predicted_label),
                    "safety": self._check_safety(predicted_label),
                    "_source": "student",
                    "_model_available": True,
                }

            except Exception as e:
                print(f"âš ï¸ Student classification failed: {e}")
                return {
                    "intent": "general_chat",
                    "confidence": 0.33,
                    "summary": f"Classification error: {str(e)[:50]}",
                    "tags": [],
                    "safety": [],
                    "_source": "student",
                    "_model_available": True,
                    "_error": str(e),
                }

    def _calculate_confidence(self, text: str, predicted_label: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if hasattr(self.pipe.named_steps.get("clf", None), "predict_proba"):
                # í™•ë¥  ê¸°ë°˜ ì‹ ë¢°ë„
                X_vec = self.pipe.named_steps["tfidf"].transform([text])
                probabilities = self.pipe.named_steps["clf"].predict_proba(X_vec)[0]
                max_prob = probabilities.max()
                return float(max_prob)
            else:
                # ê²°ì • í•¨ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„ (SGDì˜ ê²½ìš°)
                if hasattr(self.pipe.named_steps.get("clf", None), "decision_function"):
                    X_vec = self.pipe.named_steps["tfidf"].transform([text])
                    decision_scores = self.pipe.named_steps["clf"].decision_function(
                        X_vec
                    )[0]

                    if len(decision_scores.shape) > 0 and decision_scores.shape[0] > 1:
                        # ë‹¤ì¤‘ í´ë˜ìŠ¤: ìµœëŒ€ ì ìˆ˜ë¥¼ ì‹œê·¸ëª¨ì´ë“œë¡œ ë³€í™˜
                        max_score = decision_scores.max()
                        confidence = 1 / (1 + abs(max_score) ** -1)
                    else:
                        # ì´ì§„ ë¶„ë¥˜: ì ˆëŒ“ê°’ì„ ì‹œê·¸ëª¨ì´ë“œë¡œ ë³€í™˜
                        score = (
                            decision_scores
                            if hasattr(decision_scores, "__len__")
                            else decision_scores
                        )
                        confidence = 1 / (1 + abs(float(score)) ** -1)

                    return min(0.99, max(0.01, confidence))
        except Exception:
            pass

        # í´ë°±: í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ í‚¤ì›Œë“œ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ì‹ ë¢°ë„
        return self._heuristic_confidence(text, predicted_label)

    def _heuristic_confidence(self, text: str, predicted_label: str) -> float:
        """íœ´ë¦¬ìŠ¤í‹± ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.6

        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì¡°ì •
        if len(text) < 10:
            base_confidence -= 0.2
        elif len(text) > 50:
            base_confidence += 0.1

        # ë¼ë²¨ë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ì¡°ì •
        text_lower = text.lower()
        label_keywords = {
            "medical_support": ["ì˜ì‚¬", "ë³‘ì›", "ì•„í”„", "ì¦ìƒ", "ì¹˜ë£Œ"],
            "local_search": ["ê·¼ì²˜", "ì§€ë„", "ìœ„ì¹˜", "ì°¾ì•„", "ì–´ë””"],
            "web_query": ["ê²€ìƒ‰", "ì°¾ì•„", "ì•Œë ¤", "ì •ë³´"],
            "math": ["ê³„ì‚°", "ìˆ˜í•™", "ë”í•˜ê¸°", "ë¹¼ê¸°", "+", "-", "*", "/"],
            "technical_assistance": ["ì½”ë”©", "í”„ë¡œê·¸ë˜ë°", "ì½”ë“œ", "í•¨ìˆ˜", "ë²„ê·¸"],
            "creative_expression": ["ì°½ì˜", "ì•„ì´ë””ì–´", "ë§Œë“¤ì–´", "ë””ìì¸", "ê¸€"],
            "emotional_support": ["í˜ë“¤ì–´", "ìŠ¬í¼", "ìœ„ë¡œ", "ë„ì›€", "ê¸°ë¶„"],
        }

        if predicted_label in label_keywords:
            keywords = label_keywords[predicted_label]
            matches = sum(1 for keyword in keywords if keyword in text_lower)
            if matches > 0:
                base_confidence += min(0.3, matches * 0.1)

        return min(0.95, max(0.1, base_confidence))

    def _extract_tags(self, text: str, predicted_label: str) -> list:
        """íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        text_lower = text.lower()

        # ë¼ë²¨ ê¸°ë°˜ íƒœê·¸
        if predicted_label == "local_search":
            location_terms = ["ë™", "êµ¬", "ì‹œ", "ì—­", "ë³‘ì›", "í•™êµ", "ì¹´í˜"]
            for term in location_terms:
                if term in text_lower:
                    tags.append(f"location:{term}")

        elif predicted_label == "medical_support":
            medical_terms = ["ì†Œì•„ê³¼", "ë‚´ê³¼", "ì™¸ê³¼", "ì‘ê¸‰", "ì•½êµ­"]
            for term in medical_terms:
                if term in text_lower:
                    tags.append(f"medical:{term}")

        # ê¸´ê¸‰ë„ íƒœê·¸
        urgency_keywords = ["ê¸‰í•´", "ë¹¨ë¦¬", "ì‘ê¸‰", "ì§€ê¸ˆ", "ë‹¹ì¥"]
        if any(keyword in text_lower for keyword in urgency_keywords):
            tags.append("urgency:high")

        return tags

    def _check_safety(self, predicted_label: str) -> list:
        """ì•ˆì „ì„± í”Œë˜ê·¸ í™•ì¸"""
        safety_flags = []

        # ë¼ë²¨ ê¸°ë°˜ ì•ˆì „ì„± í”Œë˜ê·¸
        if predicted_label == "medical_support":
            safety_flags.append("medical")
        elif predicted_label == "sensitive_support":
            safety_flags.append("sensitive")

        return safety_flags

    def reload(self) -> bool:
        """ëª¨ë¸ í•«ìŠ¤ì™‘ (ë¬´ì¤‘ë‹¨ ëª¨ë¸ êµì²´)"""
        old_model_available = self.pipe is not None
        success = self._load_model()
        new_model_available = self.pipe is not None

        if success and new_model_available:
            if old_model_available:
                print("ğŸ”„ Student model hot-swapped successfully")
            else:
                print("âœ… Student model loaded successfully")
            return True
        elif not success and old_model_available:
            print("âš ï¸ Hot-swap failed, keeping existing model")
            return False
        else:
            print("âŒ No model available after reload attempt")
            return False

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        with self._lock:
            info = {
                "model_available": self.pipe is not None,
                "model_path": str(self.model_path),
                "model_exists": self.model_path.exists(),
            }

            if info["model_exists"]:
                try:
                    stat = self.model_path.stat()
                    info["model_size_kb"] = stat.st_size // 1024
                    info["model_modified"] = stat.st_mtime
                except:
                    pass

            if self.pipe is not None:
                try:
                    # íŒŒì´í”„ë¼ì¸ ì •ë³´
                    info["pipeline_steps"] = list(self.pipe.named_steps.keys())

                    # í´ë˜ìŠ¤ ì •ë³´
                    clf = self.pipe.named_steps.get("clf")
                    if clf and hasattr(clf, "classes_"):
                        info["classes"] = list(clf.classes_)
                        info["n_classes"] = len(clf.classes_)

                    # TF-IDF ì •ë³´
                    tfidf = self.pipe.named_steps.get("tfidf")
                    if tfidf and hasattr(tfidf, "vocabulary_"):
                        info["vocabulary_size"] = len(tfidf.vocabulary_)

                except Exception as e:
                    info["model_info_error"] = str(e)

            return info

    def is_available(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        with self._lock:
            return self.pipe is not None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_global_classifier = None
_global_lock = threading.Lock()


def get_global_classifier(
    model_dir: str = "models/intent_student",
) -> StudentClassifier:
    """ì „ì—­ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _global_classifier

    with _global_lock:
        if _global_classifier is None:
            _global_classifier = StudentClassifier(model_dir)
        return _global_classifier


def reload_global_classifier() -> bool:
    """ì „ì—­ ë¶„ë¥˜ê¸° ë¦¬ë¡œë“œ"""
    global _global_classifier

    with _global_lock:
        if _global_classifier is not None:
            return _global_classifier.reload()
        else:
            # ìƒˆë¡œ ìƒì„±
            _global_classifier = StudentClassifier()
            return _global_classifier.is_available()


# CLI ì‹¤í–‰ ì§€ì›
if __name__ == "__main__":
    import sys
    import json

    classifier = StudentClassifier()

    if len(sys.argv) < 2:
        print("Usage: python -m intent.student_classifier <command> [text]")
        print("Commands: info, classify, reload")
        sys.exit(1)

    command = sys.argv[1]

    if command == "info":
        info = classifier.get_model_info()
        print("ğŸ¤– Student Classifier Info:")
        print(json.dumps(info, indent=2, ensure_ascii=False))

    elif command == "classify" and len(sys.argv) > 2:
        text = " ".join(sys.argv[2:])
        result = classifier.classify(text)
        print("ğŸ¯ Classification Result:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

    elif command == "reload":
        success = classifier.reload()
        print(f"ğŸ”„ Reload {'successful' if success else 'failed'}")

    else:
        print("Invalid command or missing text argument")
