#!/usr/bin/env python3
"""
Echo ì„±ëŠ¥ ìµœì í™” ìë™í™” ì‹œìŠ¤í…œ
ì½”ë“œ ì„±ëŠ¥ ë³‘ëª©ì  ìë™ ê°ì§€ ë° ìµœì í™” ì œì•ˆ
"""

import ast
import time
import cProfile
import pstats
import io
import re
import json
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, asdict
from datetime import datetime

try:
    import memory_profiler
except ImportError:
    memory_profiler = None

try:
    import line_profiler
except ImportError:
    line_profiler = None
import sys
import os

logger = logging.getLogger(__name__)


@dataclass
class PerformanceIssue:
    """ì„±ëŠ¥ ì´ìŠˆ"""

    severity: str  # critical, high, medium, low
    category: str  # cpu, memory, io, algorithm, database
    description: str
    file_path: str
    line_number: int
    function_name: str
    current_performance: str
    suggested_optimization: str
    estimated_improvement: str
    confidence: float


@dataclass
class ProfileResult:
    """í”„ë¡œíŒŒì¼ë§ ê²°ê³¼"""

    total_time: float
    function_stats: Dict[str, Dict]
    memory_usage: Dict[str, float]
    hotspots: List[Dict]
    bottlenecks: List[PerformanceIssue]


class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ë¶„ì„ê¸°"""

    def __init__(self, project_dir: str = "."):
        self.project_dir = Path(project_dir)
        self.performance_issues: List[PerformanceIssue] = []

        # ğŸ¯ ì„±ëŠ¥ íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬
        self.optimization_patterns = {
            "loop_inefficiency": {
                "patterns": [
                    r"for\s+\w+\s+in\s+range\(len\(",  # for i in range(len(list))
                    r"for\s+\w+\s+in\s+\w+:\s*if\s+",  # í•„í„°ë§ì´ ì—†ëŠ” ë£¨í”„
                ],
                "optimizations": [
                    "enumerate() ì‚¬ìš©ìœ¼ë¡œ ì¸ë±ìŠ¤ ì ‘ê·¼ ìµœì í™”",
                    "list comprehension ë˜ëŠ” filter() ì‚¬ìš© ê³ ë ¤",
                ],
            },
            "string_concatenation": {
                "patterns": [
                    r"\w+\s*\+=\s*[\"'].*[\"']",  # str += "text"
                    r"\w+\s*=\s*\w+\s*\+\s*[\"']",  # str = str + "text"
                ],
                "optimizations": [
                    "join() ë©”ì„œë“œ ì‚¬ìš©ìœ¼ë¡œ ë¬¸ìì—´ ì—°ê²° ìµœì í™”",
                    "f-string ë˜ëŠ” format() ì‚¬ìš© ê³ ë ¤",
                ],
            },
            "database_queries": {
                "patterns": [
                    r"for\s+\w+\s+in\s+\w+:.*\.query\(",  # N+1 ì¿¼ë¦¬ ë¬¸ì œ
                    r"\.execute\(.*\+.*\)",  # ë™ì  ì¿¼ë¦¬ ìƒì„±
                ],
                "optimizations": [
                    "bulk ì¿¼ë¦¬ ë˜ëŠ” join ì‚¬ìš©ìœ¼ë¡œ N+1 ë¬¸ì œ í•´ê²°",
                    "prepared statement ì‚¬ìš©ìœ¼ë¡œ ì¿¼ë¦¬ ìµœì í™”",
                ],
            },
            "file_operations": {
                "patterns": [
                    r"open\(.*\)\.read\(\)",  # withë¬¸ ì—†ëŠ” íŒŒì¼ ì½ê¸°
                    r"for\s+line\s+in\s+open\(",  # íŒŒì¼ ì „ì²´ ë¡œë“œ
                ],
                "optimizations": [
                    "withë¬¸ ì‚¬ìš©ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ìµœì í™”",
                    "readline() ë˜ëŠ” chunk ë‹¨ìœ„ ì½ê¸°ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
                ],
            },
            "algorithm_complexity": {
                "patterns": [
                    r"for\s+.*:\s*for\s+.*:",  # ì¤‘ì²© ë£¨í”„
                    r"\.sort\(\).*for\s+",  # ì •ë ¬ í›„ ë°˜ë³µ
                ],
                "optimizations": [
                    "ì•Œê³ ë¦¬ì¦˜ ë³µì¡ë„ ê°œì„  (O(nÂ²) â†’ O(n log n))",
                    "ì ì ˆí•œ ìë£Œêµ¬ì¡° ì‚¬ìš© (set, dict, heap ë“±)",
                ],
            },
        }

        # ë©”ëª¨ë¦¬ ìµœì í™” íŒ¨í„´
        self.memory_patterns = {
            "large_data_structures": [
                r"list\(range\(\d{4,}\)\)",  # í° ë¦¬ìŠ¤íŠ¸ ìƒì„±
                r"\[\w+\s+for\s+\w+\s+in\s+\w+\s+if\s+.*\]",  # í° list comprehension
            ],
            "generator_opportunities": [
                r"return\s+\[.*for.*\]",  # ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ ëŒ€ì‹  ì œë„ˆë ˆì´í„°
                r"sum\(\[.*for.*\]\)",  # sumì— ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ì œë„ˆë ˆì´í„°
            ],
        }

    def analyze_project_performance(self) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ì „ì²´ ì„±ëŠ¥ ë¶„ì„"""
        logger.info("ğŸ” Starting comprehensive performance analysis...")

        analysis_result = {
            "timestamp": datetime.now().isoformat(),
            "project_path": str(self.project_dir.absolute()),
            "analyzed_files": 0,
            "performance_issues": [],
            "profile_results": {},
            "optimization_summary": {
                "total_issues": 0,
                "critical_issues": 0,
                "estimated_improvement": 0,
            },
        }

        # 1. ì •ì  ì½”ë“œ ë¶„ì„
        self._analyze_source_files()
        analysis_result["analyzed_files"] = len(list(self.project_dir.rglob("*.py")))

        # 2. ë™ì  í”„ë¡œíŒŒì¼ë§ (ì£¼ìš” ëª¨ë“ˆë§Œ)
        main_modules = self._find_main_modules()
        for module_path in main_modules:
            profile_result = self._profile_module(module_path)
            if profile_result:
                analysis_result["profile_results"][str(module_path)] = asdict(
                    profile_result
                )

        # 3. ê²°ê³¼ ì§‘ê³„
        analysis_result["performance_issues"] = [
            asdict(issue) for issue in self.performance_issues
        ]
        analysis_result["optimization_summary"] = self._calculate_optimization_summary()

        logger.info(
            f"ğŸ“Š Performance analysis completed: {len(self.performance_issues)} issues found"
        )
        return analysis_result

    def _analyze_source_files(self):
        """ì†ŒìŠ¤ íŒŒì¼ ì •ì  ë¶„ì„"""
        python_files = list(self.project_dir.rglob("*.py"))

        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue

            try:
                self._analyze_python_file(file_path)
            except Exception as e:
                logger.warning(f"Failed to analyze {file_path}: {e}")

    def _should_skip_file(self, file_path: Path) -> bool:
        """íŒŒì¼ ìŠ¤í‚µ ì—¬ë¶€ íŒë‹¨"""
        skip_dirs = {
            ".git",
            "__pycache__",
            ".venv",
            "venv",
            "node_modules",
            ".pytest_cache",
        }
        skip_patterns = {"test_", "_test", "conftest"}

        # ë””ë ‰í† ë¦¬ ì²´í¬
        for part in file_path.parts:
            if part in skip_dirs:
                return True

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìŠ¤í‚µ
        for pattern in skip_patterns:
            if pattern in file_path.name:
                return True

        return False

    def _analyze_python_file(self, file_path: Path):
        """Python íŒŒì¼ ì„±ëŠ¥ ë¶„ì„"""
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
                lines = content.split("\\n")

            # 1. íŒ¨í„´ ê¸°ë°˜ ë¶„ì„
            self._check_optimization_patterns(file_path, content, lines)

            # 2. AST ê¸°ë°˜ ë³µì¡ë„ ë¶„ì„
            self._analyze_complexity(file_path, content)

            # 3. ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
            self._analyze_memory_patterns(file_path, content, lines)

        except Exception as e:
            logger.warning(f"Failed to analyze {file_path}: {e}")

    def _check_optimization_patterns(
        self, file_path: Path, content: str, lines: List[str]
    ):
        """ìµœì í™” íŒ¨í„´ ê²€ì‚¬"""
        for category, pattern_data in self.optimization_patterns.items():
            patterns = pattern_data["patterns"]
            optimizations = pattern_data["optimizations"]

            for i, pattern in enumerate(patterns):
                for match in re.finditer(pattern, content, re.MULTILINE):
                    line_num = content[: match.start()].count("\\n") + 1

                    # í•¨ìˆ˜ëª… ì¶”ì¶œ
                    function_name = self._extract_function_name(lines, line_num)

                    # ì‹¬ê°ë„ ê²°ì •
                    severity = self._determine_severity(category, pattern)

                    self.performance_issues.append(
                        PerformanceIssue(
                            severity=severity,
                            category=self._map_category(category),
                            description=f"{category.replace('_', ' ').title()} ìµœì í™” ê¸°íšŒ ë°œê²¬",
                            file_path=str(file_path.relative_to(self.project_dir)),
                            line_number=line_num,
                            function_name=function_name,
                            current_performance="í˜„ì¬ êµ¬í˜„ì˜ ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„ í•„ìš”",
                            suggested_optimization=optimizations[
                                min(i, len(optimizations) - 1)
                            ],
                            estimated_improvement=self._estimate_improvement(category),
                            confidence=0.7,
                        )
                    )

    def _analyze_complexity(self, file_path: Path, content: str):
        """ë³µì¡ë„ ë¶„ì„"""
        try:
            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    complexity = self._calculate_cyclomatic_complexity(node)

                    if complexity > 10:  # ë†’ì€ ë³µì¡ë„
                        self.performance_issues.append(
                            PerformanceIssue(
                                severity="medium" if complexity <= 15 else "high",
                                category="algorithm",
                                description=f"ë†’ì€ ìˆœí™˜ ë³µì¡ë„ (McCabe: {complexity})",
                                file_path=str(file_path.relative_to(self.project_dir)),
                                line_number=node.lineno,
                                function_name=node.name,
                                current_performance=f"ìˆœí™˜ ë³µì¡ë„: {complexity}",
                                suggested_optimization="í•¨ìˆ˜ ë¶„í•´ ë° ì•Œê³ ë¦¬ì¦˜ ë‹¨ìˆœí™”",
                                estimated_improvement="ê°€ë…ì„± ë° ìœ ì§€ë³´ìˆ˜ì„± 30% í–¥ìƒ",
                                confidence=0.8,
                            )
                        )

        except SyntaxError:
            pass
        except Exception as e:
            logger.warning(f"Complexity analysis failed for {file_path}: {e}")

    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """ìˆœí™˜ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 1  # ê¸°ë³¸ ë³µì¡ë„

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, (ast.And, ast.Or)):
                complexity += 1

        return complexity

    def _analyze_memory_patterns(self, file_path: Path, content: str, lines: List[str]):
        """ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„"""
        for pattern_type, patterns in self.memory_patterns.items():
            for pattern in patterns:
                for match in re.finditer(pattern, content, re.MULTILINE):
                    line_num = content[: match.start()].count("\\n") + 1
                    function_name = self._extract_function_name(lines, line_num)

                    self.performance_issues.append(
                        PerformanceIssue(
                            severity="medium",
                            category="memory",
                            description=f"ë©”ëª¨ë¦¬ ìµœì í™” ê¸°íšŒ: {pattern_type.replace('_', ' ')}",
                            file_path=str(file_path.relative_to(self.project_dir)),
                            line_number=line_num,
                            function_name=function_name,
                            current_performance="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ í•„ìš”",
                            suggested_optimization=self._get_memory_optimization(
                                pattern_type
                            ),
                            estimated_improvement="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 20-50% ê°ì†Œ",
                            confidence=0.6,
                        )
                    )

    def _extract_function_name(self, lines: List[str], line_num: int) -> str:
        """ë¼ì¸ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ í•¨ìˆ˜ëª… ì¶”ì¶œ"""
        for i in range(max(0, line_num - 10), min(len(lines), line_num + 1)):
            line = lines[i].strip()
            if line.startswith("def ") or line.startswith("async def "):
                match = re.match(r"(async )?def\\s+(\\w+)", line)
                if match:
                    return match.group(2)
        return "unknown"

    def _determine_severity(self, category: str, pattern: str) -> str:
        """ì‹¬ê°ë„ ê²°ì •"""
        severity_map = {
            "database_queries": "high",
            "loop_inefficiency": "medium",
            "algorithm_complexity": "high",
            "string_concatenation": "low",
            "file_operations": "medium",
        }
        return severity_map.get(category, "low")

    def _map_category(self, category: str) -> str:
        """ì¹´í…Œê³ ë¦¬ ë§¤í•‘"""
        category_map = {
            "loop_inefficiency": "cpu",
            "string_concatenation": "cpu",
            "database_queries": "database",
            "file_operations": "io",
            "algorithm_complexity": "algorithm",
        }
        return category_map.get(category, "cpu")

    def _estimate_improvement(self, category: str) -> str:
        """ê°œì„  íš¨ê³¼ ì¶”ì •"""
        improvement_map = {
            "loop_inefficiency": "ì‹¤í–‰ ì‹œê°„ 20-40% ê°ì†Œ",
            "string_concatenation": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 30-60% ê°ì†Œ",
            "database_queries": "ì¿¼ë¦¬ ì‹œê°„ 50-90% ê°ì†Œ",
            "file_operations": "I/O ì„±ëŠ¥ 20-50% í–¥ìƒ",
            "algorithm_complexity": "í™•ì¥ì„± ë° ì„±ëŠ¥ ëŒ€í­ ê°œì„ ",
        }
        return improvement_map.get(category, "ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€")

    def _get_memory_optimization(self, pattern_type: str) -> str:
        """ë©”ëª¨ë¦¬ ìµœì í™” ì œì•ˆ"""
        optimization_map = {
            "large_data_structures": "generator ë˜ëŠ” iterator ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
            "generator_opportunities": "list ëŒ€ì‹  generator expression ì‚¬ìš©",
        }
        return optimization_map.get(pattern_type, "ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ìµœì í™”")

    def _find_main_modules(self) -> List[Path]:
        """ì£¼ìš” ëª¨ë“ˆ ì°¾ê¸°"""
        main_modules = []

        # main.py, app.py ë“± ë©”ì¸ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
        for pattern in ["main.py", "app.py", "run.py", "server.py"]:
            main_file = self.project_dir / pattern
            if main_file.exists():
                main_modules.append(main_file)

        # __main__.py ëª¨ë“ˆ
        for main_file in self.project_dir.rglob("__main__.py"):
            main_modules.append(main_file)

        return main_modules[:3]  # ìµœëŒ€ 3ê°œë§Œ

    def _profile_module(self, module_path: Path) -> Optional[ProfileResult]:
        """ëª¨ë“ˆ í”„ë¡œíŒŒì¼ë§"""
        try:
            logger.info(f"ğŸ“Š Profiling module: {module_path}")

            # cProfile ì‹¤í–‰
            pr = cProfile.Profile()

            # ëª¨ë“ˆ ë™ì  ì„í¬íŠ¸ ë° ì‹¤í–‰
            spec = self._import_and_run_module(module_path, pr)

            if not spec:
                return None

            # í†µê³„ ìˆ˜ì§‘
            s = io.StringIO()
            stats = pstats.Stats(pr, stream=s)
            stats.sort_stats("cumulative").print_stats(20)

            # ê²°ê³¼ íŒŒì‹±
            function_stats = self._parse_profile_stats(stats)
            hotspots = self._identify_hotspots(function_stats)

            return ProfileResult(
                total_time=sum(
                    stat.get("cumtime", 0) for stat in function_stats.values()
                ),
                function_stats=function_stats,
                memory_usage={},  # ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ì€ ì„ íƒì 
                hotspots=hotspots,
                bottlenecks=[],
            )

        except Exception as e:
            logger.warning(f"Profiling failed for {module_path}: {e}")
            return None

    def _import_and_run_module(
        self, module_path: Path, profiler: cProfile.Profile
    ) -> bool:
        """ëª¨ë“ˆ ì„í¬íŠ¸ ë° ì‹¤í–‰"""
        try:
            # ëª¨ë“ˆ ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€
            module_dir = module_path.parent
            if str(module_dir) not in sys.path:
                sys.path.insert(0, str(module_dir))

            # í”„ë¡œíŒŒì¼ë§ ì‹œì‘
            profiler.enable()

            # ê°„ë‹¨í•œ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰ (ì‹¤ì œ ì‹¤í–‰ì€ ìœ„í—˜í•  ìˆ˜ ìˆìŒ)
            module_name = module_path.stem

            # ì•ˆì „í•˜ê²Œ ì„í¬íŠ¸ë§Œ í…ŒìŠ¤íŠ¸
            try:
                __import__(module_name)
                time.sleep(0.1)  # ìµœì†Œí•œì˜ ì‹¤í–‰ ì‹œê°„
            except Exception:
                pass

            profiler.disable()
            return True

        except Exception as e:
            logger.warning(f"Module execution failed: {e}")
            return False

    def _parse_profile_stats(self, stats: pstats.Stats) -> Dict[str, Dict]:
        """í”„ë¡œíŒŒì¼ í†µê³„ íŒŒì‹±"""
        function_stats = {}

        try:
            for func, (cc, nc, tt, ct, callers) in stats.stats.items():
                filename, line_num, func_name = func

                function_stats[f"{filename}:{func_name}"] = {
                    "call_count": cc,
                    "total_time": tt,
                    "cumtime": ct,
                    "filename": filename,
                    "line_number": line_num,
                    "function_name": func_name,
                }
        except Exception as e:
            logger.warning(f"Failed to parse profile stats: {e}")

        return function_stats

    def _identify_hotspots(self, function_stats: Dict[str, Dict]) -> List[Dict]:
        """ì„±ëŠ¥ í•«ìŠ¤íŒŸ ì‹ë³„"""
        hotspots = []

        # ì‹¤í–‰ ì‹œê°„ ê¸°ì¤€ ìƒìœ„ í•¨ìˆ˜ë“¤
        sorted_functions = sorted(
            function_stats.items(), key=lambda x: x[1].get("cumtime", 0), reverse=True
        )

        for func_name, stats in sorted_functions[:10]:
            if stats.get("cumtime", 0) > 0.01:  # 10ms ì´ìƒ
                hotspots.append(
                    {
                        "function": func_name,
                        "cumulative_time": stats.get("cumtime", 0),
                        "call_count": stats.get("call_count", 0),
                        "avg_time": stats.get("cumtime", 0)
                        / max(stats.get("call_count", 1), 1),
                    }
                )

        return hotspots

    def _calculate_optimization_summary(self) -> Dict[str, Any]:
        """ìµœì í™” ìš”ì•½ ê³„ì‚°"""
        summary = {
            "total_issues": len(self.performance_issues),
            "critical_issues": sum(
                1 for issue in self.performance_issues if issue.severity == "critical"
            ),
            "high_issues": sum(
                1 for issue in self.performance_issues if issue.severity == "high"
            ),
            "medium_issues": sum(
                1 for issue in self.performance_issues if issue.severity == "medium"
            ),
            "low_issues": sum(
                1 for issue in self.performance_issues if issue.severity == "low"
            ),
            "category_breakdown": {},
        }

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        for issue in self.performance_issues:
            category = issue.category
            if category not in summary["category_breakdown"]:
                summary["category_breakdown"][category] = 0
            summary["category_breakdown"][category] += 1

        return summary

    def generate_optimization_report(self, output_path: str) -> Dict[str, Any]:
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        analysis_result = self.analyze_project_performance()

        # JSON ë¦¬í¬íŠ¸ ì €ì¥
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False)

        # HTML ë¦¬í¬íŠ¸ ìƒì„±
        html_path = output_path.replace(".json", ".html")
        self._generate_html_report(analysis_result, html_path)

        logger.info(f"ğŸ“Š Optimization report generated: {output_path}")
        return analysis_result

    def _generate_html_report(self, data: Dict[str, Any], html_path: str):
        """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        summary = data["optimization_summary"]
        issues = data["performance_issues"]

        html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Echo Performance Optimization Report</title>
    <style>
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            margin: 0; padding: 20px; background: #f8f9fa; 
        }}
        .container {{ 
            max-width: 1200px; margin: 0 auto; background: white;
            border-radius: 10px; padding: 30px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .header {{ text-align: center; margin-bottom: 40px; }}
        .summary {{ 
            display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px; margin-bottom: 30px; 
        }}
        .summary-card {{ 
            background: #e8f4fd; border-radius: 8px; padding: 20px; text-align: center;
        }}
        .issue-list {{ margin-top: 20px; }}
        .issue-item {{ 
            border: 1px solid #e1e8ed; border-radius: 8px; padding: 15px; 
            margin-bottom: 15px; background: #fafbfc;
        }}
        .severity-critical {{ border-left: 4px solid #dc3545; }}
        .severity-high {{ border-left: 4px solid #fd7e14; }}
        .severity-medium {{ border-left: 4px solid #ffc107; }}
        .severity-low {{ border-left: 4px solid #28a745; }}
        .issue-header {{ display: flex; justify-content: space-between; align-items: center; }}
        .issue-details {{ margin-top: 10px; font-size: 0.9em; color: #6c757d; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ Performance Optimization Report</h1>
            <p>Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="summary">
            <div class="summary-card">
                <h3>ì´ ì´ìŠˆ</h3>
                <h2>{summary['total_issues']}</h2>
            </div>
            <div class="summary-card">
                <h3>Critical</h3>
                <h2 style="color: #dc3545;">{summary['critical_issues']}</h2>
            </div>
            <div class="summary-card">
                <h3>High</h3>
                <h2 style="color: #fd7e14;">{summary['high_issues']}</h2>
            </div>
            <div class="summary-card">
                <h3>Medium</h3>
                <h2 style="color: #ffc107;">{summary['medium_issues']}</h2>
            </div>
            <div class="summary-card">
                <h3>Low</h3>
                <h2 style="color: #28a745;">{summary['low_issues']}</h2>
            </div>
        </div>
        
        <div class="issue-list">
            <h3>ğŸ“‹ ìµœì í™” ê¸°íšŒ</h3>
"""

        for issue in issues:
            html_content += f"""
            <div class="issue-item severity-{issue['severity']}">
                <div class="issue-header">
                    <strong>{issue['description']}</strong>
                    <span class="badge">{issue['severity'].upper()}</span>
                </div>
                <div class="issue-details">
                    <p><strong>íŒŒì¼:</strong> {issue['file_path']}:{issue['line_number']}</p>
                    <p><strong>í•¨ìˆ˜:</strong> {issue['function_name']}</p>
                    <p><strong>ê¶Œì¥ì‚¬í•­:</strong> {issue['suggested_optimization']}</p>
                    <p><strong>ì˜ˆìƒ ê°œì„ :</strong> {issue['estimated_improvement']}</p>
                </div>
            </div>
"""

        html_content += """
        </div>
    </div>
</body>
</html>
"""

        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_content)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="Echo Performance Optimizer")
    parser.add_argument(
        "--project-dir", default=".", help="Project directory to analyze"
    )
    parser.add_argument(
        "--output",
        default="performance_optimization_report.json",
        help="Output report file",
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose logging")

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=level, format="%(asctime)s - %(levelname)s - %(message)s")

    # ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
    optimizer = PerformanceOptimizer(args.project_dir)
    results = optimizer.generate_optimization_report(args.output)

    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    summary = results["optimization_summary"]
    print(f"\\nğŸš€ Performance Analysis Results:")
    print(f"   ğŸ“ Analyzed Files: {results['analyzed_files']}")
    print(f"   ğŸ¯ Total Issues: {summary['total_issues']}")
    print(f"   ğŸ”¥ Critical: {summary['critical_issues']}")
    print(f"   âš ï¸  High: {summary['high_issues']}")
    print(f"   ğŸ“‹ Medium: {summary['medium_issues']}")
    print(f"   â„¹ï¸  Low: {summary['low_issues']}")

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    if summary["category_breakdown"]:
        print(f"\\nğŸ“Š Issues by Category:")
        for category, count in summary["category_breakdown"].items():
            print(f"   {category}: {count}")

    return 0 if summary["total_issues"] == 0 else 1


if __name__ == "__main__":
    exit(main())
