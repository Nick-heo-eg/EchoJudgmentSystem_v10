#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stage 2 ìˆ˜ìˆ : Tag I/O ì§‘ì¤‘ ê°ì¶• ì‹œìŠ¤í…œ
mtime ê¸°ë°˜ íƒœê·¸ ìºì‹±ìœ¼ë¡œ ë°˜ë³µ íŒŒì¼ ì½ê¸° ì œê±°
# @owner: nick
# @expose
# @maturity: stable
"""
import json
import pickle
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict

ROOT = Path(__file__).resolve().parents[2]
CACHE_DIR = ROOT / "tools" / "cache"
CACHE_DIR.mkdir(exist_ok=True)


@dataclass
class TagCacheEntry:
    file_path: str
    mtime: float
    tags: Dict[str, Any]
    file_size: int


class TagIndex:
    """mtime ê¸°ë°˜ íƒœê·¸ ìºì‹± ì‹œìŠ¤í…œ - Stage 2 í˜ˆê´€ ìˆ˜ìˆ """

    def __init__(self):
        self.cache_file = CACHE_DIR / "tag_index.pkl"
        self.cache: Dict[str, TagCacheEntry] = self._load_cache()
        self.hits = 0  # ìºì‹œ íˆíŠ¸
        self.misses = 0  # ìºì‹œ ë¯¸ìŠ¤

    def _load_cache(self) -> Dict[str, TagCacheEntry]:
        """ìºì‹œ ë¡œë“œ (ë°”ì´ë„ˆë¦¬ pickle ì‚¬ìš©ìœ¼ë¡œ I/O ìµœì†Œí™”)"""
        if not self.cache_file.exists():
            return {}

        try:
            with open(self.cache_file, "rb") as f:
                data = pickle.load(f)
                return {k: TagCacheEntry(**v) for k, v in data.items()}
        except Exception:
            return {}

    def _save_cache(self):
        """ìºì‹œ ì €ì¥ (ë¹„ë™ê¸°ì  ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ ê³ ë ¤)"""
        try:
            data = {k: asdict(v) for k, v in self.cache.items()}
            with open(self.cache_file, "wb") as f:
                pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
        except Exception as e:
            print(f"íƒœê·¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def get_tags(self, file_path: Path) -> Dict[str, Any]:
        """íƒœê·¸ ì¡°íšŒ - mtime ê¸°ë°˜ ìºì‹œ ìš°ì„  ê²€ì‚¬"""
        key = str(file_path.relative_to(ROOT))

        try:
            stat = file_path.stat()
            current_mtime = stat.st_mtime
            current_size = stat.st_size
        except (OSError, ValueError):
            return {}

        # ìºì‹œ íˆíŠ¸ ê²€ì‚¬
        if key in self.cache:
            cached = self.cache[key]
            if cached.mtime == current_mtime and cached.file_size == current_size:
                self.hits += 1
                return cached.tags.copy()

        # ìºì‹œ ë¯¸ìŠ¤ - ì‹¤ì œ íŒŒì¼ ì½ê¸°
        self.misses += 1
        tags = self._extract_tags_from_file(file_path)

        # ìºì‹œ ì—…ë°ì´íŠ¸
        self.cache[key] = TagCacheEntry(
            file_path=key, mtime=current_mtime, tags=tags, file_size=current_size
        )

        return tags

    def _extract_tags_from_file(self, path: Path) -> Dict[str, Any]:
        """ì‹¤ì œ íŒŒì¼ì—ì„œ íƒœê·¸ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§)"""
        try:
            txt = path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            return {}

        head = "\n".join(txt.splitlines()[:80])  # ìƒë‹¨ 80ì¤„ë§Œ ìŠ¤ìº”
        tags: Dict[str, Any] = {}

        import re

        if re.search(r"^\s*#\s*@expose\b", head, re.M):
            tags["expose"] = True
        m_owner = re.search(r"^\s*#\s*@owner:\s*([A-Za-z0-9_\-\.]+)", head, re.M)
        if m_owner:
            tags["owner"] = m_owner.group(1)
        m_maturity = re.search(
            r"^\s*#\s*@maturity:\s*(stable|beta|experimental|deprecated)",
            head,
            re.I | re.M,
        )
        if m_maturity:
            tags["maturity"] = m_maturity.group(1).lower()

        return tags

    def batch_update(self, file_paths: list[Path]):
        """ë°°ì¹˜ ì—…ë°ì´íŠ¸ - ì—¬ëŸ¬ íŒŒì¼ì˜ íƒœê·¸ë¥¼ í•œë²ˆì— ì²˜ë¦¬"""
        for path in file_paths:
            self.get_tags(path)  # ìºì‹œ ê°±ì‹ 

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ ì„±ëŠ¥ í†µê³„"""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0

        return {
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": f"{hit_rate:.1f}%",
            "cache_entries": len(self.cache),
            "cache_size_kb": (
                self.cache_file.stat().st_size // 1024
                if self.cache_file.exists()
                else 0
            ),
        }

    def cleanup_stale(self):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ì˜ ìºì‹œ ì—”íŠ¸ë¦¬ ì •ë¦¬"""
        stale_keys = []
        for key in self.cache.keys():
            file_path = ROOT / key
            if not file_path.exists():
                stale_keys.append(key)

        for key in stale_keys:
            del self.cache[key]

        if stale_keys:
            self._save_cache()

    def flush(self):
        """ìºì‹œë¥¼ ë””ìŠ¤í¬ì— ê°•ì œ ì €ì¥"""
        self._save_cache()


# ì „ì—­ íƒœê·¸ ì¸ë±ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_tag_index: Optional[TagIndex] = None


def get_tag_index() -> TagIndex:
    """íƒœê·¸ ì¸ë±ìŠ¤ ì‹±ê¸€í†¤ ì ‘ê·¼"""
    global _tag_index
    if _tag_index is None:
        _tag_index = TagIndex()
    return _tag_index


def extract_tags_cached(path: Path) -> Dict[str, Any]:
    """ìºì‹±ëœ íƒœê·¸ ì¶”ì¶œ - feature_mapper.pyì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜"""
    return get_tag_index().get_tags(path)


if __name__ == "__main__":
    # íƒœê·¸ ì¸ë±ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    from rich.console import Console

    console = Console()

    index = get_tag_index()

    # ëª¨ë“  Python íŒŒì¼ì— ëŒ€í•´ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    test_files = list(ROOT.rglob("*.py"))[:100]  # 100ê°œ íŒŒì¼ë¡œ ì œí•œ

    console.print(f"[blue]ğŸ§ª íƒœê·¸ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: {len(test_files)}ê°œ íŒŒì¼[/blue]")

    # ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤)
    for path in test_files:
        index.get_tags(path)

    stats1 = index.get_stats()
    console.print(f"[yellow]1ì°¨ ì‹¤í–‰ (ìºì‹œ êµ¬ì¶•): {stats1}[/yellow]")

    # ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸)
    for path in test_files:
        index.get_tags(path)

    stats2 = index.get_stats()
    console.print(f"[green]2ì°¨ ì‹¤í–‰ (ìºì‹œ í™œìš©): {stats2}[/green]")

    index.flush()
    console.print("[cyan]âœ… ìºì‹œ ë””ìŠ¤í¬ ì €ì¥ ì™„ë£Œ[/cyan]")
