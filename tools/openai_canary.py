#!/usr/bin/env python3
"""
ğŸ¦ OpenAI API Canary Test
ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ OpenAI ìŠ¤íŠ¸ë¦¬ë° ì—°ê²° í…ŒìŠ¤íŠ¸

- TTI (Time To First Token) ì¸¡ì •
- ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ì„±ëŠ¥ ê²€ì¦
- STDOUT/STDERR ë¶„ë¦¬ ì¶œë ¥
- í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •

Usage:
    source .env && python tools/openai_canary.py
    CANARY_PROMPT="test message" python tools/openai_canary.py
"""

import os
import sys
import time
import io
from datetime import datetime
from openai import OpenAI

# í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì•ˆì „ ë˜í•‘ (ì„ íƒ)
try:
    sys.stdout = io.TextIOWrapper(
        sys.stdout.detach(), encoding="utf-8", errors="replace"
    )
    sys.stderr = io.TextIOWrapper(
        sys.stderr.detach(), encoding="utf-8", errors="replace"
    )
except Exception:
    pass  # ì¼ë¶€ í™˜ê²½ì—ì„œ detach ë¶ˆê°€ â†’ ì•„ë˜ buffer.write ê²½ë¡œë¡œ ìš°íšŒ


def _safe_write(s: str):
    """ì•ˆì „í•œ STDOUT ì¶œë ¥ (UTF-8 ë°”ì´ë„ˆë¦¬ ìš°íšŒ)"""
    if not isinstance(s, str):
        s = str(s)
    try:
        # í…ìŠ¤íŠ¸ ê²½ë¡œ ì‹œë„
        print(s, end="", flush=True)
    except UnicodeEncodeError:
        # ìµœí›„: ë°”ì´ë„ˆë¦¬ ê²½ë¡œ (ê¶Œì¥)
        sys.stdout.buffer.write(s.encode("utf-8", errors="replace"))
        sys.stdout.flush()


def _safe_err(s: str):
    """ì•ˆì „í•œ STDERR ì¶œë ¥ (UTF-8 ë°”ì´ë„ˆë¦¬ ìš°íšŒ)"""
    if not isinstance(s, str):
        s = str(s)
    try:
        print(s, end="", file=sys.stderr, flush=True)
    except UnicodeEncodeError:
        sys.stderr.buffer.write(str(s).encode("utf-8", errors="replace"))
        sys.stderr.flush()


MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")


def main():
    """OpenAI API ìºë‚˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        client = OpenAI()
    except Exception as e:
        print(f"[canary-err] OpenAI client init failed: {e}", file=sys.stderr)
        return 2

    # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
    prompt = os.environ.get("CANARY_PROMPT", "Echoê°€ ê¹¨ì–´ìˆë‹¤ë¥¼ 10ì ë‚´ë¡œ.")

    # ì‹œì‘ ë¡œê·¸ (STDERR)
    t0 = time.time()
    _safe_err(f"[canary] {MODEL} @ {datetime.now().isoformat(timespec='seconds')}\n")
    _safe_err(f"[canary] prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\n")

    first_token_time = None
    token_count = 0

    try:
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
        response = client.chat.completions.create(
            model=MODEL,
            messages=[{"role": "user", "content": prompt}],
            stream=True,
            max_tokens=100,
            temperature=0.7,
        )

        # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì•ˆì „í•œ ì¶œë ¥)
        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content

                # ì²« í† í° ì‹œê°„ ê¸°ë¡
                if first_token_time is None:
                    first_token_time = time.time()

                # ì•ˆì „í•œ ì¶œë ¥ (UTF-8 ë°”ì´ë„ˆë¦¬ ìš°íšŒ)
                _safe_write(content)

                token_count += 1

        # ì¤„ë°”ê¿ˆ ì¶”ê°€
        _safe_write("\n")

    except Exception as e:
        _safe_err(f"\n[canary-err] Streaming failed: {e}\n")
        return 2

    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ì¶œë ¥ (STDERR)
    total_duration = time.time() - t0
    tti = (first_token_time - t0) if first_token_time else -1

    _safe_err(
        f"[canary] TTI={tti:.2f}s | DUR={total_duration:.2f}s | chunks={token_count}\n"
    )

    # ì„±ëŠ¥ í‰ê°€
    if tti < 0:
        _safe_err("[canary] âŒ No response received\n")
        return 1
    elif tti > 5.0:
        _safe_err("[canary] âš ï¸  Slow TTI (>5s)\n")
        return 1
    elif tti > 2.0:
        _safe_err("[canary] ğŸŸ¡ Acceptable TTI (<5s)\n")
    else:
        _safe_err("[canary] âœ… Fast TTI (<2s)\n")

    _safe_err(f"[canary] âœ… OpenAI streaming operational\n")
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        _safe_err("\n[canary] â¹ï¸  Interrupted by user\n")
        sys.exit(1)
    except Exception as e:
        _safe_err(f"[canary-err] Unexpected error: {e}\n")
        sys.exit(2)
