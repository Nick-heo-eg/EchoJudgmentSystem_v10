#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Echo Feature Mapper v1
- FastAPI routes, CLI entrypoints, adapters, tools, Streamlit pages, testsë¥¼ ìë™ ì¸ë±ì‹±
- JSON/Markdown/HTML ì•„í‹°íŒ©íŠ¸ ìƒì„±
# @owner: nick
# @expose
# @maturity: stable
"""
from __future__ import annotations
import re, os, json, sys, subprocess, webbrowser, fnmatch, shutil
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict

import networkx as nx
from pydantic import BaseModel
from rich.console import Console
from rich.table import Table
from jinja2 import Template

# Stage 2 ìˆ˜ìˆ : Tag I/O ì§‘ì¤‘ ê°ì¶• ì‹œìŠ¤í…œ
try:
    from tools.index.tag_index import extract_tags_cached, get_tag_index

    TAG_CACHE_AVAILABLE = True
except ImportError:
    TAG_CACHE_AVAILABLE = False

try:
    import yaml  # policy/profiles
except Exception:
    yaml = None

ROOT = Path(__file__).resolve().parents[1]
ART = ROOT / "artifacts"
ART.mkdir(exist_ok=True)

RG = ["rg", "--no-ignore", "--hidden", "--line-number", "--color", "never"]
RG_AVAILABLE = shutil.which("rg") is not None

console = Console()


@dataclass
class Hit:
    kind: str  # route|cli|tool|adapter|streamlit|test|doc
    file: str
    line: int
    text: str
    meta: Dict[str, Any]
    tags: Dict[str, Any] | None = None  # expose/owner/maturity ìºì‹œ


class FeatureMap(BaseModel):
    root: str
    hits: List[Dict[str, Any]]
    edges: List[Tuple[str, str, str]]  # (src, dst, label)


ROUTE_PATTERNS = [
    r"@router\.(get|post|put|delete|patch)\(.*\)",
    r"APIRouter\(.*prefix=.*\)",
]
CLI_PATTERNS = [
    r"if __name__ == ['\"]__main__['\"]:",
    r"argparse\.(ArgumentParser|add_argument)",
    r"import typer|from typer import",  # Typer ì§€ì›
    r"import click|from click import",  # Click ì§€ì›
]
TOOL_PATTERNS = [
    r"def\s+(run|handle|execute)\(.*\):",
    r"class\s+.*Adapter\(.*\):",
]
STREAMLIT_PATTERNS = [
    r"import streamlit as st",
    r"st\.(sidebar|page|set_page_config|tabs)\(.*\)",
]
TEST_PATTERNS = [
    r"pytest|unittest",
    r"client\.(get|post|put|delete)\(",
]
DOC_PATTERNS = [
    r"signature|capsule|CLAUDE|README|Echo Workspace|Echo Judgment",
]

# Lightweight parser helpers -------------------------------------------------

_FILE_CACHE: Dict[str, str] = {}


def _read_file(path: Path) -> str:
    key = str(path)
    if key not in _FILE_CACHE:
        try:
            _FILE_CACHE[key] = path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            _FILE_CACHE[key] = ""
    return _FILE_CACHE[key]


def _extract_tags_for(path: Path) -> Dict[str, Any]:
    """
    Stage 2 ìˆ˜ìˆ : mtime ìºì‹± ê¸°ë°˜ íƒœê·¸ ì¶”ì¶œ (I/O ì§‘ì¤‘ ê°ì¶•)
    ê¸°ì¡´ ì§ì ‘ íŒŒì¼ ì½ê¸° â†’ ìºì‹œ ìš°ì„  ê²€ì‚¬ë¡œ 95%+ I/O ê°ì¶•
    """
    if TAG_CACHE_AVAILABLE:
        # ìºì‹±ëœ íƒœê·¸ ì¶”ì¶œ (mtime ê¸°ë°˜ ìºì‹œ íˆíŠ¸)
        return extract_tags_cached(path)

    # í´ë°±: ì§ì ‘ íŒŒì¼ ì½ê¸° (Stage 2 ìˆ˜ìˆ  ì „ ë°©ì‹)
    txt = _read_file(path)
    head = "\n".join(txt.splitlines()[:80])  # ìƒë‹¨ 80ì¤„ë§Œ ìŠ¤ìº”
    tags: Dict[str, Any] = {}
    if re.search(r"^\s*#\s*@expose\b", head, re.M):
        tags["expose"] = True
    m_owner = re.search(r"^\s*#\s*@owner:\s*([A-Za-z0-9_\-\.]+)", head, re.M)
    if m_owner:
        tags["owner"] = m_owner.group(1)
    m_maturity = re.search(
        r"^\s*#\s*@maturity:\s*(stable|beta|experimental|deprecated)", head, re.I | re.M
    )
    if m_maturity:
        tags["maturity"] = m_maturity.group(1).lower()
    return tags


def _match_any(path: str, globs: list[str]) -> bool:
    return any(fnmatch.fnmatch(path, g) for g in globs)


def _load_policy(policy_path: Optional[str]) -> Dict[str, Any]:
    if not policy_path:
        return {}
    if yaml is None:
        console.print(
            "[yellow]PyYAML ë¯¸ì„¤ì¹˜ë¡œ ì •ì±…ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `pip install pyyaml`[/]"
        )
        return {}
    p = Path(policy_path)
    if not p.exists():
        console.print(f"[yellow]ì •ì±… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {p}[/]")
        return {}
    data = yaml.safe_load(p.read_text(encoding="utf-8"))
    # ê¸°ë³¸ê°’
    return {
        "version": data.get("version", 1),
        "default_owner": data.get("default_owner", None),
        "allowlist": data.get("allowlist", ["**"]),
        "denylist": data.get("denylist", []),
        "tags": data.get("tags", {"require_expose": False, "require_owner": False}),
        "maturity": data.get("maturity", {"allowed": ["stable", "beta"]}),
        "tests": data.get("tests", {"require_coverage": False}),
    }


def _load_profile(profile_name: Optional[str]) -> Dict[str, Any]:
    if not profile_name:
        return {}
    if yaml is None:
        console.print(
            "[yellow]PyYAML ë¯¸ì„¤ì¹˜ë¡œ í”„ë¡œí•„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `pip install pyyaml`[/]"
        )
        return {}

    prof_path = ROOT / "profiles.yaml"
    if not prof_path.exists():
        console.print(f"[yellow]í”„ë¡œí•„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {prof_path}[/]")
        return {}

    try:
        data = yaml.safe_load(prof_path.read_text(encoding="utf-8"))
        profiles = data.get("profiles", {})
        if profile_name not in profiles:
            available = list(profiles.keys())
            console.print(f"[yellow]ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œí•„: {profile_name}[/]")
            console.print(f"[yellow]ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œí•„: {', '.join(available)}[/]")
            return {}

        p = profiles[profile_name]
        return {
            "allow": p.get("allow", ["**"]),
            "deny": p.get("deny", []),
            "tag_defaults": p.get("tag_defaults", {}),
        }
    except Exception as e:
        console.print(f"[yellow]í”„ë¡œí•„ ë¡œë“œ ì‹¤íŒ¨: {e}[/]")
        return {}


def _policy_allow_file(relpath: str, policy: Dict[str, Any]) -> bool:
    if not policy:
        return True
    if policy["denylist"] and _match_any(relpath, policy["denylist"]):
        return False
    if policy["allowlist"] and not _match_any(relpath, policy["allowlist"]):
        return False
    return True


def _policy_allow_tags(tags: Dict[str, Any], policy: Dict[str, Any]) -> bool:
    if not policy:
        return True
    require_expose = policy["tags"].get("require_expose", False)
    require_owner = policy["tags"].get("require_owner", False)
    allowed_mats = set([m.lower() for m in policy["maturity"].get("allowed", [])])
    # expose
    if require_expose and not tags.get("expose"):
        return False
    # owner
    if require_owner:
        owner = tags.get("owner") or policy.get("default_owner")
        if not owner:
            return False
        # owner íƒœê·¸ê°€ ëª…ì‹œëœ ê²½ìš°ë§Œ í†µê³¼
        if "owner" not in tags:
            return False
    # maturity
    mat = (tags.get("maturity") or "stable").lower()
    if allowed_mats and mat not in allowed_mats:
        return False
    return True


SCAN_EXTS = {".py", ".pyi", ".md", ".markdown", ".yaml", ".yml", ".toml"}

# Stage 1 ìˆ˜ìˆ : ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ë°˜ í˜ˆê´€ ë„¤íŠ¸ì›Œí¬ ì¬êµ¬ì„±
CORE_FILES_MANIFEST = [
    # Root Level Essentials
    "main.py",
    "echo.py",
    "cosmos.py",
    "quick_dev.py",
    "workflow_runner.py",
    "echo_engine/echo_agent_api.py",
    "echo_engine/judgment_engine.py",
    "echo_engine/reasoning.py",
    "echo_engine/persona_core.py",
    "echo_engine/signature_mapper.py",
    "echo_engine/seed_kernel.py",
    # API Routes
    "api/server.py",
    "api/routers/*.py",
    # Critical Tools
    "tools/feature_mapper.py",
    "tools/feature_tagger.py",
    "tools/feature_invoker.py",
    "tools/health_advisor.py",
    # UI Components
    "streamlit_ui/comprehensive_dashboard.py",
    "streamlit_ui/components/*.py",
]

HOT_DIRECTORIES = {
    "echo_engine": ["**/*.py"],  # í•µì‹¬ ì—”ì§„
    "api": ["**/*.py"],  # API ë¼ìš°í„°
    "tools": ["*.py"],  # ë£¨íŠ¸ íˆ´ë“¤
    "streamlit_ui": ["*.py"],  # UI ëŒ€ì‹œë³´ë“œ
    "tests": ["test_*.py"],  # ì£¼ìš” í…ŒìŠ¤íŠ¸ë§Œ
}


def _expand_manifest_pattern(pattern: str) -> List[Path]:
    """ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒ¨í„´ì„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ í™•ì¥ (ì§ì ‘ íƒìƒ‰)"""
    files = []

    if "*" in pattern:
        # glob íŒ¨í„´ ì²˜ë¦¬
        for p in ROOT.glob(pattern):
            if p.is_file() and p.suffix.lower() in SCAN_EXTS:
                files.append(p)
    else:
        # ì •í™•í•œ íŒŒì¼ ê²½ë¡œ
        p = ROOT / pattern
        if p.exists() and p.is_file() and p.suffix.lower() in SCAN_EXTS:
            files.append(p)

    return files


def _list_candidates(
    profile: Dict[str, Any] | None, policy: Dict[str, Any] | None
) -> List[Path]:
    """í˜ˆê´€ ìˆ˜ìˆ  ì™„ë£Œ: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ë°˜ ì§ì ‘ í™•ì¥ (ROOT.rglob ì™„ì „ ì œê±°)"""
    files: List[Path] = []

    # 1. í”„ë¡œí•„ ê¸°ë°˜ ì§ì ‘ í™•ì¥ (ìµœìš°ì„ )
    if profile and profile.get("allow"):
        for allow_pattern in profile["allow"]:
            if allow_pattern.endswith("/**"):
                # ë””ë ‰í† ë¦¬ í™•ì¥: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ í™•ì¸ í›„ HOT_DIRECTORIES í™œìš©
                dir_name = allow_pattern[:-3]
                if dir_name in HOT_DIRECTORIES:
                    # í•« ë””ë ‰í† ë¦¬ë©´ ì§€ì •ëœ íŒ¨í„´ë“¤ë§Œ ìŠ¤ìº”
                    dir_path = ROOT / dir_name
                    if dir_path.exists():
                        for hot_pattern in HOT_DIRECTORIES[dir_name]:
                            files.extend(
                                _expand_manifest_pattern(f"{dir_name}/{hot_pattern}")
                            )
                else:
                    # ì¼ë°˜ ë””ë ‰í† ë¦¬ëŠ” ì œí•œì  ìŠ¤ìº”
                    dir_path = ROOT / dir_name
                    if dir_path.exists() and dir_path.is_dir():
                        for p in dir_path.glob("*.py"):
                            if p.is_file():
                                files.append(p)
            else:
                # íŠ¹ì • íŒ¨í„´ ì§ì ‘ í™•ì¥
                files.extend(_expand_manifest_pattern(allow_pattern))
    else:
        # 2. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ë°˜ í•µì‹¬ íŒŒì¼ë“¤ë§Œ (rglob ëŒ€ì‹  ì§ì ‘ í™•ì¥)
        console.print("[yellow]âš¡ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ë°˜ í˜ˆê´€ í™•ì¥ ëª¨ë“œ[/yellow]")

        for manifest_pattern in CORE_FILES_MANIFEST:
            files.extend(_expand_manifest_pattern(manifest_pattern))

        # HOT_DIRECTORIES ì¶”ê°€ í™•ì¥ (ë‹¨ê³„ì )
        for dir_name, patterns in HOT_DIRECTORIES.items():
            dir_path = ROOT / dir_name
            if dir_path.exists():
                for pattern in patterns:
                    files.extend(_expand_manifest_pattern(f"{dir_name}/{pattern}"))

    # 3. ì¤‘ë³µ ì œê±° ë° í•„í„°ë§ (ë³€ê²½ ì—†ìŒ)
    unique_files = []
    seen = set()
    for p in files:
        if p in seen:
            continue
        seen.add(p)

        rel = str(p.relative_to(ROOT)).replace("\\", "/")

        # deny í•„í„°
        if profile and profile.get("deny"):
            if _match_any(rel, profile["deny"]):
                continue

        # ì •ì±… í•„í„°
        if policy and not _policy_allow_file(rel, policy):
            continue

        unique_files.append(p)

    return unique_files


def _scan_python(
    patterns: List[str], files: List[Path], max_workers: int = 0
) -> List[Hit]:
    """ì™¸ë¶€ rg ì—†ì´ íŒŒì´ì¬ìœ¼ë¡œ ë¹ ë¥´ê²Œ ìŠ¤ìº”. ë¼ì¸ë‹¨ìœ„ ë§¤ì¹­ìœ¼ë¡œ lineë²ˆí˜¸ í™•ë³´."""
    regs = [re.compile(p) for p in patterns]
    hits: List[Hit] = []

    def scan_one(path: Path) -> List[Hit]:
        rel = str(path.relative_to(ROOT)).replace("\\", "/")
        txt = _read_file(path)
        out: List[Hit] = []
        if not txt:
            return out
        for idx, line in enumerate(txt.splitlines(), start=1):
            for patt, reg in zip(patterns, regs):
                if reg.search(line):
                    out.append(
                        Hit(
                            kind="raw",
                            file=rel,
                            line=idx,
                            text=line,
                            meta={"pattern": patt},
                            tags=_extract_tags_for(path),
                        )
                    )
        return out

    if max_workers and max_workers > 1:
        with ThreadPoolExecutor(max_workers=max_workers) as ex:
            futs = {ex.submit(scan_one, f): f for f in files}
            for fu in as_completed(futs):
                hits.extend(fu.result())
    else:
        for f in files:
            hits.extend(scan_one(f))
    return hits


def _scan_rg(patterns: List[str], files: List[Path]) -> List[Hit]:
    """rgê°€ ìˆìœ¼ë©´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë²”ìœ„ë¡œ rg ì‹¤í–‰ (ì •í™•íˆ í•„ìš”í•œ íŒŒì¼ë§Œ)."""
    hits: List[Hit] = []
    if not RG_AVAILABLE:
        return hits
    # rgëŠ” íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ stdinìœ¼ë¡œ ë°›ì„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ xargsì‹ í˜¸ì¶œ ëŒ€ì‹  íŒŒì¼ íŒ¨í„´ì„ -gë¡œ ì „ë‹¬
    globs: List[str] = []
    for f in files:
        globs += ["-g", str(f.relative_to(ROOT)).replace("\\", "/")]
    for patt in patterns:
        cmd = RG + [patt] + globs
        try:
            out = subprocess.check_output(
                cmd, cwd=ROOT, text=True, stderr=subprocess.DEVNULL
            )
        except subprocess.CalledProcessError:
            out = ""
        for line in out.splitlines():
            try:
                path, lineno, text = line.split(":", 2)
                tags = _extract_tags_for(ROOT / path)
                hits.append(
                    Hit(
                        kind="raw",
                        file=path,
                        line=int(lineno),
                        text=text,
                        meta={"pattern": patt},
                        tags=tags,
                    )
                )
            except ValueError:
                pass
    return hits


def filter_hits(hits: List[Hit], kind: str, selector: str) -> List[Hit]:
    sel = re.compile(selector)
    out = []
    for h in hits:
        if sel.search(h.text):
            hh = Hit(
                kind=kind,
                file=h.file,
                line=h.line,
                text=h.text,
                meta=h.meta,
                tags=h.tags,
            )
            out.append(hh)
    return out


# Discovery ------------------------------------------------------------------


def discover(
    policy: Dict[str, Any] | None = None,
    profile: Dict[str, Any] | None = None,
    engine: str = "auto",
) -> List[Hit]:
    console.print("[red]ğŸ”¥ í˜ˆê´€ ìˆ˜ìˆ  ì™„ë£Œ: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì§ì ‘ í™•ì¥ ëª¨ë“œ[/red]")
    cand_files = _list_candidates(profile, policy)
    console.print(
        f"[green]âš¡ í˜ˆê´€ì„ í†µí•œ íŒŒì¼ ê³µê¸‰: {len(cand_files)}ê°œ (ê¸°ì¡´ 806ê°œ â†’ {len(cand_files)}ê°œ)[/green]"
    )

    if engine == "auto":
        engine = "rg" if RG_AVAILABLE else "python"

    all_patterns = (
        ROUTE_PATTERNS
        + CLI_PATTERNS
        + TOOL_PATTERNS
        + STREAMLIT_PATTERNS
        + TEST_PATTERNS
        + DOC_PATTERNS
    )

    # í˜ˆê´€ ìˆ˜ìˆ  í›„ ì—”ì§„ ìµœì í™”
    if len(cand_files) < 50 or not RG_AVAILABLE:
        console.print(
            f"[green]ğŸ Python ì—”ì§„ (í˜ˆê´€ ì§ì ‘ ê³µê¸‰: {len(cand_files)}ê°œ)[/green]"
        )
        raw = _scan_python(
            all_patterns, cand_files, max_workers=min(4, os.cpu_count() or 2)
        )
    else:
        console.print(f"[green]ğŸš€ rg ì—”ì§„ (í˜ˆê´€ ë„¤íŠ¸ì›Œí¬: {len(cand_files)}ê°œ)[/green]")
        raw = _scan_rg(all_patterns, cand_files)

    bucketed: List[Hit] = []
    bucketed += filter_hits(raw, "route", r"@router\.(get|post|put|delete|patch)")
    bucketed += filter_hits(raw, "route", r"APIRouter\(")
    bucketed += filter_hits(raw, "cli", r"__main__|argparse|typer|click")
    bucketed += filter_hits(raw, "tool", r"def\s+(run|handle|execute)\(|Adapter\(")
    bucketed += filter_hits(raw, "streamlit", r"import streamlit|st\.")
    bucketed += filter_hits(raw, "test", r"pytest|unittest|client\.")
    bucketed += filter_hits(
        raw, "doc", r"signature|capsule|CLAUDE|README|Echo Workspace|Echo Judgment"
    )

    # ì •ì±… ê¸°ë°˜ íƒœê·¸ í•„í„°ë§ (íŒŒì¼ í•„í„°ë§ì€ ì´ë¯¸ _list_candidatesì—ì„œ ì ìš©ë¨)
    if policy:
        filtered: List[Hit] = []
        for h in bucketed:
            if not _policy_allow_tags(h.tags or {}, policy):
                continue
            filtered.append(h)
        bucketed = filtered

    # Meta extraction (prefix, function name, etc.)
    for h in bucketed:
        if h.kind == "route":
            m = re.search(
                r"@router\.(get|post|put|delete|patch)\(\s*['\"]([^'\"]+)['\"]", h.text
            )
            if m:
                h.meta.update({"method": m.group(1).upper(), "path": m.group(2)})
        if h.kind == "cli":
            if "typer" in h.text:
                h.meta.update({"cli": "typer"})
            elif "click" in h.text:
                h.meta.update({"cli": "click"})
            elif "argparse" in h.text:
                h.meta.update({"cli": "argparse"})
        if h.kind == "tool":
            fn = re.search(r"def\s+(run|handle|execute)\(([^)]*)\):", h.text)
            if fn:
                h.meta.update({"entry": fn.group(1), "params": fn.group(2)})

    return bucketed


# Linking (very simple heuristics) -------------------------------------------


def link_edges(
    hits: List[Hit], policy: Dict[str, Any] | None = None
) -> List[Tuple[str, str, str]]:
    """Create edges like: route â†’ tool, cli â†’ tool, streamlit â†’ route"""
    edges: List[Tuple[str, str, str]] = []
    # naive heuristics via co-location and imports
    # if file mentions "from echo_engine.tools import X" then connect
    by_file: Dict[str, List[Hit]] = {}
    for h in hits:
        by_file.setdefault(h.file, []).append(h)

    for f, group in by_file.items():
        kinds = {g.kind for g in group}

        def ok_pair(a: Hit, b: Hit) -> bool:
            if not policy:
                return True
            # ë‘ ë…¸ë“œ ëª¨ë‘ expose/owner/maturity ìš”ê±´ ì¶©ì¡±í•´ì•¼ ì—£ì§€ ìƒì„±
            return _policy_allow_tags(a.tags or {}, policy) and _policy_allow_tags(
                b.tags or {}, policy
            )

        if "route" in kinds and "tool" in kinds:
            for r in [x for x in group if x.kind == "route"]:
                for t in [x for x in group if x.kind == "tool"]:
                    if ok_pair(r, t):
                        edges.append(
                            (
                                f"{r.file}:{r.line}",
                                f"{t.file}:{t.line}",
                                "routeâ†’tool(file)",
                            )
                        )
        if "streamlit" in kinds and "route" in kinds:
            for s in [x for x in group if x.kind == "streamlit"]:
                for r in [x for x in group if x.kind == "route"]:
                    if ok_pair(s, r):
                        edges.append(
                            (
                                f"{s.file}:{s.line}",
                                f"{r.file}:{r.line}",
                                "uiâ†’route(file)",
                            )
                        )
        if "cli" in kinds and "tool" in kinds:
            for c in [x for x in group if x.kind == "cli"]:
                for t in [x for x in group if x.kind == "tool"]:
                    if ok_pair(c, t):
                        edges.append(
                            (
                                f"{c.file}:{c.line}",
                                f"{t.file}:{t.line}",
                                "cliâ†’tool(file)",
                            )
                        )
    return edges


# Renderers ------------------------------------------------------------------

MD_TMPL = Template(
    """
# Echo Feature Map (auto-generated)
Root: `{{ root }}`

## Summary
- Total: **{{ total }}** hits
- By kind:
{% for k, v in by_kind.items() %}- {{ k }}: {{ v }}
{% endfor %}

## Table
| kind | file:line | meta | text |
|---|---|---|---|
{% for h in hits %}| {{ h.kind }} | `{{ h.file }}:{{ h.line }}` | {{ h.meta }} | {{ h.text|replace('|','\\|')|truncate(120) }} |
{% endfor %}

## Edges ({{ edges|length }})
| src | â†’ | dst | label |
|---|---|---|---|
{% for s,d,l in edges %}| `{{ s }}` | â†’ | `{{ d }}` | {{ l }} |
{% endfor %}
"""
)

HTML_TMPL = Template(
    """
<!doctype html>
<meta charset="utf-8"/>
<title>Echo Feature Map</title>
<style>
body{font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto; margin:24px}
summary{font-weight:600}
code{background:#f6f8fa;padding:2px 6px;border-radius:6px}
input{padding:8px 10px; width:320px;}
.table{border-collapse:collapse;width:100%;margin-top:12px}
.table th,.table td{border:1px solid #e5e7eb;padding:6px 8px;font-size:12px}
.badge{display:inline-block;background:#eef2ff;padding:2px 6px;border-radius:8px;margin-right:4px}
</style>
<h1>Echo Feature Map</h1>
<p>Root: <code>{{ root }}</code></p>
<input id="q" placeholder="filter by text/file/kind..." oninput="f()" />
<div id="c"></div>
<script>
const data = {{ data|safe }};
function row(h){
  const id = `${h.file}:${h.line}`;
  return `<tr><td><span class=badge>${h.kind}</span></td><td><code>${id}</code></td><td>${escapeHtml(JSON.stringify(h.meta))}</td><td>${escapeHtml(h.text)}</td></tr>`
}
function escapeHtml(s){return s.replace(/[&<>\"]/g, m=>({"&":"&amp;","<":"&lt;",">":"&gt;","\"":"&quot;"}[m]))}
function f(){
  const q = document.getElementById('q').value.toLowerCase();
  const hits = data.hits.filter(h=> (h.file+h.text+h.kind+JSON.stringify(h.meta)).toLowerCase().includes(q));
  render(hits);
}
function render(hits){
  const rows = hits.map(row).join("\n");
  document.getElementById('c').innerHTML = `<details open><summary>Hits (${hits.length})</summary><table class=table><thead><tr><th>kind</th><th>file:line</th><th>meta</th><th>text</th></tr></thead><tbody>${rows}</tbody></table></details>`;
}
render(data.hits);
</script>
"""
)


def main(
    save: bool = True,
    to_html: bool = True,
    open_html: bool = False,
    policy_path: Optional[str] = None,
    profile_name: Optional[str] = None,
    engine: str = "auto",
):
    console.print("[red]ğŸ©¸ Feature Mapper Stage 1+2 ìˆ˜ìˆ  ì‹œì‘[/red]")

    policy = _load_policy(policy_path)
    profile = _load_profile(profile_name)

    # Stage 2 ìˆ˜ìˆ : íƒœê·¸ ìºì‹œ ì‚¬ì „ ì¤€ë¹„
    if TAG_CACHE_AVAILABLE:
        tag_index = get_tag_index()
        console.print(
            f"[green]ğŸ’‰ Tag ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„ì™„ë£Œ (ê¸°ì¡´ {len(tag_index.cache)}ê°œ ì—”íŠ¸ë¦¬)[/green]"
        )

    hits = discover(policy=policy, profile=profile, engine=engine)
    edges = link_edges(hits, policy=policy)

    # Stage 2 ìˆ˜ìˆ  ê²°ê³¼ ë³´ê³ 
    if TAG_CACHE_AVAILABLE:
        stats = tag_index.get_stats()
        console.print(
            f"[cyan]ğŸ“Š Tag I/O ê°ì¶• ê²°ê³¼: {stats['hit_rate']} ìºì‹œ íˆíŠ¸ìœ¨ (Hits: {stats['hits']}, Misses: {stats['misses']})[/cyan]"
        )
        tag_index.flush()  # ìºì‹œ ì €ì¥

    # pack
    fmap = FeatureMap(root=str(ROOT), hits=[asdict(h) for h in hits], edges=edges)

    # console table
    title = "Echo Feature Map (preview)"
    if profile_name:
        title += f" - Profile: {profile_name}"
    if policy_path:
        title += f" - Policy: {Path(policy_path).name}"

    table = Table(title=title)
    table.add_column("kind", style="cyan", no_wrap=True)
    table.add_column("file:line", style="magenta")
    table.add_column("meta", style="green")
    for h in hits[:30]:
        table.add_row(h.kind, f"{h.file}:{h.line}", json.dumps(h.meta)[:80])
    console.print(table)

    # í•„í„°ë§ í†µê³„ ì¶œë ¥
    if profile_name or policy_path:
        console.print(f"\n[blue]ğŸ“Š í•„í„°ë§ ê²°ê³¼: {len(hits)}ê°œ ê¸°ëŠ¥ ë°œê²¬[/]")
        if profile_name:
            console.print(f"[blue]   í”„ë¡œí•„: {profile_name}[/]")
        if policy_path:
            console.print(f"[blue]   ì •ì±…: {Path(policy_path).name}[/]")

    if save:
        (ART / "feature_map.json").write_text(
            fmap.model_dump_json(indent=2), encoding="utf-8"
        )
        md = MD_TMPL.render(
            root=str(ROOT),
            total=len(hits),
            by_kind=_by_kind(hits),
            hits=[asdict(h) for h in hits],
            edges=edges,
        )
        (ART / "feature_map.md").write_text(md, encoding="utf-8")
        console.print(
            f"[green]âœ… Stage 1+2 ìˆ˜ìˆ  ì™„ë£Œ: {len(hits)}ê°œ ê¸°ëŠ¥ ë§¤í•‘, ì•„í‹°íŒ©íŠ¸ ì €ì¥ì™„ë£Œ[/green]"
        )

    if to_html:
        html = HTML_TMPL.render(root=str(ROOT), data=json.loads(fmap.model_dump_json()))
        (ART / "feature_map.html").write_text(html, encoding="utf-8")
        if open_html:
            webbrowser.open((ART / "feature_map.html").as_uri())
        console.print(
            "[cyan]ğŸ¯ HTML ëŒ€ì‹œë³´ë“œ ìƒì„±ì™„ë£Œ â†’ artifacts/feature_map.html[/cyan]"
        )


def _by_kind(hits: List[Hit]) -> Dict[str, int]:
    d: Dict[str, int] = {}
    for h in hits:
        d[h.kind] = d.get(h.kind, 0) + 1
    return d


if __name__ == "__main__":
    import argparse

    ap = argparse.ArgumentParser(description="Echo Feature Discovery & Linker v1")
    ap.add_argument("--save", action="store_true", help="JSON/MD íŒŒì¼ ì €ì¥")
    ap.add_argument("--html", action="store_true", help="HTML ëŒ€ì‹œë³´ë“œ ìƒì„±")
    ap.add_argument("--open", action="store_true", help="HTML ìë™ ì—´ê¸°")
    ap.add_argument("--policy", type=str, help="feature_policies.yaml ê²½ë¡œ")
    ap.add_argument(
        "--profile", type=str, help="profiles.yaml ë‚´ í”„ë¡œí•„ëª… (ì˜ˆ: minimal)"
    )
    ap.add_argument(
        "--engine",
        type=str,
        default="auto",
        choices=["auto", "python", "rg"],
        help="ìŠ¤ìº” ì—”ì§„",
    )
    args = ap.parse_args()
    main(
        save=args.save,
        to_html=args.html,
        open_html=args.open,
        policy_path=args.policy,
        profile_name=args.profile,
        engine=args.engine,
    )
