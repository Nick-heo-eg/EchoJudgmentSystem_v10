#!/usr/bin/env python3
"""
ğŸ¦ OpenAI API Simple Canary
UTF-8 ì•ˆì „ OpenAI ì—°ê²° í…ŒìŠ¤íŠ¸
"""

import os
import sys
import time
import io
from openai import OpenAI

# í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì•ˆì „ ë˜í•‘
try:
    sys.stdout = io.TextIOWrapper(
        sys.stdout.detach(), encoding="utf-8", errors="replace"
    )
    sys.stderr = io.TextIOWrapper(
        sys.stderr.detach(), encoding="utf-8", errors="replace"
    )
except Exception:
    pass


def _safe_out(s: str):
    """ì•ˆì „í•œ STDOUT ì¶œë ¥"""
    try:
        print(s, end="", flush=True)
    except UnicodeEncodeError:
        sys.stdout.buffer.write(str(s).encode("utf-8", errors="replace"))
        sys.stdout.flush()


def _safe_err(s: str):
    """ì•ˆì „í•œ STDERR ì¶œë ¥"""
    try:
        print(s, end="", file=sys.stderr, flush=True)
    except UnicodeEncodeError:
        sys.stderr.buffer.write(str(s).encode("utf-8", errors="replace"))
        sys.stderr.flush()


def main():
    _safe_err("[canary] Testing OpenAI connection...\n")

    try:
        client = OpenAI()  # í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì‚¬ìš©

        prompt = os.getenv("CANARY_PROMPT", "Echoê°€ ê¹¨ì–´ìˆë‹¤ë¥¼ 10ì ë‚´ë¡œ.")
        model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

        _safe_err(f"[canary] Model: {model}\n")
        _safe_err(f"[canary] Prompt: {prompt}\n")

        # ë…¼-ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ (ê°€ì¥ ë‹¨ìˆœ)
        t0 = time.time()
        resp = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=50,
        )
        t1 = time.time()

        text = resp.choices[0].message.content or ""
        duration = t1 - t0

        _safe_out(text)
        _safe_out("\n")

        _safe_err(f"[canary] âœ… Success in {duration:.2f}s\n")

        # ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
        _safe_err("[canary] Testing streaming...\n")
        t2 = time.time()
        first_token = None

        stream = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": "Say hello in Korean"}],
            temperature=0.5,
            stream=True,
            max_tokens=20,
        )

        _safe_err("[stream] ")
        for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                if first_token is None:
                    first_token = time.time()
                    _safe_err(f"(TTI={first_token-t2:.2f}s) ")
                _safe_out(chunk.choices[0].delta.content)

        _safe_out("\n")
        _safe_err(f"[canary] âœ… Streaming works\n")
        return 0

    except Exception as e:
        _safe_err(f"[canary-err] {e}\n")
        return 1


if __name__ == "__main__":
    sys.exit(main())
