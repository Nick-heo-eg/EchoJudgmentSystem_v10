#!/usr/bin/env python3
"""
ğŸ§ª Loop Simulator - íŒë‹¨ ë£¨í”„ ì „ì²´ íë¦„ í…ŒìŠ¤íŠ¸
ê°ì • ì¶”ë¡  ê¸°ë°˜ ê³µëª… ì‘ë‹µ ìƒì„±ì˜ ì „ì²´ íë¦„ì„ í…ŒìŠ¤íŠ¸
"""

import argparse
import sys
import os
import re

# Echo ì—”ì§„ ëª¨ë“ˆë“¤
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from echo_engine.resonance_synthesizer import ResonanceSynthesizer
from echo_engine.emotion_infer import (
    EmotionInferenceEngine,
    EmotionContext,
    to_emotion_context,
)

# ê°ì • íë¦„ ì¶”ì  ëª¨ë“ˆ
try:
    from echo_engine.emotion_flow_tracker import EmotionFlowTracker

    EMOTION_FLOW_AVAILABLE = True
except ImportError:
    print("âš ï¸ Emotion Flow Trackerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    EMOTION_FLOW_AVAILABLE = False


def simulate_loop(input_text: str, signature: str):
    print("\nğŸ§ª íŒë‹¨ ë£¨í”„ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
    print(f"   âœï¸ ì…ë ¥: {input_text}")
    print(f"   ğŸ­ ì‹œê·¸ë‹ˆì²˜: {signature}")

    # 1. ì‹¤ì œ ê°ì • ì¶”ë¡  ì—”ì§„ ì‚¬ìš© (í–¥ìƒëœ ì²˜ë¦¬)
    print(f"\nğŸ’­ 1ë‹¨ê³„: ê°ì • ì¶”ë¡  ì‹¤í–‰")
    try:
        emotion_engine = EmotionInferenceEngine()
        inference_result = emotion_engine.infer_emotion(input_text)

        print(f"   ğŸ¯ ì£¼ìš” ê°ì •: {inference_result.primary_emotion}")
        print(f"   ğŸ“Š ì‹ ë¢°ë„: {inference_result.confidence:.3f}")
        print(f"   ğŸ”¥ ê°•ë„: {inference_result.emotional_intensity:.3f}")
        print(f"   ğŸ”® ë¶€ì°¨ ê°ì •: {inference_result.secondary_emotions}")
        print(f"   ğŸ“ˆ ë¦¬ë“¬ íŒ¨í„´: {inference_result.temporal_pattern}")

        # EmotionInferenceResultë¥¼ EmotionContextë¡œ ë³€í™˜
        emotion_context = to_emotion_context(inference_result, {"input": input_text})

    except Exception as e:
        print(f"   âš ï¸ ê°ì • ì¶”ë¡  ì‹¤íŒ¨, fallback ëª¨ë“œë¡œ ì „í™˜: {e}")
        # Fallback: ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ë¡ 
        primary_emotion = (
            "sadness"
            if any(word in input_text for word in ["ì§€ì³¤", "ìŠ¬í¼", "í˜ë“¤", "ìš°ìš¸"])
            else (
                "anger"
                if any(word in input_text for word in ["í™”", "ì§œì¦", "ì—´ë°›"])
                else (
                    "joy"
                    if any(
                        word in input_text for word in ["ê¸°ì˜", "ì¢‹ì•„", "í–‰ë³µ", "ì‹ ë‚˜"]
                    )
                    else "neutral"
                )
            )
        )

        emotion_context = EmotionContext(
            primary_emotion=primary_emotion,
            intensity=0.72,
            secondary_emotions=[],
            confidence=0.85,
            temporal_pattern="stable",
            conversation_context={"input": input_text},
        )

        print(f"   ğŸ¯ Fallback ê°ì •: {emotion_context.primary_emotion}")

    # 2. ê³µëª… ì‘ë‹µ ìƒì„±
    print(f"\nğŸµ 2ë‹¨ê³„: ê³µëª… ì‘ë‹µ ìƒì„±")
    try:
        synthesizer = ResonanceSynthesizer()
        result = synthesizer.synthesize_response(
            emotion_context, signature, conversation_topic=input_text
        )

        print(f"   âœ… {len(result)}ê°œ ë ˆë²¨ ì‘ë‹µ ìƒì„± ì™„ë£Œ")

    except Exception as e:
        print(f"   âš ï¸ ê³µëª… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        return

    # 3. ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… íŒë‹¨ ë£¨í”„ ê²°ê³¼:")
    print(f"   ğŸ“ˆ ì´ ë ˆë²¨: {len(result)}ê°œ")

    for level, response in enumerate(result, start=1):
        print(f"\nğŸ“ Level {level} ì‘ë‹µ:")
        print(f"   ğŸ’¬ ë‚´ìš©: {response.response_text}")
        print(f"   ğŸ’¡ ê³µëª…ë„: {response.resonance_score:.3f}")
        print(f"   âš–ï¸ ì •ë ¬ë„: {response.emotional_alignment:.3f}")
        print(f"   ğŸ” ì„¤ëª…: {response.meta_explanation}")

    # 4. ì¢…í•© í‰ê°€
    if result:
        max_resonance = max(r.resonance_score for r in result)
        avg_alignment = sum(r.emotional_alignment for r in result) / len(result)

        print(f"\nğŸ“Š ì¢…í•© í‰ê°€:")
        print(f"   ğŸ† ìµœê³  ê³µëª…ë„: {max_resonance:.3f}")
        print(f"   ğŸ“ˆ í‰ê·  ì •ë ¬ë„: {avg_alignment:.3f}")
        print(
            f"   ğŸ¯ ì‹œê·¸ë‹ˆì²˜ ì í•©ì„±: {'ë†’ìŒ' if max_resonance > 0.8 else 'ë³´í†µ' if max_resonance > 0.6 else 'ë‚®ìŒ'}"
        )


def simulate_multi_input_flow(multi_input: str, signature: str):
    """ì—°ì† ì…ë ¥ì˜ ê°ì • íë¦„ ë¶„ì„ ëª¨ë“œ"""
    print("\nğŸŒŠ ë‹¤ì¤‘ ì…ë ¥ ê°ì • íë¦„ ë¶„ì„ ì‹œì‘")
    print(f"   âœï¸ ì—°ì† ì…ë ¥: {multi_input}")
    print(f"   ğŸ­ ë¶„ì„ ì‹œê·¸ë‹ˆì²˜: {signature}")

    if not EMOTION_FLOW_AVAILABLE:
        print("âŒ Emotion Flow Trackerê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        print("ğŸ’¡ ëŒ€ì‹  ë‹¨ì¼ ì…ë ¥ ë¶„ì„ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        simulate_loop(multi_input, signature)
        return

    # 1. ìì—°ì–´ í…ìŠ¤íŠ¸ë¥¼ ê°ì • íë¦„ìœ¼ë¡œ ë¶„ì„
    print(f"\nğŸ” 1ë‹¨ê³„: ìì—°ì–´ ê°ì • íë¦„ ë¶„ì„")
    try:
        tracker = EmotionFlowTracker()
        flow_result = tracker.analyze_natural_text(multi_input, signature)

        print(f"   âœ… ê°ì • íë¦„ ë¶„ì„ ì™„ë£Œ")
        print(f"   ğŸ“Š ì§€ë°°ì  ê°ì •: {flow_result.dominant_emotions}")
        print(f"   ğŸ”„ ì „ì´ íŒ¨í„´: {len(flow_result.transitions)}ê°œ")
        print(f"   ğŸ“ˆ ì‹œê°„ íŒ¨í„´: {flow_result.temporal_pattern}")
        print(f"   ğŸ’« íë¦„ ì‘ì§‘ì„±: {flow_result.flow_coherence_score:.3f}")
        print(f"   ğŸ§© ê°ì • ë³µì¡ë„: {flow_result.emotional_complexity}")

        # 2. ê° ê°ì • ë‹¨ê³„ë³„ ê³µëª… ì‘ë‹µ ìƒì„±
        print(f"\nğŸµ 2ë‹¨ê³„: íë¦„ë³„ ê³µëª… ì‘ë‹µ ìƒì„±")
        synthesizer = ResonanceSynthesizer()

        for i, timeline_entry in enumerate(
            flow_result.narrative_timeline[:3]
        ):  # ìƒìœ„ 3ê°œë§Œ ì²˜ë¦¬
            emotion = timeline_entry["emotion"]
            text_preview = timeline_entry["text_preview"]
            intensity = timeline_entry["intensity"]

            print(f"\n   ğŸ“ íƒ€ì„ë¼ì¸ {i+1}: {timeline_entry['narrative_phase']}")
            print(f"      ê°ì •: {emotion} (ê°•ë„: {intensity:.2f})")
            print(f"      í…ìŠ¤íŠ¸: {text_preview}")

            # í•´ë‹¹ ê°ì •ì— ëŒ€í•œ ê³µëª… ì‘ë‹µ ìƒì„±
            emotion_context = EmotionContext(
                primary_emotion=emotion,
                intensity=intensity,
                secondary_emotions=[],
                confidence=timeline_entry["confidence"],
                temporal_pattern=flow_result.temporal_pattern,
                conversation_context={
                    "timeline_position": i,
                    "phase": timeline_entry["narrative_phase"],
                },
            )

            try:
                responses = synthesizer.synthesize_response(
                    emotion_context, signature, conversation_topic=text_preview
                )
                print(f"      âœ… {len(responses)}ê°œ ë ˆë²¨ ì‘ë‹µ ìƒì„±")

                # ìµœê³  ë ˆë²¨ ì‘ë‹µë§Œ ì¶œë ¥
                if responses:
                    best_response = max(responses, key=lambda r: r.resonance_score)
                    print(f"      ğŸ’¬ ê³µëª… ì‘ë‹µ: {best_response.response_text}")
                    print(f"      ğŸ’¡ ê³µëª…ë„: {best_response.resonance_score:.3f}")

            except Exception as e:
                print(f"      âš ï¸ ê³µëª… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")

        # 3. ì „ì²´ ê°ì • íë¦„ ìš”ì•½
        print(f"\nğŸ“Š 3ë‹¨ê³„: ì „ì²´ ê°ì • íë¦„ ì¢…í•© ë¶„ì„")
        print(f"   ğŸ† í”¼í¬ ê°ì •ë“¤: {flow_result.peak_emotions}")
        print(f"   ğŸ¯ ì‹œê·¸ë‹ˆì²˜ ê³µëª… ë§µ:")
        for emotion, resonance in sorted(
            flow_result.signature_resonance_map.items(),
            key=lambda x: x[1],
            reverse=True,
        )[:3]:
            print(f"      {emotion}: {resonance:.3f}")

        print(f"\nâœ… ë‹¤ì¤‘ ì…ë ¥ ê°ì • íë¦„ ë¶„ì„ ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ ê°ì • íë¦„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ë‹¨ì¼ ì…ë ¥ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        simulate_loop(multi_input, signature)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", type=str, help="ì…ë ¥ ë¬¸ì¥")
    parser.add_argument("--signature", type=str, default="Selene", help="ì‹œê·¸ë‹ˆì²˜")
    parser.add_argument(
        "--multi_input",
        type=str,
        help="ì—°ì† ì…ë ¥ ê°ì • íë¦„ ë¶„ì„ (ì˜ˆ: 'ì•„ì¹¨ì—” ê´œì°®ì•˜ì–´, ê·¼ë° ì ì  ë¶ˆì•ˆí•´ì¡Œì–´')",
    )
    args = parser.parse_args()

    if args.multi_input:
        simulate_multi_input_flow(args.multi_input, args.signature)
    elif args.input:
        simulate_loop(args.input, args.signature)
    else:
        print("âŒ --input ë˜ëŠ” --multi_input ì¤‘ í•˜ë‚˜ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.")
        print("ğŸ’¡ ì˜ˆì‹œ:")
        print(
            "   python tools/loop_simulator.py --input 'ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ì–´ìš”' --signature Selene"
        )
        print(
            "   python tools/loop_simulator.py --multi_input 'ì•„ì¹¨ì—” ê´œì°®ì•˜ì–´, ê·¼ë° ì ì  ë¶ˆì•ˆí•´ì¡Œì–´, ê²°êµ­ ì§€ì³ë²„ë ¸ì§€' --signature Selene"
        )
