"""
EchoJudgmentSystem ê³ ê¸‰ ê¸°ëŠ¥ ëª¨ë“ˆ
- ë°°ì¹˜ ì²˜ë¦¬
- íˆìŠ¤í† ë¦¬ ë¶„ì„
- ê°ì • íŠ¸ë Œë“œ ë¶„ì„
- ìë™ í•™ìŠµ ê¸°ëŠ¥
"""

import json
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import numpy as np
from dataclasses import dataclass
import asyncio


@dataclass
class BatchRequest:
    """ë°°ì¹˜ ì²˜ë¦¬ ìš”ì²­"""

    requests: List[str]
    batch_id: str
    timestamp: datetime


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""

    user_pattern: Dict
    emotional_trend: Dict
    strategy_effectiveness: Dict
    recommendations: List[str]


class AdvancedAnalyzer:
    """ê³ ê¸‰ ë¶„ì„ ì—”ì§„"""

    def __init__(self, log_path: str = "npi_log.jsonl"):
        self.log_path = log_path
        self.history_days = 30

    def load_history(self, days: int = None) -> pd.DataFrame:
        """íˆìŠ¤í† ë¦¬ ë°ì´í„° ë¡œë“œ"""
        if days is None:
            days = self.history_days

        try:
            logs = []
            with open(self.log_path, "r", encoding="utf-8") as f:
                for line in f:
                    if line.strip():
                        logs.append(json.loads(line))

            if not logs:
                return pd.DataFrame()

            df = pd.DataFrame(logs)
            df["timestamp"] = pd.to_datetime(df["timestamp"])

            # ì§€ì •ëœ ê¸°ê°„ ë‚´ ë°ì´í„°ë§Œ í•„í„°ë§
            cutoff_date = datetime.now() - timedelta(days=days)
            df = df[df["timestamp"] >= cutoff_date]

            return df

        except Exception as e:
            print(f"íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def analyze_user_patterns(self, df: pd.DataFrame) -> Dict:
        """ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„"""
        if df.empty:
            return {"error": "ë°ì´í„° ì—†ìŒ"}

        # NPI ì ìˆ˜ ë¶„í•´
        npi_scores = (
            pd.json_normalize(df["npi_score"])
            if "npi_score" in df.columns
            else pd.DataFrame()
        )

        patterns = {
            "ì´_ìš”ì²­ìˆ˜": len(df),
            "í‰ê· _NPIì ìˆ˜": (
                npi_scores.get("total", pd.Series()).mean()
                if not npi_scores.empty
                else 0
            ),
            "ì£¼ìš”_ì „ëµ": (
                df["strategy"].mode()[0]
                if "strategy" in df.columns and not df["strategy"].mode().empty
                else "N/A"
            ),
            "ê°ì •_ë¶„í¬": {},
            "ì‹œê°„ëŒ€_ë¶„í¬": {},
            "NPI_êµ¬ì„±ìš”ì†Œ_í‰ê· ": {},
        }

        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        if "timestamp" in df.columns:
            df["hour"] = df["timestamp"].dt.hour
            hourly_dist = df["hour"].value_counts().sort_index()
            patterns["ì‹œê°„ëŒ€_ë¶„í¬"] = hourly_dist.to_dict()

        # NPI êµ¬ì„±ìš”ì†Œ í‰ê· 
        if not npi_scores.empty:
            for col in [
                "structure",
                "emotion",
                "rhythm",
                "context",
                "strategy_tone",
                "silence",
            ]:
                if col in npi_scores.columns:
                    patterns["NPI_êµ¬ì„±ìš”ì†Œ_í‰ê· "][col] = float(npi_scores[col].mean())

        return patterns

    def analyze_emotional_trends(self, df: pd.DataFrame) -> Dict:
        """ê°ì • íŠ¸ë Œë“œ ë¶„ì„"""
        if df.empty:
            return {"error": "ë°ì´í„° ì—†ìŒ"}

        # Claude ê°ì • ë°ì´í„° ë¶„ì„ (claude_summaryì—ì„œ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ)
        emotion_keywords = {
            "joy": ["ê¸°ì˜", "í–‰ë³µ", "ì¢‹", "ìµœê³ ", "ì„±ê³µ", "ì¶•í•˜"],
            "sadness": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ", "ì‹¤ë§", "í¬ê¸°"],
            "anger": ["í™”", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "ì–µìš¸", "ë¶ˆë§Œ"],
            "fear": ["ë¬´ì„œ", "ê±±ì •", "ë¶ˆì•ˆ", "ë‘ë ¤", "ê¸´ì¥", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "neutral": ["ê·¸ëƒ¥", "ë³´í†µ", "í‰ìƒì‹œ", "ì¼ë°˜ì "],
        }

        emotion_trends = {
            "daily_emotions": {},
            "emotion_distribution": {},
            "emotional_volatility": 0.0,
            "trend_direction": "stable",
        }

        # ê°ì • í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        if "claude_summary" in df.columns:
            emotion_counts = {emotion: 0 for emotion in emotion_keywords.keys()}

            for text in df["claude_summary"].fillna(""):
                text_lower = text.lower()
                for emotion, keywords in emotion_keywords.items():
                    if any(keyword in text_lower for keyword in keywords):
                        emotion_counts[emotion] += 1
                        break

            emotion_trends["emotion_distribution"] = emotion_counts

        return emotion_trends

    def analyze_strategy_effectiveness(self, df: pd.DataFrame) -> Dict:
        """ì „ëµ íš¨ê³¼ì„± ë¶„ì„"""
        if df.empty:
            return {"error": "ë°ì´í„° ì—†ìŒ"}

        strategy_analysis = {
            "strategy_performance": {},
            "best_strategy": None,
            "strategy_trends": {},
            "recommendations": [],
        }

        if "strategy" in df.columns:
            # ì „ëµë³„ ì„±ê³¼ ë¶„ì„
            npi_scores = (
                pd.json_normalize(df["npi_score"])
                if "npi_score" in df.columns
                else pd.DataFrame()
            )

            if not npi_scores.empty and "total" in npi_scores.columns:
                df["npi_total"] = npi_scores["total"]
                strategy_performance = (
                    df.groupby("strategy")["npi_total"].agg(["mean", "count"]).to_dict()
                )
                strategy_analysis["strategy_performance"] = strategy_performance

                # ìµœê³  ì„±ê³¼ ì „ëµ ì°¾ê¸°
                best_strategy = df.groupby("strategy")["npi_total"].mean().idxmax()
                strategy_analysis["best_strategy"] = best_strategy

                # ê¶Œì¥ì‚¬í•­ ìƒì„±
                recommendations = []
                for strategy, stats in strategy_performance["mean"].items():
                    if stats > 0.75:
                        recommendations.append(
                            f"{strategy} ì „ëµì€ ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤ (í‰ê· : {stats:.3f})"
                        )
                    elif stats < 0.5:
                        recommendations.append(
                            f"{strategy} ì „ëµ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ (í‰ê· : {stats:.3f})"
                        )

                strategy_analysis["recommendations"] = recommendations

        return strategy_analysis

    def generate_comprehensive_analysis(self, days: int = 7) -> AnalysisResult:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        df = self.load_history(days)

        user_pattern = self.analyze_user_patterns(df)
        emotional_trend = self.analyze_emotional_trends(df)
        strategy_effectiveness = self.analyze_strategy_effectiveness(df)

        # ì¢…í•© ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []

        # NPI ì ìˆ˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        avg_npi = user_pattern.get("í‰ê· _NPIì ìˆ˜", 0)
        if avg_npi > 0.75:
            recommendations.append(
                "ë†’ì€ ëˆˆì¹˜ ê°ë„ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ë” ì§ê´€ì ì¸ ì ‘ê·¼ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        elif avg_npi < 0.5:
            recommendations.append(
                "ë‚®ì€ ëˆˆì¹˜ ê°ë„ì…ë‹ˆë‹¤. ë§¥ë½ì„ ë” ì„¸ì‹¬íˆ ê³ ë ¤í•´ë³´ì„¸ìš”."
            )

        # ì „ëµ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if strategy_effectiveness.get("recommendations"):
            recommendations.extend(strategy_effectiveness["recommendations"])

        # ì‹œê°„ëŒ€ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        time_dist = user_pattern.get("ì‹œê°„ëŒ€_ë¶„í¬", {})
        if time_dist:
            peak_hour = max(time_dist, key=time_dist.get)
            recommendations.append(f"ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€ëŠ” {peak_hour}ì‹œì…ë‹ˆë‹¤.")

        return AnalysisResult(
            user_pattern=user_pattern,
            emotional_trend=emotional_trend,
            strategy_effectiveness=strategy_effectiveness,
            recommendations=recommendations,
        )


class BatchProcessor:
    """ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„"""

    def __init__(self):
        self.batch_history = []

    async def process_batch(self, requests: List[str], batch_id: str = None) -> Dict:
        """ë°°ì¹˜ ìš”ì²­ ì²˜ë¦¬"""
        from api.npi import evaluate_npi
        from api.llm_runner import run_claude_judgment
        from api.nunchi_response_engine import generate_response
        from api.log_writer import write_log

        if batch_id is None:
            batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        batch_request = BatchRequest(
            requests=requests, batch_id=batch_id, timestamp=datetime.now()
        )

        results = []

        for i, prompt in enumerate(requests):
            try:
                # ê°œë³„ ì²˜ë¦¬ (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
                npi_score = evaluate_npi(prompt)
                claude_result = run_claude_judgment(prompt)
                claude_str = (
                    claude_result.get("judgment", str(claude_result))
                    if isinstance(claude_result, dict)
                    else str(claude_result)
                )
                response, strategy = generate_response(prompt, npi_score, claude_str)

                # ë¡œê·¸ ê¸°ë¡ (ë°°ì¹˜ ID í¬í•¨)
                write_log(
                    f"[BATCH:{batch_id}] {prompt}",
                    npi_score,
                    strategy,
                    response,
                    claude_str,
                )

                result = {
                    "index": i,
                    "prompt": prompt,
                    "npi_score": npi_score,
                    "claude_result": claude_str,
                    "response": response,
                    "strategy": strategy,
                    "batch_id": batch_id,
                }

                results.append(result)

            except Exception as e:
                results.append(
                    {
                        "index": i,
                        "prompt": prompt,
                        "error": str(e),
                        "batch_id": batch_id,
                    }
                )

        batch_result = {
            "batch_id": batch_id,
            "total_requests": len(requests),
            "successful": len([r for r in results if "error" not in r]),
            "failed": len([r for r in results if "error" in r]),
            "results": results,
            "timestamp": batch_request.timestamp.isoformat(),
        }

        self.batch_history.append(batch_result)

        return batch_result


class AutoLearner:
    """ìë™ í•™ìŠµ ì—”ì§„"""

    def __init__(self):
        self.learning_data = []

    def extract_learning_patterns(self, df: pd.DataFrame) -> Dict:
        """í•™ìŠµ íŒ¨í„´ ì¶”ì¶œ"""
        if df.empty:
            return {}

        patterns = {
            "high_npi_prompts": [],
            "low_npi_prompts": [],
            "successful_strategies": {},
            "common_keywords": [],
        }

        # NPI ì ìˆ˜ ê¸°ë°˜ íŒ¨í„´ ë¶„ì„
        npi_scores = (
            pd.json_normalize(df["npi_score"])
            if "npi_score" in df.columns
            else pd.DataFrame()
        )

        if not npi_scores.empty and "total" in npi_scores.columns:
            df["npi_total"] = npi_scores["total"]

            # ë†’ì€/ë‚®ì€ NPI ì ìˆ˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì§‘
            high_npi = df[df["npi_total"] > 0.75]
            low_npi = df[df["npi_total"] < 0.5]

            patterns["high_npi_prompts"] = high_npi["prompt"].tolist()[:10]
            patterns["low_npi_prompts"] = low_npi["prompt"].tolist()[:10]

            # ì„±ê³µì ì¸ ì „ëµ ë¶„ì„
            strategy_success = df.groupby("strategy")["npi_total"].mean().to_dict()
            patterns["successful_strategies"] = strategy_success

        # í‚¤ì›Œë“œ ë¶„ì„
        all_prompts = " ".join(df["prompt"].astype(str))
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”)
        common_words = ["íšŒì˜", "ì œì•ˆ", "ìŠ¤íŠ¸ë ˆìŠ¤", "ê³ ë¯¼", "ë„ì›€", "ì¡°ì–¸"]
        word_counts = {word: all_prompts.count(word) for word in common_words}
        patterns["common_keywords"] = sorted(
            word_counts.items(), key=lambda x: x[1], reverse=True
        )[:5]

        return patterns

    def generate_learning_report(self) -> Dict:
        """í•™ìŠµ ë³´ê³ ì„œ ìƒì„±"""
        analyzer = AdvancedAnalyzer()
        df = analyzer.load_history(30)  # 30ì¼ ë°ì´í„°

        patterns = self.extract_learning_patterns(df)

        report = {
            "í•™ìŠµê¸°ê°„": "30ì¼",
            "ì´_ë°ì´í„°ìˆ˜": len(df),
            "í•™ìŠµíŒ¨í„´": patterns,
            "ê°œì„ ê¶Œì¥ì‚¬í•­": [
                "ë†’ì€ NPI ì ìˆ˜ í”„ë¡¬í”„íŠ¸ íŒ¨í„´ì„ í™œìš©í•˜ì—¬ ê°ë„ ê°œì„ ",
                "íš¨ê³¼ì ì¸ ì „ëµì„ ìš°ì„ ì ìœ¼ë¡œ í™œìš©",
                "ìì£¼ ì‚¬ìš©ë˜ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ ìµœì í™”",
            ],
            "ìƒì„±ì¼ì‹œ": datetime.now().isoformat(),
        }

        return report


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_analysis(days: int = 7) -> Dict:
    """ë¹ ë¥¸ ë¶„ì„"""
    analyzer = AdvancedAnalyzer()
    return analyzer.generate_comprehensive_analysis(days)


async def batch_process(prompts: List[str]) -> Dict:
    """ë°°ì¹˜ ì²˜ë¦¬"""
    processor = BatchProcessor()
    return await processor.process_batch(prompts)


def learning_report() -> Dict:
    """í•™ìŠµ ë³´ê³ ì„œ"""
    learner = AutoLearner()
    return learner.generate_learning_report()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§  EchoJudgmentSystem ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")

    # ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\n1. ì¢…í•© ë¶„ì„ í…ŒìŠ¤íŠ¸")
    analysis = quick_analysis(7)
    print(f"ë¶„ì„ ê²°ê³¼: {len(analysis.recommendations)}ê°œ ê¶Œì¥ì‚¬í•­")

    # ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\n2. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    test_prompts = ["ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ì•„ìš”", "ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ì‹¬í•´ìš”", "ì¡°ì–¸ì´ í•„ìš”í•´ìš”"]

    batch_result = asyncio.run(batch_process(test_prompts))
    print(
        f"ë°°ì¹˜ ê²°ê³¼: {batch_result['successful']}/{batch_result['total_requests']} ì„±ê³µ"
    )

    # í•™ìŠµ ë³´ê³ ì„œ í…ŒìŠ¤íŠ¸
    print("\n3. í•™ìŠµ ë³´ê³ ì„œ í…ŒìŠ¤íŠ¸")
    report = learning_report()
    print(f"í•™ìŠµ ë³´ê³ ì„œ: {report['ì´_ë°ì´í„°ìˆ˜']}ê°œ ë°ì´í„° ë¶„ì„")

    print("\nâœ… ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
