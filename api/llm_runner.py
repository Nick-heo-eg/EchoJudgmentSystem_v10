"""
Claude íŒë‹¨ê¸° ì—°ë™ ëª¨ë“ˆ - claude_bridge.py ê¸°ë°˜ API í†µí•©
LLM-Free íŒë‹¨ ì‹œìŠ¤í…œ ì§€ì› ì¶”ê°€
ê³µí†µ íŒë‹¨ ë¡œì§ í†µí•© (SharedJudgmentEngine)
"""

import asyncio
import sys
import os
import time

# ìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from echo_engine.claude_bridge import ClaudeBridge, ClaudeJudgmentRequest
from echo_engine.llm_free.llm_free_judge import FallbackJudge, quick_judgment
from echo_engine.shared_judgment_logic import (
    SharedJudgmentEngine,
    JudgmentRequest,
    JudgmentMode,
    get_shared_judgment_engine,
)
from echo_engine.judgment_mode_switcher import (
    JudgmentModeSwitcher,
    SwitchingTrigger,
    get_mode_switcher,
)
import yaml
import os
from meta_log_writer import log_llm_free_judgment


class ClaudeJudgmentRunner:
    """Claude íŒë‹¨ê¸° ì‹¤í–‰ í´ë˜ìŠ¤"""

    def __init__(self, api_mode: str = "mock", judge_mode: str = None):
        self.api_mode = api_mode

        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        self.config = self._load_config()

        # íŒë‹¨ ëª¨ë“œ ì„¤ì • (íŒŒë¼ë¯¸í„° ìš°ì„ , ê·¸ ë‹¤ìŒ ì„¤ì • íŒŒì¼)
        self.judge_mode = judge_mode or self.config.get("judge_mode", "claude")

        # Claude ë¸Œë¦¬ì§€ ì´ˆê¸°í™”
        self.bridge = ClaudeBridge(api_mode=api_mode)

        # LLM-Free íŒë‹¨ê¸° ì´ˆê¸°í™”
        self.fallback_judge = FallbackJudge()

        # ê³µí†µ íŒë‹¨ ì—”ì§„ ì´ˆê¸°í™”
        self.shared_engine = get_shared_judgment_engine()

        # ëª¨ë“œ ì „í™˜ê¸° ì´ˆê¸°í™”
        self.mode_switcher = get_mode_switcher(self.config.get("mode_switcher", {}))

        # í˜„ì¬ ëª¨ë“œ ë™ê¸°í™”
        if self.judge_mode != self.mode_switcher.get_current_mode().value:
            mode_enum = JudgmentMode(self.judge_mode)
            self.mode_switcher.switch_mode(
                mode_enum, SwitchingTrigger.MANUAL, "Initial sync"
            )

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_stats = {
            "total_requests": 0,
            "claude_requests": 0,
            "fallback_requests": 0,
            "hybrid_requests": 0,
            "failed_requests": 0,
        }

    def _load_config(self) -> dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        config_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "config",
            "llm_config.yaml",
        )

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âš ï¸  ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
            return {
                "judge_mode": "claude",
                "confidence_threshold": 0.65,
                "claude_settings": {"api_mode": "mock"},
                "fallback_settings": {"min_confidence": 0.3},
            }
        except Exception as e:
            print(f"âš ï¸  ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {"judge_mode": "claude", "confidence_threshold": 0.65}

    def run_claude_judgment(self, prompt: str, context: str = None) -> dict:
        """
        ì§€ëŠ¥í˜• íŒë‹¨ ì‹¤í–‰ (ìë™ ëª¨ë“œ ì„ íƒ í¬í•¨)

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.performance_stats["total_requests"] += 1

        try:
            # 1. ìë™ ëª¨ë“œ ìµœì í™” ì²´í¬
            judgment_context = self._build_judgment_context(prompt, context)
            auto_switch = self.mode_switcher.auto_switch_mode(judgment_context)

            if auto_switch:
                # ìë™ ì „í™˜ì´ ë°œìƒí•œ ê²½ìš° ëª¨ë“œ ë™ê¸°í™”
                self.judge_mode = self.mode_switcher.get_current_mode().value
                print(f"ğŸ›ï¸ ìë™ ëª¨ë“œ ì „í™˜: {auto_switch.reason}")

            # 2. í˜„ì¬ ëª¨ë“œì— ë”°ë¼ íŒë‹¨ ì‹¤í–‰
            current_mode = self.mode_switcher.get_current_mode()

            if current_mode == JudgmentMode.LLM_FREE:
                self.performance_stats["fallback_requests"] += 1
                result = self._run_fallback_judgment(prompt, context)
            elif current_mode == JudgmentMode.HYBRID:
                self.performance_stats["hybrid_requests"] += 1
                result = self._run_hybrid_judgment(prompt, context)
            else:  # CLAUDE or FIST_ENHANCED
                self.performance_stats["claude_requests"] += 1
                # í´ë°± ì²´ì¸ì´ í™œì„±í™”ëœ ê²½ìš° Claude ì‹¤íŒ¨ ì‹œ fallback ì‚¬ìš©
                if self.config.get("judgment_settings", {}).get(
                    "enable_multimode", False
                ):
                    try:
                        result = self._run_enhanced_claude_judgment(prompt, context)
                    except Exception as e:
                        print(f"âš ï¸  Claude íŒë‹¨ ì‹¤íŒ¨, fallbackìœ¼ë¡œ ì „í™˜: {e}")
                        self.performance_stats["fallback_requests"] += 1
                        result = self._run_fallback_judgment(prompt, context)
                else:
                    # ê³µí†µ ë¡œì§ì´ ê°•í™”ëœ Claude íŒë‹¨ ì‚¬ìš©
                    result = self._run_enhanced_claude_judgment(prompt, context)

            # 3. íŒë‹¨ ê²°ê³¼ë¥¼ ëª¨ë“œ ì „í™˜ê¸°ì— ê¸°ë¡
            self.mode_switcher.record_judgment_result(current_mode, result)

            # 4. ë©”íƒ€ ì •ë³´ ì¶”ê°€
            result["active_mode"] = current_mode.value
            result["auto_switched"] = auto_switch is not None
            if auto_switch:
                result["switch_reason"] = auto_switch.reason

            return result
        except Exception as e:
            self.performance_stats["failed_requests"] += 1
            print(f"âŒ íŒë‹¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ê°„ë‹¨í•œ fallback ì‚¬ìš©
            return self._emergency_fallback(prompt, context)

    def _build_judgment_context(self, prompt: str, context: str = None) -> dict:
        """
        íŒë‹¨ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ëª¨ë“œ ì „í™˜ê¸°ìš©)

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            íŒë‹¨ ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
        """
        # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        text_length = len(prompt) if prompt else 0

        # ë³µì¡ë„ ì¶”ì •
        complexity = "low"
        if text_length > 200 or (context and len(context) > 100):
            complexity = "high"
        elif text_length > 50:
            complexity = "medium"

        # ì»¨í…ìŠ¤íŠ¸ íƒ€ì… ì¶”ì •
        context_type = "general"
        if context:
            context_lower = context.lower()
            if any(
                word in context_lower for word in ["ì—…ë¬´", "íšŒì˜", "ì§ì¥", "í”„ë¡œì íŠ¸"]
            ):
                context_type = "work"
            elif any(
                word in context_lower for word in ["ì¹œêµ¬", "ê°€ì¡±", "ê°œì¸", "ê´€ê³„"]
            ):
                context_type = "personal"
            elif any(
                word in context_lower for word in ["ì°½ì˜", "ì•„ì´ë””ì–´", "í˜ì‹ ", "ìƒˆë¡œìš´"]
            ):
                context_type = "creative"
            elif any(
                word in context_lower for word in ["ë¶„ì„", "ë°ì´í„°", "ë…¼ë¦¬", "ì²´ê³„"]
            ):
                context_type = "analytical"

        # ê¸´ê¸‰ë„ ì¶”ì • (í‚¤ì›Œë“œ ê¸°ë°˜)
        urgency = "normal"
        if prompt:
            prompt_lower = prompt.lower()
            if any(word in prompt_lower for word in ["ê¸´ê¸‰", "ê¸‰í•´", "ë¹¨ë¦¬", "ì¦‰ì‹œ"]):
                urgency = "high"
            elif any(word in prompt_lower for word in ["ì²œì²œíˆ", "ë‚˜ì¤‘ì—", "ì—¬ìœ "]):
                urgency = "low"

        return {
            "text_length": text_length,
            "complexity": complexity,
            "context_type": context_type,
            "urgency": urgency,
            "has_context": bool(context),
            "timestamp": time.time(),
        }

    async def _async_judgment(self, prompt: str, context: str = None) -> dict:
        """ë¹„ë™ê¸° Claude íŒë‹¨ í˜¸ì¶œ"""
        request = ClaudeJudgmentRequest(
            input_text=prompt,
            context=context,
            judgment_type="comprehensive",
            include_emotion=True,
            include_strategy=True,
        )

        response = await self.bridge.request_claude_judgment(request)

        # API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        return {
            "judgment": response.judgment,
            "confidence": response.confidence,
            "reasoning": response.reasoning,
            "emotion_detected": response.emotion_detected,
            "strategy_suggested": response.strategy_suggested,
            "alternatives": response.alternatives or [],
            "processing_time": response.processing_time,
        }

    def _run_fallback_judgment(self, prompt: str, context: str = None) -> dict:
        """
        LLM-Free íŒë‹¨ ì‹¤í–‰

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        input_data = {"text": prompt, "context": context or ""}

        # LLM-Free íŒë‹¨ ì‹¤í–‰
        result = self.fallback_judge.evaluate(input_data)

        # API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        judgment_data = {
            "judgment": result.judgment,
            "confidence": result.confidence,
            "reasoning": " â†’ ".join(result.reasoning_trace),
            "emotion_detected": result.emotion_detected,
            "strategy_suggested": result.strategy_suggested,
            "alternatives": [],  # LLM-Freeì—ì„œëŠ” ëŒ€ì•ˆ ì œê³µ ì•ˆí•¨
            "processing_time": result.processing_time,
            "fallback_used": True,
            "judgment_mode": "fallback",
        }

        # ë©”íƒ€ ë¡œê·¸ ê¸°ë¡
        try:
            log_llm_free_judgment(
                input_text=prompt,
                judgment_data=judgment_data,
                context=context or "",
                meta_info={"runner_mode": "fallback_judgment"},
            )
        except Exception as e:
            print(f"âš ï¸  ë©”íƒ€ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")

        return judgment_data

    def _run_enhanced_claude_judgment(self, prompt: str, context: str = None) -> dict:
        """
        ê³µí†µ ë¡œì§ìœ¼ë¡œ ê°•í™”ëœ Claude íŒë‹¨ ì‹¤í–‰
        ìˆœì„œ: (1) ê°ì • ì¶”ë¡  â†’ (2) ì „ëµ ì¶”ì²œ â†’ (3) íŒë‹¨ ë¼ë²¨ë§ â†’ (4) Claude ì‘ë‹µê³¼ ë³‘í•©

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            ê°•í™”ëœ íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # 1. ê³µí†µ íŒë‹¨ ë¡œì§ìœ¼ë¡œ ì‚¬ì „ ë¶„ì„
            shared_request = JudgmentRequest(
                text=prompt,
                context=context,
                judgment_mode=JudgmentMode.CLAUDE,
                include_emotion=True,
                include_strategy=True,
                include_context=True,
                include_alternatives=False,
            )

            shared_result = self.shared_engine.process_judgment(shared_request)

            # 2. Claude íŒë‹¨ ì‹¤í–‰
            claude_result = asyncio.run(self._async_judgment(prompt, context))

            # 3. ê³µí†µ ë¡œì§ê³¼ Claude ê²°ê³¼ ë³‘í•©
            merged_result = self._merge_judgments(
                shared_result, claude_result, prompt, context
            )

            return merged_result

        except Exception as e:
            print(f"âš ï¸ ê°•í™”ëœ Claude íŒë‹¨ ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ì¼ë°˜ Claude íŒë‹¨ ì‹œë„
            return asyncio.run(self._async_judgment(prompt, context))

    def _run_hybrid_judgment(self, prompt: str, context: str = None) -> dict:
        """
        í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ì‹¤í–‰ (ê³µí†µ ë¡œì§ + Claude ë³‘í•© ìµœì í™”)

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # 1. ê³µí†µ íŒë‹¨ ë¡œì§ìœ¼ë¡œ ì „ì²´ ë¶„ì„
            shared_request = JudgmentRequest(
                text=prompt,
                context=context,
                judgment_mode=JudgmentMode.HYBRID,
                include_emotion=True,
                include_strategy=True,
                include_context=True,
                include_alternatives=True,
            )

            shared_result = self.shared_engine.process_judgment(shared_request)

            # 2. Claude íŒë‹¨ ë³‘ë ¬ ì‹¤í–‰ (ì„ íƒì )
            claude_result = None
            if shared_result.confidence < 0.7:  # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ Claude ë³´ê°•
                try:
                    claude_result = asyncio.run(self._async_judgment(prompt, context))
                except Exception as e:
                    print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œì—ì„œ Claude íŒë‹¨ ì‹¤íŒ¨: {e}")

            # 3. ê²°ê³¼ ë³‘í•© ë° ìµœì í™”
            if claude_result:
                merged_result = self._merge_judgments(
                    shared_result, claude_result, prompt, context, mode="hybrid"
                )
            else:
                # ê³µí†µ ë¡œì§ ê²°ê³¼ë¥¼ API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                merged_result = self._convert_shared_to_api_format(
                    shared_result, prompt, context
                )

            merged_result["judgment_mode"] = "hybrid"
            merged_result["hybrid_confidence"] = shared_result.confidence

            return merged_result

        except Exception as e:
            print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ê³µí†µ ë¡œì§ë§Œ ì‚¬ìš©
            return self._run_fallback_judgment(prompt, context)

    def _merge_judgments(
        self,
        shared_result,
        claude_result: dict,
        prompt: str,
        context: str,
        mode: str = "enhanced",
    ) -> dict:
        """
        ê³µí†µ ë¡œì§ ê²°ê³¼ì™€ Claude ê²°ê³¼ ë³‘í•©

        Args:
            shared_result: SharedJudgmentResult ê°ì²´
            claude_result: Claude íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            prompt: ì›ë³¸ í”„ë¡¬í”„íŠ¸
            context: ë¬¸ë§¥ ì •ë³´
            mode: ë³‘í•© ëª¨ë“œ ("enhanced" ë˜ëŠ” "hybrid")

        Returns:
            ë³‘í•©ëœ íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ê°ì • ë¶„ì„ ë³‘í•© (ê³µí†µ ë¡œì§ ìš°ì„ , Claude ë³´ì¡°)
            final_emotion = shared_result.emotion_detected
            if claude_result.get("emotion_detected") and shared_result.confidence < 0.6:
                # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ Claude ê°ì • ë¶„ì„ ì°¸ê³ 
                claude_emotion = claude_result.get("emotion_detected")
                if claude_emotion != "neutral":
                    final_emotion = f"{shared_result.emotion_detected}+{claude_emotion}"

            # ì „ëµ ì¶”ì²œ ë³‘í•©
            final_strategy = shared_result.strategy_suggested
            if (
                claude_result.get("strategy_suggested")
                and shared_result.confidence < 0.6
            ):
                claude_strategy = claude_result.get("strategy_suggested")
                if claude_strategy and claude_strategy != "balanced":
                    final_strategy = (
                        f"{shared_result.strategy_suggested}+{claude_strategy}"
                    )

            # íŒë‹¨ ë‚´ìš© ë³‘í•© (Claude ì£¼, ê³µí†µ ë¡œì§ ë³´ê°•)
            base_judgment = claude_result.get("judgment", shared_result.judgment)

            # ê³µí†µ ë¡œì§ì˜ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
            if (
                shared_result.confidence > 0.5
                and shared_result.judgment != base_judgment
            ):
                enhanced_judgment = (
                    f"{base_judgment}\n\n[ë³´ì¡° ë¶„ì„] {shared_result.judgment}"
                )
            else:
                enhanced_judgment = base_judgment

            # ì‹ ë¢°ë„ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            claude_confidence = claude_result.get("confidence", 0.5)
            if mode == "hybrid":
                # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œì—ì„œëŠ” ê³µí†µ ë¡œì§ ê°€ì¤‘ì¹˜ ë†’ì„
                final_confidence = (
                    shared_result.confidence * 0.7 + claude_confidence * 0.3
                )
            else:
                # ê°•í™” ëª¨ë“œì—ì„œëŠ” Claude ê°€ì¤‘ì¹˜ ë†’ì„
                final_confidence = (
                    shared_result.confidence * 0.4 + claude_confidence * 0.6
                )

            # ì¶”ë¡  ê³¼ì • ë³‘í•©
            reasoning_parts = []
            reasoning_parts.extend(
                shared_result.reasoning_trace[-3:]
            )  # ê³µí†µ ë¡œì§ ë§ˆì§€ë§‰ 3ë‹¨ê³„
            if claude_result.get("reasoning"):
                reasoning_parts.append(f"Claude ë¶„ì„: {claude_result['reasoning']}")

            # ëŒ€ì•ˆ ì œì•ˆ ë³‘í•©
            alternatives = list(shared_result.alternatives)
            if claude_result.get("alternatives"):
                alternatives.extend(claude_result["alternatives"])
            alternatives = list(dict.fromkeys(alternatives))[:3]  # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 3ê°œ

            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            merged_result = {
                "judgment": enhanced_judgment,
                "confidence": round(final_confidence, 3),
                "reasoning": " â†’ ".join(reasoning_parts),
                "emotion_detected": final_emotion,
                "strategy_suggested": final_strategy,
                "alternatives": alternatives,
                "processing_time": shared_result.processing_time
                + claude_result.get("processing_time", 0),
                "context_detected": shared_result.context_detected,
                "keywords_extracted": shared_result.keywords_extracted,
                "patterns_matched": shared_result.patterns_matched,
                # ë©”íƒ€ ì •ë³´
                "merged_mode": mode,
                "shared_confidence": shared_result.confidence,
                "claude_confidence": claude_confidence,
                "shared_judgment": shared_result.judgment,
                "claude_judgment": claude_result.get("judgment", ""),
                "stage_timings": shared_result.stage_timings,
            }

            return merged_result

        except Exception as e:
            print(f"âš ï¸ íŒë‹¨ ë³‘í•© ì‹¤íŒ¨: {e}")
            # ë³‘í•© ì‹¤íŒ¨ ì‹œ Claude ê²°ê³¼ ë°˜í™˜
            return claude_result

    def _convert_shared_to_api_format(
        self, shared_result, prompt: str, context: str
    ) -> dict:
        """
        SharedJudgmentResultë¥¼ API í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            shared_result: SharedJudgmentResult ê°ì²´
            prompt: ì›ë³¸ í”„ë¡¬í”„íŠ¸
            context: ë¬¸ë§¥ ì •ë³´

        Returns:
            API í˜•ì‹ íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "judgment": shared_result.judgment,
            "confidence": shared_result.confidence,
            "reasoning": " â†’ ".join(shared_result.reasoning_trace),
            "emotion_detected": shared_result.emotion_detected,
            "strategy_suggested": shared_result.strategy_suggested,
            "alternatives": shared_result.alternatives,
            "processing_time": shared_result.processing_time,
            "context_detected": shared_result.context_detected,
            "keywords_extracted": shared_result.keywords_extracted,
            "patterns_matched": shared_result.patterns_matched,
            "judgment_mode": shared_result.judgment_mode.value,
            "stage_timings": shared_result.stage_timings,
            "shared_logic_only": True,
        }

    def _emergency_fallback(self, prompt: str, context: str = None) -> dict:
        """
        ë¹„ìƒ í´ë°± (ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ)

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            ê¸°ë³¸ íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "judgment": "ì…ë ¥ì„ ë¶„ì„í–ˆì§€ë§Œ ëª…í™•í•œ íŒë‹¨ì„ ë‚´ë¦¬ê¸° ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.",
            "confidence": 0.1,
            "reasoning": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ",
            "emotion_detected": "neutral",
            "strategy_suggested": "cautious",
            "alternatives": [],
            "processing_time": 0.001,
            "fallback_used": True,
            "emergency_mode": True,
        }

    def get_performance_stats(self) -> dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        total = max(self.performance_stats["total_requests"], 1)

        # ê¸°ë³¸ ì„±ëŠ¥ í†µê³„
        basic_stats = {
            **self.performance_stats,
            "claude_ratio": self.performance_stats["claude_requests"] / total,
            "fallback_ratio": self.performance_stats["fallback_requests"] / total,
            "hybrid_ratio": self.performance_stats["hybrid_requests"] / total,
            "failure_rate": self.performance_stats["failed_requests"] / total,
            "judge_mode": self.judge_mode,
            "shared_engine_stats": (
                self.shared_engine.get_performance_stats()
                if hasattr(self.shared_engine, "get_performance_stats")
                else {}
            ),
        }

        # ëª¨ë“œ ì „í™˜ê¸° í†µê³„ ì¶”ê°€
        if hasattr(self, "mode_switcher") and self.mode_switcher:
            switching_stats = self.mode_switcher.get_switching_stats()
            basic_stats["mode_switcher"] = switching_stats
            basic_stats["current_active_mode"] = switching_stats["current_mode"]
            basic_stats["total_mode_switches"] = switching_stats["total_switches"]

        return basic_stats

    def manual_switch_mode(
        self, target_mode: str, reason: str = "Manual override"
    ) -> bool:
        """
        ìˆ˜ë™ ëª¨ë“œ ì „í™˜

        Args:
            target_mode: ëŒ€ìƒ ëª¨ë“œ ("claude", "llm_free", "hybrid")
            reason: ì „í™˜ ì´ìœ 

        Returns:
            ì „í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            mode_enum = JudgmentMode(target_mode)
            success = self.mode_switcher.switch_mode(
                mode_enum, SwitchingTrigger.MANUAL, reason
            )

            if success:
                self.judge_mode = target_mode
                print(f"ğŸ›ï¸ ìˆ˜ë™ ëª¨ë“œ ì „í™˜ ì™„ë£Œ: {target_mode} ({reason})")

            return success

        except Exception as e:
            print(f"âŒ ìˆ˜ë™ ëª¨ë“œ ì „í™˜ ì‹¤íŒ¨: {e}")
            return False

    def get_mode_recommendation(self, prompt: str, context: str = None) -> dict:
        """
        í˜„ì¬ ìƒí™©ì— ëŒ€í•œ ëª¨ë“œ ì¶”ì²œ

        Args:
            prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ë§¥ë½ ì •ë³´

        Returns:
            ì¶”ì²œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        judgment_context = self._build_judgment_context(prompt, context)
        recommended_mode, score, reason = self.mode_switcher.get_mode_recommendation(
            judgment_context
        )

        return {
            "recommended_mode": recommended_mode.value,
            "confidence_score": score,
            "reason": reason,
            "current_mode": self.mode_switcher.get_current_mode().value,
            "should_switch": recommended_mode != self.mode_switcher.get_current_mode(),
            "context_analysis": judgment_context,
        }


# ìƒˆë¡œìš´ í†µí•© í•¨ìˆ˜ ì¶”ê°€
def generate_response(input_data: dict) -> dict:
    """
    í†µí•© ì‘ë‹µ ìƒì„± í•¨ìˆ˜

    Args:
        input_data: ì…ë ¥ ë°ì´í„° (text, context, judge_mode ë“±)

    Returns:
        íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    judge_mode = input_data.get("judge_mode", "claude")
    text = input_data.get("text", "")
    context = input_data.get("context", "")

    if judge_mode == "fallback":
        # quick_judgment ì‚¬ìš©
        result = quick_judgment(text, context)
        judgment_data = {
            "judgment": result.judgment,
            "confidence": result.confidence,
            "reasoning": " â†’ ".join(result.reasoning_trace),
            "emotion_detected": result.emotion_detected,
            "strategy_suggested": result.strategy_suggested,
            "alternatives": [],
            "processing_time": result.processing_time,
            "fallback_used": True,
            "judgment_mode": "fallback",
        }

        # ë©”íƒ€ ë¡œê·¸ ê¸°ë¡
        try:
            log_llm_free_judgment(
                input_text=text,
                judgment_data=judgment_data,
                context=context,
                meta_info={"runner_mode": "generate_response"},
            )
        except Exception as e:
            print(f"âš ï¸  ë©”íƒ€ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")

        return judgment_data
    else:
        # ê¸°ì¡´ Claude íŒë‹¨ ì‚¬ìš©
        runner = get_claude_runner(judge_mode=judge_mode)
        return runner.run_claude_judgment(text, context)


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (API ì„±ëŠ¥ ìµœì í™”)
_claude_runner = None


def get_claude_runner(
    api_mode: str = "mock", judge_mode: str = "claude"
) -> ClaudeJudgmentRunner:
    """íŒë‹¨ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global _claude_runner
    if _claude_runner is None:
        _claude_runner = ClaudeJudgmentRunner(api_mode=api_mode, judge_mode=judge_mode)
    return _claude_runner


def run_claude_judgment(
    prompt: str, context: str = None, judge_mode: str = "claude"
) -> dict:
    """
    íŒë‹¨ í•¨ìˆ˜ (Claude, LLM-Free, Hybrid)

    Args:
        prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
        context: ì¶”ê°€ ë§¥ë½ ì •ë³´
        judge_mode: íŒë‹¨ ëª¨ë“œ ("claude", "fallback", "hybrid")

    Returns:
        íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    runner = get_claude_runner(judge_mode=judge_mode)
    return runner.run_claude_judgment(prompt, context)


def run_fallback_judgment(prompt: str, context: str = None) -> dict:
    """
    LLM-Free íŒë‹¨ í•¨ìˆ˜ (í¸ì˜ í•¨ìˆ˜)

    Args:
        prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
        context: ì¶”ê°€ ë§¥ë½ ì •ë³´

    Returns:
        LLM-Free íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    return run_claude_judgment(prompt, context, judge_mode="fallback")


def run_hybrid_judgment(prompt: str, context: str = None) -> dict:
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ í•¨ìˆ˜ (í¸ì˜ í•¨ìˆ˜)

    Args:
        prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
        context: ì¶”ê°€ ë§¥ë½ ì •ë³´

    Returns:
        í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    return run_claude_judgment(prompt, context, judge_mode="hybrid")


def run_enhanced_claude_judgment(prompt: str, context: str = None) -> dict:
    """
    ê°•í™”ëœ Claude íŒë‹¨ í•¨ìˆ˜ (í¸ì˜ í•¨ìˆ˜)
    ê³µí†µ ë¡œì§ìœ¼ë¡œ ê°ì •/ì „ëµ ë¶„ì„ í›„ Claudeì™€ ë³‘í•©

    Args:
        prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
        context: ì¶”ê°€ ë§¥ë½ ì •ë³´

    Returns:
        ê°•í™”ëœ Claude íŒë‹¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    return run_claude_judgment(prompt, context, judge_mode="claude")


def get_current_judgment_mode() -> str:
    """í˜„ì¬ í™œì„± íŒë‹¨ ëª¨ë“œ ë°˜í™˜"""
    runner = get_claude_runner()
    return runner.mode_switcher.get_current_mode().value


def switch_judgment_mode(target_mode: str, reason: str = "Manual switch") -> bool:
    """
    íŒë‹¨ ëª¨ë“œ ìˆ˜ë™ ì „í™˜

    Args:
        target_mode: ëŒ€ìƒ ëª¨ë“œ ("claude", "llm_free", "hybrid")
        reason: ì „í™˜ ì´ìœ 

    Returns:
        ì „í™˜ ì„±ê³µ ì—¬ë¶€
    """
    runner = get_claude_runner()
    return runner.manual_switch_mode(target_mode, reason)


def get_judgment_mode_recommendation(prompt: str, context: str = None) -> dict:
    """
    í˜„ì¬ ìƒí™©ì— ëŒ€í•œ ëª¨ë“œ ì¶”ì²œ

    Args:
        prompt: íŒë‹¨ ìš”ì²­ í…ìŠ¤íŠ¸
        context: ì¶”ê°€ ë§¥ë½ ì •ë³´

    Returns:
        ì¶”ì²œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    runner = get_claude_runner()
    return runner.get_mode_recommendation(prompt, context)


def get_mode_switching_stats() -> dict:
    """ëª¨ë“œ ì „í™˜ í†µê³„ ë°˜í™˜"""
    runner = get_claude_runner()
    return runner.get_performance_stats().get("mode_switcher", {})
